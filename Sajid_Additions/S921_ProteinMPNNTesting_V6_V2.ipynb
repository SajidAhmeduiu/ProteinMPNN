{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S921_ProteinMPNNTesting_V6_V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d9c98b7615384d4f95a9fa447c6d7494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73de468e723c491fa640b34cd5bd36b1",
              "IPY_MODEL_2f7936423ea5498986e8eea89b38f086",
              "IPY_MODEL_25966ccfad5f4dd2a86bc86e6703eebd"
            ],
            "layout": "IPY_MODEL_0587b488ee534c50acf8af6c84371d0b"
          }
        },
        "73de468e723c491fa640b34cd5bd36b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48baf9ed6708474f9d29866c3a3bfb93",
            "placeholder": "​",
            "style": "IPY_MODEL_75b7b720a0484e568d5d4ba226fd4422",
            "value": ""
          }
        },
        "2f7936423ea5498986e8eea89b38f086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdee9d3fe2674bd8b3c74c4a538f86af",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_004ea530fa874a39983695bc15ae7c1e",
            "value": 1
          }
        },
        "25966ccfad5f4dd2a86bc86e6703eebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48a7f5daf7424552b169cb2f3e51ebe8",
            "placeholder": "​",
            "style": "IPY_MODEL_1001b22ebf75495c9a4ed18518403ea1",
            "value": " 921/? [00:00&lt;00:00, 28897.02it/s]"
          }
        },
        "0587b488ee534c50acf8af6c84371d0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48baf9ed6708474f9d29866c3a3bfb93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75b7b720a0484e568d5d4ba226fd4422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdee9d3fe2674bd8b3c74c4a538f86af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "004ea530fa874a39983695bc15ae7c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48a7f5daf7424552b169cb2f3e51ebe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1001b22ebf75495c9a4ed18518403ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9e522f1703c4eccbfd25cd25604e5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80497dadfc524c0baba6c0bda0ee76bd",
              "IPY_MODEL_362ca61cb38a4183aad5871c37389083",
              "IPY_MODEL_20b0c948d8df4c3ba01248dc0742dd0c"
            ],
            "layout": "IPY_MODEL_f9510174c1424b86bd3afc87dc18705c"
          }
        },
        "80497dadfc524c0baba6c0bda0ee76bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3767c583b3e447eb59bd4f982096b9a",
            "placeholder": "​",
            "style": "IPY_MODEL_4a17255037fa41ccb31af94ea9ff23e8",
            "value": "100%"
          }
        },
        "362ca61cb38a4183aad5871c37389083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67f48627f650415c8d240162c5debd0f",
            "max": 195,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38e0bb227eb94805b4f00ac0a450bfee",
            "value": 195
          }
        },
        "20b0c948d8df4c3ba01248dc0742dd0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6130ed66ba5945c4841acd359b3d9711",
            "placeholder": "​",
            "style": "IPY_MODEL_8cde3ac93e504bbf91ba52e66b703c9e",
            "value": " 195/195 [00:06&lt;00:00, 51.57it/s]"
          }
        },
        "f9510174c1424b86bd3afc87dc18705c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3767c583b3e447eb59bd4f982096b9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a17255037fa41ccb31af94ea9ff23e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67f48627f650415c8d240162c5debd0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38e0bb227eb94805b4f00ac0a450bfee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6130ed66ba5945c4841acd359b3d9711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cde3ac93e504bbf91ba52e66b703c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_wbcvVBv0QJ",
        "outputId": "66904e58-bd72-4ed9-a261-9cd28384c50f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import sys \n",
        "installation_path = \"/content/drive/MyDrive/Colab_Installations_V2\"\n",
        "# The path is being modified so that everything installed in the installation path can now be used without re-installing (in this case, I just need biopython)\n",
        "sys.path.insert(0,installation_path)\n",
        "protein_mpnn_path = \"/content/drive/MyDrive/Protein_MPNN_Digging/ProteinMPNN/vanilla_proteinmpnn\"\n",
        "sys.path.insert(0,protein_mpnn_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Protein_MPNN_Digging"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgTOgsabxBaC",
        "outputId": "5aa27c5a-c7ae-4cec-9d84-a675c3e807ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1KHc6SLCFDWefngMT266PS74JQMzqN06K/Protein_MPNN_Digging\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import warnings\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, Subset\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import os\n",
        "from Bio.PDB import *\n",
        "\n",
        "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")"
      ],
      "metadata": {
        "id": "jX5ScMeGyLcy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from Bio.PDB.Polypeptide import *\n",
        "from string import ascii_uppercase"
      ],
      "metadata": {
        "id": "NBjszWagtiYL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = os.path.join(protein_mpnn_path,\"vanilla_model_weights\")\n",
        "model_name = \"v_48_020\"\n",
        "checkpoint_path = os.path.join(weights_path,model_name+\".pt\")"
      ],
      "metadata": {
        "id": "Z6ZHe2IIyy1G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, load and dig into the checkpoint object\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device) "
      ],
      "metadata": {
        "id": "JPE_pX8tzdUO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint[\"num_edges\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DD1hpMLk2-y",
        "outputId": "4a03bf4b-762b-4c6b-9bfc-1c70a1b45bb5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import json, time, os, sys, glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, Subset\n",
        "\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "#A number of functions/classes are adopted from: https://github.com/jingraham/neurips19-graph-protein-design\n",
        "\n",
        "def _scores(S, log_probs, mask):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    criterion = torch.nn.NLLLoss(reduction='none')\n",
        "    loss = criterion(\n",
        "        log_probs.contiguous().view(-1,log_probs.size(-1)),\n",
        "        S.contiguous().view(-1)\n",
        "    ).view(S.size())\n",
        "    # The designable positions have mask set to 1.0, so this function seems to be returning the average score for the designable positions\n",
        "    scores = torch.sum(loss * mask, dim=-1) / torch.sum(mask, dim=-1)\n",
        "    return scores\n",
        "\n",
        "def _S_to_seq(S, mask):\n",
        "    # This is the decoding order\n",
        "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    seq = ''.join([alphabet[c] for c, m in zip(S.tolist(), mask.tolist()) if m > 0])\n",
        "    return seq\n",
        "\n",
        "def parse_PDB_biounits(x, atoms=['N','CA','C'], chain=None):\n",
        "  '''\n",
        "  input:  x = PDB filename\n",
        "          atoms = atoms to extract (optional)\n",
        "  output: (length, atoms, coords=(x,y,z)), sequence\n",
        "  '''\n",
        "\n",
        "  alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "  states = len(alpha_1)\n",
        "  alpha_3 = ['ALA','ARG','ASN','ASP','CYS','GLN','GLU','GLY','HIS','ILE',\n",
        "             'LEU','LYS','MET','PHE','PRO','SER','THR','TRP','TYR','VAL','GAP']\n",
        "  \n",
        "  # The following dictionaries are mapping from one-letter to 0-20 index,\n",
        "  # three-letter to 0-20 index,\n",
        "  # 0-20 index to one-letter,\n",
        "  # one-letter to three-letter, and vice-versa \n",
        "  aa_1_N = {a:n for n,a in enumerate(alpha_1)}\n",
        "  aa_3_N = {a:n for n,a in enumerate(alpha_3)}\n",
        "  aa_N_1 = {n:a for n,a in enumerate(alpha_1)}\n",
        "  aa_1_3 = {a:b for a,b in zip(alpha_1,alpha_3)}\n",
        "  aa_3_1 = {b:a for a,b in zip(alpha_1,alpha_3)}\n",
        "  \n",
        "  def AA_to_N(x):\n",
        "    # [\"ARND\"] -> [[0,1,2,3]]\n",
        "    x = np.array(x);\n",
        "    if x.ndim == 0: x = x[None]\n",
        "    return [[aa_1_N.get(a, states-1) for a in y] for y in x]\n",
        "  \n",
        "  def N_to_AA(x):\n",
        "    # [[0,1,2,3]] -> [\"ARND\"]\n",
        "    x = np.array(x);\n",
        "    if x.ndim == 1: x = x[None]\n",
        "    return [\"\".join([aa_N_1.get(a,\"-\") for a in y]) for y in x]\n",
        "\n",
        "  xyz,seq,min_resn,max_resn = {},{},1e6,-1e6\n",
        "  for line in open(x,\"rb\"):\n",
        "    line = line.decode(\"utf-8\",\"ignore\").rstrip()\n",
        "\n",
        "    if line[:6] == \"HETATM\" and line[17:17+3] == \"MSE\":\n",
        "      line = line.replace(\"HETATM\",\"ATOM  \")\n",
        "      line = line.replace(\"MSE\",\"MET\")\n",
        "\n",
        "    if line[:4] == \"ATOM\":\n",
        "      ch = line[21:22]\n",
        "      # If the input chain is not in the PDB file, which can be the case if the target chains are named differently in the runner script,\n",
        "      # this line will cause the output to have literally no information, this is the case for integer named chains\n",
        "      # that does not mean that this line is not doing its job correctly, this is just a constraint that input chain names and \n",
        "      # chain names in the PDB file have to be congruent\n",
        "      if ch == chain or chain is None:\n",
        "        atom = line[12:12+4].strip()\n",
        "        resi = line[17:17+3]\n",
        "        resn = line[22:22+5].strip()\n",
        "        x,y,z = [float(line[i:(i+8)]) for i in [30,38,46]]\n",
        "\n",
        "        if resn[-1].isalpha(): \n",
        "            resa,resn = resn[-1],int(resn[:-1])-1\n",
        "        else: \n",
        "            resa,resn = \"\",int(resn)-1\n",
        "#         resn = int(resn)\n",
        "        if resn < min_resn: \n",
        "            min_resn = resn\n",
        "        if resn > max_resn: \n",
        "            max_resn = resn\n",
        "        if resn not in xyz: \n",
        "            xyz[resn] = {}\n",
        "        if resa not in xyz[resn]: \n",
        "            xyz[resn][resa] = {}\n",
        "        if resn not in seq: \n",
        "            seq[resn] = {}\n",
        "        if resa not in seq[resn]: \n",
        "            seq[resn][resa] = resi\n",
        "\n",
        "        if atom not in xyz[resn][resa]:\n",
        "          xyz[resn][resa][atom] = np.array([x,y,z])\n",
        "\n",
        "  # convert to numpy arrays, fill in missing values\n",
        "  seq_,xyz_ = [],[]\n",
        "  try:\n",
        "      for resn in range(min_resn,max_resn+1):\n",
        "        if resn in seq:\n",
        "          for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k],20))\n",
        "        else: seq_.append(20)\n",
        "        if resn in xyz:\n",
        "          for k in sorted(xyz[resn]):\n",
        "            for atom in atoms:\n",
        "              if atom in xyz[resn][k]: xyz_.append(xyz[resn][k][atom])\n",
        "              else: xyz_.append(np.full(3,np.nan))\n",
        "        else:\n",
        "          for atom in atoms: xyz_.append(np.full(3,np.nan))\n",
        "      return np.array(xyz_).reshape(-1,len(atoms),3), N_to_AA(np.array(seq_))\n",
        "  except TypeError:\n",
        "      return 'no_chain', 'no_chain'\n",
        "\n",
        "### calling signature\n",
        "# pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list)\n",
        "def parse_PDB(path_to_pdb, input_chain_list=None):\n",
        "    c=0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V','W','X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v','w','x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "     \n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list  \n",
        " \n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    # Each of the biounits is a separate PDB file, so for running with a single PDB file like from colab, this loop will be executed only once\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {} \n",
        "        # This loop will be executed only once for single chain DDG type cases\n",
        "        for letter in chain_alphabet:\n",
        "            xyz, seq = parse_PDB_biounits(biounit, atoms=['N','CA','C','O'], chain=letter)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_'+letter]=seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                coords_dict_chain['N_chain_'+letter]=xyz[:,0,:].tolist()\n",
        "                coords_dict_chain['CA_chain_'+letter]=xyz[:,1,:].tolist()\n",
        "                coords_dict_chain['C_chain_'+letter]=xyz[:,2,:].tolist()\n",
        "                coords_dict_chain['O_chain_'+letter]=xyz[:,3,:].tolist()\n",
        "                my_dict['coords_chain_'+letter]=coords_dict_chain\n",
        "                s += 1\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        my_dict['name']=biounit[(fi+1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c+=1\n",
        "    return pdb_dict_list\n",
        "\n",
        "\n",
        "# X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta \n",
        "# = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "# fixed_pos_list = fixed_position_dict[b['name']][letter]\n",
        "# The trick will be to populate this fixed_position_dict from the calling function, and \n",
        "def tied_featurize(batch, device, chain_dict, fixed_position_dict=None, omit_AA_dict=None, tied_positions_dict=None, pssm_dict=None, bias_by_res_dict=None):\n",
        "    \"\"\" Pack and pad batch into torch tensors \"\"\"\n",
        "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    B = len(batch)\n",
        "    lengths = np.array([len(b['seq']) for b in batch], dtype=np.int32) #sum of chain seq lengths\n",
        "    L_max = max([len(b['seq']) for b in batch])\n",
        "    X = np.zeros([B, L_max, 4, 3])\n",
        "    residue_idx = -100*np.ones([B, L_max], dtype=np.int32)\n",
        "    # This \"chain_M\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of the single sequence as a consequence\n",
        "    chain_M = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    pssm_coef_all = np.zeros([B, L_max], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    pssm_bias_all = np.zeros([B, L_max, 21], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    pssm_log_odds_all = 10000.0*np.ones([B, L_max, 21], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    # This \"chain_M_pos\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of single sequence as a consequence\n",
        "    chain_M_pos = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    bias_by_res_all = np.zeros([B, L_max, 21], dtype=np.float32)\n",
        "    # This \"chain_encoding_all\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of single sequence as a consequence\n",
        "    chain_encoding_all = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    S = np.zeros([B, L_max], dtype=np.int32)\n",
        "    omit_AA_mask = np.zeros([B, L_max, len(alphabet)], dtype=np.int32)\n",
        "    # Build the batch\n",
        "    letter_list_list = []\n",
        "    visible_list_list = []\n",
        "    masked_list_list = []\n",
        "    masked_chain_length_list_list = []\n",
        "    tied_pos_list_of_lists_list = []\n",
        "    #shuffle all chains before the main loop\n",
        "    for i, b in enumerate(batch):\n",
        "        # for my current energy function like usecase, the code will reach \"if and not else\" because chain_dict will not be None\n",
        "        if chain_dict != None:\n",
        "            ### Calling function argument assignment START\n",
        "            # chain_id_dict[pdb_dict_list[0]['name']] = (designed_chain_list, fixed_chain_list)\n",
        "            ### Calling function argument assignment END\n",
        "            masked_chains, visible_chains = chain_dict[b['name']] #masked_chains a list of chain letters to predict [A, D, F]\n",
        "        else:\n",
        "            masked_chains = [item[-1:] for item in list(b) if item[:10]=='seq_chain_']\n",
        "            visible_chains = []\n",
        "        num_chains = b['num_of_chains']\n",
        "        all_chains = masked_chains + visible_chains\n",
        "        #random.shuffle(all_chains)\n",
        "    # This for loop can be ignored since it will be executed only once in my single-chain or single-chain-at-a-time implementation\n",
        "    for i, b in enumerate(batch):\n",
        "        mask_dict = {}\n",
        "        a = 0\n",
        "        x_chain_list = []\n",
        "        chain_mask_list = []\n",
        "        # \"chain_seq_list\" will contain string format sequences of all the chains both fixed and designable \n",
        "        chain_seq_list = []\n",
        "        chain_encoding_list = []\n",
        "        c = 1\n",
        "        # \"letter_list\" will contain names of all the chains both fixed and designable\n",
        "        letter_list = []\n",
        "        global_idx_start_list = [0]\n",
        "        # \"visible_list\" will contain names of the fixed chains \n",
        "        visible_list = []\n",
        "        # \"masked_list\" will contain names of the designable chains\n",
        "        masked_list = []\n",
        "        masked_chain_length_list = []\n",
        "        fixed_position_mask_list = []\n",
        "        omit_AA_mask_list = []\n",
        "        pssm_coef_list = []\n",
        "        pssm_bias_list = []\n",
        "        pssm_log_odds_list = []\n",
        "        bias_by_res_list = []\n",
        "        l0 = 0\n",
        "        l1 = 0\n",
        "        # This loop will also be executed once for my single chain case,\n",
        "        # and since the same chain has both designable and fixed positions, the codes insides both of the if \n",
        "        # statements will be executed\n",
        "        for step, letter in enumerate(all_chains):\n",
        "            if letter in visible_chains:\n",
        "                letter_list.append(letter)\n",
        "                visible_list.append(letter)\n",
        "                chain_seq = b[f'seq_chain_{letter}']\n",
        "                chain_seq = ''.join([a if a!='-' else 'X' for a in chain_seq])\n",
        "                chain_length = len(chain_seq)\n",
        "                global_idx_start_list.append(global_idx_start_list[-1]+chain_length)\n",
        "                chain_coords = b[f'coords_chain_{letter}'] #this is a dictionary\n",
        "                # the \"chain_mask\" varies between fixed and designable chains (1.0 for designable chains which are maxed)\n",
        "                chain_mask = np.zeros(chain_length) #0.0 for visible chains\n",
        "                x_chain = np.stack([chain_coords[c] for c in [f'N_chain_{letter}', f'CA_chain_{letter}', f'C_chain_{letter}', f'O_chain_{letter}']], 1) #[chain_lenght,4,3]\n",
        "                x_chain_list.append(x_chain)\n",
        "                chain_mask_list.append(chain_mask)\n",
        "                chain_seq_list.append(chain_seq)\n",
        "                # \"chain_encoding_list\" contains numpy arrays corresponding to chains (each array corresponds to one chain),\n",
        "                # where all elements of the same array is the same value, which is equal to the index of the chain the it corresponds to\n",
        "                # by index, I mean index of the different numpy arrays annotating the chains\n",
        "                chain_encoding_list.append(c*np.ones(np.array(chain_mask).shape[0]))\n",
        "                # l0 points at the starting of the current chain and l1 points after the ending of the current chain\n",
        "                l1 += chain_length\n",
        "                # the only value i will have is 0 since it will be executed only once in my single-chain or single-chain-at-a-time implementation\n",
        "                # seems like the chains are separated by  \n",
        "                residue_idx[i, l0:l1] = 100*(c-1)+np.arange(l0, l1)\n",
        "                l0 += chain_length\n",
        "                c+=1\n",
        "                # The following variables are numpy arrays with entries corresponding to every position in the sequence\n",
        "                # appending these numpy arrays to a list indicates that the chains are added one after one\n",
        "                # same thing goes for the chain_mask and chain_seq variables declared above\n",
        "                # In code-block below in this cell, these lists of numpy arrays are going through np.concatenate(), which is creating\n",
        "                # the final numpy arrays containing co-ordinates, sequence identity, fixed position, masked position, PSSM bias, and everything\n",
        "                # required to pass the sequences through the model\n",
        "                ### START\n",
        "                fixed_position_mask = np.ones(chain_length)\n",
        "                fixed_position_mask_list.append(fixed_position_mask)\n",
        "                # The omit_AA_mask, pssm_coef, pssm_bias, \"bias_by_res_list\", all these numpy arrays are zero for the fixed positions\n",
        "                # since these positions are used as it is, while for the masked_positions, these values can get activated\n",
        "                # which is why the next if statement has several extra lines manipulating these variables according to the amount of information passed \n",
        "                omit_AA_mask_temp = np.zeros([chain_length, len(alphabet)], np.int32)\n",
        "                omit_AA_mask_list.append(omit_AA_mask_temp)\n",
        "                pssm_coef = np.zeros(chain_length)\n",
        "                pssm_bias = np.zeros([chain_length, 21])\n",
        "                pssm_log_odds = 10000.0*np.ones([chain_length, 21])\n",
        "                pssm_coef_list.append(pssm_coef)\n",
        "                pssm_bias_list.append(pssm_bias)\n",
        "                pssm_log_odds_list.append(pssm_log_odds)\n",
        "                bias_by_res_list.append(np.zeros([chain_length, 21]))\n",
        "                ### END\n",
        "            if letter in masked_chains:\n",
        "                masked_list.append(letter)\n",
        "                letter_list.append(letter)\n",
        "                chain_seq = b[f'seq_chain_{letter}']\n",
        "                chain_seq = ''.join([a if a!='-' else 'X' for a in chain_seq])\n",
        "                chain_length = len(chain_seq)\n",
        "                global_idx_start_list.append(global_idx_start_list[-1]+chain_length)\n",
        "                masked_chain_length_list.append(chain_length)\n",
        "                chain_coords = b[f'coords_chain_{letter}'] #this is a dictionary\n",
        "                chain_mask = np.ones(chain_length) #1.0 for masked\n",
        "                x_chain = np.stack([chain_coords[c] for c in [f'N_chain_{letter}', f'CA_chain_{letter}', f'C_chain_{letter}', f'O_chain_{letter}']], 1) #[chain_lenght,4,3]\n",
        "                x_chain_list.append(x_chain)\n",
        "                chain_mask_list.append(chain_mask)\n",
        "                chain_seq_list.append(chain_seq)\n",
        "                chain_encoding_list.append(c*np.ones(np.array(chain_mask).shape[0]))\n",
        "                l1 += chain_length\n",
        "                residue_idx[i, l0:l1] = 100*(c-1)+np.arange(l0, l1)\n",
        "                l0 += chain_length\n",
        "                c+=1\n",
        "                fixed_position_mask = np.ones(chain_length)\n",
        "                if fixed_position_dict!=None:\n",
        "                    fixed_pos_list = fixed_position_dict[b['name']][letter]\n",
        "                    if fixed_pos_list:\n",
        "                        # seems like \"fixed_pos_list\"  can be an 1-indexed integer list corresponding to positions in \"chain_seq\"\n",
        "                        # this thing ultimately controls which positions in the designable chain will be masked, which is why the fixed \n",
        "                        # positions are set to 0.0 since those positions will not be maxed (1 if maxed, 0 if not maxed)\n",
        "                        fixed_position_mask[np.array(fixed_pos_list)-1] = 0.0\n",
        "                fixed_position_mask_list.append(fixed_position_mask)\n",
        "                omit_AA_mask_temp = np.zeros([chain_length, len(alphabet)], np.int32)\n",
        "                # For my current energy function like usecase, \"omit_AA_dict\" will be None, so the following loop can be ignored\n",
        "                if omit_AA_dict!=None:\n",
        "                    for item in omit_AA_dict[b['name']][letter]:\n",
        "                        idx_AA = np.array(item[0])-1\n",
        "                        AA_idx = np.array([np.argwhere(np.array(list(alphabet))== AA)[0][0] for AA in item[1]]).repeat(idx_AA.shape[0])\n",
        "                        idx_ = np.array([[a, b] for a in idx_AA for b in AA_idx])\n",
        "                        omit_AA_mask_temp[idx_[:,0], idx_[:,1]] = 1\n",
        "                omit_AA_mask_list.append(omit_AA_mask_temp)\n",
        "                pssm_coef = np.zeros(chain_length)\n",
        "                pssm_bias = np.zeros([chain_length, 21])\n",
        "                pssm_log_odds = 10000.0*np.ones([chain_length, 21])\n",
        "                if pssm_dict:\n",
        "                    if pssm_dict[b['name']][letter]:\n",
        "                        pssm_coef = pssm_dict[b['name']][letter]['pssm_coef']\n",
        "                        pssm_bias = pssm_dict[b['name']][letter]['pssm_bias']\n",
        "                        pssm_log_odds = pssm_dict[b['name']][letter]['pssm_log_odds']\n",
        "                pssm_coef_list.append(pssm_coef)\n",
        "                pssm_bias_list.append(pssm_bias)\n",
        "                pssm_log_odds_list.append(pssm_log_odds)\n",
        "                if bias_by_res_dict:\n",
        "                    bias_by_res_list.append(bias_by_res_dict[b['name']][letter])\n",
        "                else:\n",
        "                    bias_by_res_list.append(np.zeros([chain_length, 21]))\n",
        "\n",
        "        ### TIED position START\n",
        "        # Since there will technically be no tied positions for my single chain energy-based usecase for now,\n",
        "        # I do not need to dig into this part of the code\n",
        "        letter_list_np = np.array(letter_list)\n",
        "        tied_pos_list_of_lists = []\n",
        "        tied_beta = np.ones(L_max)\n",
        "        if tied_positions_dict!=None:\n",
        "            tied_pos_list = tied_positions_dict[b['name']]\n",
        "            if tied_pos_list:\n",
        "                set_chains_tied = set(list(itertools.chain(*[list(item) for item in tied_pos_list])))\n",
        "                for tied_item in tied_pos_list:\n",
        "                    one_list = []\n",
        "                    for k, v in tied_item.items():\n",
        "                        start_idx = global_idx_start_list[np.argwhere(letter_list_np == k)[0][0]]\n",
        "                        if isinstance(v[0], list):\n",
        "                            for v_count in range(len(v[0])):\n",
        "                                one_list.append(start_idx+v[0][v_count]-1)#make 0 to be the first\n",
        "                                tied_beta[start_idx+v[0][v_count]-1] = v[1][v_count]\n",
        "                        else:\n",
        "                            for v_ in v:\n",
        "                                one_list.append(start_idx+v_-1)#make 0 to be the first\n",
        "                    tied_pos_list_of_lists.append(one_list)\n",
        "        tied_pos_list_of_lists_list.append(tied_pos_list_of_lists)\n",
        "        ### TIED position END\n",
        " \n",
        "        # Interestingly, although the backbone atom coordinates are used for generating edge features,\n",
        "        # the \"x\" in the following line contains the coodinates of the backbone atoms \n",
        "        x = np.concatenate(x_chain_list,0) #[L, 4, 3]\n",
        "        # \"all_sequence\" is a string where all the chain sequences have been put one after another\n",
        "        all_sequence = \"\".join(chain_seq_list)\n",
        "        # This \"chain_mask_list\" and \"m_pos\" below are the variables of interest if these actually contain full information regarding the\n",
        "        # fixed vs. variable positions definitions \n",
        "        # consequently, since these are concatenated numpy arrays of numpy arrays inside the lists \"chain_mask_list\" and \"fixed_position_mask_list\",\n",
        "        # when those lists are populated in the above code-block with binary numpy arrays \"fixed_position_mask\" and \"fixed_position_mask\" corresponding to \n",
        "        # each of the chains,\n",
        "        # that is where all the controlling needs to be done from\n",
        "        m = np.concatenate(chain_mask_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        # \"chain_encoding_list\" contains numpy arrays corresponding to chains (each array corresponds to one chain),\n",
        "        # where all elements of the same array is the same value, which is equal to the index of the chain the it corresponds to\n",
        "        # by index, I mean index of the different numpy arrays annotating the chains\n",
        "        chain_encoding = np.concatenate(chain_encoding_list,0)\n",
        "        m_pos = np.concatenate(fixed_position_mask_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "\n",
        "        pssm_coef_ = np.concatenate(pssm_coef_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        pssm_bias_ = np.concatenate(pssm_bias_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        pssm_log_odds_ = np.concatenate(pssm_log_odds_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "\n",
        "        bias_by_res_ = np.concatenate(bias_by_res_list, 0)  #[L,21], 0.0 for places where AA frequencies don't need to be tweaked\n",
        "\n",
        "        # Interestingly, all the chains are padded to the same length\n",
        "        # this has to be done most probably because the same layers are applied to all chains\n",
        "        # but for single chain or homomer cases, this should not be an issue\n",
        "        # need to be sure later why this is done\n",
        "        # does not significant when it comes to single chain energy-based usecase\n",
        "        # PADDING START\n",
        "        l = len(all_sequence)\n",
        "        x_pad = np.pad(x, [[0,L_max-l], [0,0], [0,0]], 'constant', constant_values=(np.nan, ))\n",
        "        X[i,:,:,:] = x_pad\n",
        "\n",
        "        m_pad = np.pad(m, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        m_pos_pad = np.pad(m_pos, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        omit_AA_mask_pad = np.pad(np.concatenate(omit_AA_mask_list,0), [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        chain_M[i,:] = m_pad\n",
        "        chain_M_pos[i,:] = m_pos_pad\n",
        "        omit_AA_mask[i,] = omit_AA_mask_pad\n",
        "\n",
        "        chain_encoding_pad = np.pad(chain_encoding, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        chain_encoding_all[i,:] = chain_encoding_pad\n",
        "\n",
        "        pssm_coef_pad = np.pad(pssm_coef_, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        pssm_bias_pad = np.pad(pssm_bias_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "        pssm_log_odds_pad = np.pad(pssm_log_odds_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "\n",
        "        pssm_coef_all[i,:] = pssm_coef_pad\n",
        "        pssm_bias_all[i,:] = pssm_bias_pad\n",
        "        pssm_log_odds_all[i,:] = pssm_log_odds_pad\n",
        "\n",
        "        bias_by_res_pad = np.pad(bias_by_res_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "        bias_by_res_all[i,:] = bias_by_res_pad\n",
        "        # PADDING END\n",
        "\n",
        "        # Convert to labels\n",
        "        indices = np.asarray([alphabet.index(a) for a in all_sequence], dtype=np.int32)\n",
        "        S[i, :l] = indices\n",
        "        letter_list_list.append(letter_list)\n",
        "        visible_list_list.append(visible_list)\n",
        "        masked_list_list.append(masked_list)\n",
        "        masked_chain_length_list_list.append(masked_chain_length_list)\n",
        "\n",
        "\n",
        "    isnan = np.isnan(X)\n",
        "    mask = np.isfinite(np.sum(X,(2,3))).astype(np.float32)\n",
        "    X[isnan] = 0.\n",
        "\n",
        "    # Conversion\n",
        "    pssm_coef_all = torch.from_numpy(pssm_coef_all).to(dtype=torch.float32, device=device)\n",
        "    pssm_bias_all = torch.from_numpy(pssm_bias_all).to(dtype=torch.float32, device=device)\n",
        "    pssm_log_odds_all = torch.from_numpy(pssm_log_odds_all).to(dtype=torch.float32, device=device)\n",
        "\n",
        "    tied_beta = torch.from_numpy(tied_beta).to(dtype=torch.float32, device=device)\n",
        "\n",
        "    jumps = ((residue_idx[:,1:]-residue_idx[:,:-1])==1).astype(np.float32)\n",
        "    bias_by_res_all = torch.from_numpy(bias_by_res_all).to(dtype=torch.float32, device=device)\n",
        "    phi_mask = np.pad(jumps, [[0,0],[1,0]])\n",
        "    psi_mask = np.pad(jumps, [[0,0],[0,1]])\n",
        "    omega_mask = np.pad(jumps, [[0,0],[0,1]])\n",
        "    dihedral_mask = np.concatenate([phi_mask[:,:,None], psi_mask[:,:,None], omega_mask[:,:,None]], -1) #[B,L,3]\n",
        "    dihedral_mask = torch.from_numpy(dihedral_mask).to(dtype=torch.float32, device=device)\n",
        "    residue_idx = torch.from_numpy(residue_idx).to(dtype=torch.long,device=device)\n",
        "    S = torch.from_numpy(S).to(dtype=torch.long,device=device)\n",
        "    X = torch.from_numpy(X).to(dtype=torch.float32, device=device)\n",
        "    mask = torch.from_numpy(mask).to(dtype=torch.float32, device=device)\n",
        "    chain_M = torch.from_numpy(chain_M).to(dtype=torch.float32, device=device)\n",
        "    chain_M_pos = torch.from_numpy(chain_M_pos).to(dtype=torch.float32, device=device)\n",
        "    omit_AA_mask = torch.from_numpy(omit_AA_mask).to(dtype=torch.float32, device=device)\n",
        "    chain_encoding_all = torch.from_numpy(chain_encoding_all).to(dtype=torch.long, device=device)\n",
        "    # in general, in this return statement, *_list_list has the list inside list format because the outer list corresponds to \"batch_clones\", \n",
        "    # whereas the inner list corresponds to \"chains\" for each of the elements of \"batch_clones\"\n",
        "    # \"masked_list_list\" contains names of the designable chains (which is my target for single chain energy), whereas \"visible_list_list\" \n",
        "    # contains names of the fixed chains (which should be empty for my single chain energy)\n",
        "    # for my single chain energy case, \"letter_list_list\" should be equal to \"masked_list_list\", and three lists should have one list for now\n",
        "    # \"chain_encoding_all\" should also contain chain-index related to the only single chain which should be 0 (all 0s)\n",
        "    # the last lists starting from \"tied_pos_list_of_lists_list\" to the end should be irrelevant for my single chain energy case\n",
        "    # but still it would be good to check the values of these irrelevant lists, and get an idea if everything makes sense or not\n",
        "    # \"chain_M_pos\" contains values from \"fixed_position_mask\" through \"m_pos\", which should get populated with 0.0 for fixed positions\n",
        "    # and 1.0 for designable positions, which can be controlled through the , which\n",
        "    # is controlled by \"fixed_position_dict\" input to this function from the running script\n",
        "    # \"chain_M\" is formed from \"m_pad\" which comes from \"m\" which comes from chain_mask = np.ones(chain_length) #1.0 for masked\n",
        "    # so, for my single chain energy usecase, \"chain_M\" should be all 1.0s with the same length as chain_M_pos\n",
        "    # I do not think \"X\", \"S\", and \"mask\" need to be manipulated for now \n",
        "    return X, S, mask, lengths, chain_M, chain_encoding_all, letter_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef_all, pssm_bias_all, pssm_log_odds_all, bias_by_res_all, tied_beta\n",
        "\n",
        "\n",
        "# No need to dig into this loss function for now\n",
        "def loss_nll(S, log_probs, mask):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    criterion = torch.nn.NLLLoss(reduction='none')\n",
        "    loss = criterion(\n",
        "        log_probs.contiguous().view(-1, log_probs.size(-1)), S.contiguous().view(-1)\n",
        "    ).view(S.size())\n",
        "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
        "    return loss, loss_av\n",
        "\n",
        "# No need to dig into this label smoothing stuff for now\n",
        "def loss_smoothed(S, log_probs, mask, weight=0.1):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    S_onehot = torch.nn.functional.one_hot(S, 21).float()\n",
        "\n",
        "    # Label smoothing\n",
        "    S_onehot = S_onehot + weight / float(S_onehot.size(-1))\n",
        "    S_onehot = S_onehot / S_onehot.sum(-1, keepdim=True)\n",
        "\n",
        "    loss = -(S_onehot * log_probs).sum(-1)\n",
        "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
        "    return loss, loss_av\n",
        "\n",
        "# Objects of this class can be indexed since dunder methods __len()__ and __getitem()__ have been implemented, which \n",
        "# indexes a list that has been declared as an instance variable in the constructor,\n",
        "# and each element of that underlying list is a dictionary containing information regarding a specific sequence\n",
        "class StructureDataset():\n",
        "    def __init__(self, jsonl_file, verbose=True, truncate=None, max_length=100,\n",
        "        alphabet='ACDEFGHIKLMNPQRSTVWYX-'):\n",
        "        alphabet_set = set([a for a in alphabet])\n",
        "        discard_count = {\n",
        "            'bad_chars': 0,\n",
        "            'too_long': 0,\n",
        "            'bad_seq_length': 0\n",
        "        }\n",
        "\n",
        "        with open(jsonl_file) as f:\n",
        "            self.data = []\n",
        "\n",
        "            lines = f.readlines()\n",
        "            start = time.time()\n",
        "            for i, line in enumerate(lines):\n",
        "                entry = json.loads(line)\n",
        "                seq = entry['seq'] \n",
        "                name = entry['name']\n",
        "\n",
        "                # Convert raw coords to np arrays\n",
        "                #for key, val in entry['coords'].items():\n",
        "                #    entry['coords'][key] = np.asarray(val)\n",
        "\n",
        "                # Check if in alphabet\n",
        "                bad_chars = set([s for s in seq]).difference(alphabet_set)\n",
        "                if len(bad_chars) == 0:\n",
        "                    if len(entry['seq']) <= max_length:\n",
        "                        if True:\n",
        "                            self.data.append(entry)\n",
        "                        else:\n",
        "                            discard_count['bad_seq_length'] += 1\n",
        "                    else:\n",
        "                        discard_count['too_long'] += 1\n",
        "                else:\n",
        "                    print(name, bad_chars, entry['seq'])\n",
        "                    discard_count['bad_chars'] += 1\n",
        "\n",
        "                # Truncate early\n",
        "                if truncate is not None and len(self.data) == truncate:\n",
        "                    return\n",
        "\n",
        "                if verbose and (i + 1) % 1000 == 0:\n",
        "                    elapsed = time.time() - start\n",
        "                    print('{} entries ({} loaded) in {:.1f} s'.format(len(self.data), i+1, elapsed))\n",
        "\n",
        "            print('discarded', discard_count)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "\n",
        "# Objects of this class can be indexed since dunder methods __len()__ and __getitem()__ have been implemented, which \n",
        "# indexes a list that has been declared as an instance variable in the constructor,\n",
        "# and each element of that underlying list is a dictionary containing information regarding a specific structure,\n",
        "# seems like a structure-specific version of the above method which deals with sequences \n",
        "class StructureDatasetPDB():\n",
        "    def __init__(self, pdb_dict_list, verbose=True, truncate=None, max_length=100,\n",
        "        alphabet='ACDEFGHIKLMNPQRSTVWYX-'):\n",
        "        alphabet_set = set([a for a in alphabet])\n",
        "        discard_count = {\n",
        "            'bad_chars': 0,\n",
        "            'too_long': 0,\n",
        "            'bad_seq_length': 0\n",
        "        }\n",
        "\n",
        "        self.data = []\n",
        "\n",
        "        start = time.time()\n",
        "        # elements of pdb_dict_list are dictionaries containing information regarding a specific pdb file\n",
        "        for i, entry in enumerate(pdb_dict_list):\n",
        "            seq = entry['seq']\n",
        "            name = entry['name']\n",
        "\n",
        "            bad_chars = set([s for s in seq]).difference(alphabet_set)\n",
        "            if len(bad_chars) == 0:\n",
        "                if len(entry['seq']) <= max_length:\n",
        "                    self.data.append(entry)\n",
        "                else:\n",
        "                    discard_count['too_long'] += 1\n",
        "            else:\n",
        "                discard_count['bad_chars'] += 1\n",
        "\n",
        "            # Truncate early\n",
        "            if truncate is not None and len(self.data) == truncate:\n",
        "                return\n",
        "\n",
        "            if verbose and (i + 1) % 1000 == 0:\n",
        "                elapsed = time.time() - start\n",
        "\n",
        "            #print('Discarded', discard_count)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "\n",
        "    \n",
        "class StructureLoader():\n",
        "    def __init__(self, dataset, batch_size=100, shuffle=True,\n",
        "        collate_fn=lambda x:x, drop_last=False):\n",
        "        self.dataset = dataset\n",
        "        self.size = len(dataset)\n",
        "        self.lengths = [len(dataset[i]['seq']) for i in range(self.size)]\n",
        "        self.batch_size = batch_size\n",
        "        sorted_ix = np.argsort(self.lengths)\n",
        "\n",
        "        # Cluster into batches of similar sizes\n",
        "        clusters, batch = [], []\n",
        "        batch_max = 0\n",
        "        for ix in sorted_ix:\n",
        "            size = self.lengths[ix]\n",
        "            if size * (len(batch) + 1) <= self.batch_size:\n",
        "                batch.append(ix)\n",
        "                batch_max = size\n",
        "            else:\n",
        "                clusters.append(batch)\n",
        "                batch, batch_max = [], 0\n",
        "        if len(batch) > 0:\n",
        "            clusters.append(batch)\n",
        "        self.clusters = clusters\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.clusters)\n",
        "\n",
        "    def __iter__(self):\n",
        "        np.random.shuffle(self.clusters)\n",
        "        for b_idx in self.clusters:\n",
        "            batch = [self.dataset[i] for i in b_idx]\n",
        "            yield batch\n",
        "            \n",
        "            \n",
        "            \n",
        "# The following gather functions\n",
        "def gather_edges(edges, neighbor_idx):\n",
        "    # Features [B,N,N,C] at Neighbor indices [B,N,K] => Neighbor features [B,N,K,C]\n",
        "    neighbors = neighbor_idx.unsqueeze(-1).expand(-1, -1, -1, edges.size(-1))\n",
        "    edge_features = torch.gather(edges, 2, neighbors)\n",
        "    return edge_features\n",
        "\n",
        "def gather_nodes(nodes, neighbor_idx):\n",
        "    # Features [B,N,C] at Neighbor indices [B,N,K] => [B,N,K,C]\n",
        "    # Flatten and expand indices per batch [B,N,K] => [B,NK] => [B,NK,C]\n",
        "    neighbors_flat = neighbor_idx.view((neighbor_idx.shape[0], -1))\n",
        "    neighbors_flat = neighbors_flat.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
        "    # Gather and re-pack\n",
        "    neighbor_features = torch.gather(nodes, 1, neighbors_flat)\n",
        "    neighbor_features = neighbor_features.view(list(neighbor_idx.shape)[:3] + [-1])\n",
        "    return neighbor_features\n",
        "\n",
        "def gather_nodes_t(nodes, neighbor_idx):\n",
        "    # Features [B,N,C] at Neighbor index [B,K] => Neighbor features[B,K,C]\n",
        "    idx_flat = neighbor_idx.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
        "    neighbor_features = torch.gather(nodes, 1, idx_flat)\n",
        "    return neighbor_features\n",
        "\n",
        "def cat_neighbors_nodes(h_nodes, h_neighbors, E_idx):\n",
        "    h_nodes = gather_nodes(h_nodes, E_idx)\n",
        "    h_nn = torch.cat([h_neighbors, h_nodes], -1)\n",
        "    return h_nn\n",
        "\n",
        "\n",
        "class EncLayer(nn.Module):\n",
        "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
        "        super(EncLayer, self).__init__()\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_in = num_in\n",
        "        self.scale = scale\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(num_hidden)\n",
        "        self.norm2 = nn.LayerNorm(num_hidden)\n",
        "        self.norm3 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W11 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W12 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W13 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
        "\n",
        "    def forward(self, h_V, h_E, E_idx, mask_V=None, mask_attend=None):\n",
        "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
        "\n",
        "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
        "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
        "        if mask_attend is not None:\n",
        "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
        "        dh = torch.sum(h_message, -2) / self.scale\n",
        "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
        "\n",
        "        dh = self.dense(h_V)\n",
        "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
        "        if mask_V is not None:\n",
        "            mask_V = mask_V.unsqueeze(-1)\n",
        "            h_V = mask_V * h_V\n",
        "\n",
        "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
        "        h_message = self.W13(self.act(self.W12(self.act(self.W11(h_EV)))))\n",
        "        h_E = self.norm3(h_E + self.dropout3(h_message))\n",
        "        return h_V, h_E\n",
        "\n",
        "\n",
        "class DecLayer(nn.Module):\n",
        "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
        "        super(DecLayer, self).__init__()\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_in = num_in\n",
        "        self.scale = scale\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(num_hidden)\n",
        "        self.norm2 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
        "\n",
        "    def forward(self, h_V, h_E, mask_V=None, mask_attend=None):\n",
        "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
        "\n",
        "        # Concatenate h_V_i to h_E_ij\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_E.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_E], -1)\n",
        "\n",
        "        # Maybe, length of the message vector can serve as attention\n",
        "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
        "        # the mask attend here is most probably just for zeroing out the padded positions\n",
        "        # I do not think it will matter that much\n",
        "        if mask_attend is not None:\n",
        "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
        "            # why divide by 30 when we are dealing with 48 neighbors in the current version of the model?\n",
        "        # Let me check the messages corresponding to \n",
        "        dh = torch.sum(h_message, -2) / self.scale\n",
        "\n",
        "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
        "\n",
        "        # Position-wise feedforward\n",
        "        dh = self.dense(h_V)\n",
        "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
        "\n",
        "        if mask_V is not None:\n",
        "            mask_V = mask_V.unsqueeze(-1)\n",
        "            h_V = mask_V * h_V\n",
        "\n",
        "        # \"h_message\" can be returned without dividing by \"self.scale\" also\n",
        "        return h_V, (h_message/self.scale) \n",
        "\n",
        "\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, num_hidden, num_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.W_in = nn.Linear(num_hidden, num_ff, bias=True)\n",
        "        self.W_out = nn.Linear(num_ff, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "    def forward(self, h_V):\n",
        "        h = self.act(self.W_in(h_V))\n",
        "        h = self.W_out(h)\n",
        "        return h\n",
        "\n",
        "class PositionalEncodings(nn.Module):\n",
        "    def __init__(self, num_embeddings, max_relative_feature=32):\n",
        "        super(PositionalEncodings, self).__init__()\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.max_relative_feature = max_relative_feature\n",
        "        self.linear = nn.Linear(2*max_relative_feature+1+1, num_embeddings)\n",
        "\n",
        "    def forward(self, offset, mask):\n",
        "        d = torch.clip(offset + self.max_relative_feature, 0, 2*self.max_relative_feature)*mask + (1-mask)*(2*self.max_relative_feature+1)\n",
        "        d_onehot = torch.nn.functional.one_hot(d, 2*self.max_relative_feature+1+1)\n",
        "        E = self.linear(d_onehot.float())\n",
        "        return E\n",
        "\n",
        "# Does not look like this function needs to be modified for now to use the model as sort of an energy function\n",
        "# The only thing that could do something is \"top_k\", which can be changed for considering more or less neighbors\n",
        "# for each of the nodes, but that too I think does not matter if the default value of top_k is updated by parameter passing\n",
        "# This function is called from the model itself with node_features=128, edge_features=128, and top_k=48\n",
        "# ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
        "class ProteinFeatures(nn.Module):\n",
        "    def __init__(self, edge_features, node_features, num_positional_embeddings=16,\n",
        "        num_rbf=16, top_k=30, augment_eps=0., num_chain_embeddings=16):\n",
        "        \"\"\" Extract protein features \"\"\"\n",
        "        super(ProteinFeatures, self).__init__()\n",
        "        self.edge_features = edge_features\n",
        "        self.node_features = node_features\n",
        "        self.top_k = top_k\n",
        "        self.augment_eps = augment_eps \n",
        "        self.num_rbf = num_rbf\n",
        "        self.num_positional_embeddings = num_positional_embeddings\n",
        "\n",
        "        self.embeddings = PositionalEncodings(num_positional_embeddings)\n",
        "        node_in, edge_in = 6, num_positional_embeddings + num_rbf*25\n",
        "        self.edge_embedding = nn.Linear(edge_in, edge_features, bias=False)\n",
        "        self.norm_edges = nn.LayerNorm(edge_features)\n",
        "\n",
        "    # the output of this function MUST be analyzed either directly or via some other function to \n",
        "    # understand how to get \"index/position\" of neighbors\n",
        "    def _dist(self, X, mask, eps=1E-6):\n",
        "        mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
        "        dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
        "        D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
        "        D_max, _ = torch.max(D, -1, keepdim=True)\n",
        "        D_adjust = D + (1. - mask_2D) * D_max\n",
        "        sampled_top_k = self.top_k\n",
        "        D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(self.top_k, X.shape[1]), dim=-1, largest=False)\n",
        "        return D_neighbors, E_idx\n",
        "\n",
        "    def _rbf(self, D):\n",
        "        device = D.device\n",
        "        D_min, D_max, D_count = 2., 22., self.num_rbf\n",
        "        D_mu = torch.linspace(D_min, D_max, D_count, device=device)\n",
        "        D_mu = D_mu.view([1,1,1,-1])\n",
        "        D_sigma = (D_max - D_min) / D_count\n",
        "        D_expand = torch.unsqueeze(D, -1)\n",
        "        RBF = torch.exp(-((D_expand - D_mu) / D_sigma)**2)\n",
        "        return RBF\n",
        "\n",
        "    def _get_rbf(self, A, B, E_idx):\n",
        "        D_A_B = torch.sqrt(torch.sum((A[:,:,None,:] - B[:,None,:,:])**2,-1) + 1e-6) #[B, L, L]\n",
        "        D_A_B_neighbors = gather_edges(D_A_B[:,:,:,None], E_idx)[:,:,:,0] #[B,L,K]\n",
        "        RBF_A_B = self._rbf(D_A_B_neighbors)\n",
        "        return RBF_A_B\n",
        "\n",
        "    # this function will be called with the arguments as forward(), but will return information regarding \n",
        "    # the neighbors which I will figure out a way to parse\n",
        "    def return_neighbor_info(self, X, mask, residue_idx, chain_labels):\n",
        "        b = X[:,:,1,:] - X[:,:,0,:]\n",
        "        c = X[:,:,2,:] - X[:,:,1,:]\n",
        "        a = torch.cross(b, c, dim=-1)\n",
        "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "        Ca = X[:,:,1,:]\n",
        "        N = X[:,:,0,:]\n",
        "        C = X[:,:,2,:]\n",
        "        O = X[:,:,3,:]\n",
        " \n",
        "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
        "\n",
        "\n",
        "    def forward(self, X, mask, residue_idx, chain_labels):\n",
        "        if self.augment_eps > 0:\n",
        "            X = X + self.augment_eps * torch.randn_like(X)\n",
        "        \n",
        "        b = X[:,:,1,:] - X[:,:,0,:]\n",
        "        c = X[:,:,2,:] - X[:,:,1,:]\n",
        "        a = torch.cross(b, c, dim=-1)\n",
        "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "        Ca = X[:,:,1,:]\n",
        "        N = X[:,:,0,:]\n",
        "        C = X[:,:,2,:]\n",
        "        O = X[:,:,3,:]\n",
        " \n",
        "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
        "\n",
        "        RBF_all = []\n",
        "        RBF_all.append(self._rbf(D_neighbors)) #Ca-Ca\n",
        "        RBF_all.append(self._get_rbf(N, N, E_idx)) #N-N\n",
        "        RBF_all.append(self._get_rbf(C, C, E_idx)) #C-C\n",
        "        RBF_all.append(self._get_rbf(O, O, E_idx)) #O-O\n",
        "        RBF_all.append(self._get_rbf(Cb, Cb, E_idx)) #Cb-Cb\n",
        "        RBF_all.append(self._get_rbf(Ca, N, E_idx)) #Ca-N\n",
        "        RBF_all.append(self._get_rbf(Ca, C, E_idx)) #Ca-C\n",
        "        RBF_all.append(self._get_rbf(Ca, O, E_idx)) #Ca-O\n",
        "        RBF_all.append(self._get_rbf(Ca, Cb, E_idx)) #Ca-Cb\n",
        "        RBF_all.append(self._get_rbf(N, C, E_idx)) #N-C\n",
        "        RBF_all.append(self._get_rbf(N, O, E_idx)) #N-O\n",
        "        RBF_all.append(self._get_rbf(N, Cb, E_idx)) #N-Cb\n",
        "        RBF_all.append(self._get_rbf(Cb, C, E_idx)) #Cb-C\n",
        "        RBF_all.append(self._get_rbf(Cb, O, E_idx)) #Cb-O\n",
        "        RBF_all.append(self._get_rbf(O, C, E_idx)) #O-C\n",
        "        RBF_all.append(self._get_rbf(N, Ca, E_idx)) #N-Ca\n",
        "        RBF_all.append(self._get_rbf(C, Ca, E_idx)) #C-Ca\n",
        "        RBF_all.append(self._get_rbf(O, Ca, E_idx)) #O-Ca\n",
        "        RBF_all.append(self._get_rbf(Cb, Ca, E_idx)) #Cb-Ca\n",
        "        RBF_all.append(self._get_rbf(C, N, E_idx)) #C-N\n",
        "        RBF_all.append(self._get_rbf(O, N, E_idx)) #O-N\n",
        "        RBF_all.append(self._get_rbf(Cb, N, E_idx)) #Cb-N\n",
        "        RBF_all.append(self._get_rbf(C, Cb, E_idx)) #C-Cb\n",
        "        RBF_all.append(self._get_rbf(O, Cb, E_idx)) #O-Cb\n",
        "        RBF_all.append(self._get_rbf(C, O, E_idx)) #C-O\n",
        "        RBF_all = torch.cat(tuple(RBF_all), dim=-1)\n",
        "\n",
        "        offset = residue_idx[:,:,None]-residue_idx[:,None,:]\n",
        "        offset = gather_edges(offset[:,:,:,None], E_idx)[:,:,:,0] #[B, L, K]\n",
        "\n",
        "        d_chains = ((chain_labels[:, :, None] - chain_labels[:,None,:])==0).long() #find self vs non-self interaction\n",
        "        E_chains = gather_edges(d_chains[:,:,:,None], E_idx)[:,:,:,0]\n",
        "        E_positional = self.embeddings(offset.long(), E_chains)\n",
        "        E = torch.cat((E_positional, RBF_all), -1)\n",
        "        E = self.edge_embedding(E)\n",
        "        E = self.norm_edges(E)\n",
        "        return E, E_idx \n",
        "\n",
        "\n",
        "\n",
        "class ProteinMPNN(nn.Module):\n",
        "    # \"node_features\" and \"edge_features\" are actually dimensionality of these features (\"hidden_dim\" in the calling script)\n",
        "    # the value is 128 for the version that I am using\n",
        "    def __init__(self, num_letters, node_features, edge_features,\n",
        "        hidden_dim, num_encoder_layers=3, num_decoder_layers=3,\n",
        "        vocab=21, k_neighbors=64, augment_eps=0.05, dropout=0.1):\n",
        "        super(ProteinMPNN, self).__init__()\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.node_features = node_features\n",
        "        self.edge_features = edge_features\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Featurization layers\n",
        "        # The version that I am using considers 48 neighbors for each position\n",
        "        self.features = ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
        "\n",
        "        self.W_e = nn.Linear(edge_features, hidden_dim, bias=True)\n",
        "        # This W_s is for embedding the sequence\n",
        "        self.W_s = nn.Embedding(vocab, hidden_dim)\n",
        "\n",
        "        # Encoder layers\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            EncLayer(hidden_dim, hidden_dim*2, dropout=dropout)\n",
        "            for _ in range(num_encoder_layers)\n",
        "        ])\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            DecLayer(hidden_dim, hidden_dim*3, dropout=dropout)\n",
        "            for _ in range(num_decoder_layers)\n",
        "        ])\n",
        "        self.W_out = nn.Linear(hidden_dim, num_letters, bias=True)\n",
        "\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    # Creating my own versions of forward should be an easy way to get embeddings or attention weights from diffrerent layers of the model\n",
        "    # See here (https://discuss.pytorch.org/t/how-can-i-extract-intermediate-layer-output-from-loaded-cnn-model/77301) in the forums for adding forward\n",
        "    # hooks or manipulating the forward method\n",
        "    # but my easy solution would be to create different versions of the forward method with different namaes, and calling them explicitly\n",
        "    # \"chain_M\" and \"mask\" seem to be the things that I need to understand very well and play-around with \n",
        "    def forward(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn, use_input_decoding_order=False, decoding_order=None):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Concatenate sequence embeddings for autoregressive decoder\n",
        "        # h_S denotes embedding of the sequence itself for use in decoder\n",
        "        h_S = self.W_s(S)\n",
        "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "\n",
        "\n",
        "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
        "        if not use_input_decoding_order:\n",
        "            decoding_order = torch.argsort((chain_M+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for layer in self.decoder_layers:\n",
        "            # Masked positions attend to encoder information, unmasked see. \n",
        "            h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "            h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
        "            # only the last layer decoder-messages will be stored in \"decoder_messages\"\n",
        "            h_V, decoder_messages = layer(h_V, h_ESV, mask)\n",
        "\n",
        "        logits = self.W_out(h_V)\n",
        "        # The probabilities are passed through log() function so that the sequences can be ranked based by summing the respective values \n",
        "        # for each position instead of multiplication \n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        # messages from the last layer decoder will also be returned for extracting neighbor-attention approximation\\\n",
        "        # last layer embeddings can be extracted from the \"h_V\" tensor \n",
        "        return log_probs, decoder_messages, h_V\n",
        "\n",
        "\n",
        "\n",
        "    # Seems like this is the method which is used by the notebook for calculating probabilites and scoring\n",
        "    # Need to dig into it thoroughly\n",
        "    # \"chain_mask\" and \"residue_idx\" seem like the tensors of interest\n",
        "    def sample(self, X, randn, S_true, chain_mask, chain_encoding_all, residue_idx, mask=None, temperature=1.0, omit_AAs_np=None, bias_AAs_np=None, chain_M_pos=None, omit_AA_mask=None, pssm_coef=None, pssm_bias=None, pssm_multi=None, pssm_log_odds_flag=None, pssm_log_odds_mask=None, pssm_bias_flag=None, bias_by_res=None):\n",
        "        device = X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Decoder uses masked self-attention\n",
        "        chain_mask = chain_mask*chain_M_pos*mask #update chain_M to include missing regions\n",
        "        decoding_order = torch.argsort((chain_mask+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        N_batch, N_nodes = X.size(0), X.size(1)\n",
        "        log_probs = torch.zeros((N_batch, N_nodes, 21), device=device)\n",
        "        all_probs = torch.zeros((N_batch, N_nodes, 21), device=device, dtype=torch.float32)\n",
        "        h_S = torch.zeros_like(h_V, device=device)\n",
        "        S = torch.zeros((N_batch, N_nodes), dtype=torch.int64, device=device)\n",
        "        h_V_stack = [h_V] + [torch.zeros_like(h_V, device=device) for _ in range(len(self.decoder_layers))]\n",
        "        constant = torch.tensor(omit_AAs_np, device=device)\n",
        "        constant_bias = torch.tensor(bias_AAs_np, device=device)\n",
        "        #chain_mask_combined = chain_mask*chain_M_pos \n",
        "        omit_AA_mask_flag = omit_AA_mask != None\n",
        "\n",
        "\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for t_ in range(N_nodes):\n",
        "            t = decoding_order[:,t_] #[B]\n",
        "            chain_mask_gathered = torch.gather(chain_mask, 1, t[:,None]) #[B]\n",
        "            bias_by_res_gathered = torch.gather(bias_by_res, 1, t[:,None,None].repeat(1,1,21))[:,0,:] #[B, 21]\n",
        "            if (chain_mask_gathered==0).all():\n",
        "                S_t = torch.gather(S_true, 1, t[:,None])\n",
        "            else:\n",
        "                # Hidden layers\n",
        "                E_idx_t = torch.gather(E_idx, 1, t[:,None,None].repeat(1,1,E_idx.shape[-1]))\n",
        "                h_E_t = torch.gather(h_E, 1, t[:,None,None,None].repeat(1,1,h_E.shape[-2], h_E.shape[-1]))\n",
        "                h_ES_t = cat_neighbors_nodes(h_S, h_E_t, E_idx_t)\n",
        "                h_EXV_encoder_t = torch.gather(h_EXV_encoder_fw, 1, t[:,None,None,None].repeat(1,1,h_EXV_encoder_fw.shape[-2], h_EXV_encoder_fw.shape[-1]))\n",
        "                mask_t = torch.gather(mask, 1, t[:,None])\n",
        "                for l, layer in enumerate(self.decoder_layers):\n",
        "                    # Updated relational features for future states\n",
        "                    h_ESV_decoder_t = cat_neighbors_nodes(h_V_stack[l], h_ES_t, E_idx_t)\n",
        "                    h_V_t = torch.gather(h_V_stack[l], 1, t[:,None,None].repeat(1,1,h_V_stack[l].shape[-1]))\n",
        "                    h_ESV_t = torch.gather(mask_bw, 1, t[:,None,None,None].repeat(1,1,mask_bw.shape[-2], mask_bw.shape[-1])) * h_ESV_decoder_t + h_EXV_encoder_t\n",
        "                    h_V_stack[l+1].scatter_(1, t[:,None,None].repeat(1,1,h_V.shape[-1]), layer(h_V_t, h_ESV_t, mask_V=mask_t))\n",
        "                # Sampling step\n",
        "                h_V_t = torch.gather(h_V_stack[-1], 1, t[:,None,None].repeat(1,1,h_V_stack[-1].shape[-1]))[:,0]\n",
        "                logits = self.W_out(h_V_t) / temperature\n",
        "                probs = F.softmax(logits-constant[None,:]*1e8+constant_bias[None,:]/temperature+bias_by_res_gathered/temperature, dim=-1)\n",
        "                if pssm_bias_flag:\n",
        "                    pssm_coef_gathered = torch.gather(pssm_coef, 1, t[:,None])[:,0]\n",
        "                    pssm_bias_gathered = torch.gather(pssm_bias, 1, t[:,None,None].repeat(1,1,pssm_bias.shape[-1]))[:,0]\n",
        "                    probs = (1-pssm_multi*pssm_coef_gathered[:,None])*probs + pssm_multi*pssm_coef_gathered[:,None]*pssm_bias_gathered\n",
        "                if pssm_log_odds_flag:\n",
        "                    pssm_log_odds_mask_gathered = torch.gather(pssm_log_odds_mask, 1, t[:,None, None].repeat(1,1,pssm_log_odds_mask.shape[-1]))[:,0] #[B, 21]\n",
        "                    probs_masked = probs*pssm_log_odds_mask_gathered\n",
        "                    probs_masked += probs * 0.001\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                if omit_AA_mask_flag:\n",
        "                    omit_AA_mask_gathered = torch.gather(omit_AA_mask, 1, t[:,None, None].repeat(1,1,omit_AA_mask.shape[-1]))[:,0] #[B, 21]\n",
        "                    probs_masked = probs*(1.0-omit_AA_mask_gathered)\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                # Here is where sampling from the multinomial distribution is happening\n",
        "                # this will sample 1 element according to the given distribution, and return the index of that element [from 0 to 20]\n",
        "                S_t = torch.multinomial(probs, 1)\n",
        "                all_probs.scatter_(1, t[:,None,None].repeat(1,1,21), (chain_mask_gathered[:,:,None,]*probs[:,None,:]).float())\n",
        "            S_true_gathered = torch.gather(S_true, 1, t[:,None])\n",
        "            S_t = (S_t*chain_mask_gathered+S_true_gathered*(1.0-chain_mask_gathered)).long()\n",
        "            temp1 = self.W_s(S_t)\n",
        "            h_S.scatter_(1, t[:,None,None].repeat(1,1,temp1.shape[-1]), temp1)\n",
        "            S.scatter_(1, t[:,None], S_t)\n",
        "        output_dict = {\"S\": S, \"probs\": all_probs, \"decoding_order\": decoding_order}\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "    def tied_sample(self, X, randn, S_true, chain_mask, chain_encoding_all, residue_idx, mask=None, temperature=1.0, omit_AAs_np=None, bias_AAs_np=None, chain_M_pos=None, omit_AA_mask=None, pssm_coef=None, pssm_bias=None, pssm_multi=None, pssm_log_odds_flag=None, pssm_log_odds_mask=None, pssm_bias_flag=None, tied_pos=None, tied_beta=None, bias_by_res=None):\n",
        "        device = X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=device)\n",
        "        h_E = self.W_e(E)\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Decoder uses masked self-attention\n",
        "        chain_mask = chain_mask*chain_M_pos*mask #update chain_M to include missing regions\n",
        "        decoding_order = torch.argsort((chain_mask+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "\n",
        "        new_decoding_order = []\n",
        "        for t_dec in list(decoding_order[0,].cpu().data.numpy()):\n",
        "            if t_dec not in list(itertools.chain(*new_decoding_order)):\n",
        "                list_a = [item for item in tied_pos if t_dec in item]\n",
        "                if list_a:\n",
        "                    new_decoding_order.append(list_a[0])\n",
        "                else:\n",
        "                    new_decoding_order.append([t_dec])\n",
        "        decoding_order = torch.tensor(list(itertools.chain(*new_decoding_order)), device=device)[None,].repeat(X.shape[0],1)\n",
        "\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        N_batch, N_nodes = X.size(0), X.size(1)\n",
        "        log_probs = torch.zeros((N_batch, N_nodes, 21), device=device)\n",
        "        all_probs = torch.zeros((N_batch, N_nodes, 21), device=device, dtype=torch.float32)\n",
        "        h_S = torch.zeros_like(h_V, device=device)\n",
        "        S = torch.zeros((N_batch, N_nodes), dtype=torch.int64, device=device)\n",
        "        h_V_stack = [h_V] + [torch.zeros_like(h_V, device=device) for _ in range(len(self.decoder_layers))]\n",
        "        constant = torch.tensor(omit_AAs_np, device=device)\n",
        "        constant_bias = torch.tensor(bias_AAs_np, device=device)\n",
        "        omit_AA_mask_flag = omit_AA_mask != None\n",
        "\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for t_list in new_decoding_order:\n",
        "            logits = 0.0\n",
        "            logit_list = []\n",
        "            done_flag = False\n",
        "            for t in t_list:\n",
        "                if (chain_mask[:,t]==0).all():\n",
        "                    S_t = S_true[:,t]\n",
        "                    for t in t_list:\n",
        "                        h_S[:,t,:] = self.W_s(S_t)\n",
        "                        S[:,t] = S_t\n",
        "                    done_flag = True\n",
        "                    break\n",
        "                else:\n",
        "                    E_idx_t = E_idx[:,t:t+1,:]\n",
        "                    h_E_t = h_E[:,t:t+1,:,:]\n",
        "                    h_ES_t = cat_neighbors_nodes(h_S, h_E_t, E_idx_t)\n",
        "                    h_EXV_encoder_t = h_EXV_encoder_fw[:,t:t+1,:,:]\n",
        "                    mask_t = mask[:,t:t+1]\n",
        "                    for l, layer in enumerate(self.decoder_layers):\n",
        "                        h_ESV_decoder_t = cat_neighbors_nodes(h_V_stack[l], h_ES_t, E_idx_t)\n",
        "                        h_V_t = h_V_stack[l][:,t:t+1,:]\n",
        "                        h_ESV_t = mask_bw[:,t:t+1,:,:] * h_ESV_decoder_t + h_EXV_encoder_t\n",
        "                        h_V_stack[l+1][:,t,:] = layer(h_V_t, h_ESV_t, mask_V=mask_t).squeeze(1)\n",
        "                    h_V_t = h_V_stack[-1][:,t,:]\n",
        "                    logit_list.append((self.W_out(h_V_t) / temperature)/len(t_list))\n",
        "                    logits += tied_beta[t]*(self.W_out(h_V_t) / temperature)/len(t_list)\n",
        "            if done_flag:\n",
        "                pass\n",
        "            else:\n",
        "                bias_by_res_gathered = bias_by_res[:,t,:] #[B, 21]\n",
        "                probs = F.softmax(logits-constant[None,:]*1e8+constant_bias[None,:]/temperature+bias_by_res_gathered/temperature, dim=-1)\n",
        "                if pssm_bias_flag:\n",
        "                    pssm_coef_gathered = pssm_coef[:,t]\n",
        "                    pssm_bias_gathered = pssm_bias[:,t]\n",
        "                    probs = (1-pssm_multi*pssm_coef_gathered[:,None])*probs + pssm_multi*pssm_coef_gathered[:,None]*pssm_bias_gathered\n",
        "                if pssm_log_odds_flag:\n",
        "                    pssm_log_odds_mask_gathered = pssm_log_odds_mask[:,t]\n",
        "                    probs_masked = probs*pssm_log_odds_mask_gathered\n",
        "                    probs_masked += probs * 0.001\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                if omit_AA_mask_flag:\n",
        "                    omit_AA_mask_gathered = omit_AA_mask[:,t]\n",
        "                    probs_masked = probs*(1.0-omit_AA_mask_gathered)\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                S_t_repeat = torch.multinomial(probs, 1).squeeze(-1)\n",
        "                for t in t_list:\n",
        "                    h_S[:,t,:] = self.W_s(S_t_repeat)\n",
        "                    S[:,t] = S_t_repeat\n",
        "                    all_probs[:,t,:] = probs.float()\n",
        "        output_dict = {\"S\": S, \"probs\": all_probs, \"decoding_order\": decoding_order}\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "    # I am not seeing an immediate use of this method when the model is called through notebook\n",
        "    # So, will skip further commenting and digging for now\n",
        "    # But, seems like an interesting way of interacting with the model in a specific way, so\n",
        "    # might get back to this later\n",
        "    def conditional_probs(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn, backbone_only=False):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V_enc = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V_enc, h_E = layer(h_V_enc, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Concatenate sequence embeddings for autoregressive decoder\n",
        "        h_S = self.W_s(S)\n",
        "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V_enc, h_EX_encoder, E_idx)\n",
        "\n",
        "\n",
        "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
        "  \n",
        "        chain_M_np = chain_M.cpu().numpy()\n",
        "        idx_to_loop = np.argwhere(chain_M_np[0,:]==1)[:,0]\n",
        "        log_conditional_probs = torch.zeros([X.shape[0], chain_M.shape[1], 21], device=device).float()\n",
        "\n",
        "        for idx in idx_to_loop:\n",
        "            h_V = torch.clone(h_V_enc)\n",
        "            order_mask = torch.zeros(chain_M.shape[1], device=device).float()\n",
        "            if backbone_only:\n",
        "                order_mask = torch.ones(chain_M.shape[1], device=device).float()\n",
        "                order_mask[idx] = 0.\n",
        "            else:\n",
        "                order_mask = torch.zeros(chain_M.shape[1], device=device).float()\n",
        "                order_mask[idx] = 1.\n",
        "            decoding_order = torch.argsort((order_mask[None,]+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "            mask_size = E_idx.shape[1]\n",
        "            permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "            order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "            mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "            mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "            mask_bw = mask_1D * mask_attend\n",
        "            mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "            h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "            for layer in self.decoder_layers:\n",
        "                # Masked positions attend to encoder information, unmasked see. \n",
        "                h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "                h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
        "                h_V = layer(h_V, h_ESV, mask)\n",
        "\n",
        "            logits = self.W_out(h_V)\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "            log_conditional_probs[:,idx,:] = log_probs[:,idx,:]\n",
        "        return log_conditional_probs\n",
        "\n",
        "\n",
        "    # I am not seeing an immediate use of this method when the model is called through notebook\n",
        "    # So, will skip further commenting and digging for now\n",
        "    # But, seems like an interesting way of interacting with the model in a specific way, so\n",
        "    # might get back to this later\n",
        "    def unconditional_probs(self, X, mask, residue_idx, chain_encoding_all):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_V), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "\n",
        "        order_mask_backward = torch.zeros([X.shape[0], X.shape[1], X.shape[1]], device=device)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for layer in self.decoder_layers:\n",
        "            h_V = layer(h_V, h_EXV_encoder_fw, mask)\n",
        "\n",
        "        logits = self.W_out(h_V)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        return log_probs"
      ],
      "metadata": {
        "id": "HjbVWJkg7zik"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 128\n",
        "num_layers = 3 \n",
        "# Seems like, backbone_noise is set to 0 at inference path which seems logical\n",
        "backbone_noise=0.00\n",
        "mpnn_model = ProteinMPNN(num_letters=21, node_features=hidden_dim, edge_features=hidden_dim, hidden_dim=hidden_dim, num_encoder_layers=num_layers, num_decoder_layers=num_layers, augment_eps=backbone_noise, k_neighbors=checkpoint['num_edges'])\n",
        "mpnn_model.to(device)\n",
        "mpnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "mpnn_model.eval()"
      ],
      "metadata": {
        "id": "QBgBJd3J0N_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint['model_state_dict'].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pYLpMQS-ill",
        "outputId": "b59b9615-3cb9-4cfc-ad06-05ad3dfb6491"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['features.embeddings.linear.weight', 'features.embeddings.linear.bias', 'features.edge_embedding.weight', 'features.norm_edges.weight', 'features.norm_edges.bias', 'W_e.weight', 'W_e.bias', 'W_s.weight', 'encoder_layers.0.norm1.weight', 'encoder_layers.0.norm1.bias', 'encoder_layers.0.norm2.weight', 'encoder_layers.0.norm2.bias', 'encoder_layers.0.norm3.weight', 'encoder_layers.0.norm3.bias', 'encoder_layers.0.W1.weight', 'encoder_layers.0.W1.bias', 'encoder_layers.0.W2.weight', 'encoder_layers.0.W2.bias', 'encoder_layers.0.W3.weight', 'encoder_layers.0.W3.bias', 'encoder_layers.0.W11.weight', 'encoder_layers.0.W11.bias', 'encoder_layers.0.W12.weight', 'encoder_layers.0.W12.bias', 'encoder_layers.0.W13.weight', 'encoder_layers.0.W13.bias', 'encoder_layers.0.dense.W_in.weight', 'encoder_layers.0.dense.W_in.bias', 'encoder_layers.0.dense.W_out.weight', 'encoder_layers.0.dense.W_out.bias', 'encoder_layers.1.norm1.weight', 'encoder_layers.1.norm1.bias', 'encoder_layers.1.norm2.weight', 'encoder_layers.1.norm2.bias', 'encoder_layers.1.norm3.weight', 'encoder_layers.1.norm3.bias', 'encoder_layers.1.W1.weight', 'encoder_layers.1.W1.bias', 'encoder_layers.1.W2.weight', 'encoder_layers.1.W2.bias', 'encoder_layers.1.W3.weight', 'encoder_layers.1.W3.bias', 'encoder_layers.1.W11.weight', 'encoder_layers.1.W11.bias', 'encoder_layers.1.W12.weight', 'encoder_layers.1.W12.bias', 'encoder_layers.1.W13.weight', 'encoder_layers.1.W13.bias', 'encoder_layers.1.dense.W_in.weight', 'encoder_layers.1.dense.W_in.bias', 'encoder_layers.1.dense.W_out.weight', 'encoder_layers.1.dense.W_out.bias', 'encoder_layers.2.norm1.weight', 'encoder_layers.2.norm1.bias', 'encoder_layers.2.norm2.weight', 'encoder_layers.2.norm2.bias', 'encoder_layers.2.norm3.weight', 'encoder_layers.2.norm3.bias', 'encoder_layers.2.W1.weight', 'encoder_layers.2.W1.bias', 'encoder_layers.2.W2.weight', 'encoder_layers.2.W2.bias', 'encoder_layers.2.W3.weight', 'encoder_layers.2.W3.bias', 'encoder_layers.2.W11.weight', 'encoder_layers.2.W11.bias', 'encoder_layers.2.W12.weight', 'encoder_layers.2.W12.bias', 'encoder_layers.2.W13.weight', 'encoder_layers.2.W13.bias', 'encoder_layers.2.dense.W_in.weight', 'encoder_layers.2.dense.W_in.bias', 'encoder_layers.2.dense.W_out.weight', 'encoder_layers.2.dense.W_out.bias', 'decoder_layers.0.norm1.weight', 'decoder_layers.0.norm1.bias', 'decoder_layers.0.norm2.weight', 'decoder_layers.0.norm2.bias', 'decoder_layers.0.W1.weight', 'decoder_layers.0.W1.bias', 'decoder_layers.0.W2.weight', 'decoder_layers.0.W2.bias', 'decoder_layers.0.W3.weight', 'decoder_layers.0.W3.bias', 'decoder_layers.0.dense.W_in.weight', 'decoder_layers.0.dense.W_in.bias', 'decoder_layers.0.dense.W_out.weight', 'decoder_layers.0.dense.W_out.bias', 'decoder_layers.1.norm1.weight', 'decoder_layers.1.norm1.bias', 'decoder_layers.1.norm2.weight', 'decoder_layers.1.norm2.bias', 'decoder_layers.1.W1.weight', 'decoder_layers.1.W1.bias', 'decoder_layers.1.W2.weight', 'decoder_layers.1.W2.bias', 'decoder_layers.1.W3.weight', 'decoder_layers.1.W3.bias', 'decoder_layers.1.dense.W_in.weight', 'decoder_layers.1.dense.W_in.bias', 'decoder_layers.1.dense.W_out.weight', 'decoder_layers.1.dense.W_out.bias', 'decoder_layers.2.norm1.weight', 'decoder_layers.2.norm1.bias', 'decoder_layers.2.norm2.weight', 'decoder_layers.2.norm2.bias', 'decoder_layers.2.W1.weight', 'decoder_layers.2.W1.bias', 'decoder_layers.2.W2.weight', 'decoder_layers.2.W2.bias', 'decoder_layers.2.W3.weight', 'decoder_layers.2.W3.bias', 'decoder_layers.2.dense.W_in.weight', 'decoder_layers.2.dense.W_in.bias', 'decoder_layers.2.dense.W_out.weight', 'decoder_layers.2.dense.W_out.bias', 'W_out.weight', 'W_out.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse and create dictionaries for all the mutations in PremPS 2648\n",
        "# This dictionary will be a dictionary of dictionaries, where outer-dict keys will be pdbid+mutchain and inner-dict keys will be (wild+pos+mut) and ddg\n",
        "# the icodes can be brought to picture later\n",
        "# this \"two_level_dict\" is literally used everywhere throughout this code for storing all the numbers that are compared with each other under feature-specific keys\n",
        "git_url = \"https://raw.githubusercontent.com/SajidAhmeduiu/PremPS/main/Datasets/S921/S921.txt\"\n",
        "dataset =  pd.read_csv(git_url,delimiter=\"\\t\")\n",
        "\n",
        "pdbIds = list(dataset[\"PDB Id\"])\n",
        "mutChains = list(dataset[\"Mutated Chain\"])\n",
        "mutations = list(dataset[\"Mutation_PDB\"])\n",
        "ddgs = list(dataset[\"DDGexp\"])\n",
        "\n",
        "two_level_dict = {}\n",
        "\n",
        "for pdbId, mutChain, mutation, ddg in tqdm(zip(pdbIds,mutChains,mutations,ddgs)):\n",
        "    pos = [int(s) for s in re.findall('-?\\d+',mutation)][0]\n",
        "    wild = mutation[0]\n",
        "    mut = mutation[len(mutation)-1]\n",
        "\n",
        "    pdbId = pdbId.lower()\n",
        "\n",
        "    inner_dict = {}\n",
        "    inner_dict[\"mut\"] = f\"{wild}{pos}{mut}\"\n",
        "    inner_dict[\"ddg\"] = float(ddg)\n",
        "    outer_key = f\"{pdbId}{mutChain}\"\n",
        "    if outer_key not in two_level_dict:\n",
        "        two_level_dict[f\"{pdbId}{mutChain}\"] = [inner_dict]\n",
        "    else:\n",
        "        two_level_dict[f\"{pdbId}{mutChain}\"].append(inner_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d9c98b7615384d4f95a9fa447c6d7494",
            "73de468e723c491fa640b34cd5bd36b1",
            "2f7936423ea5498986e8eea89b38f086",
            "25966ccfad5f4dd2a86bc86e6703eebd",
            "0587b488ee534c50acf8af6c84371d0b",
            "48baf9ed6708474f9d29866c3a3bfb93",
            "75b7b720a0484e568d5d4ba226fd4422",
            "bdee9d3fe2674bd8b3c74c4a538f86af",
            "004ea530fa874a39983695bc15ae7c1e",
            "48a7f5daf7424552b169cb2f3e51ebe8",
            "1001b22ebf75495c9a4ed18518403ea1"
          ]
        },
        "id": "vP_unq7_sXrn",
        "outputId": "5025e3a6-c4eb-4419-a677-89afcb236b97"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9c98b7615384d4f95a9fa447c6d7494"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a seqres to position mapping dictionary\n",
        "# This dictionary will be a dictionary of dictionaries, where outer-dict keys will be pdbid+mutchain and inner-dict key will be (wild+pos) and value of 0-indexed position\n",
        "# the icodes can be brought to picture later\n",
        "mapping_dict = {}\n",
        "pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_921_PDB_Files\"\n",
        "parser = PDBParser(QUIET=True)\n",
        "# some proteins need to be skipped for now due to ICODE related discrapency\n",
        "proteins_to_skip = []\n",
        "\n",
        "for filename in tqdm(os.listdir(pdbDirectory)):\n",
        "    filepath = os.path.join(pdbDirectory,filename)\n",
        "    structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "    model = structure[0]\n",
        "    inner_dict = {}\n",
        "    outer_key = filename.split(\".\")[0]\n",
        "    skip_flag = False\n",
        "    # single chain-assumption in action again\n",
        "    for chain in model:\n",
        "        for i,residue in enumerate(chain):\n",
        "            inner_key = f\"{three_to_one(residue.get_resname())}{residue.get_id()[1]}\"\n",
        "            if inner_key not in inner_dict:\n",
        "                inner_dict[inner_key] = i\n",
        "            else:\n",
        "                # For \"2immA:N31\" and \"1lveA:S27\", I have been fucked\n",
        "                # Need to think whether this will effect other positions or I can just avoid these two-protein related mutations for now?\n",
        "                # Let me just avoid these two proteins for now\n",
        "                print(\"YOU HAVE JUST BEEN FUCKED BY ICODE\")\n",
        "                print(f\"{outer_key}:{inner_key}\")\n",
        "                skip_flag = True\n",
        "    # The ICODE related problematic proteins will not be considered for now\n",
        "    if not skip_flag:\n",
        "        mapping_dict[outer_key] = inner_dict\n",
        "    else:\n",
        "        proteins_to_skip.append(outer_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a9e522f1703c4eccbfd25cd25604e5ce",
            "80497dadfc524c0baba6c0bda0ee76bd",
            "362ca61cb38a4183aad5871c37389083",
            "20b0c948d8df4c3ba01248dc0742dd0c",
            "f9510174c1424b86bd3afc87dc18705c",
            "c3767c583b3e447eb59bd4f982096b9a",
            "4a17255037fa41ccb31af94ea9ff23e8",
            "67f48627f650415c8d240162c5debd0f",
            "38e0bb227eb94805b4f00ac0a450bfee",
            "6130ed66ba5945c4841acd359b3d9711",
            "8cde3ac93e504bbf91ba52e66b703c9e"
          ]
        },
        "id": "vxARThyX3VYv",
        "outputId": "15d12611-9114-4c91-ca12-05c2f826583c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/195 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9e522f1703c4eccbfd25cd25604e5ce"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing this \"parse_PDB_biounits()\" function locally for addressing the fucked up integer named chain problem  \n",
        "def parse_PDB_biounits(x, atoms=['N', 'CA', 'C'], chain=None):\n",
        "    '''\n",
        "    input:  x = PDB filename\n",
        "            atoms = atoms to extract (optional)\n",
        "    output: (length, atoms, coords=(x,y,z)), sequence\n",
        "    '''\n",
        "    alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "    states = len(alpha_1)\n",
        "    alpha_3 = ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE',\n",
        "               'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL', 'GAP']\n",
        "\n",
        "    # The following dictionaries are mapping from one-letter to 0-20 index,\n",
        "    # three-letter to 0-20 index,\n",
        "    # 0-20 index to one-letter,\n",
        "    # one-letter to three-letter, and vice-versa\n",
        "    aa_1_N = {a: n for n, a in enumerate(alpha_1)}\n",
        "    aa_3_N = {a: n for n, a in enumerate(alpha_3)}\n",
        "    aa_N_1 = {n: a for n, a in enumerate(alpha_1)}\n",
        "    aa_1_3 = {a: b for a, b in zip(alpha_1, alpha_3)}\n",
        "    aa_3_1 = {b: a for a, b in zip(alpha_1, alpha_3)}\n",
        "\n",
        "    def AA_to_N(x):\n",
        "        # [\"ARND\"] -> [[0,1,2,3]]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 0: x = x[None]\n",
        "        return [[aa_1_N.get(a, states - 1) for a in y] for y in x]\n",
        "\n",
        "    def N_to_AA(x):\n",
        "        # [[0,1,2,3]] -> [\"ARND\"]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 1: x = x[None]\n",
        "        return [\"\".join([aa_N_1.get(a, \"-\") for a in y]) for y in x]\n",
        "\n",
        "    xyz, seq, min_resn, max_resn = {}, {}, 1e6, -1e6\n",
        "    for line in open(x, \"rb\"):\n",
        "        line = line.decode(\"utf-8\", \"ignore\").rstrip()\n",
        "\n",
        "        if line[:6] == \"HETATM\" and line[17:17 + 3] == \"MSE\":\n",
        "            line = line.replace(\"HETATM\", \"ATOM  \")\n",
        "            line = line.replace(\"MSE\", \"MET\")\n",
        "\n",
        "        if line[:4] == \"ATOM\":\n",
        "            ch = line[21:22]\n",
        "            # If the input chain is not in the PDB file, which can be the case if the target chains are named differently in the runner script,\n",
        "            # this line will cause the output to have literally no information, this is the case for integer named chains\n",
        "            # that does not mean that this line is not doing its job correctly, this is just a constraint that input chain names and\n",
        "            # chain names in the PDB file have to be congruent\n",
        "            # If \"ch\" is an integer, map it to alphabet, because input \"chain\" has been converted to alphabet\n",
        "            # In rare cases, some PDB files number chains with 1,2,3 instead of A,B,C\n",
        "            # This \"loc_dict\" dictionary contains integer to alphabet mapping for weird as fuck integer chain names\n",
        "            # This conversion will be done only when  chain name is actually an integer\n",
        "            if ord(ch) >= 49 and ord(ch) <= 57:\n",
        "                loc_dict = {(idx+1):ch for idx,ch in enumerate(ascii_uppercase)}\n",
        "                ch =  str(loc_dict[int(ch)])\n",
        "            if ch == chain or chain is None:\n",
        "                atom = line[12:12 + 4].strip()\n",
        "                resi = line[17:17 + 3]\n",
        "                resn = line[22:22 + 5].strip()\n",
        "                x, y, z = [float(line[i:(i + 8)]) for i in [30, 38, 46]]\n",
        "\n",
        "                if resn[-1].isalpha():\n",
        "                    resa, resn = resn[-1], int(resn[:-1]) - 1\n",
        "                else:\n",
        "                    resa, resn = \"\", int(resn) - 1\n",
        "                #         resn = int(resn)\n",
        "                if resn < min_resn:\n",
        "                    min_resn = resn\n",
        "                if resn > max_resn:\n",
        "                    max_resn = resn\n",
        "                if resn not in xyz:\n",
        "                    xyz[resn] = {}\n",
        "                if resa not in xyz[resn]:\n",
        "                    xyz[resn][resa] = {}\n",
        "                if resn not in seq:\n",
        "                    seq[resn] = {}\n",
        "                if resa not in seq[resn]:\n",
        "                    seq[resn][resa] = resi\n",
        "\n",
        "                if atom not in xyz[resn][resa]:\n",
        "                    xyz[resn][resa][atom] = np.array([x, y, z])\n",
        "\n",
        "    # convert to numpy arrays, fill in missing values\n",
        "    seq_, xyz_ = [], []\n",
        "    try:\n",
        "        for resn in range(min_resn, max_resn + 1):\n",
        "            if resn in seq:\n",
        "                for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k], 20))\n",
        "            else:\n",
        "                seq_.append(20)\n",
        "            if resn in xyz:\n",
        "                for k in sorted(xyz[resn]):\n",
        "                    for atom in atoms:\n",
        "                        if atom in xyz[resn][k]:\n",
        "                            xyz_.append(xyz[resn][k][atom])\n",
        "                        else:\n",
        "                            xyz_.append(np.full(3, np.nan))\n",
        "            else:\n",
        "                for atom in atoms: xyz_.append(np.full(3, np.nan))\n",
        "        return np.array(xyz_).reshape(-1, len(atoms), 3), N_to_AA(np.array(seq_))\n",
        "    except TypeError:\n",
        "        return 'no_chain', 'no_chain'\n",
        "\n",
        "# Took this part out of \"utils.py\", and put here so that smalll changes can be made to address pesky issues like\n",
        "# integer named chain, and shit like those\n",
        "def parse_PDB(path_to_pdb, input_chain_list=None):\n",
        "    c=0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V','W','X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v','w','x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "     \n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list  \n",
        " \n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    # Each of the biounits is a separate PDB file, so for running with a single PDB file like from colab, this loop will be executed only once\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {} \n",
        "        # This loop will be executed only once for single chain DDG type cases\n",
        "        for letter in chain_alphabet:\n",
        "            xyz, seq = parse_PDB_biounits(biounit, atoms=['N','CA','C','O'], chain=letter)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_'+letter]=seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                coords_dict_chain['N_chain_'+letter]=xyz[:,0,:].tolist()\n",
        "                coords_dict_chain['CA_chain_'+letter]=xyz[:,1,:].tolist()\n",
        "                coords_dict_chain['C_chain_'+letter]=xyz[:,2,:].tolist()\n",
        "                coords_dict_chain['O_chain_'+letter]=xyz[:,3,:].tolist()\n",
        "                my_dict['coords_chain_'+letter]=coords_dict_chain\n",
        "                s += 1\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        my_dict['name']=biounit[(fi+1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c+=1\n",
        "    return pdb_dict_list"
      ],
      "metadata": {
        "id": "UzBk27pmlfh7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_func_local(X, mask, eps=1E-6):\n",
        "    mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
        "    dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
        "    D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
        "    D_max, _ = torch.max(D, -1, keepdim=True)\n",
        "    D_adjust = D + (1. - mask_2D) * D_max\n",
        "    top_k = checkpoint[\"num_edges\"]\n",
        "    sampled_top_k = top_k\n",
        "    D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(top_k, X.shape[1]), dim=-1, largest=False)\n",
        "    return D_neighbors, E_idx\n",
        "\n",
        "def return_neighbor_info(X, mask):\n",
        "    b = X[:,:,1,:] - X[:,:,0,:]\n",
        "    c = X[:,:,2,:] - X[:,:,1,:]\n",
        "    a = torch.cross(b, c, dim=-1)\n",
        "    Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "    Ca = X[:,:,1,:]\n",
        "    N = X[:,:,0,:]\n",
        "    C = X[:,:,2,:]\n",
        "    O = X[:,:,3,:]\n",
        "\n",
        "    D_neighbors, E_idx = distance_func_local(Ca, mask)\n",
        "    # Got the indices of the neighbors, E_idx should be the 0-based indexing of the topK closest neighbors\n",
        "    # and D_neighbors should be the distances of those neighbors\n",
        "    return D_neighbors, E_idx"
      ],
      "metadata": {
        "id": "l6pA80oESa7Y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "from scipy.special import kl_div"
      ],
      "metadata": {
        "id": "5mFg99eN_UqM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the PDB files from the directory where the S_2648 PDB Files are stored, and set-them up one by one for featuirization, and passing through the model\n",
        "pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_921_PDB_Files\"\n",
        "parser = PDBParser(QUIET=True)\n",
        "\n",
        "pdbId_info = []\n",
        "pos_info = []\n",
        "neighbor_pos = []\n",
        "neighbor_attention = []\n",
        "neighbor_attention_softmaxed = []\n",
        "neighbor_distances_tracking = []\n",
        "\n",
        "import time\n",
        "\n",
        "np.set_printoptions(suppress=True,precision=2)\n",
        "loc_proteins = []\n",
        "for i,filename in tqdm(enumerate(os.listdir(pdbDirectory))):\n",
        "    #ICODE related problematic proteins will be skipped from analysis for now\n",
        "    if (filename.split(\".\")[0] not in proteins_to_skip):\n",
        "        prot_start = time.time()\n",
        "        print(f\"Prot Processing:{i+1}\")\n",
        "        loc_proteins.append(filename.split(\".\")[0])\n",
        "        filepath = os.path.join(pdbDirectory,filename)\n",
        "        structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "        model = structure[0]\n",
        "        \n",
        "        # Since there is only one chain, and that same chain is both fixed designable for different residues, extracting that name, and putting them in pertinent lists\n",
        "        # taking chainname from filename since one of the files \"1rtpA.pdb\" has chain name with \"1\" instead of \"A\"\n",
        "        # fuck you motherfucking fucked up PDB file submitter. Have you shoved your head into your ass?\n",
        "        chain_name = (filename.split(\".\")[0])[-1]\n",
        "        fixed_chain_list = []\n",
        "        # the trick is to put the single chain as designable chain, and then create the \"fixed_positions_dict\" dictionary  \n",
        "        designed_chain_list = [chain_name]\n",
        "        chain_list = list(set(designed_chain_list + fixed_chain_list))\n",
        "\n",
        "        # Using the programs custome PDB parser for processing the PDB files\n",
        "        pdb_dict_list = parse_PDB(filepath, input_chain_list=chain_list)\n",
        "        # tacking max_length parameter value from the original colab notebook since I need to process all residues at the same time\n",
        "        # all the PDB files can technically be processed together and put inside the dataset_valid list-like object, but right now\n",
        "        # I am trying to keep everything consistent and simple\n",
        "        # Each element of dataset_valid is a dictionary \n",
        "        dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=20000)\n",
        "\n",
        "        # Simplying the sequence generation loop\n",
        "        protein = dataset_valid[0]\n",
        "\n",
        "        wildtype_seq = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        # If there are gaps in the wildtype_seq \"seq\", remove those positions from both the \"seq\", \"\" and ('coords_chain_{designed_chain_list[0]}'), \n",
        "        # and ('seq_chain_{designed_chain_list[0]}') of the \"protein\"\n",
        "        # print(protein.keys())\n",
        "        # protein is a dict with keys(['seq_chain_A', 'coords_chain_A', 'name', 'num_of_chains', 'seq'])\n",
        "        # \"seq_chain\" and \"seq_all\" are both strings of the same length where gapped positions need to be identified and removed\n",
        "        seq_chain = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "        seq_all = protein[f\"seq\"]\n",
        "        # \"coordinates_chain\" is a dict with keys(['N_chain_A', 'CA_chain_A', 'C_chain_A', 'O_chain_A'])\n",
        "        coordinates_chain = protein[f\"coords_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        \n",
        "        # The following four variables are lists of length equal to seq_chain and seq_all length\n",
        "        # Therefore, the gapped positions can be retrived from seq_chain and removed from everything accordingly\n",
        "        N_chain = coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"]\n",
        "        CA_chain = coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"]\n",
        "        C_chain = coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"]\n",
        "        O_chain = coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        # delete everything related to gapped positions now\n",
        "        # at first, find out the positions that are gapped\n",
        "        # these gapped positions are absolutely messed up fucked up artifact of some kind of sophistification \n",
        "        # provided by proteinMPNN, FUCK YOU motherfucking oversmart CODERS\n",
        "        N_chain = [v for i,v in enumerate(N_chain) if seq_chain[i] != \"-\"]\n",
        "        CA_chain = [v for i,v in enumerate(CA_chain) if seq_chain[i] != \"-\"]\n",
        "        C_chain = [v for i,v in enumerate(C_chain) if seq_chain[i] != \"-\"]\n",
        "        O_chain = [v for i,v in enumerate(O_chain) if seq_chain[i] != \"-\"]\n",
        "        seq_all = [v for i,v in enumerate(seq_all) if seq_chain[i] != \"-\"]\n",
        "        seq_chain = [v for i,v in enumerate(seq_chain) if seq_chain[i] != \"-\"]\n",
        "\n",
        "        # Now, finally, pack everything back to the dictionary \"protein\"\n",
        "        protein[f\"seq_chain_{designed_chain_list[0]}\"] = seq_chain\n",
        "        protein[f\"seq\"] = seq_all\n",
        "        coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"] = N_chain\n",
        "        coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"] = CA_chain\n",
        "        coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"] = C_chain\n",
        "        coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"] = O_chain\n",
        "        protein[f\"coords_chain_{designed_chain_list[0]}\"] = coordinates_chain\n",
        "\n",
        "        # At this point, probably need to put None values in a lot of parameters that are not relevant to my usecase, but need to be sent to featurizer before running model forward\n",
        "        # For now, I will not tie positions together\n",
        "        tied_positions_dict = None\n",
        "        pssm_dict = None\n",
        "        omit_AA_dict = None\n",
        "        bias_AA_dict = None\n",
        "        tied_positions_dict = None\n",
        "        bias_by_res_dict = None\n",
        "        alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "        bias_AAs_np = np.zeros(len(alphabet))\n",
        "\n",
        "        chain_id_dict = {}\n",
        "        chain_id_dict[pdb_dict_list[0]['name']]= (designed_chain_list, fixed_chain_list)\n",
        "\n",
        "        BATCH_COPIES = 1\n",
        "\n",
        "        batch_clones = [copy.deepcopy(protein) for i in range(BATCH_COPIES)]\n",
        "\n",
        "        # \"muts_for_prot\" is a list with information about all the mutations in \"protein\", whose sequence only version is \"wildtype_seq\" \n",
        "        muts_for_prot = two_level_dict[filename.split(\".\")[0]]\n",
        "        # \"cur_map_dict\" will give the 0-based sequence index for the mutations, which will be almost directly used for masking and then running the model\n",
        "        # 1-based indexing needed for the fixed position\n",
        "        cur_map_dict = mapping_dict[filename.split(\".\")[0]]\n",
        "\n",
        "        for mut_track,mut in enumerate(muts_for_prot):\n",
        "            print(f\"Processing_Mut:{mut_track+1}, From_Prot:{i+1}\")\n",
        "            wild_aa = mut[\"mut\"][0]\n",
        "            alternate_aa = mut[\"mut\"][-1]\n",
        "            # (+1) because we need to pass 1-based indexing to tied_featurize() method\n",
        "            seq_pos = cur_map_dict[mut[\"mut\"][0:-1]] + 1\n",
        "            # only need to mask the mutated position position in \"wildtype_seq\" for now\n",
        "            fixed_positions_dict = {}\n",
        "            fixed_positions_dict[protein[\"name\"]] = {}\n",
        "            f_list = []\n",
        "            for ind_fixed in range(0,len(seq_chain)):\n",
        "                if (ind_fixed + 1) not in [seq_pos]:\n",
        "                    f_list.append(ind_fixed + 1)\n",
        "            fixed_positions_dict[protein[\"name\"]][filename.split(\".\")[0][-1]] = f_list\n",
        "\n",
        "            # finally, had to take chain-name from filename instead of biopython parsing to get rid of chain-name with \"1\" instead of \"A\" in \"1rtpA.pdb\"\n",
        "            X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "            omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "            = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "            randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "            log_probs, decoder_messages, node_embedding_info = mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "            # Adding the log_probs to the same inner dictionary where DDG values exist for easier comparison\n",
        "            mut[\"log_prob\"] = log_probs.cpu().data.numpy()\n",
        "            \n",
        "            # the top_k attention weights will be stored here for weighted sum later\n",
        "            # \"seq_pos\" is 1-based since \"fixed_positions_dict\" above needs to hold 1-based indices for the mutation,\n",
        "            # but accessing the tensors will require 0-based indexing\n",
        "            seq_index = seq_pos - 1\n",
        "            # \"dim = 1\", because decoder_messages[0,seq_index,:,:] should be (48,128), and we want to take norm of each of the 48 vectors across the last dimension,\n",
        "            # get 48 norm values, and fetch out the k highest values from there\n",
        "            message_norms = (torch.linalg.vector_norm(x=decoder_messages[0,seq_index,:,:],ord=2,dim=1))\n",
        "            local_distances, local_neighbors = return_neighbor_info(X, mask)\n",
        "            # \"top_k_attended_neighbor_indices\" is the indices from [0,47] corresponding to the highest attended neighbors\n",
        "            # top_(k-1) can technically be extracted from top_k, but currently just for simplicity and easier debugging, extracting everything separately\n",
        "            top_15_attention_vals, top_15_attended_neighbor_indices = torch.topk(message_norms,k=15)\n",
        "            top_10_attention_vals, top_10_attended_neighbor_indices = torch.topk(message_norms,k=10)\n",
        "            top_5_attention_vals, top_5_attended_neighbor_indices = torch.topk(message_norms,k=5)\n",
        "            # now, using \"local_neighbors\" to get the original indices of the neighbors corresponding to the top_k attended positions\n",
        "            # taking both top_5 and top_10 for now\n",
        "            top_15_attended_neighbor_indices = local_neighbors[0,seq_index,top_15_attended_neighbor_indices]\n",
        "            top_10_attended_neighbor_indices = local_neighbors[0,seq_index,top_10_attended_neighbor_indices]\n",
        "            top_5_attended_neighbor_indices = local_neighbors[0,seq_index,top_5_attended_neighbor_indices]\n",
        "            top_15_closest_neighbor_indices = local_neighbors[0,seq_index,1:16]\n",
        "            top_10_closest_neighbor_indices = local_neighbors[0,seq_index,1:11]\n",
        "            mut[\"top_15_attention_weights\"] = top_15_attention_vals.cpu().data.numpy()\n",
        "            mut[\"top_10_attention_weights\"] = top_10_attention_vals.cpu().data.numpy()\n",
        "            mut[\"top_5_attention_weights\"] = top_5_attention_vals.cpu().data.numpy()\n",
        "            # the neighbor indices corresponding to the top_k attention weights will be stored here for entropy calculation later\n",
        "            # 0-based indices of the neighbors will be saved so that corresponding log-probability vectors can be extracted readily from \"log_prob\" keyed value\n",
        "            mut[\"top_15_neighbor_indices\"] = top_15_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_10_neighbor_indices\"] = top_10_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_5_neighbor_indices\"] = top_5_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_15_closest_neighbor_indices\"] = top_15_closest_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_10_closest_neighbor_indices\"] = top_10_closest_neighbor_indices.cpu().data.numpy()\n",
        "\n",
        "            # The lines below are mostly for printing purposes to do external analysis with PyMol,and ROSETTA with Cristina\n",
        "            loc_pos_scores = []\n",
        "            for enum_val,(neighbor_p, neighbor_s, neighbor_distance) in enumerate(zip(local_neighbors[0,seq_index,1:15].cpu().data.numpy(),\n",
        "                                                                 (torch.linalg.vector_norm(x=decoder_messages[0,seq_index,1:15,:],ord=2,dim=1)).cpu().data.numpy(),\n",
        "                  \n",
        "                                                               local_distances[0,seq_index,1:15].cpu().data.numpy())):\n",
        "                # skippoing the first neighbor since it is the mutated position itself\n",
        "                if enum_val == 0:\n",
        "                    continue\n",
        "                pdbId_info.append(filename)\n",
        "                pos_info.append(seq_index+1)\n",
        "                neighbor_pos.append(neighbor_p+1)\n",
        "                neighbor_attention.append(neighbor_s)\n",
        "                loc_pos_scores.append(neighbor_s)\n",
        "                neighbor_distances_tracking.append(neighbor_distance)\n",
        "            # since softmax has to be done over all the neighbors, taking the softmax, and later adding it to the data generation list after\n",
        "            # neighbor enumeration loop\n",
        "            loc_pos_scores = softmax(np.array(loc_pos_scores))\n",
        "            for s in loc_pos_scores:\n",
        "                neighbor_attention_softmaxed.append(s)\n",
        "\n",
        "            # take (\"neighbor_attention\"-weighted sum/average) of the entropies of the top 5 attended neighbors\n",
        "            # are the neighbors with highest message passing values always among the closest 10?\n",
        "            # point to be noted that the closest, therefore the first neighbor of every position is the neighbor itself\n",
        "            # check correlation between distance and attention values since a possible manual edge feature would be distance\n",
        "            # let us see if the model attends to distant neighbors more, or attention value is inversely proportional to distance?\n",
        "            # take L2-norms of the message vectors instead of attention\n",
        "            # take the softmax of L2-norms to approximate attention, although technically the positions are not constrained by each other, this can be considered a sigmoid attention\n",
        "            # where having neighbors with large messages will effect differently than having neighbors with small messages\n",
        "            # can this be correlated with position-entropy?\n",
        "            # the L2-norms should be able to approximate how much each of the neighbors are effecting the mutated position\n",
        "            # This information can be stored for checking the effect of center mutation on those positions afterwards\n",
        "            # Identify major interacting partners (neighbors that are important for center prediction, and also which take center into consideration for its own prediction)\n",
        "            # then check how much the major neighbor position deviates from wildtype due to the mutation\n",
        "            # another much more simples thing can be to check the deviation for top 10 neighbors\n",
        "            # this deviation can be calculated using the log(W) for the neighbor before center mutation, and log(W) for the neighbor after center mutation \n",
        "\n",
        "            # Now, take top_k most attended positions, make them designable, mutate center, and take change in -log(p) of the wildtype at each of the neighbor positions\n",
        "            # take weighted sum of these neighbor energy changes, see if there is any correlation\n",
        "            # next, go for \"strong\" neighbor positions (both way strong attention)\n",
        "            # Many of the tensors will take on new values after running the model again with different fixed positions\n",
        "            \n",
        "            # the \"fixed_positions_dict\" has to be repopulated now since neighbor positions will be masked one by one\n",
        "            # here, \"n_ind\" is the 0-based index corresponding to one of the \"top_k\" attended neighbors \n",
        "            # these lists will contain the log_probabilities for the top_k most attended neighbors serially\n",
        "            # before and after making the center mutation currently at hand, these probabilities will be used later for calculating\n",
        "            # attention_weighted change in neighbor_wildtype probability, attention_weighted_change in KL, and all those things \n",
        "            neighbor_w_log_probs = []\n",
        "            neighbor_m_log_probs = []\n",
        "            # the following array will contain the identities of the neighbors serially so that specific wildtype neighbor positions in the probability\n",
        "            # distribution can be extracted later\n",
        "            neighbor_aa_identities = []\n",
        "            # \"top5\" and \"top10\" should be extractable from \"top15\", since the neighbor\n",
        "            neighbor_w_message_vector_coming_from_center = []\n",
        "            neighbor_m_message_vector_coming_from_center = []\n",
        "            # I will pick out the neighbor embeddings, and put them inside the lists below\n",
        "            # But, do I need to access them one by one, or can I just take a slice out of the embedding tensor across the seq_pos dimension?\n",
        "            # what more information will I get if I fetch out the embeddings one by one?\n",
        "            # if I want to do a slicing, I might have to make all the neighbors designable at the same time, which will \n",
        "            # for one, I can take out the embeddings for each of the neighbors while they are designable, before and \n",
        "            # okay, lets say we will fetch the neighbors out, one by one; we can do that right inside the next loop\n",
        "            # what will be the significance of those neighbor embeddings, in that case?\n",
        "            # they will see everything around them, expcept the mutated position, will they change much due to that?\n",
        "            # neighbor embedding difference in that case might actually catch something about the new interactions that have\n",
        "            # been formed, interesting...very, very interesting\n",
        "            neighbor_w_embedding_info = []\n",
        "            neighbor_m_embedding_info = [] \n",
        "            # informations are stored serially in the lists\n",
        "            for n_ind in mut[\"top_15_neighbor_indices\"]:\n",
        "                neighbor_aa_identities.append(seq_chain[n_ind])\n",
        "                # Some sequence-input manipulation is done later in this loop, so the wildtype aa is placed in the position, so that\n",
        "                # previous iteration manipulations do not cause trouble in this iteration\n",
        "                alpha_tok = \"ACDEFGHIKLMNPQRSTVWYX\"\n",
        "                aa_1_N = {a:n for n,a in enumerate(alpha_tok)}\n",
        "                aa_N_1 = {n:a for n,a in enumerate(alpha_tok)}\n",
        "\n",
        "                # adding (+1) to n_ind, since fixed positions are 1-indexed in the original implementation\n",
        "                n_pos = n_ind + 1  \n",
        "                fixed_positions_dict = {}\n",
        "                fixed_positions_dict[protein[\"name\"]] = {}\n",
        "                f_list = []\n",
        "                for ind_fixed in range(0,len(seq_chain)):\n",
        "                    # Fixing everything except the \"n_pos\" neighbor position\n",
        "                    if (ind_fixed + 1) not in [n_pos]:\n",
        "                        f_list.append(ind_fixed + 1)\n",
        "                fixed_positions_dict[protein[\"name\"]][filename.split(\".\")[0][-1]] = f_list\n",
        "\n",
        "                # Extracting \"n_ind\" 21-way log probabilities when the center is wildtype \n",
        "                X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "                omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "                = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "                randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "\n",
        "                # we want to store the 128-length message vector coming from the center to the neighbor at \"n_ind\"\n",
        "                # for this, at first, we need to find which neighbor of \"n_ind\" is our center so that we can pull out the message vector coming from \n",
        "                # the center to the neighbor at \"n_ind\" \n",
        "                loc_local_distances, loc_local_neighbors = return_neighbor_info(X, mask)\n",
        "                # \"neighbor_neighbor_index\" is the index of the center with respect to the neighbor at \"n_ind\"\n",
        "                # if len(neighbor_neighbor_index) is 0, center is not among the spatially close 48 neighbors of the neighbor at \"n_ind\"\n",
        "                # in that case, message vector passed from center to that neighbor can be considered as a 128 length all 0 vector for now\n",
        "                # for now, it is important to note that if len(neighbor_neighbor_index) is not zero, then the index can be retrived by neighbor_neighbor_index[0][0]  \n",
        "                neighbor_neighbor_index = (loc_local_neighbors[0,n_ind,:] == seq_index).nonzero(as_tuple=False)\n",
        "                neighbor_neighbor_index =  neighbor_neighbor_index[0][0] if (len(neighbor_neighbor_index) == 1) else torch.tensor(-1,device=neighbor_neighbor_index.device)\n",
        "\n",
        "                # calling \"mpnn_model\" \"forward\" function three times below for getting the three tensors is definitely not efficient,\n",
        "                # but, doing it this way for now, since I am getting CUDA out-of-memory errors due to some unsolved (for now) reason   \n",
        "                n_log_probs  = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[0][0,n_ind,:].cpu().data.numpy()\n",
        "                decoder_message = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[1][0,n_ind,neighbor_neighbor_index,:].cpu().data.numpy()\n",
        "                node_embedding_info = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[2][0,n_ind,:].cpu().data.numpy()\n",
        "\n",
        "                neighbor_w_log_probs.append(n_log_probs)\n",
        "                neighbor_w_embedding_info.append(node_embedding_info)\n",
        "\n",
        "                if neighbor_neighbor_index >= 0:\n",
        "                    neighbor_w_message_vector_coming_from_center.append(decoder_message)\n",
        "                else:\n",
        "                    # Adding all-0 vector of length 128 if the center is not among the closest 48 neighbors of center\n",
        "                    neighbor_w_message_vector_coming_from_center.append(np.zeros(128)) \n",
        "                 \n",
        "                # Now, make mutation, and process the corresponding probabilities\n",
        "                X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "                omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "                = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "                randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "                # seems like passing mutant sequence through the model will be a bit more difficult that expected since PDB file is read in by the underlying parser\n",
        "                # How, do I only change the amino acids identity in the sequence, but keep the PDB backbone and everything same?\n",
        "                # At first, just try to manipulate the input \"S\"\n",
        "                S[0,seq_index] = aa_1_N[alternate_aa]\n",
        "                n_log_probs  = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[0][0,n_ind,:].cpu().data.numpy()\n",
        "                decoder_message = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[1][0,n_ind,neighbor_neighbor_index,:].cpu().data.numpy()\n",
        "                node_embedding_info = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[2][0,n_ind,:].cpu().data.numpy()\n",
        "\n",
        "                neighbor_m_log_probs.append(n_log_probs)\n",
        "                neighbor_m_embedding_info.append(node_embedding_info)\n",
        "\n",
        "                if neighbor_neighbor_index >= 0:\n",
        "                    neighbor_m_message_vector_coming_from_center.append(decoder_message)\n",
        "                else:\n",
        "                    # Adding all-0 vector of length 128 if the center is not among the closest 48 neighbors of center\n",
        "                    neighbor_m_message_vector_coming_from_center.append(np.zeros(128))           \n",
        "            mut[\"w_n_log_prob\"] = neighbor_w_log_probs\n",
        "            mut[\"m_n_log_prob\"] = neighbor_m_log_probs\n",
        "            mut[\"neighbor_aa_identities\"] = neighbor_aa_identities\n",
        "            mut[\"neighbor_w_message_vector_coming_from_center\"] = neighbor_w_message_vector_coming_from_center\n",
        "            mut[\"neighbor_m_message_vector_coming_from_center\"] = neighbor_m_message_vector_coming_from_center\n",
        "            mut[\"neighbor_w_neighbor_embedding\"] = neighbor_w_embedding_info\n",
        "            mut[\"neighbor_m_neighbor_embedding\"] = neighbor_m_embedding_info\n",
        "        prot_end = time.time()\n",
        "        print(f\"Took {prot_end-prot_start} for {filename} with {mut_track+1} forward-mutations\")\n",
        "        print(\"....................\")"
      ],
      "metadata": {
        "id": "b8cEsTK1EQ9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Save the incomplete \"two_level_dict\" as pickle file for a quick dirty comparison\n",
        "# import pickle\n",
        "# with open(\"S_921_pmppn_info_dict_V2.pickle\",\"wb\") as f:\n",
        "#     pickle.dump(two_level_dict,f)"
      ],
      "metadata": {
        "id": "rXvc5PDmIQyF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# with open(\"S_921_pmppn_info_dict_V2.pickle\",\"rb\") as f:\n",
        "#     two_level_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "T8iPDaqrZg4U"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import entropy\n",
        "from scipy.special import expit\n",
        "alpha_list = list(\"ACDEFGHIKLMNPQRSTVWYX\")\n",
        "# The following dictionary will be used for fetching out the log-probabilities corresponding to the wild-type and mutated residues at the mutation positions\n",
        "aa_to_N = {a:n for n,a in enumerate(alpha_list)}\n",
        "# This list will contain the experimental ddg values for the mutations for which two-level dict contains information regarding log_probabilities\n",
        "true_vals = []\n",
        "# This list will contain (wild_proba,mut_proba) tuples for the mutations for which two-level dict contains information regarding log_probabilities\n",
        "wild_mut_log_probabilities = []\n",
        "# saving max probabilites for debugging\n",
        "max_log_probabilities = []\n",
        "# Want to add entropy of the position with some kind of weight (maybe, just a for loop for checking weight combinations that sum to 1?)\n",
        "position_entropies = []\n",
        "weighted_neighbor_entropies = []\n",
        "# This \"weighted_neighbor_energy_changes\" will be ((-log(m))-(-log(w))) for each of the topk neighbors, weighted summed by corresponding attention weights   \n",
        "weighted_neighbor_energy_changes = []\n",
        "#\n",
        "backward_weighted_neighbor_energy_changes = []\n",
        "V2_backward_weighted_neighbor_energy_changes = []\n",
        "# the neighbor-forward-KL will at this point treat the center-wildtype conditioned neighbor distributions as true, \n",
        "# and center-mutated conditioned neighbor distributions as approximation\n",
        "weighted_neighbor_forward_KL = []\n",
        "# the neighbor-backward-KL will treat the center-mutated conditioned neighbor distributions as true, \n",
        "# and center-wildtype conditioned neighbor distributions as approximation\n",
        "weighted_neighbor_backward_KL = []\n",
        "#\n",
        "backward_weighted_neighbor_backward_KL = []\n",
        "V2_backward_weighted_neighbor_backward_KL = []  \n",
        "# # This \"weighted_neighbor_entropy_changes\" will be ((entropy(p(nieghbor|m))-(entropy(p(nieghbor|w))) for each of the topk neighbors, weighted summed by corresponding attention weights \n",
        "weighted_neighbor_entropy_changes = []\n",
        "## the weights will now be based on change in center->neighbor message vector L2-norm due to mutation, instead of neighbor->center message norm \n",
        "## however, I think a softmaxing across all those weights will now be a must since scales could be crazily different\n",
        "backward_weighted_neighbor_entropy_changes = []\n",
        "V2_backward_weighted_neighbor_entropy_changes = []\n",
        "# the two arrays below are being saved for checking correlations of (m/w) and (w/m) attention weight changes to ddgs\n",
        "# this debugging-type correlation analysis could reveal significant insights into the best weighing mechanism, and even provide a way to differentiate\n",
        "# between neighbors that have established new connections with the center, and neighbors whose connections with the center has been severed (kinda severed,maybe or weakened?..whatever)  \n",
        "center_neighbor_weight_check_m_w = []\n",
        "center_neighbor_weight_check_w_m = []\n",
        "\n",
        "# putting the dictionary here since we are going to need positions corresponding to alternate amino acid 1-letter codes\n",
        "alpha_tok = \"ACDEFGHIKLMNPQRSTVWYX\"\n",
        "aa_1_N = {a:n for n,a in enumerate(alpha_tok)}\n",
        "for i,(prot,muts) in enumerate(two_level_dict.items()):\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for ind_track, mut in enumerate(muts):\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            # where the fuck is \"log_prob\" coming from, but \"top_5_attention_weights\" and \"top_5_neighbor_indices\" are not there?\n",
        "            if (\"log_prob\" in mut) and (\"w_n_log_prob\" in mut):\n",
        "                wild = mut[\"mut\"][0] \n",
        "                alternate = mut[\"mut\"][-1]\n",
        "                true_vals.append(mut[\"ddg\"])\n",
        "                sequence_index_of_mutation = cur_map_dict[mut[\"mut\"][0:-1]]\n",
        "                position_log_probabilities = mut[\"log_prob\"][0,sequence_index_of_mutation,:]\n",
        "                wild_mut_log_probabilities.append((position_log_probabilities[aa_to_N[wild]],position_log_probabilities[aa_to_N[alternate]]))\n",
        "                max_log_probabilities.append(position_log_probabilities.max())\n",
        "                position_entropies.append(entropy(np.exp(position_log_probabilities)))\n",
        "                # These 0-based neighbor indices will be used for extracting the log-probabilities corresponding to the neighbor positions\n",
        "                n_indices= mut[\"top_15_neighbor_indices\"]\n",
        "                # The neighbor weights will be used here for multiplying \n",
        "                n_weights = mut[\"top_15_attention_weights\"].reshape(-1,1)\n",
        "                # Take entropy while taking care of the dimension along which entropy is calculated\n",
        "                # Taking entropy across last axis, because the shape of the input is (k,21), where 21 is the 21-way probability distribution \n",
        "                n_entropies = entropy(np.exp(mut[\"log_prob\"][0,n_indices,:]),axis=-1).reshape(-1,1)\n",
        "                # I think this element-wise product is getting wrong \n",
        "                weighted_neighbor_entropies.append((n_entropies*softmax(n_weights)).sum())\n",
        "                # weighted_neighbor_entropies.append((n_entropies*softmax(n_weights)).sum())\n",
        "                # weighted_neighbor_entropies.append((n_entropies*n_weights).sum())\n",
        "\n",
        "                # Now, calculate neighbor energy changes, and then weighted sum them after extracting specific log_probabilities\n",
        "                # for mutant center, and wildtype center impacted versions for the top neighbor positions\n",
        "                neighbor_w_log_probabilities = mut[\"w_n_log_prob\"]\n",
        "                neighbor_m_log_probabilities = mut[\"m_n_log_prob\"]\n",
        "                neighbor_amino_a_identities = mut[\"neighbor_aa_identities\"]\n",
        "                neighbor_w_message_vector_coming_from_center = mut[\"neighbor_w_message_vector_coming_from_center\"]\n",
        "                neighbor_m_message_vector_coming_from_center = mut[\"neighbor_m_message_vector_coming_from_center\"]\n",
        "                neighbor_w_neighbor_embedding = mut[\"neighbor_w_neighbor_embedding\"]\n",
        "                neighbor_m_neighbor_embedding = mut[\"neighbor_m_neighbor_embedding\"]\n",
        "                # The \"local_neighbor_log_prob_vals\" will be a list of negative log-probability differences(a.k.a. energy differences)\n",
        "                local_neighbor_log_prob_vals = []\n",
        "                local_neighbor_forward_KL_vals = []\n",
        "                local_neighbor_backward_KL_vals = []\n",
        "                local_neighbor_entropy_change_vals = []\n",
        "                local_neighbor_attention_change_vals = []\n",
        "                # the two lists below are for debugging, and insight-revelation purposes, mostly\n",
        "                local_center_neighbor_weight_check_m_w = []\n",
        "                local_center_neighbor_weight_check_w_m = []\n",
        "                # the \"local_neighbor_embedding_changes\" list below will hold (neighbor_m_embedding/neighbor_w_embedding) arrays of length 128\n",
        "                # so, technically, this list can be converted to a (15,128) 2D numpy array\n",
        "                # all those (15,128) numpy arrays will later be concatenated across axis-0 before taking the PCA in the next cell\n",
        "                local_neighbor_embedding_changes = []\n",
        "                local_neighbor_embedding_changes_raw = []\n",
        "                # the vector below is very similar to (w/m), but L2 norm is taken on the difference vector\n",
        "                local_center_neighbor_message_change_diff = []\n",
        "                # For example, selecting the numbers from the first 5 iterations of this loop will give neighbor energy change corresponding to the first 5 neighbors\n",
        "                for neighbor_w, neighbor_m, neighbor_aa, neighbor_w_message, neighbor_m_message, neighbor_w_embedding, neighbor_m_embedding  in \\\n",
        "                zip(neighbor_w_log_probabilities,neighbor_m_log_probabilities,neighbor_amino_a_identities,neighbor_w_message_vector_coming_from_center,neighbor_m_message_vector_coming_from_center,\n",
        "                    neighbor_w_neighbor_embedding,neighbor_m_neighbor_embedding):\n",
        "                    # get the amino acid identity for the neighbor position, run it through the mapping dictionary, get the log probabilities from those positions,\n",
        "                    # \"neighbor_w\" and \"neighbor_m\" arrays will directly give the log probabilities that need to be substracted to get the energy (put (-1) before thoese numbers?...think a bit)\n",
        "                    neighbor_index = aa_1_N[neighbor_aa]\n",
        "                    local_neighbor_log_prob_vals.append((-1*neighbor_m[neighbor_index])-(-1*neighbor_w[neighbor_index]))\n",
        "                    # summing the output of \"kl_div\", because one number comes for every positions in the currently processing neighbor distribution,\n",
        "                    # and I want to take the total deviation in that distribution \n",
        "                    local_neighbor_forward_KL_vals.append(kl_div(np.exp(neighbor_w),np.exp(neighbor_m)).sum())\n",
        "                    local_neighbor_backward_KL_vals.append(kl_div(np.exp(neighbor_m),np.exp(neighbor_w)).sum())\n",
        "                    local_neighbor_entropy_change_vals.append(entropy(np.exp(neighbor_m))-entropy(np.exp(neighbor_w)))\n",
        "                    # lets just put the absolute value of the difference between the L2-norms for now (taking sign into consideration will require\n",
        "                    # taking care of the correct direction of change, which might make things a bit ncomplicated for now, and have unintended effects)\n",
        "                    # But, having a direction can definitely help with stabilization vs. de-stabilization figuring out\n",
        "                    # some kind of \n",
        "                    # usiung only the norm would more like predict the magnitude of DDG\n",
        "                    # local_neighbor_attention_change_vals.append()\n",
        "                    neighbor_w_message = neighbor_w_message.reshape((-1,1))\n",
        "                    neighbor_m_message = neighbor_m_message.reshape((-1,1))\n",
        "                    # Adding the small numbers for numerical stability, which hopefully will not change the information content of these features\n",
        "                    neighbor_w_message_norm = np.linalg.norm(neighbor_w_message,ord=2,axis=0) + 0.00000001\n",
        "                    neighbor_m_message_norm = np.linalg.norm(neighbor_m_message,ord=2,axis=0) + 0.00000001\n",
        "                    # taking average of two ratios for kind of capturing the change in both (mutant->wild) and (wild->mutant) directions with the same measure \n",
        "                    # the ratio should help to avoid any neighbor to neighbor variability related-scale\n",
        "                    # but scale could also be important, right? since, the same transformation is applied for calculating the numbers for every position in the proteins \n",
        "                    # local_neighbor_attention_change_vals.append((0.5*(neighbor_w_message_norm/neighbor_m_message_norm))+(0.5*(neighbor_m_message_norm/neighbor_w_message_norm)))\n",
        "                    local_neighbor_attention_change_vals.append((neighbor_w_message_norm/neighbor_m_message_norm))\n",
        "                    # the two list-appending lines below are mostly for debugging purposes at the moment,\n",
        "                    # might be something more than that in a few minutes?\n",
        "                    local_center_neighbor_weight_check_m_w.append(neighbor_m_message_norm/neighbor_w_message_norm)\n",
        "                    local_center_neighbor_weight_check_w_m.append(neighbor_w_message_norm/neighbor_m_message_norm)\n",
        "                    # can take PCA of the below as well\n",
        "                    # currently, taking the norm of division vector (-1 to discourage (+1) from contributing to the norm)\n",
        "                    # local_neighbor_embedding_changes.append(np.linalg.norm((neighbor_m_embedding/neighbor_w_embedding)))\n",
        "                    # local_neighbor_embedding_changes.append(neighbor_m_embedding/neighbor_w_embedding)\n",
        "                    # local_neighbor_embedding_changes.append(neighbor_w_embedding)\n",
        "                    local_neighbor_embedding_changes.append(np.linalg.norm(neighbor_w_embedding-neighbor_m_embedding))\n",
        "                    local_neighbor_embedding_changes_raw.append(neighbor_w_embedding-neighbor_m_embedding)\n",
        "                    local_center_neighbor_message_change_diff.append(np.linalg.norm(neighbor_w_message-neighbor_m_message))\n",
        "                # The energy change approximation can be constrained to the top few neighbors by just indexing the arrays below\n",
        "                # So, it looks like a better idea to save log_probs for atleast the top_20 neighbors since we can always fetch the first few from there\n",
        "                weighted_neighbor_energy_changes.append((np.array(local_neighbor_log_prob_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_forward_KL.append((np.array(local_neighbor_forward_KL_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_backward_KL.append((np.array(local_neighbor_backward_KL_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_entropy_changes.append((np.array(local_neighbor_entropy_change_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                # versions of neighbor features, just weighted by backward weights (center->neighbor attention change due to mutation) instead of forward weights (neighbor->center attention)\n",
        "                # sum() of these (m/w) weight-change is apparently positively correlated with DDGs\n",
        "                backward_weighted_neighbor_energy_changes.append((np.array(local_neighbor_log_prob_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_m_w))[0:15])).sum())\n",
        "                backward_weighted_neighbor_backward_KL.append((np.array(local_neighbor_backward_KL_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_m_w))[0:15])).sum())\n",
        "                backward_weighted_neighbor_entropy_changes.append(((np.array(local_neighbor_entropy_change_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_m_w)))[0:15]).sum()))\n",
        "                # the two list-appending lines below are mostly for debugging purposes at the moment,\n",
        "                # might be something more than that in a few minutes?\n",
        "                center_neighbor_weight_check_m_w.append(np.array(local_center_neighbor_weight_check_m_w).sum())\n",
        "                center_neighbor_weight_check_w_m.append(np.array(local_center_neighbor_weight_check_w_m).sum())\n",
        "                # now, let us add features weighted by the other version of attention changes\n",
        "                # sum() of these (w/m) weight-change is apparently negatievly correlated with DDGs\n",
        "                V2_backward_weighted_neighbor_energy_changes.append((np.array(local_neighbor_log_prob_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_w_m))[0:15])).sum())\n",
        "                V2_backward_weighted_neighbor_backward_KL.append((np.array(local_neighbor_backward_KL_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_w_m))[0:15])).sum())\n",
        "                V2_backward_weighted_neighbor_entropy_changes.append(((np.array(local_neighbor_entropy_change_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_w_m)))[0:15]).sum()))\n",
        "\n",
        "\n",
        "                # let us also save the features in the \"mut\" dictionary, so that \"two_letter_dict\" containing all the features for every mutation\n",
        "                # can be saved after this cell in pickle format, and later be accessed from any other script\n",
        "                # print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "                # print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "                # energies (negative log probabilities of the most_probable,wild,and mutated residue, respectively, at the center position)\n",
        "                e_max = (-1*(max_log_probabilities[-1]))\n",
        "                e_wild = (-1*((wild_mut_log_probabilities[-1])[0]))\n",
        "                e_mut = (-1*((wild_mut_log_probabilities[-1])[1]))\n",
        "                mut[\"center_mut_wild_energy\"] = e_mut - e_wild \n",
        "                mut[\"center_mut_max_energy\"] = e_mut - e_max\n",
        "                mut[\"center_entropy\"] = (position_entropies[-1] * (-1))\n",
        "                mut[\"weighted_neighbor_entropies\"] = weighted_neighbor_entropies[-1] \n",
        "                mut[\"weighted_neighbor_energy_changes\"] = weighted_neighbor_energy_changes[-1]\n",
        "                mut[\"backward_weighted_neighbor_energy_changes\"] = backward_weighted_neighbor_energy_changes[-1]\n",
        "                mut[\"V2_backward_weighted_neighbor_energy_changes\"] = V2_backward_weighted_neighbor_energy_changes[-1]\n",
        "                mut[\"weighted_neighbor_forward_KL\"] = weighted_neighbor_forward_KL[-1] \n",
        "                mut[\"weighted_neighbor_backward_KL\"] = weighted_neighbor_backward_KL[-1]\n",
        "                mut[\"backward_weighted_neighbor_backward_KL\"] = backward_weighted_neighbor_backward_KL[-1]\n",
        "                mut[\"V2_backward_weighted_neighbor_backward_KL\"] = V2_backward_weighted_neighbor_backward_KL[-1]  \n",
        "                mut[\"weighted_neighbor_entropy_changes\"] = weighted_neighbor_entropy_changes[-1]\n",
        "                mut[\"backward_weighted_neighbor_entropy_changes\"] = backward_weighted_neighbor_entropy_changes[-1]\n",
        "                mut[\"V2_backward_weighted_neighbor_entropy_changes\"] = V2_backward_weighted_neighbor_entropy_changes[-1]  \n",
        "                mut[\"center_neighbor_weight_check_m_w\"] = center_neighbor_weight_check_m_w[-1]\n",
        "                mut[\"center_neighbor_weight_check_w_m\"] = center_neighbor_weight_check_w_m[-1]\n",
        "                # mut[\"neighbor_embedding_change_m_w\"] should be a (15,128) numpy array for every mutation since we are currently \n",
        "                # considering top15 attended neighbors for every mutation, and the decoder last layer embedding before \n",
        "                # output_transformation is of length 128 \n",
        "                # mut[\"neighbor_embedding_change_m_w\"] = np.array(local_neighbor_embedding_changes)\n",
        "                mut[\"neighbor_embedding_change_m_w\"] = np.array(local_neighbor_embedding_changes).sum()\n",
        "                # for each mutation, mut[\"neighbor_embedding_change_m_w_raw\"] should be a (15,128) array since we are considering\n",
        "                # top15 most attended neighbors \n",
        "                mut[\"neighbor_embedding_change_m_w_raw\"] = np.array(local_neighbor_embedding_changes_raw)\n",
        "                mut[\"neighbor_message_change_m_w\"] = np.array(local_center_neighbor_message_change_diff).sum()\n",
        "                mut[\"unweighted_backward_KL\"] = np.array(local_neighbor_backward_KL_vals).sum()\n",
        "                mut[\"unweighted_forward_KL\"] = np.array(local_neighbor_forward_KL_vals).sum()"
      ],
      "metadata": {
        "id": "7m4jsITsJHmE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.decomposition import PCA\n",
        "\n",
        "# # the data is definitely stored in the correct format here, now how to do PCA\n",
        "# # we have to do fit_transform on a (15*2620,128) matrix\n",
        "# # also, save those PCA results\n",
        "# # check the correlation results for two PCAs weighted by top_15_attention_weights right here in this fucking cell\n",
        "# # most probably, normalization will be needed across all the (15*2620) vectors for now, in order to avoid scale-difference-related issues\n",
        "# # this normalizer has to be saved as well along with the PCA objects for testing on other datasets\n",
        "# very_very_loc_ddg = []\n",
        "# # The \"very_very_loc_embedding_changes\" list below will contain the (15,128) that needs to be concatenated across dimension-0,\n",
        "# # I will override this list with the concatenated numpy array  \n",
        "# very_very_loc_embedding_changes = []\n",
        "\n",
        "# for i,(prot,muts) in enumerate(two_level_dict.items()):\n",
        "#     if prot not in proteins_to_skip:\n",
        "#         try:\n",
        "#             cur_map_dict = mapping_dict[prot]\n",
        "#         except:\n",
        "#             continue\n",
        "#         for ind_track, mut in enumerate(muts):\n",
        "#             very_very_loc_ddg.append(mut[\"ddg\"])\n",
        "#             very_very_loc_embedding_changes.append(mut[\"neighbor_embedding_change_m_w\"])\n",
        "\n",
        "# # let us here concatenate all the (15,128) arrays across dimension-0 for PCA fitting\n",
        "# # pass the concatenated matrix through Scikit-learn StandardScaler() before passing it through PCA\n",
        "# # save both the Scaling object and the PCA object that would be fitted on this S_2648 training set\n",
        "# # the concatenated array has to be divided back for each of the mutations, and mapped to the \"two_level_dict\" in some way\n",
        "# # How about concatenating in a separate array, learning the PCA, and applying to each mutation separately,\n",
        "# # that code should be transferrable to the test datasets directly\n",
        "# very_very_loc_embedding_changes = np.concatenate(very_very_loc_embedding_changes,axis=0)\n",
        "# loc_scaler = StandardScaler()\n",
        "# print(very_very_loc_embedding_changes.shape)\n",
        "# loc_scaler.fit(very_very_loc_embedding_changes)\n",
        "# # now since \"loc_scaler\" has been fit on the whole dataset, it can be saved, and used on each of the mutations separately whenever needed\n",
        "# very_very_loc_embedding_changes = loc_scaler.transform(very_very_loc_embedding_changes)\n",
        "# # now, since the data has been concatenated, and scaled, it can be passed through PCA, which can be saved and used later on each \n",
        "# # of the mutations separately\n",
        "# loc_pca = PCA(n_components=20)\n",
        "# loc_pca.fit(very_very_loc_embedding_changes)\n",
        "# print(loc_pca.explained_variance_ratio_)\n",
        "# print(loc_pca.singular_values_)\n",
        "# # check local correlations (for each of the mutants separately)\n",
        "# # then check  "
      ],
      "metadata": {
        "id": "f96PtuuC_U00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "TwMx2ZMs60Pz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(120):\n",
        "#     for j in range(i+1,120):\n",
        "#         abdgf = pearsonr(very_very_loc_embedding_changes[:,i],very_very_loc_embedding_changes[:,j])[0]\n",
        "#         if abs(abdgf) > 0.05:\n",
        "#             print(\"YESSSSSS\",i,j,abdgf)"
      ],
      "metadata": {
        "id": "HswduBjPlCm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experimental_energies = []\n",
        "mut_wild_predictions = []\n",
        "mut_min_predictions = []\n",
        "entropy_predictions = []\n",
        "neighbor_entropy_change_predictions = []\n",
        "neighbor_energy_change_predictions = []\n",
        "center_neighbor_weight_check_w_m = []\n",
        "V2_backward_weighted_neighbor_backward_KL = []\n",
        "sum_neighbor_embedding_change_m_w = []\n",
        "neighbor_message_change_m_w = []\n",
        "\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        for mut in muts:\n",
        "            if \"center_mut_wild_energy\" in mut:\n",
        "                experimental_energies.append(mut[\"ddg\"])\n",
        "                mut_wild_predictions.append(mut[\"center_mut_wild_energy\"])\n",
        "                mut_min_predictions.append(mut[\"center_mut_max_energy\"])\n",
        "                entropy_predictions.append(mut[\"center_entropy\"])\n",
        "                neighbor_entropy_change_predictions.append(mut[\"weighted_neighbor_entropy_changes\"])\n",
        "                neighbor_energy_change_predictions.append(mut[\"weighted_neighbor_energy_changes\"])\n",
        "                center_neighbor_weight_check_w_m.append(mut[\"center_neighbor_weight_check_w_m\"])\n",
        "                V2_backward_weighted_neighbor_backward_KL.append(mut[\"V2_backward_weighted_neighbor_backward_KL\"])\n",
        "                sum_neighbor_embedding_change_m_w.append(mut[\"neighbor_embedding_change_m_w\"])\n",
        "                neighbor_message_change_m_w.append(mut[\"neighbor_message_change_m_w\"])\n",
        "\n",
        "print(len(experimental_energies),len(mut_wild_predictions))\n",
        "\n",
        "print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "print(pearsonr(experimental_energies,entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_entropy_change_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_energy_change_predictions))\n",
        "print(pearsonr(experimental_energies,center_neighbor_weight_check_w_m))\n",
        "print(pearsonr(experimental_energies,V2_backward_weighted_neighbor_backward_KL))\n",
        "print(pearsonr(experimental_energies,sum_neighbor_embedding_change_m_w))\n",
        "print(pearsonr(experimental_energies,neighbor_message_change_m_w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StvbASTsfta0",
        "outputId": "120d9601-ca51-4960-c8eb-be4bd38752c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "921 921\n",
            "(0.6437524074179247, 6.570883810058129e-109)\n",
            "(0.6087083189593055, 1.8420984699912024e-94)\n",
            "(0.2554844559696742, 3.4363589203343696e-15)\n",
            "(0.45691431920722453, 1.0678160933285664e-48)\n",
            "(0.4493345799090913, 5.7635883521732165e-47)\n",
            "(-0.12114416840426181, 0.0002286414968347316)\n",
            "(0.39835140877181585, 2.1686931431259903e-36)\n",
            "(0.36368579871712997, 3.5053706633604764e-30)\n",
            "(0.18077367050573223, 3.309160809183777e-08)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let me get PSSM values and do some comparison quickly\n",
        "# getting the PSSM extraction functions from my custom model data processing scripts\n",
        "from string import ascii_uppercase\n",
        "\n",
        "# In rare cases, some PDB files number chains with 1,2,3 instead of A,B,C\n",
        "def convertChainFromAlphabetToNumber(alphabet):\n",
        "    mappingDict = {ch:(idx+1) for idx,ch in enumerate(ascii_uppercase)}\n",
        "    return str(mappingDict[alphabet])\n",
        "\n",
        "# Before executing this function, the PSSM files with naming format \"pdbIdchain.pssm\" needs to be stored\n",
        "# in the pssm_dir\n",
        "def returnPSSMArray(pdbIdPlusChain,pssm_dir=\"train_pssm_dir\",convert_upper = False):\n",
        "#     Currently, assuming that the pssm file names contain pdbId in upper case\n",
        "    if convert_upper:\n",
        "        fileName = pdbIdPlusChain.upper() + \".pssm\"\n",
        "    else:\n",
        "        fileName = pdbIdPlusChain + \".pssm\"\n",
        "    try:\n",
        "        fullPath = os.path.join(pssm_dir,fileName)\n",
        "        f = open(fullPath)\n",
        "    except:\n",
        "        fileName = pdbIdPlusChain[0:4].upper() + str(convertChainFromAlphabetToNumber(pdbIdPlusChain[4])) + \".pssm\" \n",
        "        fullPath = os.path.join(pssm_dir,fileName)\n",
        "        f = open(fullPath)\n",
        "        \n",
        "# #     all the target lines in the PSSM files have (2+20+20+2=44) strings after line.split()\n",
        "    target_lines = [line.split() for line in f.readlines() if (len(line.split()))==44]\n",
        "    number_of_residues = len(target_lines)\n",
        "    \n",
        "    pssm_features = np.zeros((number_of_residues,20))\n",
        "\n",
        "    for idx,line in enumerate(target_lines):\n",
        "        pssm_features[idx,:] = line[2:22]\n",
        "\n",
        "    f.close()\n",
        "    \n",
        "    return pssm_features\n",
        "\n",
        "# This function also seems necessary for extracting the two pssm values\n",
        "# Must review the three pssm feature functions (this one and the two above) later\n",
        "# These functions seem to be taking up a lot of time....must review\n",
        "def returnPSSMMapping(residue):\n",
        "    pssm_letter_to_index_dict = {\"A\" : 0,   \n",
        "    \"R\" : 1,\n",
        "    \"N\" : 2,\n",
        "    \"D\" : 3,\n",
        "    \"C\" : 4,\n",
        "    \"Q\" : 5,\n",
        "    \"E\" : 6,\n",
        "    \"G\" : 7,\n",
        "    \"H\" : 8,\n",
        "    \"I\" : 9,\n",
        "    \"L\" : 10,\n",
        "    \"K\" : 11,\n",
        "    \"M\" : 12,\n",
        "    \"F\" : 13,\n",
        "    \"P\" : 14,\n",
        "    \"S\" : 15,\n",
        "    \"T\" : 16,\n",
        "    \"W\" : 17,\n",
        "    \"Y\" : 18,\n",
        "    \"V\" : 19}\n",
        "\n",
        "    return pssm_letter_to_index_dict[residue]\n",
        "\n",
        "\n",
        "# I will add PSSM values to the two-level dictionary for places where log_prob is available\n",
        "pssmDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_921_pssm_dir\"\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                wild = mut[\"mut\"][0] \n",
        "                alternate = mut[\"mut\"][-1]\n",
        "                sequence_index_of_mutation = cur_map_dict[mut[\"mut\"][0:-1]]\n",
        "                pdbId = prot[0:-1]\n",
        "                mutChain = prot[-1]\n",
        "                pssm_array = returnPSSMArray(pdbId + mutChain,pssm_dir=pssmDirectory,convert_upper = False)\n",
        "                position_pssm = pssm_array[sequence_index_of_mutation]\n",
        "                wild_pssm = position_pssm[returnPSSMMapping(wild)] \n",
        "                alternate_pssm = position_pssm[returnPSSMMapping(alternate)]\n",
        "                mut[\"wild_pssm\"] = wild_pssm\n",
        "                mut[\"alternate_pssm\"] = alternate_pssm"
      ],
      "metadata": {
        "id": "eBgpxQx4ispc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pssm_predictions = []\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                pssm_predictions.append((mut[\"wild_pssm\"]-mut[\"alternate_pssm\"]))"
      ],
      "metadata": {
        "id": "xOkQhEQzn32m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experimental_energies = []\n",
        "mut_wild_predictions = []\n",
        "mut_min_predictions = []\n",
        "entropy_predictions = []\n",
        "neighbor_entropy_change_predictions = []\n",
        "neighbor_energy_change_predictions = []\n",
        "center_neighbor_weight_check_w_m = []\n",
        "V2_backward_weighted_neighbor_backward_KL = []\n",
        "sum_neighbor_embedding_change_m_w = []\n",
        "neighbor_message_change_m_w = []\n",
        "\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        for mut in muts:\n",
        "            if \"center_mut_wild_energy\" in mut:\n",
        "                experimental_energies.append(mut[\"ddg\"])\n",
        "                mut_wild_predictions.append(mut[\"center_mut_wild_energy\"])\n",
        "                mut_min_predictions.append(mut[\"center_mut_max_energy\"])\n",
        "                entropy_predictions.append(mut[\"center_entropy\"])\n",
        "                neighbor_entropy_change_predictions.append(mut[\"weighted_neighbor_entropy_changes\"])\n",
        "                neighbor_energy_change_predictions.append(mut[\"weighted_neighbor_energy_changes\"])\n",
        "                center_neighbor_weight_check_w_m.append(mut[\"center_neighbor_weight_check_w_m\"])\n",
        "                V2_backward_weighted_neighbor_backward_KL.append(mut[\"V2_backward_weighted_neighbor_backward_KL\"])\n",
        "                sum_neighbor_embedding_change_m_w.append(mut[\"neighbor_embedding_change_m_w\"])\n",
        "                neighbor_message_change_m_w.append(mut[\"neighbor_message_change_m_w\"])\n",
        "\n",
        "print(len(experimental_energies),len(mut_wild_predictions))\n",
        "\n",
        "print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "print(pearsonr(experimental_energies,entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_entropy_change_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_energy_change_predictions))\n",
        "print(pearsonr(experimental_energies,center_neighbor_weight_check_w_m))\n",
        "print(pearsonr(experimental_energies,V2_backward_weighted_neighbor_backward_KL))\n",
        "print(pearsonr(experimental_energies,sum_neighbor_embedding_change_m_w))\n",
        "print(pearsonr(experimental_energies,neighbor_message_change_m_w))\n",
        "print(pearsonr(experimental_energies,pssm_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tyw_4erpj1C",
        "outputId": "46147555-34d0-4fce-b497-27e58bff4243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "921 921\n",
            "(0.6437524074179247, 6.570883810058129e-109)\n",
            "(0.6087083189593054, 1.8420984699914118e-94)\n",
            "(0.25548445596967423, 3.436358920334565e-15)\n",
            "(0.45691431920722453, 1.0678160933285664e-48)\n",
            "(0.4493345799090913, 5.7635883521732165e-47)\n",
            "(-0.12114416840426183, 0.0002286414968347316)\n",
            "(0.39835140877181585, 2.1686931431259903e-36)\n",
            "(0.36368579782829774, 3.505371871870569e-30)\n",
            "(0.18077366538521142, 3.3091638076336455e-08)\n",
            "(0.5145587134119901, 2.1316560964554222e-63)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "df_Ssym = pd.DataFrame(\n",
        "\n",
        "    {'DDG' : experimental_energies,\n",
        "     'P_DP': mut_wild_predictions,\n",
        "     'P_ET': entropy_predictions,\n",
        "     'P_DEC': pssm_predictions,\n",
        "     'Neighbor_Energy_Change' : neighbor_energy_change_predictions,\n",
        "     'Neighbor_backward_KL' : V2_backward_weighted_neighbor_backward_KL,\n",
        "     'Neighbor_Entropy_Change' : neighbor_entropy_change_predictions,\n",
        "     'neighbor_attention_change_w/m' : center_neighbor_weight_check_w_m,\n",
        "     'neighbor_embedding_change' : sum_neighbor_embedding_change_m_w,\n",
        "     'Z' : neighbor_message_change_m_w  \n",
        "    })\n",
        "corr = df_Ssym.corr()\n",
        "\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(corr, \n",
        "        xticklabels=corr.columns,\n",
        "        yticklabels=corr.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "QlQuGW7f7KDy",
        "outputId": "a8d3604d-f6b6-464f-e171-4cbd75445de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f89c0c49650>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}