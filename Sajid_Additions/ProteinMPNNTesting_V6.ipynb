{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProteinMPNNTesting_V6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd8907fa0c914791852cab120af14dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb14ed18efdb4716bb43078723d62b0c",
              "IPY_MODEL_b5038e7e2c1e421695ebc81edc3f0b4b",
              "IPY_MODEL_58e8ea753d714b36bd45cd3ee7a3e19b"
            ],
            "layout": "IPY_MODEL_329e2fedfa924b50b9bbc969615c36ac"
          }
        },
        "eb14ed18efdb4716bb43078723d62b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f70fe12bb0d34953832ed362e1bd2e6f",
            "placeholder": "​",
            "style": "IPY_MODEL_12f41f2379b4493b9684cf241080ce3e",
            "value": ""
          }
        },
        "b5038e7e2c1e421695ebc81edc3f0b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bf11afa4650459dbb4cf26749604f64",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f534a1b5aab46128d296ec434ad93f4",
            "value": 1
          }
        },
        "58e8ea753d714b36bd45cd3ee7a3e19b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2bc343fbd8242ae8f24f1fd4668e5b8",
            "placeholder": "​",
            "style": "IPY_MODEL_b8249be24c81437297a2c537a5a83f67",
            "value": " 2648/? [00:00&lt;00:00, 47428.68it/s]"
          }
        },
        "329e2fedfa924b50b9bbc969615c36ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f70fe12bb0d34953832ed362e1bd2e6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12f41f2379b4493b9684cf241080ce3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bf11afa4650459dbb4cf26749604f64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1f534a1b5aab46128d296ec434ad93f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2bc343fbd8242ae8f24f1fd4668e5b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8249be24c81437297a2c537a5a83f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88e37fbcf8bc45e184df0208a487617f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1a4d35b4c0444e3bbe5f3e34bcf91cb",
              "IPY_MODEL_7c0bed04d93a443da70c6f379c440ed0",
              "IPY_MODEL_8839ddb0aec643efa8cec8154e2301a7"
            ],
            "layout": "IPY_MODEL_cb8d7de293304f19941de98618b5397b"
          }
        },
        "c1a4d35b4c0444e3bbe5f3e34bcf91cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_624c353a4cca461e85666854b132fcef",
            "placeholder": "​",
            "style": "IPY_MODEL_167583f480014a5bbdbb056ec2aea18d",
            "value": "100%"
          }
        },
        "7c0bed04d93a443da70c6f379c440ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b4fc86687ea47218ffc9f17e6d37c3a",
            "max": 131,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e5d2985e4504e98b1ece6071f6ccdbb",
            "value": 131
          }
        },
        "8839ddb0aec643efa8cec8154e2301a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03cf52ea2a6047c1a09b7959f8a74518",
            "placeholder": "​",
            "style": "IPY_MODEL_441e6d4575bf4b10a59d582ca75400c5",
            "value": " 131/131 [00:05&lt;00:00, 30.58it/s]"
          }
        },
        "cb8d7de293304f19941de98618b5397b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624c353a4cca461e85666854b132fcef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "167583f480014a5bbdbb056ec2aea18d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b4fc86687ea47218ffc9f17e6d37c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e5d2985e4504e98b1ece6071f6ccdbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03cf52ea2a6047c1a09b7959f8a74518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "441e6d4575bf4b10a59d582ca75400c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "570d57ccce5c48ceb933791aba077951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e12ccc7cb75342da901353b7b126f962",
              "IPY_MODEL_1c6157a0d03a492e906c5f3e798f1849",
              "IPY_MODEL_ef8c97cf6a4b4ae79baf6293999f07b7"
            ],
            "layout": "IPY_MODEL_adee8d7c007c4e22b6a1feef845a3cce"
          }
        },
        "e12ccc7cb75342da901353b7b126f962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_647e2ac58c404b87ad202cd1289298c5",
            "placeholder": "​",
            "style": "IPY_MODEL_f3d618b81e624577911c43608dbfde29",
            "value": ""
          }
        },
        "1c6157a0d03a492e906c5f3e798f1849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6573275f1136413ab13c6d89e1bd3533",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c8f22732a274f8a80316bd082c621c2",
            "value": 1
          }
        },
        "ef8c97cf6a4b4ae79baf6293999f07b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb37a08a78a49d38ea3e0accc2ef5dc",
            "placeholder": "​",
            "style": "IPY_MODEL_dd6f8c07662f4730870c888dea7b3f67",
            "value": " 131/? [24:57&lt;00:00,  8.48s/it]"
          }
        },
        "adee8d7c007c4e22b6a1feef845a3cce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "647e2ac58c404b87ad202cd1289298c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d618b81e624577911c43608dbfde29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6573275f1136413ab13c6d89e1bd3533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0c8f22732a274f8a80316bd082c621c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6eb37a08a78a49d38ea3e0accc2ef5dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd6f8c07662f4730870c888dea7b3f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_wbcvVBv0QJ",
        "outputId": "4620a723-00b7-4e57-d05a-84128edc2142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import sys \n",
        "installation_path = \"/content/drive/MyDrive/Colab_Installations_V2\"\n",
        "# The path is being modified so that everything installed in the installation path can now be used without re-installing (in this case, I just need biopython)\n",
        "sys.path.insert(0,installation_path)\n",
        "protein_mpnn_path = \"/content/drive/MyDrive/Protein_MPNN_Digging/ProteinMPNN/vanilla_proteinmpnn\"\n",
        "sys.path.insert(0,protein_mpnn_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Protein_MPNN_Digging"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgTOgsabxBaC",
        "outputId": "810596bd-4c56-46ab-b607-d3969cfca8b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Protein_MPNN_Digging\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import warnings\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, Subset\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import os\n",
        "from Bio.PDB import *\n",
        "\n",
        "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")"
      ],
      "metadata": {
        "id": "jX5ScMeGyLcy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from Bio.PDB.Polypeptide import *\n",
        "from string import ascii_uppercase"
      ],
      "metadata": {
        "id": "NBjszWagtiYL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = os.path.join(protein_mpnn_path,\"vanilla_model_weights\")\n",
        "model_name = \"v_48_020\"\n",
        "checkpoint_path = os.path.join(weights_path,model_name+\".pt\")"
      ],
      "metadata": {
        "id": "Z6ZHe2IIyy1G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, load and dig into the checkpoint object\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device) "
      ],
      "metadata": {
        "id": "JPE_pX8tzdUO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint[\"num_edges\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DD1hpMLk2-y",
        "outputId": "57bc4c61-90dd-446c-9fa8-5ee4ff343c25"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import json, time, os, sys, glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, Subset\n",
        "\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "#A number of functions/classes are adopted from: https://github.com/jingraham/neurips19-graph-protein-design\n",
        "\n",
        "def _scores(S, log_probs, mask):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    criterion = torch.nn.NLLLoss(reduction='none')\n",
        "    loss = criterion(\n",
        "        log_probs.contiguous().view(-1,log_probs.size(-1)),\n",
        "        S.contiguous().view(-1)\n",
        "    ).view(S.size())\n",
        "    # The designable positions have mask set to 1.0, so this function seems to be returning the average score for the designable positions\n",
        "    scores = torch.sum(loss * mask, dim=-1) / torch.sum(mask, dim=-1)\n",
        "    return scores\n",
        "\n",
        "def _S_to_seq(S, mask):\n",
        "    # This is the decoding order\n",
        "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    seq = ''.join([alphabet[c] for c, m in zip(S.tolist(), mask.tolist()) if m > 0])\n",
        "    return seq\n",
        "\n",
        "def parse_PDB_biounits(x, atoms=['N','CA','C'], chain=None):\n",
        "  '''\n",
        "  input:  x = PDB filename\n",
        "          atoms = atoms to extract (optional)\n",
        "  output: (length, atoms, coords=(x,y,z)), sequence\n",
        "  '''\n",
        "\n",
        "  alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "  states = len(alpha_1)\n",
        "  alpha_3 = ['ALA','ARG','ASN','ASP','CYS','GLN','GLU','GLY','HIS','ILE',\n",
        "             'LEU','LYS','MET','PHE','PRO','SER','THR','TRP','TYR','VAL','GAP']\n",
        "  \n",
        "  # The following dictionaries are mapping from one-letter to 0-20 index,\n",
        "  # three-letter to 0-20 index,\n",
        "  # 0-20 index to one-letter,\n",
        "  # one-letter to three-letter, and vice-versa \n",
        "  aa_1_N = {a:n for n,a in enumerate(alpha_1)}\n",
        "  aa_3_N = {a:n for n,a in enumerate(alpha_3)}\n",
        "  aa_N_1 = {n:a for n,a in enumerate(alpha_1)}\n",
        "  aa_1_3 = {a:b for a,b in zip(alpha_1,alpha_3)}\n",
        "  aa_3_1 = {b:a for a,b in zip(alpha_1,alpha_3)}\n",
        "  \n",
        "  def AA_to_N(x):\n",
        "    # [\"ARND\"] -> [[0,1,2,3]]\n",
        "    x = np.array(x);\n",
        "    if x.ndim == 0: x = x[None]\n",
        "    return [[aa_1_N.get(a, states-1) for a in y] for y in x]\n",
        "  \n",
        "  def N_to_AA(x):\n",
        "    # [[0,1,2,3]] -> [\"ARND\"]\n",
        "    x = np.array(x);\n",
        "    if x.ndim == 1: x = x[None]\n",
        "    return [\"\".join([aa_N_1.get(a,\"-\") for a in y]) for y in x]\n",
        "\n",
        "  xyz,seq,min_resn,max_resn = {},{},1e6,-1e6\n",
        "  for line in open(x,\"rb\"):\n",
        "    line = line.decode(\"utf-8\",\"ignore\").rstrip()\n",
        "\n",
        "    if line[:6] == \"HETATM\" and line[17:17+3] == \"MSE\":\n",
        "      line = line.replace(\"HETATM\",\"ATOM  \")\n",
        "      line = line.replace(\"MSE\",\"MET\")\n",
        "\n",
        "    if line[:4] == \"ATOM\":\n",
        "      ch = line[21:22]\n",
        "      # If the input chain is not in the PDB file, which can be the case if the target chains are named differently in the runner script,\n",
        "      # this line will cause the output to have literally no information, this is the case for integer named chains\n",
        "      # that does not mean that this line is not doing its job correctly, this is just a constraint that input chain names and \n",
        "      # chain names in the PDB file have to be congruent\n",
        "      if ch == chain or chain is None:\n",
        "        atom = line[12:12+4].strip()\n",
        "        resi = line[17:17+3]\n",
        "        resn = line[22:22+5].strip()\n",
        "        x,y,z = [float(line[i:(i+8)]) for i in [30,38,46]]\n",
        "\n",
        "        if resn[-1].isalpha(): \n",
        "            resa,resn = resn[-1],int(resn[:-1])-1\n",
        "        else: \n",
        "            resa,resn = \"\",int(resn)-1\n",
        "#         resn = int(resn)\n",
        "        if resn < min_resn: \n",
        "            min_resn = resn\n",
        "        if resn > max_resn: \n",
        "            max_resn = resn\n",
        "        if resn not in xyz: \n",
        "            xyz[resn] = {}\n",
        "        if resa not in xyz[resn]: \n",
        "            xyz[resn][resa] = {}\n",
        "        if resn not in seq: \n",
        "            seq[resn] = {}\n",
        "        if resa not in seq[resn]: \n",
        "            seq[resn][resa] = resi\n",
        "\n",
        "        if atom not in xyz[resn][resa]:\n",
        "          xyz[resn][resa][atom] = np.array([x,y,z])\n",
        "\n",
        "  # convert to numpy arrays, fill in missing values\n",
        "  seq_,xyz_ = [],[]\n",
        "  try:\n",
        "      for resn in range(min_resn,max_resn+1):\n",
        "        if resn in seq:\n",
        "          for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k],20))\n",
        "        else: seq_.append(20)\n",
        "        if resn in xyz:\n",
        "          for k in sorted(xyz[resn]):\n",
        "            for atom in atoms:\n",
        "              if atom in xyz[resn][k]: xyz_.append(xyz[resn][k][atom])\n",
        "              else: xyz_.append(np.full(3,np.nan))\n",
        "        else:\n",
        "          for atom in atoms: xyz_.append(np.full(3,np.nan))\n",
        "      return np.array(xyz_).reshape(-1,len(atoms),3), N_to_AA(np.array(seq_))\n",
        "  except TypeError:\n",
        "      return 'no_chain', 'no_chain'\n",
        "\n",
        "### calling signature\n",
        "# pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list)\n",
        "def parse_PDB(path_to_pdb, input_chain_list=None):\n",
        "    c=0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V','W','X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v','w','x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "     \n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list  \n",
        " \n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    # Each of the biounits is a separate PDB file, so for running with a single PDB file like from colab, this loop will be executed only once\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {} \n",
        "        # This loop will be executed only once for single chain DDG type cases\n",
        "        for letter in chain_alphabet:\n",
        "            xyz, seq = parse_PDB_biounits(biounit, atoms=['N','CA','C','O'], chain=letter)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_'+letter]=seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                coords_dict_chain['N_chain_'+letter]=xyz[:,0,:].tolist()\n",
        "                coords_dict_chain['CA_chain_'+letter]=xyz[:,1,:].tolist()\n",
        "                coords_dict_chain['C_chain_'+letter]=xyz[:,2,:].tolist()\n",
        "                coords_dict_chain['O_chain_'+letter]=xyz[:,3,:].tolist()\n",
        "                my_dict['coords_chain_'+letter]=coords_dict_chain\n",
        "                s += 1\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        my_dict['name']=biounit[(fi+1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c+=1\n",
        "    return pdb_dict_list\n",
        "\n",
        "\n",
        "# X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta \n",
        "# = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "# fixed_pos_list = fixed_position_dict[b['name']][letter]\n",
        "# The trick will be to populate this fixed_position_dict from the calling function, and \n",
        "def tied_featurize(batch, device, chain_dict, fixed_position_dict=None, omit_AA_dict=None, tied_positions_dict=None, pssm_dict=None, bias_by_res_dict=None):\n",
        "    \"\"\" Pack and pad batch into torch tensors \"\"\"\n",
        "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    B = len(batch)\n",
        "    lengths = np.array([len(b['seq']) for b in batch], dtype=np.int32) #sum of chain seq lengths\n",
        "    L_max = max([len(b['seq']) for b in batch])\n",
        "    X = np.zeros([B, L_max, 4, 3])\n",
        "    residue_idx = -100*np.ones([B, L_max], dtype=np.int32)\n",
        "    # This \"chain_M\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of the single sequence as a consequence\n",
        "    chain_M = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    pssm_coef_all = np.zeros([B, L_max], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    pssm_bias_all = np.zeros([B, L_max, 21], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    pssm_log_odds_all = 10000.0*np.ones([B, L_max, 21], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    # This \"chain_M_pos\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of single sequence as a consequence\n",
        "    chain_M_pos = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    bias_by_res_all = np.zeros([B, L_max, 21], dtype=np.float32)\n",
        "    # This \"chain_encoding_all\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of single sequence as a consequence\n",
        "    chain_encoding_all = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    S = np.zeros([B, L_max], dtype=np.int32)\n",
        "    omit_AA_mask = np.zeros([B, L_max, len(alphabet)], dtype=np.int32)\n",
        "    # Build the batch\n",
        "    letter_list_list = []\n",
        "    visible_list_list = []\n",
        "    masked_list_list = []\n",
        "    masked_chain_length_list_list = []\n",
        "    tied_pos_list_of_lists_list = []\n",
        "    #shuffle all chains before the main loop\n",
        "    for i, b in enumerate(batch):\n",
        "        # for my current energy function like usecase, the code will reach \"if and not else\" because chain_dict will not be None\n",
        "        if chain_dict != None:\n",
        "            ### Calling function argument assignment START\n",
        "            # chain_id_dict[pdb_dict_list[0]['name']] = (designed_chain_list, fixed_chain_list)\n",
        "            ### Calling function argument assignment END\n",
        "            masked_chains, visible_chains = chain_dict[b['name']] #masked_chains a list of chain letters to predict [A, D, F]\n",
        "        else:\n",
        "            masked_chains = [item[-1:] for item in list(b) if item[:10]=='seq_chain_']\n",
        "            visible_chains = []\n",
        "        num_chains = b['num_of_chains']\n",
        "        all_chains = masked_chains + visible_chains\n",
        "        #random.shuffle(all_chains)\n",
        "    # This for loop can be ignored since it will be executed only once in my single-chain or single-chain-at-a-time implementation\n",
        "    for i, b in enumerate(batch):\n",
        "        mask_dict = {}\n",
        "        a = 0\n",
        "        x_chain_list = []\n",
        "        chain_mask_list = []\n",
        "        # \"chain_seq_list\" will contain string format sequences of all the chains both fixed and designable \n",
        "        chain_seq_list = []\n",
        "        chain_encoding_list = []\n",
        "        c = 1\n",
        "        # \"letter_list\" will contain names of all the chains both fixed and designable\n",
        "        letter_list = []\n",
        "        global_idx_start_list = [0]\n",
        "        # \"visible_list\" will contain names of the fixed chains \n",
        "        visible_list = []\n",
        "        # \"masked_list\" will contain names of the designable chains\n",
        "        masked_list = []\n",
        "        masked_chain_length_list = []\n",
        "        fixed_position_mask_list = []\n",
        "        omit_AA_mask_list = []\n",
        "        pssm_coef_list = []\n",
        "        pssm_bias_list = []\n",
        "        pssm_log_odds_list = []\n",
        "        bias_by_res_list = []\n",
        "        l0 = 0\n",
        "        l1 = 0\n",
        "        # This loop will also be executed once for my single chain case,\n",
        "        # and since the same chain has both designable and fixed positions, the codes insides both of the if \n",
        "        # statements will be executed\n",
        "        for step, letter in enumerate(all_chains):\n",
        "            if letter in visible_chains:\n",
        "                letter_list.append(letter)\n",
        "                visible_list.append(letter)\n",
        "                chain_seq = b[f'seq_chain_{letter}']\n",
        "                chain_seq = ''.join([a if a!='-' else 'X' for a in chain_seq])\n",
        "                chain_length = len(chain_seq)\n",
        "                global_idx_start_list.append(global_idx_start_list[-1]+chain_length)\n",
        "                chain_coords = b[f'coords_chain_{letter}'] #this is a dictionary\n",
        "                # the \"chain_mask\" varies between fixed and designable chains (1.0 for designable chains which are maxed)\n",
        "                chain_mask = np.zeros(chain_length) #0.0 for visible chains\n",
        "                x_chain = np.stack([chain_coords[c] for c in [f'N_chain_{letter}', f'CA_chain_{letter}', f'C_chain_{letter}', f'O_chain_{letter}']], 1) #[chain_lenght,4,3]\n",
        "                x_chain_list.append(x_chain)\n",
        "                chain_mask_list.append(chain_mask)\n",
        "                chain_seq_list.append(chain_seq)\n",
        "                # \"chain_encoding_list\" contains numpy arrays corresponding to chains (each array corresponds to one chain),\n",
        "                # where all elements of the same array is the same value, which is equal to the index of the chain the it corresponds to\n",
        "                # by index, I mean index of the different numpy arrays annotating the chains\n",
        "                chain_encoding_list.append(c*np.ones(np.array(chain_mask).shape[0]))\n",
        "                # l0 points at the starting of the current chain and l1 points after the ending of the current chain\n",
        "                l1 += chain_length\n",
        "                # the only value i will have is 0 since it will be executed only once in my single-chain or single-chain-at-a-time implementation\n",
        "                # seems like the chains are separated by  \n",
        "                residue_idx[i, l0:l1] = 100*(c-1)+np.arange(l0, l1)\n",
        "                l0 += chain_length\n",
        "                c+=1\n",
        "                # The following variables are numpy arrays with entries corresponding to every position in the sequence\n",
        "                # appending these numpy arrays to a list indicates that the chains are added one after one\n",
        "                # same thing goes for the chain_mask and chain_seq variables declared above\n",
        "                # In code-block below in this cell, these lists of numpy arrays are going through np.concatenate(), which is creating\n",
        "                # the final numpy arrays containing co-ordinates, sequence identity, fixed position, masked position, PSSM bias, and everything\n",
        "                # required to pass the sequences through the model\n",
        "                ### START\n",
        "                fixed_position_mask = np.ones(chain_length)\n",
        "                fixed_position_mask_list.append(fixed_position_mask)\n",
        "                # The omit_AA_mask, pssm_coef, pssm_bias, \"bias_by_res_list\", all these numpy arrays are zero for the fixed positions\n",
        "                # since these positions are used as it is, while for the masked_positions, these values can get activated\n",
        "                # which is why the next if statement has several extra lines manipulating these variables according to the amount of information passed \n",
        "                omit_AA_mask_temp = np.zeros([chain_length, len(alphabet)], np.int32)\n",
        "                omit_AA_mask_list.append(omit_AA_mask_temp)\n",
        "                pssm_coef = np.zeros(chain_length)\n",
        "                pssm_bias = np.zeros([chain_length, 21])\n",
        "                pssm_log_odds = 10000.0*np.ones([chain_length, 21])\n",
        "                pssm_coef_list.append(pssm_coef)\n",
        "                pssm_bias_list.append(pssm_bias)\n",
        "                pssm_log_odds_list.append(pssm_log_odds)\n",
        "                bias_by_res_list.append(np.zeros([chain_length, 21]))\n",
        "                ### END\n",
        "            if letter in masked_chains:\n",
        "                masked_list.append(letter)\n",
        "                letter_list.append(letter)\n",
        "                chain_seq = b[f'seq_chain_{letter}']\n",
        "                chain_seq = ''.join([a if a!='-' else 'X' for a in chain_seq])\n",
        "                chain_length = len(chain_seq)\n",
        "                global_idx_start_list.append(global_idx_start_list[-1]+chain_length)\n",
        "                masked_chain_length_list.append(chain_length)\n",
        "                chain_coords = b[f'coords_chain_{letter}'] #this is a dictionary\n",
        "                chain_mask = np.ones(chain_length) #1.0 for masked\n",
        "                x_chain = np.stack([chain_coords[c] for c in [f'N_chain_{letter}', f'CA_chain_{letter}', f'C_chain_{letter}', f'O_chain_{letter}']], 1) #[chain_lenght,4,3]\n",
        "                x_chain_list.append(x_chain)\n",
        "                chain_mask_list.append(chain_mask)\n",
        "                chain_seq_list.append(chain_seq)\n",
        "                chain_encoding_list.append(c*np.ones(np.array(chain_mask).shape[0]))\n",
        "                l1 += chain_length\n",
        "                residue_idx[i, l0:l1] = 100*(c-1)+np.arange(l0, l1)\n",
        "                l0 += chain_length\n",
        "                c+=1\n",
        "                fixed_position_mask = np.ones(chain_length)\n",
        "                if fixed_position_dict!=None:\n",
        "                    fixed_pos_list = fixed_position_dict[b['name']][letter]\n",
        "                    if fixed_pos_list:\n",
        "                        # seems like \"fixed_pos_list\"  can be an 1-indexed integer list corresponding to positions in \"chain_seq\"\n",
        "                        # this thing ultimately controls which positions in the designable chain will be masked, which is why the fixed \n",
        "                        # positions are set to 0.0 since those positions will not be maxed (1 if maxed, 0 if not maxed)\n",
        "                        fixed_position_mask[np.array(fixed_pos_list)-1] = 0.0\n",
        "                fixed_position_mask_list.append(fixed_position_mask)\n",
        "                omit_AA_mask_temp = np.zeros([chain_length, len(alphabet)], np.int32)\n",
        "                # For my current energy function like usecase, \"omit_AA_dict\" will be None, so the following loop can be ignored\n",
        "                if omit_AA_dict!=None:\n",
        "                    for item in omit_AA_dict[b['name']][letter]:\n",
        "                        idx_AA = np.array(item[0])-1\n",
        "                        AA_idx = np.array([np.argwhere(np.array(list(alphabet))== AA)[0][0] for AA in item[1]]).repeat(idx_AA.shape[0])\n",
        "                        idx_ = np.array([[a, b] for a in idx_AA for b in AA_idx])\n",
        "                        omit_AA_mask_temp[idx_[:,0], idx_[:,1]] = 1\n",
        "                omit_AA_mask_list.append(omit_AA_mask_temp)\n",
        "                pssm_coef = np.zeros(chain_length)\n",
        "                pssm_bias = np.zeros([chain_length, 21])\n",
        "                pssm_log_odds = 10000.0*np.ones([chain_length, 21])\n",
        "                if pssm_dict:\n",
        "                    if pssm_dict[b['name']][letter]:\n",
        "                        pssm_coef = pssm_dict[b['name']][letter]['pssm_coef']\n",
        "                        pssm_bias = pssm_dict[b['name']][letter]['pssm_bias']\n",
        "                        pssm_log_odds = pssm_dict[b['name']][letter]['pssm_log_odds']\n",
        "                pssm_coef_list.append(pssm_coef)\n",
        "                pssm_bias_list.append(pssm_bias)\n",
        "                pssm_log_odds_list.append(pssm_log_odds)\n",
        "                if bias_by_res_dict:\n",
        "                    bias_by_res_list.append(bias_by_res_dict[b['name']][letter])\n",
        "                else:\n",
        "                    bias_by_res_list.append(np.zeros([chain_length, 21]))\n",
        "\n",
        "        ### TIED position START\n",
        "        # Since there will technically be no tied positions for my single chain energy-based usecase for now,\n",
        "        # I do not need to dig into this part of the code\n",
        "        letter_list_np = np.array(letter_list)\n",
        "        tied_pos_list_of_lists = []\n",
        "        tied_beta = np.ones(L_max)\n",
        "        if tied_positions_dict!=None:\n",
        "            tied_pos_list = tied_positions_dict[b['name']]\n",
        "            if tied_pos_list:\n",
        "                set_chains_tied = set(list(itertools.chain(*[list(item) for item in tied_pos_list])))\n",
        "                for tied_item in tied_pos_list:\n",
        "                    one_list = []\n",
        "                    for k, v in tied_item.items():\n",
        "                        start_idx = global_idx_start_list[np.argwhere(letter_list_np == k)[0][0]]\n",
        "                        if isinstance(v[0], list):\n",
        "                            for v_count in range(len(v[0])):\n",
        "                                one_list.append(start_idx+v[0][v_count]-1)#make 0 to be the first\n",
        "                                tied_beta[start_idx+v[0][v_count]-1] = v[1][v_count]\n",
        "                        else:\n",
        "                            for v_ in v:\n",
        "                                one_list.append(start_idx+v_-1)#make 0 to be the first\n",
        "                    tied_pos_list_of_lists.append(one_list)\n",
        "        tied_pos_list_of_lists_list.append(tied_pos_list_of_lists)\n",
        "        ### TIED position END\n",
        " \n",
        "        # Interestingly, although the backbone atom coordinates are used for generating edge features,\n",
        "        # the \"x\" in the following line contains the coodinates of the backbone atoms \n",
        "        x = np.concatenate(x_chain_list,0) #[L, 4, 3]\n",
        "        # \"all_sequence\" is a string where all the chain sequences have been put one after another\n",
        "        all_sequence = \"\".join(chain_seq_list)\n",
        "        # This \"chain_mask_list\" and \"m_pos\" below are the variables of interest if these actually contain full information regarding the\n",
        "        # fixed vs. variable positions definitions \n",
        "        # consequently, since these are concatenated numpy arrays of numpy arrays inside the lists \"chain_mask_list\" and \"fixed_position_mask_list\",\n",
        "        # when those lists are populated in the above code-block with binary numpy arrays \"fixed_position_mask\" and \"fixed_position_mask\" corresponding to \n",
        "        # each of the chains,\n",
        "        # that is where all the controlling needs to be done from\n",
        "        m = np.concatenate(chain_mask_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        # \"chain_encoding_list\" contains numpy arrays corresponding to chains (each array corresponds to one chain),\n",
        "        # where all elements of the same array is the same value, which is equal to the index of the chain the it corresponds to\n",
        "        # by index, I mean index of the different numpy arrays annotating the chains\n",
        "        chain_encoding = np.concatenate(chain_encoding_list,0)\n",
        "        m_pos = np.concatenate(fixed_position_mask_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "\n",
        "        pssm_coef_ = np.concatenate(pssm_coef_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        pssm_bias_ = np.concatenate(pssm_bias_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        pssm_log_odds_ = np.concatenate(pssm_log_odds_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "\n",
        "        bias_by_res_ = np.concatenate(bias_by_res_list, 0)  #[L,21], 0.0 for places where AA frequencies don't need to be tweaked\n",
        "\n",
        "        # Interestingly, all the chains are padded to the same length\n",
        "        # this has to be done most probably because the same layers are applied to all chains\n",
        "        # but for single chain or homomer cases, this should not be an issue\n",
        "        # need to be sure later why this is done\n",
        "        # does not significant when it comes to single chain energy-based usecase\n",
        "        # PADDING START\n",
        "        l = len(all_sequence)\n",
        "        x_pad = np.pad(x, [[0,L_max-l], [0,0], [0,0]], 'constant', constant_values=(np.nan, ))\n",
        "        X[i,:,:,:] = x_pad\n",
        "\n",
        "        m_pad = np.pad(m, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        m_pos_pad = np.pad(m_pos, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        omit_AA_mask_pad = np.pad(np.concatenate(omit_AA_mask_list,0), [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        chain_M[i,:] = m_pad\n",
        "        chain_M_pos[i,:] = m_pos_pad\n",
        "        omit_AA_mask[i,] = omit_AA_mask_pad\n",
        "\n",
        "        chain_encoding_pad = np.pad(chain_encoding, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        chain_encoding_all[i,:] = chain_encoding_pad\n",
        "\n",
        "        pssm_coef_pad = np.pad(pssm_coef_, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        pssm_bias_pad = np.pad(pssm_bias_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "        pssm_log_odds_pad = np.pad(pssm_log_odds_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "\n",
        "        pssm_coef_all[i,:] = pssm_coef_pad\n",
        "        pssm_bias_all[i,:] = pssm_bias_pad\n",
        "        pssm_log_odds_all[i,:] = pssm_log_odds_pad\n",
        "\n",
        "        bias_by_res_pad = np.pad(bias_by_res_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "        bias_by_res_all[i,:] = bias_by_res_pad\n",
        "        # PADDING END\n",
        "\n",
        "        # Convert to labels\n",
        "        indices = np.asarray([alphabet.index(a) for a in all_sequence], dtype=np.int32)\n",
        "        S[i, :l] = indices\n",
        "        letter_list_list.append(letter_list)\n",
        "        visible_list_list.append(visible_list)\n",
        "        masked_list_list.append(masked_list)\n",
        "        masked_chain_length_list_list.append(masked_chain_length_list)\n",
        "\n",
        "\n",
        "    isnan = np.isnan(X)\n",
        "    mask = np.isfinite(np.sum(X,(2,3))).astype(np.float32)\n",
        "    X[isnan] = 0.\n",
        "\n",
        "    # Conversion\n",
        "    pssm_coef_all = torch.from_numpy(pssm_coef_all).to(dtype=torch.float32, device=device)\n",
        "    pssm_bias_all = torch.from_numpy(pssm_bias_all).to(dtype=torch.float32, device=device)\n",
        "    pssm_log_odds_all = torch.from_numpy(pssm_log_odds_all).to(dtype=torch.float32, device=device)\n",
        "\n",
        "    tied_beta = torch.from_numpy(tied_beta).to(dtype=torch.float32, device=device)\n",
        "\n",
        "    jumps = ((residue_idx[:,1:]-residue_idx[:,:-1])==1).astype(np.float32)\n",
        "    bias_by_res_all = torch.from_numpy(bias_by_res_all).to(dtype=torch.float32, device=device)\n",
        "    phi_mask = np.pad(jumps, [[0,0],[1,0]])\n",
        "    psi_mask = np.pad(jumps, [[0,0],[0,1]])\n",
        "    omega_mask = np.pad(jumps, [[0,0],[0,1]])\n",
        "    dihedral_mask = np.concatenate([phi_mask[:,:,None], psi_mask[:,:,None], omega_mask[:,:,None]], -1) #[B,L,3]\n",
        "    dihedral_mask = torch.from_numpy(dihedral_mask).to(dtype=torch.float32, device=device)\n",
        "    residue_idx = torch.from_numpy(residue_idx).to(dtype=torch.long,device=device)\n",
        "    S = torch.from_numpy(S).to(dtype=torch.long,device=device)\n",
        "    X = torch.from_numpy(X).to(dtype=torch.float32, device=device)\n",
        "    mask = torch.from_numpy(mask).to(dtype=torch.float32, device=device)\n",
        "    chain_M = torch.from_numpy(chain_M).to(dtype=torch.float32, device=device)\n",
        "    chain_M_pos = torch.from_numpy(chain_M_pos).to(dtype=torch.float32, device=device)\n",
        "    omit_AA_mask = torch.from_numpy(omit_AA_mask).to(dtype=torch.float32, device=device)\n",
        "    chain_encoding_all = torch.from_numpy(chain_encoding_all).to(dtype=torch.long, device=device)\n",
        "    # in general, in this return statement, *_list_list has the list inside list format because the outer list corresponds to \"batch_clones\", \n",
        "    # whereas the inner list corresponds to \"chains\" for each of the elements of \"batch_clones\"\n",
        "    # \"masked_list_list\" contains names of the designable chains (which is my target for single chain energy), whereas \"visible_list_list\" \n",
        "    # contains names of the fixed chains (which should be empty for my single chain energy)\n",
        "    # for my single chain energy case, \"letter_list_list\" should be equal to \"masked_list_list\", and three lists should have one list for now\n",
        "    # \"chain_encoding_all\" should also contain chain-index related to the only single chain which should be 0 (all 0s)\n",
        "    # the last lists starting from \"tied_pos_list_of_lists_list\" to the end should be irrelevant for my single chain energy case\n",
        "    # but still it would be good to check the values of these irrelevant lists, and get an idea if everything makes sense or not\n",
        "    # \"chain_M_pos\" contains values from \"fixed_position_mask\" through \"m_pos\", which should get populated with 0.0 for fixed positions\n",
        "    # and 1.0 for designable positions, which can be controlled through the , which\n",
        "    # is controlled by \"fixed_position_dict\" input to this function from the running script\n",
        "    # \"chain_M\" is formed from \"m_pad\" which comes from \"m\" which comes from chain_mask = np.ones(chain_length) #1.0 for masked\n",
        "    # so, for my single chain energy usecase, \"chain_M\" should be all 1.0s with the same length as chain_M_pos\n",
        "    # I do not think \"X\", \"S\", and \"mask\" need to be manipulated for now \n",
        "    return X, S, mask, lengths, chain_M, chain_encoding_all, letter_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef_all, pssm_bias_all, pssm_log_odds_all, bias_by_res_all, tied_beta\n",
        "\n",
        "\n",
        "# No need to dig into this loss function for now\n",
        "def loss_nll(S, log_probs, mask):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    criterion = torch.nn.NLLLoss(reduction='none')\n",
        "    loss = criterion(\n",
        "        log_probs.contiguous().view(-1, log_probs.size(-1)), S.contiguous().view(-1)\n",
        "    ).view(S.size())\n",
        "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
        "    return loss, loss_av\n",
        "\n",
        "# No need to dig into this label smoothing stuff for now\n",
        "def loss_smoothed(S, log_probs, mask, weight=0.1):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    S_onehot = torch.nn.functional.one_hot(S, 21).float()\n",
        "\n",
        "    # Label smoothing\n",
        "    S_onehot = S_onehot + weight / float(S_onehot.size(-1))\n",
        "    S_onehot = S_onehot / S_onehot.sum(-1, keepdim=True)\n",
        "\n",
        "    loss = -(S_onehot * log_probs).sum(-1)\n",
        "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
        "    return loss, loss_av\n",
        "\n",
        "# Objects of this class can be indexed since dunder methods __len()__ and __getitem()__ have been implemented, which \n",
        "# indexes a list that has been declared as an instance variable in the constructor,\n",
        "# and each element of that underlying list is a dictionary containing information regarding a specific sequence\n",
        "class StructureDataset():\n",
        "    def __init__(self, jsonl_file, verbose=True, truncate=None, max_length=100,\n",
        "        alphabet='ACDEFGHIKLMNPQRSTVWYX-'):\n",
        "        alphabet_set = set([a for a in alphabet])\n",
        "        discard_count = {\n",
        "            'bad_chars': 0,\n",
        "            'too_long': 0,\n",
        "            'bad_seq_length': 0\n",
        "        }\n",
        "\n",
        "        with open(jsonl_file) as f:\n",
        "            self.data = []\n",
        "\n",
        "            lines = f.readlines()\n",
        "            start = time.time()\n",
        "            for i, line in enumerate(lines):\n",
        "                entry = json.loads(line)\n",
        "                seq = entry['seq'] \n",
        "                name = entry['name']\n",
        "\n",
        "                # Convert raw coords to np arrays\n",
        "                #for key, val in entry['coords'].items():\n",
        "                #    entry['coords'][key] = np.asarray(val)\n",
        "\n",
        "                # Check if in alphabet\n",
        "                bad_chars = set([s for s in seq]).difference(alphabet_set)\n",
        "                if len(bad_chars) == 0:\n",
        "                    if len(entry['seq']) <= max_length:\n",
        "                        if True:\n",
        "                            self.data.append(entry)\n",
        "                        else:\n",
        "                            discard_count['bad_seq_length'] += 1\n",
        "                    else:\n",
        "                        discard_count['too_long'] += 1\n",
        "                else:\n",
        "                    print(name, bad_chars, entry['seq'])\n",
        "                    discard_count['bad_chars'] += 1\n",
        "\n",
        "                # Truncate early\n",
        "                if truncate is not None and len(self.data) == truncate:\n",
        "                    return\n",
        "\n",
        "                if verbose and (i + 1) % 1000 == 0:\n",
        "                    elapsed = time.time() - start\n",
        "                    print('{} entries ({} loaded) in {:.1f} s'.format(len(self.data), i+1, elapsed))\n",
        "\n",
        "            print('discarded', discard_count)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "\n",
        "# Objects of this class can be indexed since dunder methods __len()__ and __getitem()__ have been implemented, which \n",
        "# indexes a list that has been declared as an instance variable in the constructor,\n",
        "# and each element of that underlying list is a dictionary containing information regarding a specific structure,\n",
        "# seems like a structure-specific version of the above method which deals with sequences \n",
        "class StructureDatasetPDB():\n",
        "    def __init__(self, pdb_dict_list, verbose=True, truncate=None, max_length=100,\n",
        "        alphabet='ACDEFGHIKLMNPQRSTVWYX-'):\n",
        "        alphabet_set = set([a for a in alphabet])\n",
        "        discard_count = {\n",
        "            'bad_chars': 0,\n",
        "            'too_long': 0,\n",
        "            'bad_seq_length': 0\n",
        "        }\n",
        "\n",
        "        self.data = []\n",
        "\n",
        "        start = time.time()\n",
        "        # elements of pdb_dict_list are dictionaries containing information regarding a specific pdb file\n",
        "        for i, entry in enumerate(pdb_dict_list):\n",
        "            seq = entry['seq']\n",
        "            name = entry['name']\n",
        "\n",
        "            bad_chars = set([s for s in seq]).difference(alphabet_set)\n",
        "            if len(bad_chars) == 0:\n",
        "                if len(entry['seq']) <= max_length:\n",
        "                    self.data.append(entry)\n",
        "                else:\n",
        "                    discard_count['too_long'] += 1\n",
        "            else:\n",
        "                discard_count['bad_chars'] += 1\n",
        "\n",
        "            # Truncate early\n",
        "            if truncate is not None and len(self.data) == truncate:\n",
        "                return\n",
        "\n",
        "            if verbose and (i + 1) % 1000 == 0:\n",
        "                elapsed = time.time() - start\n",
        "\n",
        "            #print('Discarded', discard_count)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "\n",
        "    \n",
        "class StructureLoader():\n",
        "    def __init__(self, dataset, batch_size=100, shuffle=True,\n",
        "        collate_fn=lambda x:x, drop_last=False):\n",
        "        self.dataset = dataset\n",
        "        self.size = len(dataset)\n",
        "        self.lengths = [len(dataset[i]['seq']) for i in range(self.size)]\n",
        "        self.batch_size = batch_size\n",
        "        sorted_ix = np.argsort(self.lengths)\n",
        "\n",
        "        # Cluster into batches of similar sizes\n",
        "        clusters, batch = [], []\n",
        "        batch_max = 0\n",
        "        for ix in sorted_ix:\n",
        "            size = self.lengths[ix]\n",
        "            if size * (len(batch) + 1) <= self.batch_size:\n",
        "                batch.append(ix)\n",
        "                batch_max = size\n",
        "            else:\n",
        "                clusters.append(batch)\n",
        "                batch, batch_max = [], 0\n",
        "        if len(batch) > 0:\n",
        "            clusters.append(batch)\n",
        "        self.clusters = clusters\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.clusters)\n",
        "\n",
        "    def __iter__(self):\n",
        "        np.random.shuffle(self.clusters)\n",
        "        for b_idx in self.clusters:\n",
        "            batch = [self.dataset[i] for i in b_idx]\n",
        "            yield batch\n",
        "            \n",
        "            \n",
        "            \n",
        "# The following gather functions\n",
        "def gather_edges(edges, neighbor_idx):\n",
        "    # Features [B,N,N,C] at Neighbor indices [B,N,K] => Neighbor features [B,N,K,C]\n",
        "    neighbors = neighbor_idx.unsqueeze(-1).expand(-1, -1, -1, edges.size(-1))\n",
        "    edge_features = torch.gather(edges, 2, neighbors)\n",
        "    return edge_features\n",
        "\n",
        "def gather_nodes(nodes, neighbor_idx):\n",
        "    # Features [B,N,C] at Neighbor indices [B,N,K] => [B,N,K,C]\n",
        "    # Flatten and expand indices per batch [B,N,K] => [B,NK] => [B,NK,C]\n",
        "    neighbors_flat = neighbor_idx.view((neighbor_idx.shape[0], -1))\n",
        "    neighbors_flat = neighbors_flat.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
        "    # Gather and re-pack\n",
        "    neighbor_features = torch.gather(nodes, 1, neighbors_flat)\n",
        "    neighbor_features = neighbor_features.view(list(neighbor_idx.shape)[:3] + [-1])\n",
        "    return neighbor_features\n",
        "\n",
        "def gather_nodes_t(nodes, neighbor_idx):\n",
        "    # Features [B,N,C] at Neighbor index [B,K] => Neighbor features[B,K,C]\n",
        "    idx_flat = neighbor_idx.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
        "    neighbor_features = torch.gather(nodes, 1, idx_flat)\n",
        "    return neighbor_features\n",
        "\n",
        "def cat_neighbors_nodes(h_nodes, h_neighbors, E_idx):\n",
        "    h_nodes = gather_nodes(h_nodes, E_idx)\n",
        "    h_nn = torch.cat([h_neighbors, h_nodes], -1)\n",
        "    return h_nn\n",
        "\n",
        "\n",
        "class EncLayer(nn.Module):\n",
        "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
        "        super(EncLayer, self).__init__()\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_in = num_in\n",
        "        self.scale = scale\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(num_hidden)\n",
        "        self.norm2 = nn.LayerNorm(num_hidden)\n",
        "        self.norm3 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W11 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W12 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W13 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
        "\n",
        "    def forward(self, h_V, h_E, E_idx, mask_V=None, mask_attend=None):\n",
        "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
        "\n",
        "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
        "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
        "        if mask_attend is not None:\n",
        "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
        "        dh = torch.sum(h_message, -2) / self.scale\n",
        "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
        "\n",
        "        dh = self.dense(h_V)\n",
        "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
        "        if mask_V is not None:\n",
        "            mask_V = mask_V.unsqueeze(-1)\n",
        "            h_V = mask_V * h_V\n",
        "\n",
        "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
        "        h_message = self.W13(self.act(self.W12(self.act(self.W11(h_EV)))))\n",
        "        h_E = self.norm3(h_E + self.dropout3(h_message))\n",
        "        return h_V, h_E\n",
        "\n",
        "\n",
        "class DecLayer(nn.Module):\n",
        "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
        "        super(DecLayer, self).__init__()\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_in = num_in\n",
        "        self.scale = scale\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(num_hidden)\n",
        "        self.norm2 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
        "\n",
        "    def forward(self, h_V, h_E, mask_V=None, mask_attend=None):\n",
        "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
        "\n",
        "        # Concatenate h_V_i to h_E_ij\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_E.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_E], -1)\n",
        "\n",
        "        # Maybe, length of the message vector can serve as attention\n",
        "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
        "        # the mask attend here is most probably just for zeroing out the padded positions\n",
        "        # I do not think it will matter that much\n",
        "        if mask_attend is not None:\n",
        "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
        "            # why divide by 30 when we are dealing with 48 neighbors in the current version of the model?\n",
        "        # Let me check the messages corresponding to \n",
        "        dh = torch.sum(h_message, -2) / self.scale\n",
        "\n",
        "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
        "\n",
        "        # Position-wise feedforward\n",
        "        dh = self.dense(h_V)\n",
        "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
        "\n",
        "        if mask_V is not None:\n",
        "            mask_V = mask_V.unsqueeze(-1)\n",
        "            h_V = mask_V * h_V\n",
        "\n",
        "        # \"h_message\" can be returned without dividing by \"self.scale\" also\n",
        "        return h_V, (h_message/self.scale) \n",
        "\n",
        "\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, num_hidden, num_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.W_in = nn.Linear(num_hidden, num_ff, bias=True)\n",
        "        self.W_out = nn.Linear(num_ff, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "    def forward(self, h_V):\n",
        "        h = self.act(self.W_in(h_V))\n",
        "        h = self.W_out(h)\n",
        "        return h\n",
        "\n",
        "class PositionalEncodings(nn.Module):\n",
        "    def __init__(self, num_embeddings, max_relative_feature=32):\n",
        "        super(PositionalEncodings, self).__init__()\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.max_relative_feature = max_relative_feature\n",
        "        self.linear = nn.Linear(2*max_relative_feature+1+1, num_embeddings)\n",
        "\n",
        "    def forward(self, offset, mask):\n",
        "        d = torch.clip(offset + self.max_relative_feature, 0, 2*self.max_relative_feature)*mask + (1-mask)*(2*self.max_relative_feature+1)\n",
        "        d_onehot = torch.nn.functional.one_hot(d, 2*self.max_relative_feature+1+1)\n",
        "        E = self.linear(d_onehot.float())\n",
        "        return E\n",
        "\n",
        "# Does not look like this function needs to be modified for now to use the model as sort of an energy function\n",
        "# The only thing that could do something is \"top_k\", which can be changed for considering more or less neighbors\n",
        "# for each of the nodes, but that too I think does not matter if the default value of top_k is updated by parameter passing\n",
        "# This function is called from the model itself with node_features=128, edge_features=128, and top_k=48\n",
        "# ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
        "class ProteinFeatures(nn.Module):\n",
        "    def __init__(self, edge_features, node_features, num_positional_embeddings=16,\n",
        "        num_rbf=16, top_k=30, augment_eps=0., num_chain_embeddings=16):\n",
        "        \"\"\" Extract protein features \"\"\"\n",
        "        super(ProteinFeatures, self).__init__()\n",
        "        self.edge_features = edge_features\n",
        "        self.node_features = node_features\n",
        "        self.top_k = top_k\n",
        "        self.augment_eps = augment_eps \n",
        "        self.num_rbf = num_rbf\n",
        "        self.num_positional_embeddings = num_positional_embeddings\n",
        "\n",
        "        self.embeddings = PositionalEncodings(num_positional_embeddings)\n",
        "        node_in, edge_in = 6, num_positional_embeddings + num_rbf*25\n",
        "        self.edge_embedding = nn.Linear(edge_in, edge_features, bias=False)\n",
        "        self.norm_edges = nn.LayerNorm(edge_features)\n",
        "\n",
        "    # the output of this function MUST be analyzed either directly or via some other function to \n",
        "    # understand how to get \"index/position\" of neighbors\n",
        "    def _dist(self, X, mask, eps=1E-6):\n",
        "        mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
        "        dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
        "        D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
        "        D_max, _ = torch.max(D, -1, keepdim=True)\n",
        "        D_adjust = D + (1. - mask_2D) * D_max\n",
        "        sampled_top_k = self.top_k\n",
        "        D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(self.top_k, X.shape[1]), dim=-1, largest=False)\n",
        "        return D_neighbors, E_idx\n",
        "\n",
        "    def _rbf(self, D):\n",
        "        device = D.device\n",
        "        D_min, D_max, D_count = 2., 22., self.num_rbf\n",
        "        D_mu = torch.linspace(D_min, D_max, D_count, device=device)\n",
        "        D_mu = D_mu.view([1,1,1,-1])\n",
        "        D_sigma = (D_max - D_min) / D_count\n",
        "        D_expand = torch.unsqueeze(D, -1)\n",
        "        RBF = torch.exp(-((D_expand - D_mu) / D_sigma)**2)\n",
        "        return RBF\n",
        "\n",
        "    def _get_rbf(self, A, B, E_idx):\n",
        "        D_A_B = torch.sqrt(torch.sum((A[:,:,None,:] - B[:,None,:,:])**2,-1) + 1e-6) #[B, L, L]\n",
        "        D_A_B_neighbors = gather_edges(D_A_B[:,:,:,None], E_idx)[:,:,:,0] #[B,L,K]\n",
        "        RBF_A_B = self._rbf(D_A_B_neighbors)\n",
        "        return RBF_A_B\n",
        "\n",
        "    # this function will be called with the arguments as forward(), but will return information regarding \n",
        "    # the neighbors which I will figure out a way to parse\n",
        "    def return_neighbor_info(self, X, mask, residue_idx, chain_labels):\n",
        "        b = X[:,:,1,:] - X[:,:,0,:]\n",
        "        c = X[:,:,2,:] - X[:,:,1,:]\n",
        "        a = torch.cross(b, c, dim=-1)\n",
        "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "        Ca = X[:,:,1,:]\n",
        "        N = X[:,:,0,:]\n",
        "        C = X[:,:,2,:]\n",
        "        O = X[:,:,3,:]\n",
        " \n",
        "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
        "\n",
        "\n",
        "    def forward(self, X, mask, residue_idx, chain_labels):\n",
        "        if self.augment_eps > 0:\n",
        "            X = X + self.augment_eps * torch.randn_like(X)\n",
        "        \n",
        "        b = X[:,:,1,:] - X[:,:,0,:]\n",
        "        c = X[:,:,2,:] - X[:,:,1,:]\n",
        "        a = torch.cross(b, c, dim=-1)\n",
        "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "        Ca = X[:,:,1,:]\n",
        "        N = X[:,:,0,:]\n",
        "        C = X[:,:,2,:]\n",
        "        O = X[:,:,3,:]\n",
        " \n",
        "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
        "\n",
        "        RBF_all = []\n",
        "        RBF_all.append(self._rbf(D_neighbors)) #Ca-Ca\n",
        "        RBF_all.append(self._get_rbf(N, N, E_idx)) #N-N\n",
        "        RBF_all.append(self._get_rbf(C, C, E_idx)) #C-C\n",
        "        RBF_all.append(self._get_rbf(O, O, E_idx)) #O-O\n",
        "        RBF_all.append(self._get_rbf(Cb, Cb, E_idx)) #Cb-Cb\n",
        "        RBF_all.append(self._get_rbf(Ca, N, E_idx)) #Ca-N\n",
        "        RBF_all.append(self._get_rbf(Ca, C, E_idx)) #Ca-C\n",
        "        RBF_all.append(self._get_rbf(Ca, O, E_idx)) #Ca-O\n",
        "        RBF_all.append(self._get_rbf(Ca, Cb, E_idx)) #Ca-Cb\n",
        "        RBF_all.append(self._get_rbf(N, C, E_idx)) #N-C\n",
        "        RBF_all.append(self._get_rbf(N, O, E_idx)) #N-O\n",
        "        RBF_all.append(self._get_rbf(N, Cb, E_idx)) #N-Cb\n",
        "        RBF_all.append(self._get_rbf(Cb, C, E_idx)) #Cb-C\n",
        "        RBF_all.append(self._get_rbf(Cb, O, E_idx)) #Cb-O\n",
        "        RBF_all.append(self._get_rbf(O, C, E_idx)) #O-C\n",
        "        RBF_all.append(self._get_rbf(N, Ca, E_idx)) #N-Ca\n",
        "        RBF_all.append(self._get_rbf(C, Ca, E_idx)) #C-Ca\n",
        "        RBF_all.append(self._get_rbf(O, Ca, E_idx)) #O-Ca\n",
        "        RBF_all.append(self._get_rbf(Cb, Ca, E_idx)) #Cb-Ca\n",
        "        RBF_all.append(self._get_rbf(C, N, E_idx)) #C-N\n",
        "        RBF_all.append(self._get_rbf(O, N, E_idx)) #O-N\n",
        "        RBF_all.append(self._get_rbf(Cb, N, E_idx)) #Cb-N\n",
        "        RBF_all.append(self._get_rbf(C, Cb, E_idx)) #C-Cb\n",
        "        RBF_all.append(self._get_rbf(O, Cb, E_idx)) #O-Cb\n",
        "        RBF_all.append(self._get_rbf(C, O, E_idx)) #C-O\n",
        "        RBF_all = torch.cat(tuple(RBF_all), dim=-1)\n",
        "\n",
        "        offset = residue_idx[:,:,None]-residue_idx[:,None,:]\n",
        "        offset = gather_edges(offset[:,:,:,None], E_idx)[:,:,:,0] #[B, L, K]\n",
        "\n",
        "        d_chains = ((chain_labels[:, :, None] - chain_labels[:,None,:])==0).long() #find self vs non-self interaction\n",
        "        E_chains = gather_edges(d_chains[:,:,:,None], E_idx)[:,:,:,0]\n",
        "        E_positional = self.embeddings(offset.long(), E_chains)\n",
        "        E = torch.cat((E_positional, RBF_all), -1)\n",
        "        E = self.edge_embedding(E)\n",
        "        E = self.norm_edges(E)\n",
        "        return E, E_idx \n",
        "\n",
        "\n",
        "\n",
        "class ProteinMPNN(nn.Module):\n",
        "    # \"node_features\" and \"edge_features\" are actually dimensionality of these features (\"hidden_dim\" in the calling script)\n",
        "    # the value is 128 for the version that I am using\n",
        "    def __init__(self, num_letters, node_features, edge_features,\n",
        "        hidden_dim, num_encoder_layers=3, num_decoder_layers=3,\n",
        "        vocab=21, k_neighbors=64, augment_eps=0.05, dropout=0.1):\n",
        "        super(ProteinMPNN, self).__init__()\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.node_features = node_features\n",
        "        self.edge_features = edge_features\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Featurization layers\n",
        "        # The version that I am using considers 48 neighbors for each position\n",
        "        self.features = ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
        "\n",
        "        self.W_e = nn.Linear(edge_features, hidden_dim, bias=True)\n",
        "        # This W_s is for embedding the sequence\n",
        "        self.W_s = nn.Embedding(vocab, hidden_dim)\n",
        "\n",
        "        # Encoder layers\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            EncLayer(hidden_dim, hidden_dim*2, dropout=dropout)\n",
        "            for _ in range(num_encoder_layers)\n",
        "        ])\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            DecLayer(hidden_dim, hidden_dim*3, dropout=dropout)\n",
        "            for _ in range(num_decoder_layers)\n",
        "        ])\n",
        "        self.W_out = nn.Linear(hidden_dim, num_letters, bias=True)\n",
        "\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    # Creating my own versions of forward should be an easy way to get embeddings or attention weights from diffrerent layers of the model\n",
        "    # See here (https://discuss.pytorch.org/t/how-can-i-extract-intermediate-layer-output-from-loaded-cnn-model/77301) in the forums for adding forward\n",
        "    # hooks or manipulating the forward method\n",
        "    # but my easy solution would be to create different versions of the forward method with different namaes, and calling them explicitly\n",
        "    # \"chain_M\" and \"mask\" seem to be the things that I need to understand very well and play-around with \n",
        "    def forward(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn, use_input_decoding_order=False, decoding_order=None):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Concatenate sequence embeddings for autoregressive decoder\n",
        "        # h_S denotes embedding of the sequence itself for use in decoder\n",
        "        h_S = self.W_s(S)\n",
        "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "\n",
        "\n",
        "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
        "        if not use_input_decoding_order:\n",
        "            decoding_order = torch.argsort((chain_M+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for layer in self.decoder_layers:\n",
        "            # Masked positions attend to encoder information, unmasked see. \n",
        "            h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "            h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
        "            # only the last layer decoder-messages will be stored in \"decoder_messages\"\n",
        "            h_V, decoder_messages = layer(h_V, h_ESV, mask)\n",
        "\n",
        "        logits = self.W_out(h_V)\n",
        "        # The probabilities are passed through log() function so that the sequences can be ranked based by summing the respective values \n",
        "        # for each position instead of multiplication \n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        # messages from the last layer decoder will also be returned for extracting neighbor-attention approximation\n",
        "        return log_probs, decoder_messages\n",
        "\n",
        "\n",
        "\n",
        "    # Seems like this is the method which is used by the notebook for calculating probabilites and scoring\n",
        "    # Need to dig into it thoroughly\n",
        "    # \"chain_mask\" and \"residue_idx\" seem like the tensors of interest\n",
        "    def sample(self, X, randn, S_true, chain_mask, chain_encoding_all, residue_idx, mask=None, temperature=1.0, omit_AAs_np=None, bias_AAs_np=None, chain_M_pos=None, omit_AA_mask=None, pssm_coef=None, pssm_bias=None, pssm_multi=None, pssm_log_odds_flag=None, pssm_log_odds_mask=None, pssm_bias_flag=None, bias_by_res=None):\n",
        "        device = X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Decoder uses masked self-attention\n",
        "        chain_mask = chain_mask*chain_M_pos*mask #update chain_M to include missing regions\n",
        "        decoding_order = torch.argsort((chain_mask+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        N_batch, N_nodes = X.size(0), X.size(1)\n",
        "        log_probs = torch.zeros((N_batch, N_nodes, 21), device=device)\n",
        "        all_probs = torch.zeros((N_batch, N_nodes, 21), device=device, dtype=torch.float32)\n",
        "        h_S = torch.zeros_like(h_V, device=device)\n",
        "        S = torch.zeros((N_batch, N_nodes), dtype=torch.int64, device=device)\n",
        "        h_V_stack = [h_V] + [torch.zeros_like(h_V, device=device) for _ in range(len(self.decoder_layers))]\n",
        "        constant = torch.tensor(omit_AAs_np, device=device)\n",
        "        constant_bias = torch.tensor(bias_AAs_np, device=device)\n",
        "        #chain_mask_combined = chain_mask*chain_M_pos \n",
        "        omit_AA_mask_flag = omit_AA_mask != None\n",
        "\n",
        "\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for t_ in range(N_nodes):\n",
        "            t = decoding_order[:,t_] #[B]\n",
        "            chain_mask_gathered = torch.gather(chain_mask, 1, t[:,None]) #[B]\n",
        "            bias_by_res_gathered = torch.gather(bias_by_res, 1, t[:,None,None].repeat(1,1,21))[:,0,:] #[B, 21]\n",
        "            if (chain_mask_gathered==0).all():\n",
        "                S_t = torch.gather(S_true, 1, t[:,None])\n",
        "            else:\n",
        "                # Hidden layers\n",
        "                E_idx_t = torch.gather(E_idx, 1, t[:,None,None].repeat(1,1,E_idx.shape[-1]))\n",
        "                h_E_t = torch.gather(h_E, 1, t[:,None,None,None].repeat(1,1,h_E.shape[-2], h_E.shape[-1]))\n",
        "                h_ES_t = cat_neighbors_nodes(h_S, h_E_t, E_idx_t)\n",
        "                h_EXV_encoder_t = torch.gather(h_EXV_encoder_fw, 1, t[:,None,None,None].repeat(1,1,h_EXV_encoder_fw.shape[-2], h_EXV_encoder_fw.shape[-1]))\n",
        "                mask_t = torch.gather(mask, 1, t[:,None])\n",
        "                for l, layer in enumerate(self.decoder_layers):\n",
        "                    # Updated relational features for future states\n",
        "                    h_ESV_decoder_t = cat_neighbors_nodes(h_V_stack[l], h_ES_t, E_idx_t)\n",
        "                    h_V_t = torch.gather(h_V_stack[l], 1, t[:,None,None].repeat(1,1,h_V_stack[l].shape[-1]))\n",
        "                    h_ESV_t = torch.gather(mask_bw, 1, t[:,None,None,None].repeat(1,1,mask_bw.shape[-2], mask_bw.shape[-1])) * h_ESV_decoder_t + h_EXV_encoder_t\n",
        "                    h_V_stack[l+1].scatter_(1, t[:,None,None].repeat(1,1,h_V.shape[-1]), layer(h_V_t, h_ESV_t, mask_V=mask_t))\n",
        "                # Sampling step\n",
        "                h_V_t = torch.gather(h_V_stack[-1], 1, t[:,None,None].repeat(1,1,h_V_stack[-1].shape[-1]))[:,0]\n",
        "                logits = self.W_out(h_V_t) / temperature\n",
        "                probs = F.softmax(logits-constant[None,:]*1e8+constant_bias[None,:]/temperature+bias_by_res_gathered/temperature, dim=-1)\n",
        "                if pssm_bias_flag:\n",
        "                    pssm_coef_gathered = torch.gather(pssm_coef, 1, t[:,None])[:,0]\n",
        "                    pssm_bias_gathered = torch.gather(pssm_bias, 1, t[:,None,None].repeat(1,1,pssm_bias.shape[-1]))[:,0]\n",
        "                    probs = (1-pssm_multi*pssm_coef_gathered[:,None])*probs + pssm_multi*pssm_coef_gathered[:,None]*pssm_bias_gathered\n",
        "                if pssm_log_odds_flag:\n",
        "                    pssm_log_odds_mask_gathered = torch.gather(pssm_log_odds_mask, 1, t[:,None, None].repeat(1,1,pssm_log_odds_mask.shape[-1]))[:,0] #[B, 21]\n",
        "                    probs_masked = probs*pssm_log_odds_mask_gathered\n",
        "                    probs_masked += probs * 0.001\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                if omit_AA_mask_flag:\n",
        "                    omit_AA_mask_gathered = torch.gather(omit_AA_mask, 1, t[:,None, None].repeat(1,1,omit_AA_mask.shape[-1]))[:,0] #[B, 21]\n",
        "                    probs_masked = probs*(1.0-omit_AA_mask_gathered)\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                # Here is where sampling from the multinomial distribution is happening\n",
        "                # this will sample 1 element according to the given distribution, and return the index of that element [from 0 to 20]\n",
        "                S_t = torch.multinomial(probs, 1)\n",
        "                all_probs.scatter_(1, t[:,None,None].repeat(1,1,21), (chain_mask_gathered[:,:,None,]*probs[:,None,:]).float())\n",
        "            S_true_gathered = torch.gather(S_true, 1, t[:,None])\n",
        "            S_t = (S_t*chain_mask_gathered+S_true_gathered*(1.0-chain_mask_gathered)).long()\n",
        "            temp1 = self.W_s(S_t)\n",
        "            h_S.scatter_(1, t[:,None,None].repeat(1,1,temp1.shape[-1]), temp1)\n",
        "            S.scatter_(1, t[:,None], S_t)\n",
        "        output_dict = {\"S\": S, \"probs\": all_probs, \"decoding_order\": decoding_order}\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "    def tied_sample(self, X, randn, S_true, chain_mask, chain_encoding_all, residue_idx, mask=None, temperature=1.0, omit_AAs_np=None, bias_AAs_np=None, chain_M_pos=None, omit_AA_mask=None, pssm_coef=None, pssm_bias=None, pssm_multi=None, pssm_log_odds_flag=None, pssm_log_odds_mask=None, pssm_bias_flag=None, tied_pos=None, tied_beta=None, bias_by_res=None):\n",
        "        device = X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=device)\n",
        "        h_E = self.W_e(E)\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Decoder uses masked self-attention\n",
        "        chain_mask = chain_mask*chain_M_pos*mask #update chain_M to include missing regions\n",
        "        decoding_order = torch.argsort((chain_mask+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "\n",
        "        new_decoding_order = []\n",
        "        for t_dec in list(decoding_order[0,].cpu().data.numpy()):\n",
        "            if t_dec not in list(itertools.chain(*new_decoding_order)):\n",
        "                list_a = [item for item in tied_pos if t_dec in item]\n",
        "                if list_a:\n",
        "                    new_decoding_order.append(list_a[0])\n",
        "                else:\n",
        "                    new_decoding_order.append([t_dec])\n",
        "        decoding_order = torch.tensor(list(itertools.chain(*new_decoding_order)), device=device)[None,].repeat(X.shape[0],1)\n",
        "\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        N_batch, N_nodes = X.size(0), X.size(1)\n",
        "        log_probs = torch.zeros((N_batch, N_nodes, 21), device=device)\n",
        "        all_probs = torch.zeros((N_batch, N_nodes, 21), device=device, dtype=torch.float32)\n",
        "        h_S = torch.zeros_like(h_V, device=device)\n",
        "        S = torch.zeros((N_batch, N_nodes), dtype=torch.int64, device=device)\n",
        "        h_V_stack = [h_V] + [torch.zeros_like(h_V, device=device) for _ in range(len(self.decoder_layers))]\n",
        "        constant = torch.tensor(omit_AAs_np, device=device)\n",
        "        constant_bias = torch.tensor(bias_AAs_np, device=device)\n",
        "        omit_AA_mask_flag = omit_AA_mask != None\n",
        "\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for t_list in new_decoding_order:\n",
        "            logits = 0.0\n",
        "            logit_list = []\n",
        "            done_flag = False\n",
        "            for t in t_list:\n",
        "                if (chain_mask[:,t]==0).all():\n",
        "                    S_t = S_true[:,t]\n",
        "                    for t in t_list:\n",
        "                        h_S[:,t,:] = self.W_s(S_t)\n",
        "                        S[:,t] = S_t\n",
        "                    done_flag = True\n",
        "                    break\n",
        "                else:\n",
        "                    E_idx_t = E_idx[:,t:t+1,:]\n",
        "                    h_E_t = h_E[:,t:t+1,:,:]\n",
        "                    h_ES_t = cat_neighbors_nodes(h_S, h_E_t, E_idx_t)\n",
        "                    h_EXV_encoder_t = h_EXV_encoder_fw[:,t:t+1,:,:]\n",
        "                    mask_t = mask[:,t:t+1]\n",
        "                    for l, layer in enumerate(self.decoder_layers):\n",
        "                        h_ESV_decoder_t = cat_neighbors_nodes(h_V_stack[l], h_ES_t, E_idx_t)\n",
        "                        h_V_t = h_V_stack[l][:,t:t+1,:]\n",
        "                        h_ESV_t = mask_bw[:,t:t+1,:,:] * h_ESV_decoder_t + h_EXV_encoder_t\n",
        "                        h_V_stack[l+1][:,t,:] = layer(h_V_t, h_ESV_t, mask_V=mask_t).squeeze(1)\n",
        "                    h_V_t = h_V_stack[-1][:,t,:]\n",
        "                    logit_list.append((self.W_out(h_V_t) / temperature)/len(t_list))\n",
        "                    logits += tied_beta[t]*(self.W_out(h_V_t) / temperature)/len(t_list)\n",
        "            if done_flag:\n",
        "                pass\n",
        "            else:\n",
        "                bias_by_res_gathered = bias_by_res[:,t,:] #[B, 21]\n",
        "                probs = F.softmax(logits-constant[None,:]*1e8+constant_bias[None,:]/temperature+bias_by_res_gathered/temperature, dim=-1)\n",
        "                if pssm_bias_flag:\n",
        "                    pssm_coef_gathered = pssm_coef[:,t]\n",
        "                    pssm_bias_gathered = pssm_bias[:,t]\n",
        "                    probs = (1-pssm_multi*pssm_coef_gathered[:,None])*probs + pssm_multi*pssm_coef_gathered[:,None]*pssm_bias_gathered\n",
        "                if pssm_log_odds_flag:\n",
        "                    pssm_log_odds_mask_gathered = pssm_log_odds_mask[:,t]\n",
        "                    probs_masked = probs*pssm_log_odds_mask_gathered\n",
        "                    probs_masked += probs * 0.001\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                if omit_AA_mask_flag:\n",
        "                    omit_AA_mask_gathered = omit_AA_mask[:,t]\n",
        "                    probs_masked = probs*(1.0-omit_AA_mask_gathered)\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                S_t_repeat = torch.multinomial(probs, 1).squeeze(-1)\n",
        "                for t in t_list:\n",
        "                    h_S[:,t,:] = self.W_s(S_t_repeat)\n",
        "                    S[:,t] = S_t_repeat\n",
        "                    all_probs[:,t,:] = probs.float()\n",
        "        output_dict = {\"S\": S, \"probs\": all_probs, \"decoding_order\": decoding_order}\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "    # I am not seeing an immediate use of this method when the model is called through notebook\n",
        "    # So, will skip further commenting and digging for now\n",
        "    # But, seems like an interesting way of interacting with the model in a specific way, so\n",
        "    # might get back to this later\n",
        "    def conditional_probs(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn, backbone_only=False):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V_enc = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V_enc, h_E = layer(h_V_enc, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Concatenate sequence embeddings for autoregressive decoder\n",
        "        h_S = self.W_s(S)\n",
        "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V_enc, h_EX_encoder, E_idx)\n",
        "\n",
        "\n",
        "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
        "  \n",
        "        chain_M_np = chain_M.cpu().numpy()\n",
        "        idx_to_loop = np.argwhere(chain_M_np[0,:]==1)[:,0]\n",
        "        log_conditional_probs = torch.zeros([X.shape[0], chain_M.shape[1], 21], device=device).float()\n",
        "\n",
        "        for idx in idx_to_loop:\n",
        "            h_V = torch.clone(h_V_enc)\n",
        "            order_mask = torch.zeros(chain_M.shape[1], device=device).float()\n",
        "            if backbone_only:\n",
        "                order_mask = torch.ones(chain_M.shape[1], device=device).float()\n",
        "                order_mask[idx] = 0.\n",
        "            else:\n",
        "                order_mask = torch.zeros(chain_M.shape[1], device=device).float()\n",
        "                order_mask[idx] = 1.\n",
        "            decoding_order = torch.argsort((order_mask[None,]+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "            mask_size = E_idx.shape[1]\n",
        "            permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "            order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "            mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "            mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "            mask_bw = mask_1D * mask_attend\n",
        "            mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "            h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "            for layer in self.decoder_layers:\n",
        "                # Masked positions attend to encoder information, unmasked see. \n",
        "                h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "                h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
        "                h_V = layer(h_V, h_ESV, mask)\n",
        "\n",
        "            logits = self.W_out(h_V)\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "            log_conditional_probs[:,idx,:] = log_probs[:,idx,:]\n",
        "        return log_conditional_probs\n",
        "\n",
        "\n",
        "    # I am not seeing an immediate use of this method when the model is called through notebook\n",
        "    # So, will skip further commenting and digging for now\n",
        "    # But, seems like an interesting way of interacting with the model in a specific way, so\n",
        "    # might get back to this later\n",
        "    def unconditional_probs(self, X, mask, residue_idx, chain_encoding_all):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_V), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "\n",
        "        order_mask_backward = torch.zeros([X.shape[0], X.shape[1], X.shape[1]], device=device)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for layer in self.decoder_layers:\n",
        "            h_V = layer(h_V, h_EXV_encoder_fw, mask)\n",
        "\n",
        "        logits = self.W_out(h_V)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        return log_probs"
      ],
      "metadata": {
        "id": "HjbVWJkg7zik"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 128\n",
        "num_layers = 3 \n",
        "# Seems like, backbone_noise is set to 0 at inference path which seems logical\n",
        "backbone_noise=0.00\n",
        "mpnn_model = ProteinMPNN(num_letters=21, node_features=hidden_dim, edge_features=hidden_dim, hidden_dim=hidden_dim, num_encoder_layers=num_layers, num_decoder_layers=num_layers, augment_eps=backbone_noise, k_neighbors=checkpoint['num_edges'])\n",
        "mpnn_model.to(device)\n",
        "mpnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "mpnn_model.eval()"
      ],
      "metadata": {
        "id": "QBgBJd3J0N_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint['model_state_dict'].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pYLpMQS-ill",
        "outputId": "2c9272d6-9736-470b-bba6-07f3e2743bbc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['features.embeddings.linear.weight', 'features.embeddings.linear.bias', 'features.edge_embedding.weight', 'features.norm_edges.weight', 'features.norm_edges.bias', 'W_e.weight', 'W_e.bias', 'W_s.weight', 'encoder_layers.0.norm1.weight', 'encoder_layers.0.norm1.bias', 'encoder_layers.0.norm2.weight', 'encoder_layers.0.norm2.bias', 'encoder_layers.0.norm3.weight', 'encoder_layers.0.norm3.bias', 'encoder_layers.0.W1.weight', 'encoder_layers.0.W1.bias', 'encoder_layers.0.W2.weight', 'encoder_layers.0.W2.bias', 'encoder_layers.0.W3.weight', 'encoder_layers.0.W3.bias', 'encoder_layers.0.W11.weight', 'encoder_layers.0.W11.bias', 'encoder_layers.0.W12.weight', 'encoder_layers.0.W12.bias', 'encoder_layers.0.W13.weight', 'encoder_layers.0.W13.bias', 'encoder_layers.0.dense.W_in.weight', 'encoder_layers.0.dense.W_in.bias', 'encoder_layers.0.dense.W_out.weight', 'encoder_layers.0.dense.W_out.bias', 'encoder_layers.1.norm1.weight', 'encoder_layers.1.norm1.bias', 'encoder_layers.1.norm2.weight', 'encoder_layers.1.norm2.bias', 'encoder_layers.1.norm3.weight', 'encoder_layers.1.norm3.bias', 'encoder_layers.1.W1.weight', 'encoder_layers.1.W1.bias', 'encoder_layers.1.W2.weight', 'encoder_layers.1.W2.bias', 'encoder_layers.1.W3.weight', 'encoder_layers.1.W3.bias', 'encoder_layers.1.W11.weight', 'encoder_layers.1.W11.bias', 'encoder_layers.1.W12.weight', 'encoder_layers.1.W12.bias', 'encoder_layers.1.W13.weight', 'encoder_layers.1.W13.bias', 'encoder_layers.1.dense.W_in.weight', 'encoder_layers.1.dense.W_in.bias', 'encoder_layers.1.dense.W_out.weight', 'encoder_layers.1.dense.W_out.bias', 'encoder_layers.2.norm1.weight', 'encoder_layers.2.norm1.bias', 'encoder_layers.2.norm2.weight', 'encoder_layers.2.norm2.bias', 'encoder_layers.2.norm3.weight', 'encoder_layers.2.norm3.bias', 'encoder_layers.2.W1.weight', 'encoder_layers.2.W1.bias', 'encoder_layers.2.W2.weight', 'encoder_layers.2.W2.bias', 'encoder_layers.2.W3.weight', 'encoder_layers.2.W3.bias', 'encoder_layers.2.W11.weight', 'encoder_layers.2.W11.bias', 'encoder_layers.2.W12.weight', 'encoder_layers.2.W12.bias', 'encoder_layers.2.W13.weight', 'encoder_layers.2.W13.bias', 'encoder_layers.2.dense.W_in.weight', 'encoder_layers.2.dense.W_in.bias', 'encoder_layers.2.dense.W_out.weight', 'encoder_layers.2.dense.W_out.bias', 'decoder_layers.0.norm1.weight', 'decoder_layers.0.norm1.bias', 'decoder_layers.0.norm2.weight', 'decoder_layers.0.norm2.bias', 'decoder_layers.0.W1.weight', 'decoder_layers.0.W1.bias', 'decoder_layers.0.W2.weight', 'decoder_layers.0.W2.bias', 'decoder_layers.0.W3.weight', 'decoder_layers.0.W3.bias', 'decoder_layers.0.dense.W_in.weight', 'decoder_layers.0.dense.W_in.bias', 'decoder_layers.0.dense.W_out.weight', 'decoder_layers.0.dense.W_out.bias', 'decoder_layers.1.norm1.weight', 'decoder_layers.1.norm1.bias', 'decoder_layers.1.norm2.weight', 'decoder_layers.1.norm2.bias', 'decoder_layers.1.W1.weight', 'decoder_layers.1.W1.bias', 'decoder_layers.1.W2.weight', 'decoder_layers.1.W2.bias', 'decoder_layers.1.W3.weight', 'decoder_layers.1.W3.bias', 'decoder_layers.1.dense.W_in.weight', 'decoder_layers.1.dense.W_in.bias', 'decoder_layers.1.dense.W_out.weight', 'decoder_layers.1.dense.W_out.bias', 'decoder_layers.2.norm1.weight', 'decoder_layers.2.norm1.bias', 'decoder_layers.2.norm2.weight', 'decoder_layers.2.norm2.bias', 'decoder_layers.2.W1.weight', 'decoder_layers.2.W1.bias', 'decoder_layers.2.W2.weight', 'decoder_layers.2.W2.bias', 'decoder_layers.2.W3.weight', 'decoder_layers.2.W3.bias', 'decoder_layers.2.dense.W_in.weight', 'decoder_layers.2.dense.W_in.bias', 'decoder_layers.2.dense.W_out.weight', 'decoder_layers.2.dense.W_out.bias', 'W_out.weight', 'W_out.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse and create dictionaries for all the mutations in PremPS 2648\n",
        "# This dictionary will be a dictionary of dictionaries, where outer-dict keys will be pdbid+mutchain and inner-dict keys will be (wild+pos+mut) and ddg\n",
        "# the icodes can be brought to picture later\n",
        "# this \"two_level_dict\" is literally used everywhere throughout this code for storing all the numbers that are compared with each other under feature-specific keys\n",
        "git_url = \"https://raw.githubusercontent.com/SajidAhmeduiu/PremPS/main/Datasets/S2648/S2648.txt\"\n",
        "dataset =  pd.read_csv(git_url,delimiter=\"\\t\")\n",
        "\n",
        "pdbIds = list(dataset[\"PDB Id\"])\n",
        "mutChains = list(dataset[\"Mutated Chain\"])\n",
        "mutations = list(dataset[\"Mutation_PDB\"])\n",
        "ddgs = list(dataset[\"DDGexp\"])\n",
        "\n",
        "two_level_dict = {}\n",
        "\n",
        "for pdbId, mutChain, mutation, ddg in tqdm(zip(pdbIds,mutChains,mutations,ddgs)):\n",
        "    pos = [int(s) for s in re.findall('-?\\d+',mutation)][0]\n",
        "    wild = mutation[0]\n",
        "    mut = mutation[len(mutation)-1]\n",
        "\n",
        "    pdbId = pdbId.lower()\n",
        "\n",
        "    inner_dict = {}\n",
        "    inner_dict[\"mut\"] = f\"{wild}{pos}{mut}\"\n",
        "    inner_dict[\"ddg\"] = float(ddg)\n",
        "    outer_key = f\"{pdbId}{mutChain}\"\n",
        "    if outer_key not in two_level_dict:\n",
        "        two_level_dict[f\"{pdbId}{mutChain}\"] = [inner_dict]\n",
        "    else:\n",
        "        two_level_dict[f\"{pdbId}{mutChain}\"].append(inner_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "dd8907fa0c914791852cab120af14dca",
            "eb14ed18efdb4716bb43078723d62b0c",
            "b5038e7e2c1e421695ebc81edc3f0b4b",
            "58e8ea753d714b36bd45cd3ee7a3e19b",
            "329e2fedfa924b50b9bbc969615c36ac",
            "f70fe12bb0d34953832ed362e1bd2e6f",
            "12f41f2379b4493b9684cf241080ce3e",
            "6bf11afa4650459dbb4cf26749604f64",
            "1f534a1b5aab46128d296ec434ad93f4",
            "e2bc343fbd8242ae8f24f1fd4668e5b8",
            "b8249be24c81437297a2c537a5a83f67"
          ]
        },
        "id": "vP_unq7_sXrn",
        "outputId": "bc94add4-5086-4906-d85a-882b4c2023ff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd8907fa0c914791852cab120af14dca"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a seqres to position mapping dictionary\n",
        "# This dictionary will be a dictionary of dictionaries, where outer-dict keys will be pdbid+mutchain and inner-dict key will be (wild+pos) and value of 0-indexed position\n",
        "# the icodes can be brought to picture later\n",
        "mapping_dict = {}\n",
        "pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_2648_PDB_Files\"\n",
        "parser = PDBParser(QUIET=True)\n",
        "# some proteins need to be skipped for now due to ICODE related discrapency\n",
        "proteins_to_skip = []\n",
        "\n",
        "for filename in tqdm(os.listdir(pdbDirectory)):\n",
        "    filepath = os.path.join(pdbDirectory,filename)\n",
        "    structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "    model = structure[0]\n",
        "    inner_dict = {}\n",
        "    outer_key = filename.split(\".\")[0]\n",
        "    skip_flag = False\n",
        "    # single chain-assumption in action again\n",
        "    for chain in model:\n",
        "        for i,residue in enumerate(chain):\n",
        "            inner_key = f\"{three_to_one(residue.get_resname())}{residue.get_id()[1]}\"\n",
        "            if inner_key not in inner_dict:\n",
        "                inner_dict[inner_key] = i\n",
        "            else:\n",
        "                # For \"2immA:N31\" and \"1lveA:S27\", I have been fucked\n",
        "                # Need to think whether this will effect other positions or I can just avoid these two-protein related mutations for now?\n",
        "                # Let me just avoid these two proteins for now\n",
        "                print(\"YOU HAVE JUST BEEN FUCKED BY ICODE\")\n",
        "                print(f\"{outer_key}:{inner_key}\")\n",
        "                skip_flag = True\n",
        "    # The ICODE related problematic proteins will not be considered for now\n",
        "    if not skip_flag:\n",
        "        mapping_dict[outer_key] = inner_dict\n",
        "    else:\n",
        "        proteins_to_skip.append(outer_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "88e37fbcf8bc45e184df0208a487617f",
            "c1a4d35b4c0444e3bbe5f3e34bcf91cb",
            "7c0bed04d93a443da70c6f379c440ed0",
            "8839ddb0aec643efa8cec8154e2301a7",
            "cb8d7de293304f19941de98618b5397b",
            "624c353a4cca461e85666854b132fcef",
            "167583f480014a5bbdbb056ec2aea18d",
            "3b4fc86687ea47218ffc9f17e6d37c3a",
            "4e5d2985e4504e98b1ece6071f6ccdbb",
            "03cf52ea2a6047c1a09b7959f8a74518",
            "441e6d4575bf4b10a59d582ca75400c5"
          ]
        },
        "id": "vxARThyX3VYv",
        "outputId": "8eee6855-09bd-4706-f899-dcea965ec397"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/131 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88e37fbcf8bc45e184df0208a487617f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "1lveA:S27\n",
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "1lveA:S27\n",
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "2immA:N31\n",
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "2immA:N31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing this \"parse_PDB_biounits()\" function locally for addressing the fucked up integer named chain problem  \n",
        "def parse_PDB_biounits(x, atoms=['N', 'CA', 'C'], chain=None):\n",
        "    '''\n",
        "    input:  x = PDB filename\n",
        "            atoms = atoms to extract (optional)\n",
        "    output: (length, atoms, coords=(x,y,z)), sequence\n",
        "    '''\n",
        "    alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "    states = len(alpha_1)\n",
        "    alpha_3 = ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE',\n",
        "               'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL', 'GAP']\n",
        "\n",
        "    # The following dictionaries are mapping from one-letter to 0-20 index,\n",
        "    # three-letter to 0-20 index,\n",
        "    # 0-20 index to one-letter,\n",
        "    # one-letter to three-letter, and vice-versa\n",
        "    aa_1_N = {a: n for n, a in enumerate(alpha_1)}\n",
        "    aa_3_N = {a: n for n, a in enumerate(alpha_3)}\n",
        "    aa_N_1 = {n: a for n, a in enumerate(alpha_1)}\n",
        "    aa_1_3 = {a: b for a, b in zip(alpha_1, alpha_3)}\n",
        "    aa_3_1 = {b: a for a, b in zip(alpha_1, alpha_3)}\n",
        "\n",
        "    def AA_to_N(x):\n",
        "        # [\"ARND\"] -> [[0,1,2,3]]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 0: x = x[None]\n",
        "        return [[aa_1_N.get(a, states - 1) for a in y] for y in x]\n",
        "\n",
        "    def N_to_AA(x):\n",
        "        # [[0,1,2,3]] -> [\"ARND\"]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 1: x = x[None]\n",
        "        return [\"\".join([aa_N_1.get(a, \"-\") for a in y]) for y in x]\n",
        "\n",
        "    xyz, seq, min_resn, max_resn = {}, {}, 1e6, -1e6\n",
        "    for line in open(x, \"rb\"):\n",
        "        line = line.decode(\"utf-8\", \"ignore\").rstrip()\n",
        "\n",
        "        if line[:6] == \"HETATM\" and line[17:17 + 3] == \"MSE\":\n",
        "            line = line.replace(\"HETATM\", \"ATOM  \")\n",
        "            line = line.replace(\"MSE\", \"MET\")\n",
        "\n",
        "        if line[:4] == \"ATOM\":\n",
        "            ch = line[21:22]\n",
        "            # If the input chain is not in the PDB file, which can be the case if the target chains are named differently in the runner script,\n",
        "            # this line will cause the output to have literally no information, this is the case for integer named chains\n",
        "            # that does not mean that this line is not doing its job correctly, this is just a constraint that input chain names and\n",
        "            # chain names in the PDB file have to be congruent\n",
        "            # If \"ch\" is an integer, map it to alphabet, because input \"chain\" has been converted to alphabet\n",
        "            # In rare cases, some PDB files number chains with 1,2,3 instead of A,B,C\n",
        "            # This \"loc_dict\" dictionary contains integer to alphabet mapping for weird as fuck integer chain names\n",
        "            # This conversion will be done only when  chain name is actually an integer\n",
        "            if ord(ch) >= 49 and ord(ch) <= 57:\n",
        "                loc_dict = {(idx+1):ch for idx,ch in enumerate(ascii_uppercase)}\n",
        "                ch =  str(loc_dict[int(ch)])\n",
        "            if ch == chain or chain is None:\n",
        "                atom = line[12:12 + 4].strip()\n",
        "                resi = line[17:17 + 3]\n",
        "                resn = line[22:22 + 5].strip()\n",
        "                x, y, z = [float(line[i:(i + 8)]) for i in [30, 38, 46]]\n",
        "\n",
        "                if resn[-1].isalpha():\n",
        "                    resa, resn = resn[-1], int(resn[:-1]) - 1\n",
        "                else:\n",
        "                    resa, resn = \"\", int(resn) - 1\n",
        "                #         resn = int(resn)\n",
        "                if resn < min_resn:\n",
        "                    min_resn = resn\n",
        "                if resn > max_resn:\n",
        "                    max_resn = resn\n",
        "                if resn not in xyz:\n",
        "                    xyz[resn] = {}\n",
        "                if resa not in xyz[resn]:\n",
        "                    xyz[resn][resa] = {}\n",
        "                if resn not in seq:\n",
        "                    seq[resn] = {}\n",
        "                if resa not in seq[resn]:\n",
        "                    seq[resn][resa] = resi\n",
        "\n",
        "                if atom not in xyz[resn][resa]:\n",
        "                    xyz[resn][resa][atom] = np.array([x, y, z])\n",
        "\n",
        "    # convert to numpy arrays, fill in missing values\n",
        "    seq_, xyz_ = [], []\n",
        "    try:\n",
        "        for resn in range(min_resn, max_resn + 1):\n",
        "            if resn in seq:\n",
        "                for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k], 20))\n",
        "            else:\n",
        "                seq_.append(20)\n",
        "            if resn in xyz:\n",
        "                for k in sorted(xyz[resn]):\n",
        "                    for atom in atoms:\n",
        "                        if atom in xyz[resn][k]:\n",
        "                            xyz_.append(xyz[resn][k][atom])\n",
        "                        else:\n",
        "                            xyz_.append(np.full(3, np.nan))\n",
        "            else:\n",
        "                for atom in atoms: xyz_.append(np.full(3, np.nan))\n",
        "        return np.array(xyz_).reshape(-1, len(atoms), 3), N_to_AA(np.array(seq_))\n",
        "    except TypeError:\n",
        "        return 'no_chain', 'no_chain'\n",
        "\n",
        "# Took this part out of \"utils.py\", and put here so that smalll changes can be made to address pesky issues like\n",
        "# integer named chain, and shit like those\n",
        "def parse_PDB(path_to_pdb, input_chain_list=None):\n",
        "    c=0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V','W','X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v','w','x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "     \n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list  \n",
        " \n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    # Each of the biounits is a separate PDB file, so for running with a single PDB file like from colab, this loop will be executed only once\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {} \n",
        "        # This loop will be executed only once for single chain DDG type cases\n",
        "        for letter in chain_alphabet:\n",
        "            xyz, seq = parse_PDB_biounits(biounit, atoms=['N','CA','C','O'], chain=letter)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_'+letter]=seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                coords_dict_chain['N_chain_'+letter]=xyz[:,0,:].tolist()\n",
        "                coords_dict_chain['CA_chain_'+letter]=xyz[:,1,:].tolist()\n",
        "                coords_dict_chain['C_chain_'+letter]=xyz[:,2,:].tolist()\n",
        "                coords_dict_chain['O_chain_'+letter]=xyz[:,3,:].tolist()\n",
        "                my_dict['coords_chain_'+letter]=coords_dict_chain\n",
        "                s += 1\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        my_dict['name']=biounit[(fi+1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c+=1\n",
        "    return pdb_dict_list"
      ],
      "metadata": {
        "id": "UzBk27pmlfh7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_func_local(X, mask, eps=1E-6):\n",
        "    mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
        "    dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
        "    D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
        "    D_max, _ = torch.max(D, -1, keepdim=True)\n",
        "    D_adjust = D + (1. - mask_2D) * D_max\n",
        "    top_k = checkpoint[\"num_edges\"]\n",
        "    sampled_top_k = top_k\n",
        "    D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(top_k, X.shape[1]), dim=-1, largest=False)\n",
        "    return D_neighbors, E_idx\n",
        "\n",
        "def return_neighbor_info(X, mask):\n",
        "    b = X[:,:,1,:] - X[:,:,0,:]\n",
        "    c = X[:,:,2,:] - X[:,:,1,:]\n",
        "    a = torch.cross(b, c, dim=-1)\n",
        "    Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "    Ca = X[:,:,1,:]\n",
        "    N = X[:,:,0,:]\n",
        "    C = X[:,:,2,:]\n",
        "    O = X[:,:,3,:]\n",
        "\n",
        "    D_neighbors, E_idx = distance_func_local(Ca, mask)\n",
        "    # Got the indices of the neighbors, E_idx should be the 0-based indexing of the topK closest neighbors\n",
        "    # and D_neighbors should be the distances of those neighbors\n",
        "    return D_neighbors, E_idx"
      ],
      "metadata": {
        "id": "l6pA80oESa7Y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "from scipy.special import kl_div\n",
        "\n",
        "# read in the PDB files from the directory where the S_2648 PDB Files are stored, and set-them up one by one for featuirization, and passing through the model\n",
        "pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_2648_PDB_Files\"\n",
        "parser = PDBParser(QUIET=True)\n",
        "\n",
        "pdbId_info = []\n",
        "pos_info = []\n",
        "neighbor_pos = []\n",
        "neighbor_attention = []\n",
        "neighbor_attention_softmaxed = []\n",
        "neighbor_distances_tracking = []\n",
        "\n",
        "np.set_printoptions(suppress=True,precision=2)\n",
        "loc_proteins = []\n",
        "for i,filename in tqdm(enumerate(os.listdir(pdbDirectory))):\n",
        "    #ICODE related problematic proteins will be skipped from analysis for now\n",
        "    if (filename.split(\".\")[0] not in proteins_to_skip):\n",
        "        # if i > 100:\n",
        "        #     break\n",
        "        loc_proteins.append(filename.split(\".\")[0])\n",
        "        filepath = os.path.join(pdbDirectory,filename)\n",
        "        structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "        model = structure[0]\n",
        "        \n",
        "        # Since there is only one chain, and that same chain is both fixed designable for different residues, extracting that name, and putting them in pertinent lists\n",
        "        # taking chainname from filename since one of the files \"1rtpA.pdb\" has chain name with \"1\" instead of \"A\"\n",
        "        # fuck you motherfucking fucked up PDB file submitter. Have you shoved your head into your ass?\n",
        "        chain_name = (filename.split(\".\")[0])[-1]\n",
        "        fixed_chain_list = []\n",
        "        # the trick is to put the single chain as designable chain, and then create the \"fixed_positions_dict\" dictionary  \n",
        "        designed_chain_list = [chain_name]\n",
        "        chain_list = list(set(designed_chain_list + fixed_chain_list))\n",
        "\n",
        "        # Using the programs custome PDB parser for processing the PDB files\n",
        "        pdb_dict_list = parse_PDB(filepath, input_chain_list=chain_list)\n",
        "        # tacking max_length parameter value from the original colab notebook since I need to process all residues at the same time\n",
        "        # all the PDB files can technically be processed together and put inside the dataset_valid list-like object, but right now\n",
        "        # I am trying to keep everything consistent and simple\n",
        "        # Each element of dataset_valid is a dictionary \n",
        "        dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=20000)\n",
        "\n",
        "        # Simplying the sequence generation loop\n",
        "        protein = dataset_valid[0]\n",
        "\n",
        "        wildtype_seq = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        # If there are gaps in the wildtype_seq \"seq\", remove those positions from both the \"seq\", \"\" and ('coords_chain_{designed_chain_list[0]}'), \n",
        "        # and ('seq_chain_{designed_chain_list[0]}') of the \"protein\"\n",
        "        # print(protein.keys())\n",
        "        # protein is a dict with keys(['seq_chain_A', 'coords_chain_A', 'name', 'num_of_chains', 'seq'])\n",
        "        # \"seq_chain\" and \"seq_all\" are both strings of the same length where gapped positions need to be identified and removed\n",
        "        seq_chain = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "        seq_all = protein[f\"seq\"]\n",
        "        # \"coordinates_chain\" is a dict with keys(['N_chain_A', 'CA_chain_A', 'C_chain_A', 'O_chain_A'])\n",
        "        coordinates_chain = protein[f\"coords_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        \n",
        "        # The following four variables are lists of length equal to seq_chain and seq_all length\n",
        "        # Therefore, the gapped positions can be retrived from seq_chain and removed from everything accordingly\n",
        "        N_chain = coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"]\n",
        "        CA_chain = coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"]\n",
        "        C_chain = coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"]\n",
        "        O_chain = coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        # delete everything related to gapped positions now\n",
        "        # at first, find out the positions that are gapped\n",
        "        # these gapped positions are absolutely messed up fucked up artifact of some kind of sophistification \n",
        "        # provided by proteinMPNN, FUCK YOU motherfucking oversmart CODERS\n",
        "        N_chain = [v for i,v in enumerate(N_chain) if seq_chain[i] != \"-\"]\n",
        "        CA_chain = [v for i,v in enumerate(CA_chain) if seq_chain[i] != \"-\"]\n",
        "        C_chain = [v for i,v in enumerate(C_chain) if seq_chain[i] != \"-\"]\n",
        "        O_chain = [v for i,v in enumerate(O_chain) if seq_chain[i] != \"-\"]\n",
        "        seq_all = [v for i,v in enumerate(seq_all) if seq_chain[i] != \"-\"]\n",
        "        seq_chain = [v for i,v in enumerate(seq_chain) if seq_chain[i] != \"-\"]\n",
        "\n",
        "        # Now, finally, pack everything back to the dictionary \"protein\"\n",
        "        protein[f\"seq_chain_{designed_chain_list[0]}\"] = seq_chain\n",
        "        protein[f\"seq\"] = seq_all\n",
        "        coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"] = N_chain\n",
        "        coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"] = CA_chain\n",
        "        coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"] = C_chain\n",
        "        coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"] = O_chain\n",
        "        protein[f\"coords_chain_{designed_chain_list[0]}\"] = coordinates_chain\n",
        "\n",
        "        # At this point, probably need to put None values in a lot of parameters that are not relevant to my usecase, but need to be sent to featurizer before running model forward\n",
        "        # For now, I will not tie positions together\n",
        "        tied_positions_dict = None\n",
        "        pssm_dict = None\n",
        "        omit_AA_dict = None\n",
        "        bias_AA_dict = None\n",
        "        tied_positions_dict = None\n",
        "        bias_by_res_dict = None\n",
        "        alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "        bias_AAs_np = np.zeros(len(alphabet))\n",
        "\n",
        "        chain_id_dict = {}\n",
        "        chain_id_dict[pdb_dict_list[0]['name']]= (designed_chain_list, fixed_chain_list)\n",
        "\n",
        "        BATCH_COPIES = 1\n",
        "\n",
        "        batch_clones = [copy.deepcopy(protein) for i in range(BATCH_COPIES)]\n",
        "\n",
        "        # \"muts_for_prot\" is a list with information about all the mutations in \"protein\", whose sequence only version is \"wildtype_seq\" \n",
        "        muts_for_prot = two_level_dict[filename.split(\".\")[0]]\n",
        "        # \"cur_map_dict\" will give the 0-based sequence index for the mutations, which will be almost directly used for masking and then running the model\n",
        "        # 1-based indexing needed for the fixed position\n",
        "        cur_map_dict = mapping_dict[filename.split(\".\")[0]]\n",
        "\n",
        "        for mut in muts_for_prot:\n",
        "            wild_aa = mut[\"mut\"][0]\n",
        "            alternate_aa = mut[\"mut\"][-1]\n",
        "            # (+1) because we need to pass 1-based indexing to tied_featurize() method\n",
        "            seq_pos = cur_map_dict[mut[\"mut\"][0:-1]] + 1\n",
        "            # only need to mask the mutated position position in \"wildtype_seq\" for now\n",
        "            fixed_positions_dict = {}\n",
        "            fixed_positions_dict[protein[\"name\"]] = {}\n",
        "            f_list = []\n",
        "            for ind_fixed in range(0,len(seq_chain)):\n",
        "                if (ind_fixed + 1) not in [seq_pos]:\n",
        "                    f_list.append(ind_fixed + 1)\n",
        "            fixed_positions_dict[protein[\"name\"]][filename.split(\".\")[0][-1]] = f_list\n",
        "\n",
        "            # finally, had to take chain-name from filename instead of biopython parsing to get rid of chain-name with \"1\" instead of \"A\" in \"1rtpA.pdb\"\n",
        "            X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "            omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "            = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "            randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "            log_probs, decoder_messages = mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "            # Adding the log_probs to the same inner dictionary where DDG values exist for easier comparison\n",
        "            mut[\"log_prob\"] = log_probs.cpu().data.numpy()\n",
        "            \n",
        "            # the top_k attention weights will be stored here for weighted sum later\n",
        "            # \"seq_pos\" is 1-based since \"fixed_positions_dict\" above needs to hold 1-based indices for the mutation,\n",
        "            # but accessing the tensors will require 0-based indexing\n",
        "            seq_index = seq_pos - 1\n",
        "            # \"dim = 1\", because decoder_messages[0,seq_index,:,:] should be (48,128), and we want to take norm of each of the 48 vectors across the last dimension,\n",
        "            # get 48 norm values, and fetch out the k highest values from there\n",
        "            message_norms = (torch.linalg.vector_norm(x=decoder_messages[0,seq_index,:,:],ord=2,dim=1))\n",
        "            local_distances, local_neighbors = return_neighbor_info(X, mask)\n",
        "            # \"top_k_attended_neighbor_indices\" is the indices from [0,47] corresponding to the highest attended neighbors\n",
        "            # top_(k-1) can technically be extracted from top_k, but currently just for simplicity and easier debugging, extracting everything separately\n",
        "            top_15_attention_vals, top_15_attended_neighbor_indices = torch.topk(message_norms,k=15)\n",
        "            top_10_attention_vals, top_10_attended_neighbor_indices = torch.topk(message_norms,k=10)\n",
        "            top_5_attention_vals, top_5_attended_neighbor_indices = torch.topk(message_norms,k=5)\n",
        "            # now, using \"local_neighbors\" to get the original indices of the neighbors corresponding to the top_k attended positions\n",
        "            # taking both top_5 and top_10 for now\n",
        "            top_15_attended_neighbor_indices = local_neighbors[0,seq_index,top_15_attended_neighbor_indices]\n",
        "            top_10_attended_neighbor_indices = local_neighbors[0,seq_index,top_10_attended_neighbor_indices]\n",
        "            top_5_attended_neighbor_indices = local_neighbors[0,seq_index,top_5_attended_neighbor_indices]\n",
        "            top_15_closest_neighbor_indices = local_neighbors[0,seq_index,1:16]\n",
        "            top_10_closest_neighbor_indices = local_neighbors[0,seq_index,1:11]\n",
        "            mut[\"top_15_attention_weights\"] = top_15_attention_vals.cpu().data.numpy()\n",
        "            mut[\"top_10_attention_weights\"] = top_10_attention_vals.cpu().data.numpy()\n",
        "            mut[\"top_5_attention_weights\"] = top_5_attention_vals.cpu().data.numpy()\n",
        "            # the neighbor indices corresponding to the top_k attention weights will be stored here for entropy calculation later\n",
        "            # 0-based indices of the neighbors will be saved so that corresponding log-probability vectors can be extracted readily from \"log_prob\" keyed value\n",
        "            mut[\"top_15_neighbor_indices\"] = top_15_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_10_neighbor_indices\"] = top_10_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_5_neighbor_indices\"] = top_5_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_15_closest_neighbor_indices\"] = top_15_closest_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_10_closest_neighbor_indices\"] = top_10_closest_neighbor_indices.cpu().data.numpy()\n",
        "\n",
        "            # The lines below are mostly for printing purposes to do external analysis with PyMol,and ROSETTA with Cristina\n",
        "            loc_pos_scores = []\n",
        "            for enum_val,(neighbor_p, neighbor_s, neighbor_distance) in enumerate(zip(local_neighbors[0,seq_index,1:15].cpu().data.numpy(),\n",
        "                                                                 (torch.linalg.vector_norm(x=decoder_messages[0,seq_index,1:15,:],ord=2,dim=1)).cpu().data.numpy(),\n",
        "                  \n",
        "                                                               local_distances[0,seq_index,1:15].cpu().data.numpy())):\n",
        "                # skippoing the first neighbor since it is the mutated position itself\n",
        "                if enum_val == 0:\n",
        "                    continue\n",
        "                pdbId_info.append(filename)\n",
        "                pos_info.append(seq_index+1)\n",
        "                neighbor_pos.append(neighbor_p+1)\n",
        "                neighbor_attention.append(neighbor_s)\n",
        "                loc_pos_scores.append(neighbor_s)\n",
        "                neighbor_distances_tracking.append(neighbor_distance)\n",
        "            # since softmax has to be done over all the neighbors, taking the softmax, and later adding it to the data generation list after\n",
        "            # neighbor enumeration loop\n",
        "            loc_pos_scores = softmax(np.array(loc_pos_scores))\n",
        "            for s in loc_pos_scores:\n",
        "                neighbor_attention_softmaxed.append(s)\n",
        "\n",
        "            # take (\"neighbor_attention\"-weighted sum/average) of the entropies of the top 5 attended neighbors\n",
        "            # are the neighbors with highest message passing values always among the closest 10?\n",
        "            # point to be noted that the closest, therefore the first neighbor of every position is the neighbor itself\n",
        "            # check correlation between distance and attention values since a possible manual edge feature would be distance\n",
        "            # let us see if the model attends to distant neighbors more, or attention value is inversely proportional to distance?\n",
        "            # take L2-norms of the message vectors instead of attention\n",
        "            # take the softmax of L2-norms to approximate attention, although technically the positions are not constrained by each other, this can be considered a sigmoid attention\n",
        "            # where having neighbors with large messages will effect differently than having neighbors with small messages\n",
        "            # can this be correlated with position-entropy?\n",
        "            # the L2-norms should be able to approximate how much each of the neighbors are effecting the mutated position\n",
        "            # This information can be stored for checking the effect of center mutation on those positions afterwards\n",
        "            # Identify major interacting partners (neighbors that are important for center prediction, and also which take center into consideration for its own prediction)\n",
        "            # then check how much the major neighbor position deviates from wildtype due to the mutation\n",
        "            # another much more simples thing can be to check the deviation for top 10 neighbors\n",
        "            # this deviation can be calculated using the log(W) for the neighbor before center mutation, and log(W) for the neighbor after center mutation \n",
        "\n",
        "            # Now, take top_k most attended positions, make them designable, mutate center, and take change in -log(p) of the wildtype at each of the neighbor positions\n",
        "            # take weighted sum of these neighbor energy changes, see if there is any correlation\n",
        "            # next, go for \"strong\" neighbor positions (both way strong attention)\n",
        "            # Many of the tensors will take on new values after running the model again with different fixed positions\n",
        "            \n",
        "            # the \"fixed_positions_dict\" has to be repopulated now since neighbor positions will be masked one by one\n",
        "            # here, \"n_ind\" is the 0-based index corresponding to one of the \"top_k\" attended neighbors \n",
        "            # these lists will contain the log_probabilities for the top_k most attended neighbors serially\n",
        "            # before and after making the center mutation currently at hand, these probabilities will be used later for calculating\n",
        "            # attention_weighted change in neighbor_wildtype probability, attention_weighted_change in KL, and all those things \n",
        "            neighbor_w_log_probs = []\n",
        "            neighbor_m_log_probs = []\n",
        "            # the following array will contain the identities of the neighbors serially so that specific wildtype neighbor positions in the probability\n",
        "            # distribution can be extracted later\n",
        "            neighbor_aa_identities = []\n",
        "            # \"top5\" and \"top10\" should be extractable from \"top15\", since the neighbor \n",
        "            # informations are stored serially in the lists\n",
        "            for n_ind in mut[\"top_15_neighbor_indices\"]:\n",
        "                neighbor_aa_identities.append(seq_chain[n_ind])\n",
        "                # Some sequence-input manipulation is done later in this loop, so the wildtype aa is placed in the position, so that\n",
        "                # previous iteration manipulations do not cause trouble in this iteration\n",
        "                alpha_tok = \"ACDEFGHIKLMNPQRSTVWYX\"\n",
        "                aa_1_N = {a:n for n,a in enumerate(alpha_tok)}\n",
        "                aa_N_1 = {n:a for n,a in enumerate(alpha_tok)}\n",
        "\n",
        "                # adding (+1) to n_ind, since fixed positions are 1-indexed in the original implementation\n",
        "                n_pos = n_ind + 1  \n",
        "                fixed_positions_dict = {}\n",
        "                fixed_positions_dict[protein[\"name\"]] = {}\n",
        "                f_list = []\n",
        "                for ind_fixed in range(0,len(seq_chain)):\n",
        "                    # Fixing everything except the \"n_pos\" neighbor position\n",
        "                    if (ind_fixed + 1) not in [n_pos]:\n",
        "                        f_list.append(ind_fixed + 1)\n",
        "                fixed_positions_dict[protein[\"name\"]][filename.split(\".\")[0][-1]] = f_list\n",
        "\n",
        "                # Extracting \"n_ind\" 21-way log probabilities when the center is wildtype \n",
        "                X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "                omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "                = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "                randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "                log_probs, decoder_messages = mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "                # Adding the log_probs to the same inner dictionary where DDG values exist for easier comparison\n",
        "                # Here, ideally only n_ind should be extracted from log_probs before saving to the dictionary for memory efficiency\n",
        "                n_log_probs = log_probs.cpu().data.numpy()\n",
        "                n_log_probs = n_log_probs[0,n_ind,:]\n",
        "                # This is the 21-way log_probability for the neighbor position when the center is the wildtype residue\n",
        "                neighbor_w_log_probs.append(n_log_probs) \n",
        "                 \n",
        "                # Now, make mutation, and process the corresponding probabilities\n",
        "                X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "                omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "                = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "                randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "                # seems like passing mutant sequence through the model will be a bit more difficult that expected since PDB file is read in by the underlying parser\n",
        "                # How, do I only change the amino acids identity in the sequence, but keep the PDB backbone and everything same?\n",
        "                # At first, just try to manipulate the input \"S\"\n",
        "                S[0,seq_index] = aa_1_N[alternate_aa]\n",
        "                log_probs, decoder_messages = mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "                # Adding the log_probs to the same inner dictionary where DDG values exist for easier comparison\n",
        "                # Here, ideally only n_ind should be extracted from log_probs before saving to the dictionary for memory efficiency\n",
        "                n_log_probs = log_probs.cpu().data.numpy()\n",
        "                n_log_probs = n_log_probs[0,n_ind,:]\n",
        "                # This is the 21-way log_probability for the neighbor position when the center is the mutated residue \n",
        "                neighbor_m_log_probs.append(n_log_probs)\n",
        "                # take KL of the before mutation, and after mutation distributions\n",
        "                # before mutation is the true distribution, and after mutation is the perturbed, that might decide forward vs. reverse KL\n",
        "                # also, consider entropy change\n",
        "            mut[\"w_n_log_prob\"] = neighbor_w_log_probs\n",
        "            mut[\"m_n_log_prob\"] = neighbor_m_log_probs\n",
        "            mut[\"neighbor_aa_identities\"] = neighbor_aa_identities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "570d57ccce5c48ceb933791aba077951",
            "e12ccc7cb75342da901353b7b126f962",
            "1c6157a0d03a492e906c5f3e798f1849",
            "ef8c97cf6a4b4ae79baf6293999f07b7",
            "adee8d7c007c4e22b6a1feef845a3cce",
            "647e2ac58c404b87ad202cd1289298c5",
            "f3d618b81e624577911c43608dbfde29",
            "6573275f1136413ab13c6d89e1bd3533",
            "0c8f22732a274f8a80316bd082c621c2",
            "6eb37a08a78a49d38ea3e0accc2ef5dc",
            "dd6f8c07662f4730870c888dea7b3f67"
          ]
        },
        "id": "b8cEsTK1EQ9J",
        "outputId": "e21edb2d-d347-4c4f-d83f-abdaf863bd38"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "570d57ccce5c48ceb933791aba077951"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn on this line when values need to be put into an excel file for Cristina Analysis\n",
        "# write_frame_loc = pd.DataFrame({\"pdbId\":pdbId_info,\"center_position\":pos_info,\"neighbor_position\":neighbor_pos,\"neighbor_attention\":neighbor_attention,\"neighbor_attention_softmaxed\":neighbor_attention_softmaxed})\n",
        "# write_frame_loc.to_excel(\"dat.xlsx\",float_format=\"%.3f\")"
      ],
      "metadata": {
        "id": "pPYxHivvUIR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the incomplete \"two_level_dict\" as pickle file for a quick dirty comparison\n",
        "# import pickle\n",
        "# with open(\"S_2648_pmppn_info_dict.pickle\",\"wb\") as f:\n",
        "#     pickle.dump(two_level_dict,f)"
      ],
      "metadata": {
        "id": "rXvc5PDmIQyF"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# with open(\"S_2648_pmppn_info_dict.pickle\",\"rb\") as f:\n",
        "#     two_level_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "QVXEWT9ye7NP"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import entropy\n",
        "alpha_list = list(\"ACDEFGHIKLMNPQRSTVWYX\")\n",
        "# The following dictionary will be used for fetching out the log-probabilities corresponding to the wild-type and mutated residues at the mutation positions\n",
        "aa_to_N = {a:n for n,a in enumerate(alpha_list)}\n",
        "# This list will contain the experimental ddg values for the mutations for which two-level dict contains information regarding log_probabilities\n",
        "true_vals = []\n",
        "# This list will contain (wild_proba,mut_proba) tuples for the mutations for which two-level dict contains information regarding log_probabilities\n",
        "wild_mut_log_probabilities = []\n",
        "# saving max probabilites for debugging\n",
        "max_log_probabilities = []\n",
        "# Want to add entropy of the position with some kind of weight (maybe, just a for loop for checking weight combinations that sum to 1?)\n",
        "position_entropies = []\n",
        "weighted_neighbor_entropies = []\n",
        "# This \"weighted_neighbor_energy_changes\" will be ((-log(m))-(-log(w))) for each of the topk neighbors, weighted summed by corresponding attention weights   \n",
        "weighted_neighbor_energy_changes = []\n",
        "# the neighbor-forward-KL will at this point treat the center-wildtype conditioned neighbor distributions as true, \n",
        "# and center-mutated conditioned neighbor distributions as approximation\n",
        "weighted_neighbor_forward_KL = []\n",
        "# the neighbor-backward-KL will treat the center-mutated conditioned neighbor distributions as true, \n",
        "# and center-wildtype conditioned neighbor distributions as approximation\n",
        "weighted_neighbor_backward_KL = []\n",
        "# putting the dictionary here since we are going to need positions corresponding to alternate amino acid 1-letter codes\n",
        "alpha_tok = \"ACDEFGHIKLMNPQRSTVWYX\"\n",
        "aa_1_N = {a:n for n,a in enumerate(alpha_tok)}\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            # where the fuck is \"log_prob\" coming from, but \"top_5_attention_weights\" and \"top_5_neighbor_indices\" are not there?\n",
        "            if (\"log_prob\" in mut) and (\"w_n_log_prob\" in mut):\n",
        "                wild = mut[\"mut\"][0] \n",
        "                alternate = mut[\"mut\"][-1]\n",
        "                true_vals.append(mut[\"ddg\"])\n",
        "                sequence_index_of_mutation = cur_map_dict[mut[\"mut\"][0:-1]]\n",
        "                position_log_probabilities = mut[\"log_prob\"][0,sequence_index_of_mutation,:]\n",
        "                wild_mut_log_probabilities.append((position_log_probabilities[aa_to_N[wild]],position_log_probabilities[aa_to_N[alternate]]))\n",
        "                max_log_probabilities.append(position_log_probabilities.max())\n",
        "                position_entropies.append(entropy(np.exp(position_log_probabilities)))\n",
        "                # These 0-based neighbor indices will be used for extracting the log-probabilities corresponding to the neighbor positions\n",
        "                n_indices= mut[\"top_15_neighbor_indices\"]\n",
        "                # The neighbor weights will be used here for multiplying \n",
        "                n_weights = mut[\"top_15_attention_weights\"].reshape(-1,1)\n",
        "                # Take entropy while taking care of the dimension along which entropy is calculated\n",
        "                # Taking entropy across last axis, because the shape of the input is (k,21), where 21 is the 21-way probability distribution \n",
        "                n_entropies = entropy(np.exp(mut[\"log_prob\"][0,n_indices,:]),axis=-1).reshape(-1,1)\n",
        "                # I think this element-wise product is getting wrong \n",
        "                weighted_neighbor_entropies.append((n_entropies*softmax(n_weights)).sum())\n",
        "                # weighted_neighbor_entropies.append((n_entropies*softmax(n_weights)).sum())\n",
        "                # weighted_neighbor_entropies.append((n_entropies*n_weights).sum())\n",
        "\n",
        "                # Now, calculate neighbor energy changes, and then weighted sum them after extracting specific log_probabilities\n",
        "                # for mutant center, and wildtype center impacted versions for the top neighbor positions\n",
        "                neighbor_w_log_probabilities = mut[\"w_n_log_prob\"]\n",
        "                neighbor_m_log_probabilities = mut[\"m_n_log_prob\"]\n",
        "                neighbor_amino_a_identities = mut[\"neighbor_aa_identities\"]\n",
        "                # The \"local_neighbor_log_prob_vals\" will be a list of negative log-probability differences(a.k.a. energy differences)\n",
        "                local_neighbor_log_prob_vals = []\n",
        "                local_neighbor_forward_KL_vals = []\n",
        "                local_neighbor_backward_KL_vals = []\n",
        "                # For example, selecting the numbers from the first 5 iterations of this loop will give neighbor energy change corresponding to the first 5 neighbors\n",
        "                for neighbor_w, neighbor_m, neighbor_aa  in zip(neighbor_w_log_probabilities,neighbor_m_log_probabilities,neighbor_amino_a_identities):\n",
        "                    # get the amino acid identity for the neighbor position, run it through the mapping dictionary, get the log probabilities from those positions,\n",
        "                    # \"neighbor_w\" and \"neighbor_m\" arrays will directly give the log probabilities that need to be substracted to get the energy (put (-1) before thoese numbers?...think a bit)\n",
        "                    neighbor_index = aa_1_N[neighbor_aa]\n",
        "                    local_neighbor_log_prob_vals.append((-1*neighbor_m[neighbor_index])-(-1*neighbor_w[neighbor_index]))\n",
        "                    # summing the output of \"kl_div\", because one number comes for every positions in the currently processing neighbor distribution,\n",
        "                    # and I want to take the total deviation in that distribution \n",
        "                    local_neighbor_forward_KL_vals.append(kl_div(np.exp(neighbor_w),np.exp(neighbor_m)).sum())\n",
        "                    local_neighbor_backward_KL_vals.append(kl_div(np.exp(neighbor_m),np.exp(neighbor_w)).sum())\n",
        "                # The energy change approximation can be constrained to the top few neighbors by just indexing the arrays below\n",
        "                # So, it looks like a better idea to save log_probs for atleast the top_20 neighbors since we can always fetch the first few from there\n",
        "                weighted_neighbor_energy_changes.append((np.array(local_neighbor_log_prob_vals[0:15])*softmax(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_forward_KL.append((np.array(local_neighbor_forward_KL_vals[0:15])*softmax(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_backward_KL.append((np.array(local_neighbor_backward_KL_vals[0:15])*softmax(n_weights[0:15])).sum())"
      ],
      "metadata": {
        "id": "7m4jsITsJHmE"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let us also look at the energy of the most probable amino acid in those mutation positions\n",
        "wild_energies = []\n",
        "mut_energies = []\n",
        "min_energies = []\n",
        "experimental_energies = []\n",
        "entropy_conservations = []\n",
        "neighbor_entropy_conservations = []\n",
        "# Now, add entropy of the position\n",
        "for true, estimate, max_prob, entropy_conservation, neighbor_entropy_conservation in zip(true_vals,wild_mut_log_probabilities,max_log_probabilities,position_entropies,weighted_neighbor_entropies):\n",
        "    experimental_energies.append(true)\n",
        "    wild_energies.append(estimate[0]*-1)\n",
        "    mut_energies.append(estimate[1]*-1)\n",
        "    min_energies.append(max_prob*-1)\n",
        "    entropy_conservations.append(entropy_conservation*-1)\n",
        "    neighbor_entropy_conservations.append(neighbor_entropy_conservation*-1)"
      ],
      "metadata": {
        "id": "vn-AjUmcoYDF"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "TwMx2ZMs60Pz"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wild_energies = np.array(wild_energies)\n",
        "mut_energies = np.array(mut_energies)\n",
        "min_energies = np.array(min_energies)\n",
        "experimental_energies = np.array(experimental_energies)\n",
        "mut_wild_predictions = mut_energies - wild_energies\n",
        "mut_min_predictions = mut_energies - min_energies\n",
        "entropy_predictions = np.array(entropy_conservations)\n",
        "neighbor_entropy_predictions = np.array(neighbor_entropy_conservations)\n",
        "neighbor_energy_change_predictions = np.array(weighted_neighbor_energy_changes)\n",
        "neighbor_forward_KL_predictions = np.array(weighted_neighbor_forward_KL)\n",
        "neighbor_backward_KL_predictions = np.array(weighted_neighbor_backward_KL)\n",
        "print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "print(pearsonr(experimental_energies,entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_energy_change_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_forward_KL_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_backward_KL_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jrRRaEi7fJY",
        "outputId": "5aea97d2-59a5-4c50-ea11-9e0b9ae8ca60"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.5063450006152611, 1.2092239061429858e-170)\n",
            "(0.47143355275134274, 4.253998216601191e-145)\n",
            "(0.35223899773367473, 2.1670024567479525e-77)\n",
            "(0.15455901241323095, 1.7867002720136317e-15)\n",
            "(0.2943613554832809, 1.5750985446446538e-53)\n",
            "(0.21396471448047497, 1.6540671719161292e-28)\n",
            "(0.25288807071338204, 1.6466538393286582e-39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now combine \"mut_wild_predictions\" and \"entropy_predictions\" using weight combinations from 0 to 1 in 0.05 increments so that they some to one\n",
        "# so, when one weight is x, the other weight is automatically (1-x)\n",
        "# The keys of this dictionary will be (term1_coeff,term2_coeff) tuples, and values will be the observed correlations \n",
        "coefficient_result_dictionary = {}\n",
        "for i in np.arange(0.0,1.000001,0.005):\n",
        "    term1_coeff = round(i,2)\n",
        "    term2_coeff = round((1.000001 - i),2)\n",
        "    local_preds = (term1_coeff*mut_wild_predictions) + (term2_coeff*entropy_predictions)\n",
        "    coefficient_result_dictionary[(term1_coeff,term2_coeff)] = round(pearsonr(experimental_energies,local_preds)[0],2) "
      ],
      "metadata": {
        "id": "xI2DgnlzMh6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefficient_result_dictionary"
      ],
      "metadata": {
        "id": "pUMxNOmfUwX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let me get PSSM values and do some comparison quickly\n",
        "# getting the PSSM extraction functions from my custom model data processing scripts\n",
        "from string import ascii_uppercase\n",
        "\n",
        "# In rare cases, some PDB files number chains with 1,2,3 instead of A,B,C\n",
        "def convertChainFromAlphabetToNumber(alphabet):\n",
        "    mappingDict = {ch:(idx+1) for idx,ch in enumerate(ascii_uppercase)}\n",
        "    return str(mappingDict[alphabet])\n",
        "\n",
        "# Before executing this function, the PSSM files with naming format \"pdbIdchain.pssm\" needs to be stored\n",
        "# in the pssm_dir\n",
        "def returnPSSMArray(pdbIdPlusChain,pssm_dir=\"train_pssm_dir\",convert_upper = False):\n",
        "#     Currently, assuming that the pssm file names contain pdbId in upper case\n",
        "    if convert_upper:\n",
        "        fileName = pdbIdPlusChain.upper() + \".pssm\"\n",
        "    else:\n",
        "        fileName = pdbIdPlusChain + \".pssm\"\n",
        "    try:\n",
        "        fullPath = os.path.join(pssm_dir,fileName)\n",
        "        f = open(fullPath)\n",
        "    except:\n",
        "        fileName = pdbIdPlusChain[0:4].upper() + str(convertChainFromAlphabetToNumber(pdbIdPlusChain[4])) + \".pssm\" \n",
        "        fullPath = os.path.join(pssm_dir,fileName)\n",
        "        f = open(fullPath)\n",
        "        \n",
        "# #     all the target lines in the PSSM files have (2+20+20+2=44) strings after line.split()\n",
        "    target_lines = [line.split() for line in f.readlines() if (len(line.split()))==44]\n",
        "    number_of_residues = len(target_lines)\n",
        "    \n",
        "    pssm_features = np.zeros((number_of_residues,20))\n",
        "\n",
        "    for idx,line in enumerate(target_lines):\n",
        "        pssm_features[idx,:] = line[2:22]\n",
        "\n",
        "    f.close()\n",
        "    \n",
        "    return pssm_features\n",
        "\n",
        "# This function also seems necessary for extracting the two pssm values\n",
        "# Must review the three pssm feature functions (this one and the two above) later\n",
        "# These functions seem to be taking up a lot of time....must review\n",
        "def returnPSSMMapping(residue):\n",
        "    pssm_letter_to_index_dict = {\"A\" : 0,   \n",
        "    \"R\" : 1,\n",
        "    \"N\" : 2,\n",
        "    \"D\" : 3,\n",
        "    \"C\" : 4,\n",
        "    \"Q\" : 5,\n",
        "    \"E\" : 6,\n",
        "    \"G\" : 7,\n",
        "    \"H\" : 8,\n",
        "    \"I\" : 9,\n",
        "    \"L\" : 10,\n",
        "    \"K\" : 11,\n",
        "    \"M\" : 12,\n",
        "    \"F\" : 13,\n",
        "    \"P\" : 14,\n",
        "    \"S\" : 15,\n",
        "    \"T\" : 16,\n",
        "    \"W\" : 17,\n",
        "    \"Y\" : 18,\n",
        "    \"V\" : 19}\n",
        "\n",
        "    return pssm_letter_to_index_dict[residue]\n",
        "\n",
        "\n",
        "# I will add PSSM values to the two-level dictionary for places where log_prob is available\n",
        "pssmDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_2648_pssm_dir\"\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                wild = mut[\"mut\"][0] \n",
        "                alternate = mut[\"mut\"][-1]\n",
        "                sequence_index_of_mutation = cur_map_dict[mut[\"mut\"][0:-1]]\n",
        "                pdbId = prot[0:-1]\n",
        "                mutChain = prot[-1]\n",
        "                pssm_array = returnPSSMArray(pdbId + mutChain,pssm_dir=pssmDirectory,convert_upper = False)\n",
        "                position_pssm = pssm_array[sequence_index_of_mutation]\n",
        "                wild_pssm = position_pssm[returnPSSMMapping(wild)] \n",
        "                alternate_pssm = position_pssm[returnPSSMMapping(alternate)]\n",
        "                mut[\"wild_pssm\"] = wild_pssm\n",
        "                mut[\"alternate_pssm\"] = alternate_pssm"
      ],
      "metadata": {
        "id": "eBgpxQx4ispc"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pssm_predictions = []\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                pssm_predictions.append((mut[\"wild_pssm\"]-mut[\"alternate_pssm\"]))"
      ],
      "metadata": {
        "id": "xOkQhEQzn32m"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wild_energies = np.array(wild_energies)\n",
        "mut_energies = np.array(mut_energies)\n",
        "min_energies = np.array(min_energies)\n",
        "experimental_energies = np.array(experimental_energies)\n",
        "mut_wild_predictions = mut_energies - wild_energies\n",
        "mut_min_predictions = mut_energies - min_energies\n",
        "entropy_predictions = np.array(entropy_conservations)\n",
        "pssm_predictions = np.array(pssm_predictions)\n",
        "neighbor_entropy_predictions = np.array(neighbor_entropy_conservations)\n",
        "neighbor_energy_change_predictions = np.array(neighbor_energy_change_predictions)\n",
        "neighbor_forward_KL_predictions = np.array(weighted_neighbor_forward_KL)\n",
        "neighbor_backward_KL_predictions = np.array(weighted_neighbor_backward_KL)\n",
        "print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "print(pearsonr(experimental_energies,entropy_predictions))\n",
        "print(pearsonr(experimental_energies,pssm_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_energy_change_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_forward_KL_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_backward_KL_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tyw_4erpj1C",
        "outputId": "ab5c4f36-4e8d-4f1d-83f1-322f5ef8820e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.5063450006152611, 1.2092239061429858e-170)\n",
            "(0.35223899773367473, 2.1670024567479525e-77)\n",
            "(0.2752044285125163, 9.492115203744281e-47)\n",
            "(0.15455901241323095, 1.7867002720136317e-15)\n",
            "(0.2943613554832809, 1.5750985446446538e-53)\n",
            "(0.21396471448047497, 1.6540671719161292e-28)\n",
            "(0.25288807071338204, 1.6466538393286582e-39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now combine \"mut_wild_predictions\" and \"pssm_predictions\" using weight combinations from 0 to 1 in 0.05 increments so that they some to one\n",
        "# so, when one weight is x, the other weight is automatically (1-x)\n",
        "# The keys of this dictionary will be (term1_coeff,term2_coeff) tuples, and values will be the observed correlations \n",
        "coefficient_result_dictionary = {}\n",
        "for i in np.arange(0.0,1.000001,0.005):\n",
        "    term1_coeff = round(i,2)\n",
        "    term2_coeff = round((1.000001 - i),2)\n",
        "    local_preds = (term1_coeff*pssm_predictions) + (term2_coeff*neighbor_energy_change_predictions)\n",
        "    coefficient_result_dictionary[(term1_coeff,term2_coeff)] = round(pearsonr(experimental_energies,local_preds)[0],2) "
      ],
      "metadata": {
        "id": "nP6x7ym_10QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefficient_result_dictionary"
      ],
      "metadata": {
        "id": "fQ6lfx3VunPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coefficient_result_dictionary\n",
        "# (0.82, 0.18): 0.52,\n",
        "#  (0.82, 0.19): 0.51,\n",
        "#  (0.83, 0.17): 0.52,\n",
        "#  (0.84, 0.16): 0.52,\n",
        "#  (0.84, 0.17): 0.52,\n",
        "#  (0.85, 0.15): 0.52,\n",
        "#  (0.86, 0.14): 0.52,\n",
        "#  (0.86, 0.15): 0.52,\n",
        "#  (0.87, 0.13): 0.52,\n",
        "#  (0.88, 0.12): 0.52,\n",
        "#  (0.88, 0.13): 0.52,\n",
        "#  (0.89, 0.11): 0.52,\n",
        "#  (0.9, 0.1): 0.52,\n",
        "#  (0.9, 0.11): 0.52,\n",
        "#  (0.91, 0.09): 0.52,\n",
        "#  (0.92, 0.08): 0.52,\n",
        "#  (0.92, 0.09): 0.52,\n",
        "#  (0.93, 0.07): 0.52,\n",
        "#  (0.94, 0.06): 0.52,\n",
        "#  (0.94, 0.07): 0.52,\n",
        "#  (0.95, 0.05): 0.52,\n",
        "#  (0.96, 0.04): 0.52,\n",
        "# great thing since the decorrelation is actually interesting, and using both definitely seems to help"
      ],
      "metadata": {
        "id": "GZYSS4zz2CSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now combine \"mut_wild_predictions\" and \"neighbor_entropy_predictions\" using weight combinations from 0 to 1 in 0.05 increments so that they some to one\n",
        "# so, when one weight is x, the other weight is automatically (1-x)\n",
        "# The keys of this dictionary will be (term1_coeff,term2_coeff) tuples, and values will be the observed correlations \n",
        "coefficient_result_dictionary = {}\n",
        "for i in np.arange(0.0,1.000001,0.005):\n",
        "    term1_coeff = round(i,2)\n",
        "    term2_coeff = round((1.000001 - i),2)\n",
        "    local_preds = (term1_coeff*neighbor_forward_KL_predictions) + (term2_coeff*neighbor_backward_KL_predictions)\n",
        "    coefficient_result_dictionary[(term1_coeff,term2_coeff)] = round(pearsonr(experimental_energies,local_preds)[0],2) "
      ],
      "metadata": {
        "id": "8_mCddKfl4ig"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefficient_result_dictionary"
      ],
      "metadata": {
        "id": "wG7gTr0zmI9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "methods = ['PMPNN_DEP','PMPNN_ET','PMPNN_DEP_ET','PSSM_DEC','PMPNN_DEP_PSSM_DEC']\n",
        "vals = [0.64,0.26,0.64,0.51,0.67]\n",
        "plt.ylabel(\"Pearson Correlation\",fontsize=18)\n",
        "plt.xlabel(\"Informative Features\",fontsize=18)\n",
        "plt.xticks(fontsize=18, rotation=90)\n",
        "plt.yticks(fontsize=18)\n",
        "plt.ylim(0.20,0.70)\n",
        "ax.bar(methods,vals,color=\"maroon\",width=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "sirQvLLnyerw",
        "outputId": "102b2f5e-e58b-4571-8cc9-f6adfbdb08eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "mut_wild_predictions = np.array(mut_energies - wild_energies)\n",
        "entropy_predictions = np.array(entropy_conservations)\n",
        "first_second_combined = 0.5*mut_wild_predictions + 0.5*entropy_predictions\n",
        "pssm_predictions = np.array(pssm_predictions)\n",
        "# first_pssm_combined = 0.89*mut_wild_predictions + 0.11*pssm_predictions\n",
        "neighbor_energy_change_predictions = np.array(neighbor_energy_change_predictions)\n",
        "neighbor_entropy_predictions = np.array(neighbor_entropy_predictions)\n",
        "neighbor_forward_KL_predictions = np.array(weighted_neighbor_forward_KL)\n",
        "neighbor_backward_KL_predictions = np.array(weighted_neighbor_backward_KL)\n",
        "\n",
        "df_Ssym = pd.DataFrame(\n",
        "    {'P_DP': mut_wild_predictions,\n",
        "     'P_ET': entropy_predictions,\n",
        "     'P_DP_ET':first_second_combined,\n",
        "     'P_DEC': pssm_predictions,\n",
        "    #  'PMPNN_DP_PSSM_DEC' : first_pssm_combined,\n",
        "     'Neighbor_Entropy' : neighbor_entropy_predictions,\n",
        "     'Neighbor_Energy_Change' : neighbor_energy_change_predictions,\n",
        "     'Neighbor_forward_KL' : neighbor_forward_KL_predictions,\n",
        "     'Neighbor_backward_KL' : neighbor_backward_KL_predictions \n",
        "    })\n",
        "corr = df_Ssym.corr()\n",
        "\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(corr, \n",
        "        xticklabels=corr.columns,\n",
        "        yticklabels=corr.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "QlQuGW7f7KDy",
        "outputId": "b4efddef-8c7d-4f5a-ace4-251ad678d379"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdf947e5b50>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}