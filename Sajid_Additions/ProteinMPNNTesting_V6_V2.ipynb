{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProteinMPNNTesting_V6_V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a5415aac15024b9b9ce2db5f36ba8512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2d3ea060b084ef19663b313eef56e46",
              "IPY_MODEL_a77c9deea3714115993ba45cd270bf71",
              "IPY_MODEL_6805ef826c98479a9c48914783f37fbd"
            ],
            "layout": "IPY_MODEL_94f70e2fb21448c6a9460d05e1f911d3",
            "tabbable": null,
            "tooltip": null
          }
        },
        "d2d3ea060b084ef19663b313eef56e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_d298ba5b7b6741e8a506a3ac5c9be404",
            "placeholder": "​",
            "style": "IPY_MODEL_464bbddda64d420e8148bcffd6b09e5e",
            "tabbable": null,
            "tooltip": null,
            "value": ""
          }
        },
        "a77c9deea3714115993ba45cd270bf71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4407f21b5f29493b9337ae080a08694a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ca9823303de4c25bdca2ecf581184e6",
            "tabbable": null,
            "tooltip": null,
            "value": 1
          }
        },
        "6805ef826c98479a9c48914783f37fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e1a54995b0904eb2986c060e3ca4e56e",
            "placeholder": "​",
            "style": "IPY_MODEL_e3ae24221f944646acb6f20b1e4d2373",
            "tabbable": null,
            "tooltip": null,
            "value": " 2648/? [00:00&lt;00:00, 62177.15it/s]"
          }
        },
        "94f70e2fb21448c6a9460d05e1f911d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d298ba5b7b6741e8a506a3ac5c9be404": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "464bbddda64d420e8148bcffd6b09e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "4407f21b5f29493b9337ae080a08694a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5ca9823303de4c25bdca2ecf581184e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1a54995b0904eb2986c060e3ca4e56e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3ae24221f944646acb6f20b1e4d2373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "ef679cc2c5ca4c1888209195a708a3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd22f37d91b84c039c37968b5ce21107",
              "IPY_MODEL_f96e29f5059844f9b7c541bee7ffc729",
              "IPY_MODEL_ae4ed4b4dc4644408fbb752646018db9"
            ],
            "layout": "IPY_MODEL_09bc8981202c4c4798000d58685d1b93",
            "tabbable": null,
            "tooltip": null
          }
        },
        "dd22f37d91b84c039c37968b5ce21107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_96275151c3bb4fc4a9e7c3927d1943cb",
            "placeholder": "​",
            "style": "IPY_MODEL_c68818a455074c499c7e9803763349df",
            "tabbable": null,
            "tooltip": null,
            "value": "100%"
          }
        },
        "f96e29f5059844f9b7c541bee7ffc729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c4b6cef1488546a6aadd780f04eb128a",
            "max": 131,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_beded96e8cf34afdbd2b7902ad59a6b9",
            "tabbable": null,
            "tooltip": null,
            "value": 131
          }
        },
        "ae4ed4b4dc4644408fbb752646018db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_364645da5c84405a9adccbb35d3ae76b",
            "placeholder": "​",
            "style": "IPY_MODEL_fe1d3c35c04743ceb34a0b4d2538a908",
            "tabbable": null,
            "tooltip": null,
            "value": " 131/131 [00:03&lt;00:00, 30.49it/s]"
          }
        },
        "09bc8981202c4c4798000d58685d1b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96275151c3bb4fc4a9e7c3927d1943cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c68818a455074c499c7e9803763349df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "c4b6cef1488546a6aadd780f04eb128a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beded96e8cf34afdbd2b7902ad59a6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "364645da5c84405a9adccbb35d3ae76b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe1d3c35c04743ceb34a0b4d2538a908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_wbcvVBv0QJ",
        "outputId": "2d3effa2-180c-4842-a69a-6443509e79a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import sys \n",
        "installation_path = \"/content/drive/MyDrive/Colab_Installations_V2\"\n",
        "# The path is being modified so that everything installed in the installation path can now be used without re-installing (in this case, I just need biopython)\n",
        "sys.path.insert(0,installation_path)\n",
        "protein_mpnn_path = \"/content/drive/MyDrive/Protein_MPNN_Digging/ProteinMPNN/vanilla_proteinmpnn\"\n",
        "sys.path.insert(0,protein_mpnn_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Protein_MPNN_Digging"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgTOgsabxBaC",
        "outputId": "864e9868-4d21-4a8c-b051-09739e254895"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Protein_MPNN_Digging\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import warnings\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, Subset\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import os\n",
        "from Bio.PDB import *\n",
        "\n",
        "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")"
      ],
      "metadata": {
        "id": "jX5ScMeGyLcy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from Bio.PDB.Polypeptide import *\n",
        "from string import ascii_uppercase"
      ],
      "metadata": {
        "id": "NBjszWagtiYL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = os.path.join(protein_mpnn_path,\"vanilla_model_weights\")\n",
        "model_name = \"v_48_020\"\n",
        "checkpoint_path = os.path.join(weights_path,model_name+\".pt\")"
      ],
      "metadata": {
        "id": "Z6ZHe2IIyy1G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, load and dig into the checkpoint object\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device) "
      ],
      "metadata": {
        "id": "JPE_pX8tzdUO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint[\"num_edges\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DD1hpMLk2-y",
        "outputId": "6056ebe2-e4c9-4f28-8269-ced0788ce173"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import json, time, os, sys, glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, Subset\n",
        "\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "#A number of functions/classes are adopted from: https://github.com/jingraham/neurips19-graph-protein-design\n",
        "\n",
        "def _scores(S, log_probs, mask):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    criterion = torch.nn.NLLLoss(reduction='none')\n",
        "    loss = criterion(\n",
        "        log_probs.contiguous().view(-1,log_probs.size(-1)),\n",
        "        S.contiguous().view(-1)\n",
        "    ).view(S.size())\n",
        "    # The designable positions have mask set to 1.0, so this function seems to be returning the average score for the designable positions\n",
        "    scores = torch.sum(loss * mask, dim=-1) / torch.sum(mask, dim=-1)\n",
        "    return scores\n",
        "\n",
        "def _S_to_seq(S, mask):\n",
        "    # This is the decoding order\n",
        "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    seq = ''.join([alphabet[c] for c, m in zip(S.tolist(), mask.tolist()) if m > 0])\n",
        "    return seq\n",
        "\n",
        "def parse_PDB_biounits(x, atoms=['N','CA','C'], chain=None):\n",
        "  '''\n",
        "  input:  x = PDB filename\n",
        "          atoms = atoms to extract (optional)\n",
        "  output: (length, atoms, coords=(x,y,z)), sequence\n",
        "  '''\n",
        "\n",
        "  alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "  states = len(alpha_1)\n",
        "  alpha_3 = ['ALA','ARG','ASN','ASP','CYS','GLN','GLU','GLY','HIS','ILE',\n",
        "             'LEU','LYS','MET','PHE','PRO','SER','THR','TRP','TYR','VAL','GAP']\n",
        "  \n",
        "  # The following dictionaries are mapping from one-letter to 0-20 index,\n",
        "  # three-letter to 0-20 index,\n",
        "  # 0-20 index to one-letter,\n",
        "  # one-letter to three-letter, and vice-versa \n",
        "  aa_1_N = {a:n for n,a in enumerate(alpha_1)}\n",
        "  aa_3_N = {a:n for n,a in enumerate(alpha_3)}\n",
        "  aa_N_1 = {n:a for n,a in enumerate(alpha_1)}\n",
        "  aa_1_3 = {a:b for a,b in zip(alpha_1,alpha_3)}\n",
        "  aa_3_1 = {b:a for a,b in zip(alpha_1,alpha_3)}\n",
        "  \n",
        "  def AA_to_N(x):\n",
        "    # [\"ARND\"] -> [[0,1,2,3]]\n",
        "    x = np.array(x);\n",
        "    if x.ndim == 0: x = x[None]\n",
        "    return [[aa_1_N.get(a, states-1) for a in y] for y in x]\n",
        "  \n",
        "  def N_to_AA(x):\n",
        "    # [[0,1,2,3]] -> [\"ARND\"]\n",
        "    x = np.array(x);\n",
        "    if x.ndim == 1: x = x[None]\n",
        "    return [\"\".join([aa_N_1.get(a,\"-\") for a in y]) for y in x]\n",
        "\n",
        "  xyz,seq,min_resn,max_resn = {},{},1e6,-1e6\n",
        "  for line in open(x,\"rb\"):\n",
        "    line = line.decode(\"utf-8\",\"ignore\").rstrip()\n",
        "\n",
        "    if line[:6] == \"HETATM\" and line[17:17+3] == \"MSE\":\n",
        "      line = line.replace(\"HETATM\",\"ATOM  \")\n",
        "      line = line.replace(\"MSE\",\"MET\")\n",
        "\n",
        "    if line[:4] == \"ATOM\":\n",
        "      ch = line[21:22]\n",
        "      # If the input chain is not in the PDB file, which can be the case if the target chains are named differently in the runner script,\n",
        "      # this line will cause the output to have literally no information, this is the case for integer named chains\n",
        "      # that does not mean that this line is not doing its job correctly, this is just a constraint that input chain names and \n",
        "      # chain names in the PDB file have to be congruent\n",
        "      if ch == chain or chain is None:\n",
        "        atom = line[12:12+4].strip()\n",
        "        resi = line[17:17+3]\n",
        "        resn = line[22:22+5].strip()\n",
        "        x,y,z = [float(line[i:(i+8)]) for i in [30,38,46]]\n",
        "\n",
        "        if resn[-1].isalpha(): \n",
        "            resa,resn = resn[-1],int(resn[:-1])-1\n",
        "        else: \n",
        "            resa,resn = \"\",int(resn)-1\n",
        "#         resn = int(resn)\n",
        "        if resn < min_resn: \n",
        "            min_resn = resn\n",
        "        if resn > max_resn: \n",
        "            max_resn = resn\n",
        "        if resn not in xyz: \n",
        "            xyz[resn] = {}\n",
        "        if resa not in xyz[resn]: \n",
        "            xyz[resn][resa] = {}\n",
        "        if resn not in seq: \n",
        "            seq[resn] = {}\n",
        "        if resa not in seq[resn]: \n",
        "            seq[resn][resa] = resi\n",
        "\n",
        "        if atom not in xyz[resn][resa]:\n",
        "          xyz[resn][resa][atom] = np.array([x,y,z])\n",
        "\n",
        "  # convert to numpy arrays, fill in missing values\n",
        "  seq_,xyz_ = [],[]\n",
        "  try:\n",
        "      for resn in range(min_resn,max_resn+1):\n",
        "        if resn in seq:\n",
        "          for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k],20))\n",
        "        else: seq_.append(20)\n",
        "        if resn in xyz:\n",
        "          for k in sorted(xyz[resn]):\n",
        "            for atom in atoms:\n",
        "              if atom in xyz[resn][k]: xyz_.append(xyz[resn][k][atom])\n",
        "              else: xyz_.append(np.full(3,np.nan))\n",
        "        else:\n",
        "          for atom in atoms: xyz_.append(np.full(3,np.nan))\n",
        "      return np.array(xyz_).reshape(-1,len(atoms),3), N_to_AA(np.array(seq_))\n",
        "  except TypeError:\n",
        "      return 'no_chain', 'no_chain'\n",
        "\n",
        "### calling signature\n",
        "# pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list)\n",
        "def parse_PDB(path_to_pdb, input_chain_list=None):\n",
        "    c=0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V','W','X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v','w','x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "     \n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list  \n",
        " \n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    # Each of the biounits is a separate PDB file, so for running with a single PDB file like from colab, this loop will be executed only once\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {} \n",
        "        # This loop will be executed only once for single chain DDG type cases\n",
        "        for letter in chain_alphabet:\n",
        "            xyz, seq = parse_PDB_biounits(biounit, atoms=['N','CA','C','O'], chain=letter)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_'+letter]=seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                coords_dict_chain['N_chain_'+letter]=xyz[:,0,:].tolist()\n",
        "                coords_dict_chain['CA_chain_'+letter]=xyz[:,1,:].tolist()\n",
        "                coords_dict_chain['C_chain_'+letter]=xyz[:,2,:].tolist()\n",
        "                coords_dict_chain['O_chain_'+letter]=xyz[:,3,:].tolist()\n",
        "                my_dict['coords_chain_'+letter]=coords_dict_chain\n",
        "                s += 1\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        my_dict['name']=biounit[(fi+1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c+=1\n",
        "    return pdb_dict_list\n",
        "\n",
        "\n",
        "# X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta \n",
        "# = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "# fixed_pos_list = fixed_position_dict[b['name']][letter]\n",
        "# The trick will be to populate this fixed_position_dict from the calling function, and \n",
        "def tied_featurize(batch, device, chain_dict, fixed_position_dict=None, omit_AA_dict=None, tied_positions_dict=None, pssm_dict=None, bias_by_res_dict=None):\n",
        "    \"\"\" Pack and pad batch into torch tensors \"\"\"\n",
        "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    B = len(batch)\n",
        "    lengths = np.array([len(b['seq']) for b in batch], dtype=np.int32) #sum of chain seq lengths\n",
        "    L_max = max([len(b['seq']) for b in batch])\n",
        "    X = np.zeros([B, L_max, 4, 3])\n",
        "    residue_idx = -100*np.ones([B, L_max], dtype=np.int32)\n",
        "    # This \"chain_M\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of the single sequence as a consequence\n",
        "    chain_M = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    pssm_coef_all = np.zeros([B, L_max], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    pssm_bias_all = np.zeros([B, L_max, 21], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    pssm_log_odds_all = 10000.0*np.ones([B, L_max, 21], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    # This \"chain_M_pos\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of single sequence as a consequence\n",
        "    chain_M_pos = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    bias_by_res_all = np.zeros([B, L_max, 21], dtype=np.float32)\n",
        "    # This \"chain_encoding_all\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of single sequence as a consequence\n",
        "    chain_encoding_all = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    S = np.zeros([B, L_max], dtype=np.int32)\n",
        "    omit_AA_mask = np.zeros([B, L_max, len(alphabet)], dtype=np.int32)\n",
        "    # Build the batch\n",
        "    letter_list_list = []\n",
        "    visible_list_list = []\n",
        "    masked_list_list = []\n",
        "    masked_chain_length_list_list = []\n",
        "    tied_pos_list_of_lists_list = []\n",
        "    #shuffle all chains before the main loop\n",
        "    for i, b in enumerate(batch):\n",
        "        # for my current energy function like usecase, the code will reach \"if and not else\" because chain_dict will not be None\n",
        "        if chain_dict != None:\n",
        "            ### Calling function argument assignment START\n",
        "            # chain_id_dict[pdb_dict_list[0]['name']] = (designed_chain_list, fixed_chain_list)\n",
        "            ### Calling function argument assignment END\n",
        "            masked_chains, visible_chains = chain_dict[b['name']] #masked_chains a list of chain letters to predict [A, D, F]\n",
        "        else:\n",
        "            masked_chains = [item[-1:] for item in list(b) if item[:10]=='seq_chain_']\n",
        "            visible_chains = []\n",
        "        num_chains = b['num_of_chains']\n",
        "        all_chains = masked_chains + visible_chains\n",
        "        #random.shuffle(all_chains)\n",
        "    # This for loop can be ignored since it will be executed only once in my single-chain or single-chain-at-a-time implementation\n",
        "    for i, b in enumerate(batch):\n",
        "        mask_dict = {}\n",
        "        a = 0\n",
        "        x_chain_list = []\n",
        "        chain_mask_list = []\n",
        "        # \"chain_seq_list\" will contain string format sequences of all the chains both fixed and designable \n",
        "        chain_seq_list = []\n",
        "        chain_encoding_list = []\n",
        "        c = 1\n",
        "        # \"letter_list\" will contain names of all the chains both fixed and designable\n",
        "        letter_list = []\n",
        "        global_idx_start_list = [0]\n",
        "        # \"visible_list\" will contain names of the fixed chains \n",
        "        visible_list = []\n",
        "        # \"masked_list\" will contain names of the designable chains\n",
        "        masked_list = []\n",
        "        masked_chain_length_list = []\n",
        "        fixed_position_mask_list = []\n",
        "        omit_AA_mask_list = []\n",
        "        pssm_coef_list = []\n",
        "        pssm_bias_list = []\n",
        "        pssm_log_odds_list = []\n",
        "        bias_by_res_list = []\n",
        "        l0 = 0\n",
        "        l1 = 0\n",
        "        # This loop will also be executed once for my single chain case,\n",
        "        # and since the same chain has both designable and fixed positions, the codes insides both of the if \n",
        "        # statements will be executed\n",
        "        for step, letter in enumerate(all_chains):\n",
        "            if letter in visible_chains:\n",
        "                letter_list.append(letter)\n",
        "                visible_list.append(letter)\n",
        "                chain_seq = b[f'seq_chain_{letter}']\n",
        "                chain_seq = ''.join([a if a!='-' else 'X' for a in chain_seq])\n",
        "                chain_length = len(chain_seq)\n",
        "                global_idx_start_list.append(global_idx_start_list[-1]+chain_length)\n",
        "                chain_coords = b[f'coords_chain_{letter}'] #this is a dictionary\n",
        "                # the \"chain_mask\" varies between fixed and designable chains (1.0 for designable chains which are maxed)\n",
        "                chain_mask = np.zeros(chain_length) #0.0 for visible chains\n",
        "                x_chain = np.stack([chain_coords[c] for c in [f'N_chain_{letter}', f'CA_chain_{letter}', f'C_chain_{letter}', f'O_chain_{letter}']], 1) #[chain_lenght,4,3]\n",
        "                x_chain_list.append(x_chain)\n",
        "                chain_mask_list.append(chain_mask)\n",
        "                chain_seq_list.append(chain_seq)\n",
        "                # \"chain_encoding_list\" contains numpy arrays corresponding to chains (each array corresponds to one chain),\n",
        "                # where all elements of the same array is the same value, which is equal to the index of the chain the it corresponds to\n",
        "                # by index, I mean index of the different numpy arrays annotating the chains\n",
        "                chain_encoding_list.append(c*np.ones(np.array(chain_mask).shape[0]))\n",
        "                # l0 points at the starting of the current chain and l1 points after the ending of the current chain\n",
        "                l1 += chain_length\n",
        "                # the only value i will have is 0 since it will be executed only once in my single-chain or single-chain-at-a-time implementation\n",
        "                # seems like the chains are separated by  \n",
        "                residue_idx[i, l0:l1] = 100*(c-1)+np.arange(l0, l1)\n",
        "                l0 += chain_length\n",
        "                c+=1\n",
        "                # The following variables are numpy arrays with entries corresponding to every position in the sequence\n",
        "                # appending these numpy arrays to a list indicates that the chains are added one after one\n",
        "                # same thing goes for the chain_mask and chain_seq variables declared above\n",
        "                # In code-block below in this cell, these lists of numpy arrays are going through np.concatenate(), which is creating\n",
        "                # the final numpy arrays containing co-ordinates, sequence identity, fixed position, masked position, PSSM bias, and everything\n",
        "                # required to pass the sequences through the model\n",
        "                ### START\n",
        "                fixed_position_mask = np.ones(chain_length)\n",
        "                fixed_position_mask_list.append(fixed_position_mask)\n",
        "                # The omit_AA_mask, pssm_coef, pssm_bias, \"bias_by_res_list\", all these numpy arrays are zero for the fixed positions\n",
        "                # since these positions are used as it is, while for the masked_positions, these values can get activated\n",
        "                # which is why the next if statement has several extra lines manipulating these variables according to the amount of information passed \n",
        "                omit_AA_mask_temp = np.zeros([chain_length, len(alphabet)], np.int32)\n",
        "                omit_AA_mask_list.append(omit_AA_mask_temp)\n",
        "                pssm_coef = np.zeros(chain_length)\n",
        "                pssm_bias = np.zeros([chain_length, 21])\n",
        "                pssm_log_odds = 10000.0*np.ones([chain_length, 21])\n",
        "                pssm_coef_list.append(pssm_coef)\n",
        "                pssm_bias_list.append(pssm_bias)\n",
        "                pssm_log_odds_list.append(pssm_log_odds)\n",
        "                bias_by_res_list.append(np.zeros([chain_length, 21]))\n",
        "                ### END\n",
        "            if letter in masked_chains:\n",
        "                masked_list.append(letter)\n",
        "                letter_list.append(letter)\n",
        "                chain_seq = b[f'seq_chain_{letter}']\n",
        "                chain_seq = ''.join([a if a!='-' else 'X' for a in chain_seq])\n",
        "                chain_length = len(chain_seq)\n",
        "                global_idx_start_list.append(global_idx_start_list[-1]+chain_length)\n",
        "                masked_chain_length_list.append(chain_length)\n",
        "                chain_coords = b[f'coords_chain_{letter}'] #this is a dictionary\n",
        "                chain_mask = np.ones(chain_length) #1.0 for masked\n",
        "                x_chain = np.stack([chain_coords[c] for c in [f'N_chain_{letter}', f'CA_chain_{letter}', f'C_chain_{letter}', f'O_chain_{letter}']], 1) #[chain_lenght,4,3]\n",
        "                x_chain_list.append(x_chain)\n",
        "                chain_mask_list.append(chain_mask)\n",
        "                chain_seq_list.append(chain_seq)\n",
        "                chain_encoding_list.append(c*np.ones(np.array(chain_mask).shape[0]))\n",
        "                l1 += chain_length\n",
        "                residue_idx[i, l0:l1] = 100*(c-1)+np.arange(l0, l1)\n",
        "                l0 += chain_length\n",
        "                c+=1\n",
        "                fixed_position_mask = np.ones(chain_length)\n",
        "                if fixed_position_dict!=None:\n",
        "                    fixed_pos_list = fixed_position_dict[b['name']][letter]\n",
        "                    if fixed_pos_list:\n",
        "                        # seems like \"fixed_pos_list\"  can be an 1-indexed integer list corresponding to positions in \"chain_seq\"\n",
        "                        # this thing ultimately controls which positions in the designable chain will be masked, which is why the fixed \n",
        "                        # positions are set to 0.0 since those positions will not be maxed (1 if maxed, 0 if not maxed)\n",
        "                        fixed_position_mask[np.array(fixed_pos_list)-1] = 0.0\n",
        "                fixed_position_mask_list.append(fixed_position_mask)\n",
        "                omit_AA_mask_temp = np.zeros([chain_length, len(alphabet)], np.int32)\n",
        "                # For my current energy function like usecase, \"omit_AA_dict\" will be None, so the following loop can be ignored\n",
        "                if omit_AA_dict!=None:\n",
        "                    for item in omit_AA_dict[b['name']][letter]:\n",
        "                        idx_AA = np.array(item[0])-1\n",
        "                        AA_idx = np.array([np.argwhere(np.array(list(alphabet))== AA)[0][0] for AA in item[1]]).repeat(idx_AA.shape[0])\n",
        "                        idx_ = np.array([[a, b] for a in idx_AA for b in AA_idx])\n",
        "                        omit_AA_mask_temp[idx_[:,0], idx_[:,1]] = 1\n",
        "                omit_AA_mask_list.append(omit_AA_mask_temp)\n",
        "                pssm_coef = np.zeros(chain_length)\n",
        "                pssm_bias = np.zeros([chain_length, 21])\n",
        "                pssm_log_odds = 10000.0*np.ones([chain_length, 21])\n",
        "                if pssm_dict:\n",
        "                    if pssm_dict[b['name']][letter]:\n",
        "                        pssm_coef = pssm_dict[b['name']][letter]['pssm_coef']\n",
        "                        pssm_bias = pssm_dict[b['name']][letter]['pssm_bias']\n",
        "                        pssm_log_odds = pssm_dict[b['name']][letter]['pssm_log_odds']\n",
        "                pssm_coef_list.append(pssm_coef)\n",
        "                pssm_bias_list.append(pssm_bias)\n",
        "                pssm_log_odds_list.append(pssm_log_odds)\n",
        "                if bias_by_res_dict:\n",
        "                    bias_by_res_list.append(bias_by_res_dict[b['name']][letter])\n",
        "                else:\n",
        "                    bias_by_res_list.append(np.zeros([chain_length, 21]))\n",
        "\n",
        "        ### TIED position START\n",
        "        # Since there will technically be no tied positions for my single chain energy-based usecase for now,\n",
        "        # I do not need to dig into this part of the code\n",
        "        letter_list_np = np.array(letter_list)\n",
        "        tied_pos_list_of_lists = []\n",
        "        tied_beta = np.ones(L_max)\n",
        "        if tied_positions_dict!=None:\n",
        "            tied_pos_list = tied_positions_dict[b['name']]\n",
        "            if tied_pos_list:\n",
        "                set_chains_tied = set(list(itertools.chain(*[list(item) for item in tied_pos_list])))\n",
        "                for tied_item in tied_pos_list:\n",
        "                    one_list = []\n",
        "                    for k, v in tied_item.items():\n",
        "                        start_idx = global_idx_start_list[np.argwhere(letter_list_np == k)[0][0]]\n",
        "                        if isinstance(v[0], list):\n",
        "                            for v_count in range(len(v[0])):\n",
        "                                one_list.append(start_idx+v[0][v_count]-1)#make 0 to be the first\n",
        "                                tied_beta[start_idx+v[0][v_count]-1] = v[1][v_count]\n",
        "                        else:\n",
        "                            for v_ in v:\n",
        "                                one_list.append(start_idx+v_-1)#make 0 to be the first\n",
        "                    tied_pos_list_of_lists.append(one_list)\n",
        "        tied_pos_list_of_lists_list.append(tied_pos_list_of_lists)\n",
        "        ### TIED position END\n",
        " \n",
        "        # Interestingly, although the backbone atom coordinates are used for generating edge features,\n",
        "        # the \"x\" in the following line contains the coodinates of the backbone atoms \n",
        "        x = np.concatenate(x_chain_list,0) #[L, 4, 3]\n",
        "        # \"all_sequence\" is a string where all the chain sequences have been put one after another\n",
        "        all_sequence = \"\".join(chain_seq_list)\n",
        "        # This \"chain_mask_list\" and \"m_pos\" below are the variables of interest if these actually contain full information regarding the\n",
        "        # fixed vs. variable positions definitions \n",
        "        # consequently, since these are concatenated numpy arrays of numpy arrays inside the lists \"chain_mask_list\" and \"fixed_position_mask_list\",\n",
        "        # when those lists are populated in the above code-block with binary numpy arrays \"fixed_position_mask\" and \"fixed_position_mask\" corresponding to \n",
        "        # each of the chains,\n",
        "        # that is where all the controlling needs to be done from\n",
        "        m = np.concatenate(chain_mask_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        # \"chain_encoding_list\" contains numpy arrays corresponding to chains (each array corresponds to one chain),\n",
        "        # where all elements of the same array is the same value, which is equal to the index of the chain the it corresponds to\n",
        "        # by index, I mean index of the different numpy arrays annotating the chains\n",
        "        chain_encoding = np.concatenate(chain_encoding_list,0)\n",
        "        m_pos = np.concatenate(fixed_position_mask_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "\n",
        "        pssm_coef_ = np.concatenate(pssm_coef_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        pssm_bias_ = np.concatenate(pssm_bias_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        pssm_log_odds_ = np.concatenate(pssm_log_odds_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "\n",
        "        bias_by_res_ = np.concatenate(bias_by_res_list, 0)  #[L,21], 0.0 for places where AA frequencies don't need to be tweaked\n",
        "\n",
        "        # Interestingly, all the chains are padded to the same length\n",
        "        # this has to be done most probably because the same layers are applied to all chains\n",
        "        # but for single chain or homomer cases, this should not be an issue\n",
        "        # need to be sure later why this is done\n",
        "        # does not significant when it comes to single chain energy-based usecase\n",
        "        # PADDING START\n",
        "        l = len(all_sequence)\n",
        "        x_pad = np.pad(x, [[0,L_max-l], [0,0], [0,0]], 'constant', constant_values=(np.nan, ))\n",
        "        X[i,:,:,:] = x_pad\n",
        "\n",
        "        m_pad = np.pad(m, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        m_pos_pad = np.pad(m_pos, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        omit_AA_mask_pad = np.pad(np.concatenate(omit_AA_mask_list,0), [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        chain_M[i,:] = m_pad\n",
        "        chain_M_pos[i,:] = m_pos_pad\n",
        "        omit_AA_mask[i,] = omit_AA_mask_pad\n",
        "\n",
        "        chain_encoding_pad = np.pad(chain_encoding, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        chain_encoding_all[i,:] = chain_encoding_pad\n",
        "\n",
        "        pssm_coef_pad = np.pad(pssm_coef_, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        pssm_bias_pad = np.pad(pssm_bias_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "        pssm_log_odds_pad = np.pad(pssm_log_odds_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "\n",
        "        pssm_coef_all[i,:] = pssm_coef_pad\n",
        "        pssm_bias_all[i,:] = pssm_bias_pad\n",
        "        pssm_log_odds_all[i,:] = pssm_log_odds_pad\n",
        "\n",
        "        bias_by_res_pad = np.pad(bias_by_res_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "        bias_by_res_all[i,:] = bias_by_res_pad\n",
        "        # PADDING END\n",
        "\n",
        "        # Convert to labels\n",
        "        indices = np.asarray([alphabet.index(a) for a in all_sequence], dtype=np.int32)\n",
        "        S[i, :l] = indices\n",
        "        letter_list_list.append(letter_list)\n",
        "        visible_list_list.append(visible_list)\n",
        "        masked_list_list.append(masked_list)\n",
        "        masked_chain_length_list_list.append(masked_chain_length_list)\n",
        "\n",
        "\n",
        "    isnan = np.isnan(X)\n",
        "    mask = np.isfinite(np.sum(X,(2,3))).astype(np.float32)\n",
        "    X[isnan] = 0.\n",
        "\n",
        "    # Conversion\n",
        "    pssm_coef_all = torch.from_numpy(pssm_coef_all).to(dtype=torch.float32, device=device)\n",
        "    pssm_bias_all = torch.from_numpy(pssm_bias_all).to(dtype=torch.float32, device=device)\n",
        "    pssm_log_odds_all = torch.from_numpy(pssm_log_odds_all).to(dtype=torch.float32, device=device)\n",
        "\n",
        "    tied_beta = torch.from_numpy(tied_beta).to(dtype=torch.float32, device=device)\n",
        "\n",
        "    jumps = ((residue_idx[:,1:]-residue_idx[:,:-1])==1).astype(np.float32)\n",
        "    bias_by_res_all = torch.from_numpy(bias_by_res_all).to(dtype=torch.float32, device=device)\n",
        "    phi_mask = np.pad(jumps, [[0,0],[1,0]])\n",
        "    psi_mask = np.pad(jumps, [[0,0],[0,1]])\n",
        "    omega_mask = np.pad(jumps, [[0,0],[0,1]])\n",
        "    dihedral_mask = np.concatenate([phi_mask[:,:,None], psi_mask[:,:,None], omega_mask[:,:,None]], -1) #[B,L,3]\n",
        "    dihedral_mask = torch.from_numpy(dihedral_mask).to(dtype=torch.float32, device=device)\n",
        "    residue_idx = torch.from_numpy(residue_idx).to(dtype=torch.long,device=device)\n",
        "    S = torch.from_numpy(S).to(dtype=torch.long,device=device)\n",
        "    X = torch.from_numpy(X).to(dtype=torch.float32, device=device)\n",
        "    mask = torch.from_numpy(mask).to(dtype=torch.float32, device=device)\n",
        "    chain_M = torch.from_numpy(chain_M).to(dtype=torch.float32, device=device)\n",
        "    chain_M_pos = torch.from_numpy(chain_M_pos).to(dtype=torch.float32, device=device)\n",
        "    omit_AA_mask = torch.from_numpy(omit_AA_mask).to(dtype=torch.float32, device=device)\n",
        "    chain_encoding_all = torch.from_numpy(chain_encoding_all).to(dtype=torch.long, device=device)\n",
        "    # in general, in this return statement, *_list_list has the list inside list format because the outer list corresponds to \"batch_clones\", \n",
        "    # whereas the inner list corresponds to \"chains\" for each of the elements of \"batch_clones\"\n",
        "    # \"masked_list_list\" contains names of the designable chains (which is my target for single chain energy), whereas \"visible_list_list\" \n",
        "    # contains names of the fixed chains (which should be empty for my single chain energy)\n",
        "    # for my single chain energy case, \"letter_list_list\" should be equal to \"masked_list_list\", and three lists should have one list for now\n",
        "    # \"chain_encoding_all\" should also contain chain-index related to the only single chain which should be 0 (all 0s)\n",
        "    # the last lists starting from \"tied_pos_list_of_lists_list\" to the end should be irrelevant for my single chain energy case\n",
        "    # but still it would be good to check the values of these irrelevant lists, and get an idea if everything makes sense or not\n",
        "    # \"chain_M_pos\" contains values from \"fixed_position_mask\" through \"m_pos\", which should get populated with 0.0 for fixed positions\n",
        "    # and 1.0 for designable positions, which can be controlled through the , which\n",
        "    # is controlled by \"fixed_position_dict\" input to this function from the running script\n",
        "    # \"chain_M\" is formed from \"m_pad\" which comes from \"m\" which comes from chain_mask = np.ones(chain_length) #1.0 for masked\n",
        "    # so, for my single chain energy usecase, \"chain_M\" should be all 1.0s with the same length as chain_M_pos\n",
        "    # I do not think \"X\", \"S\", and \"mask\" need to be manipulated for now \n",
        "    return X, S, mask, lengths, chain_M, chain_encoding_all, letter_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef_all, pssm_bias_all, pssm_log_odds_all, bias_by_res_all, tied_beta\n",
        "\n",
        "\n",
        "# No need to dig into this loss function for now\n",
        "def loss_nll(S, log_probs, mask):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    criterion = torch.nn.NLLLoss(reduction='none')\n",
        "    loss = criterion(\n",
        "        log_probs.contiguous().view(-1, log_probs.size(-1)), S.contiguous().view(-1)\n",
        "    ).view(S.size())\n",
        "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
        "    return loss, loss_av\n",
        "\n",
        "# No need to dig into this label smoothing stuff for now\n",
        "def loss_smoothed(S, log_probs, mask, weight=0.1):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    S_onehot = torch.nn.functional.one_hot(S, 21).float()\n",
        "\n",
        "    # Label smoothing\n",
        "    S_onehot = S_onehot + weight / float(S_onehot.size(-1))\n",
        "    S_onehot = S_onehot / S_onehot.sum(-1, keepdim=True)\n",
        "\n",
        "    loss = -(S_onehot * log_probs).sum(-1)\n",
        "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
        "    return loss, loss_av\n",
        "\n",
        "# Objects of this class can be indexed since dunder methods __len()__ and __getitem()__ have been implemented, which \n",
        "# indexes a list that has been declared as an instance variable in the constructor,\n",
        "# and each element of that underlying list is a dictionary containing information regarding a specific sequence\n",
        "class StructureDataset():\n",
        "    def __init__(self, jsonl_file, verbose=True, truncate=None, max_length=100,\n",
        "        alphabet='ACDEFGHIKLMNPQRSTVWYX-'):\n",
        "        alphabet_set = set([a for a in alphabet])\n",
        "        discard_count = {\n",
        "            'bad_chars': 0,\n",
        "            'too_long': 0,\n",
        "            'bad_seq_length': 0\n",
        "        }\n",
        "\n",
        "        with open(jsonl_file) as f:\n",
        "            self.data = []\n",
        "\n",
        "            lines = f.readlines()\n",
        "            start = time.time()\n",
        "            for i, line in enumerate(lines):\n",
        "                entry = json.loads(line)\n",
        "                seq = entry['seq'] \n",
        "                name = entry['name']\n",
        "\n",
        "                # Convert raw coords to np arrays\n",
        "                #for key, val in entry['coords'].items():\n",
        "                #    entry['coords'][key] = np.asarray(val)\n",
        "\n",
        "                # Check if in alphabet\n",
        "                bad_chars = set([s for s in seq]).difference(alphabet_set)\n",
        "                if len(bad_chars) == 0:\n",
        "                    if len(entry['seq']) <= max_length:\n",
        "                        if True:\n",
        "                            self.data.append(entry)\n",
        "                        else:\n",
        "                            discard_count['bad_seq_length'] += 1\n",
        "                    else:\n",
        "                        discard_count['too_long'] += 1\n",
        "                else:\n",
        "                    print(name, bad_chars, entry['seq'])\n",
        "                    discard_count['bad_chars'] += 1\n",
        "\n",
        "                # Truncate early\n",
        "                if truncate is not None and len(self.data) == truncate:\n",
        "                    return\n",
        "\n",
        "                if verbose and (i + 1) % 1000 == 0:\n",
        "                    elapsed = time.time() - start\n",
        "                    print('{} entries ({} loaded) in {:.1f} s'.format(len(self.data), i+1, elapsed))\n",
        "\n",
        "            print('discarded', discard_count)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "\n",
        "# Objects of this class can be indexed since dunder methods __len()__ and __getitem()__ have been implemented, which \n",
        "# indexes a list that has been declared as an instance variable in the constructor,\n",
        "# and each element of that underlying list is a dictionary containing information regarding a specific structure,\n",
        "# seems like a structure-specific version of the above method which deals with sequences \n",
        "class StructureDatasetPDB():\n",
        "    def __init__(self, pdb_dict_list, verbose=True, truncate=None, max_length=100,\n",
        "        alphabet='ACDEFGHIKLMNPQRSTVWYX-'):\n",
        "        alphabet_set = set([a for a in alphabet])\n",
        "        discard_count = {\n",
        "            'bad_chars': 0,\n",
        "            'too_long': 0,\n",
        "            'bad_seq_length': 0\n",
        "        }\n",
        "\n",
        "        self.data = []\n",
        "\n",
        "        start = time.time()\n",
        "        # elements of pdb_dict_list are dictionaries containing information regarding a specific pdb file\n",
        "        for i, entry in enumerate(pdb_dict_list):\n",
        "            seq = entry['seq']\n",
        "            name = entry['name']\n",
        "\n",
        "            bad_chars = set([s for s in seq]).difference(alphabet_set)\n",
        "            if len(bad_chars) == 0:\n",
        "                if len(entry['seq']) <= max_length:\n",
        "                    self.data.append(entry)\n",
        "                else:\n",
        "                    discard_count['too_long'] += 1\n",
        "            else:\n",
        "                discard_count['bad_chars'] += 1\n",
        "\n",
        "            # Truncate early\n",
        "            if truncate is not None and len(self.data) == truncate:\n",
        "                return\n",
        "\n",
        "            if verbose and (i + 1) % 1000 == 0:\n",
        "                elapsed = time.time() - start\n",
        "\n",
        "            #print('Discarded', discard_count)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "\n",
        "    \n",
        "class StructureLoader():\n",
        "    def __init__(self, dataset, batch_size=100, shuffle=True,\n",
        "        collate_fn=lambda x:x, drop_last=False):\n",
        "        self.dataset = dataset\n",
        "        self.size = len(dataset)\n",
        "        self.lengths = [len(dataset[i]['seq']) for i in range(self.size)]\n",
        "        self.batch_size = batch_size\n",
        "        sorted_ix = np.argsort(self.lengths)\n",
        "\n",
        "        # Cluster into batches of similar sizes\n",
        "        clusters, batch = [], []\n",
        "        batch_max = 0\n",
        "        for ix in sorted_ix:\n",
        "            size = self.lengths[ix]\n",
        "            if size * (len(batch) + 1) <= self.batch_size:\n",
        "                batch.append(ix)\n",
        "                batch_max = size\n",
        "            else:\n",
        "                clusters.append(batch)\n",
        "                batch, batch_max = [], 0\n",
        "        if len(batch) > 0:\n",
        "            clusters.append(batch)\n",
        "        self.clusters = clusters\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.clusters)\n",
        "\n",
        "    def __iter__(self):\n",
        "        np.random.shuffle(self.clusters)\n",
        "        for b_idx in self.clusters:\n",
        "            batch = [self.dataset[i] for i in b_idx]\n",
        "            yield batch\n",
        "            \n",
        "            \n",
        "            \n",
        "# The following gather functions\n",
        "def gather_edges(edges, neighbor_idx):\n",
        "    # Features [B,N,N,C] at Neighbor indices [B,N,K] => Neighbor features [B,N,K,C]\n",
        "    neighbors = neighbor_idx.unsqueeze(-1).expand(-1, -1, -1, edges.size(-1))\n",
        "    edge_features = torch.gather(edges, 2, neighbors)\n",
        "    return edge_features\n",
        "\n",
        "def gather_nodes(nodes, neighbor_idx):\n",
        "    # Features [B,N,C] at Neighbor indices [B,N,K] => [B,N,K,C]\n",
        "    # Flatten and expand indices per batch [B,N,K] => [B,NK] => [B,NK,C]\n",
        "    neighbors_flat = neighbor_idx.view((neighbor_idx.shape[0], -1))\n",
        "    neighbors_flat = neighbors_flat.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
        "    # Gather and re-pack\n",
        "    neighbor_features = torch.gather(nodes, 1, neighbors_flat)\n",
        "    neighbor_features = neighbor_features.view(list(neighbor_idx.shape)[:3] + [-1])\n",
        "    return neighbor_features\n",
        "\n",
        "def gather_nodes_t(nodes, neighbor_idx):\n",
        "    # Features [B,N,C] at Neighbor index [B,K] => Neighbor features[B,K,C]\n",
        "    idx_flat = neighbor_idx.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
        "    neighbor_features = torch.gather(nodes, 1, idx_flat)\n",
        "    return neighbor_features\n",
        "\n",
        "def cat_neighbors_nodes(h_nodes, h_neighbors, E_idx):\n",
        "    h_nodes = gather_nodes(h_nodes, E_idx)\n",
        "    h_nn = torch.cat([h_neighbors, h_nodes], -1)\n",
        "    return h_nn\n",
        "\n",
        "\n",
        "class EncLayer(nn.Module):\n",
        "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
        "        super(EncLayer, self).__init__()\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_in = num_in\n",
        "        self.scale = scale\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(num_hidden)\n",
        "        self.norm2 = nn.LayerNorm(num_hidden)\n",
        "        self.norm3 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W11 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W12 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W13 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
        "\n",
        "    def forward(self, h_V, h_E, E_idx, mask_V=None, mask_attend=None):\n",
        "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
        "\n",
        "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
        "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
        "        if mask_attend is not None:\n",
        "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
        "        dh = torch.sum(h_message, -2) / self.scale\n",
        "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
        "\n",
        "        dh = self.dense(h_V)\n",
        "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
        "        if mask_V is not None:\n",
        "            mask_V = mask_V.unsqueeze(-1)\n",
        "            h_V = mask_V * h_V\n",
        "\n",
        "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
        "        h_message = self.W13(self.act(self.W12(self.act(self.W11(h_EV)))))\n",
        "        h_E = self.norm3(h_E + self.dropout3(h_message))\n",
        "        return h_V, h_E\n",
        "\n",
        "\n",
        "class DecLayer(nn.Module):\n",
        "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
        "        super(DecLayer, self).__init__()\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_in = num_in\n",
        "        self.scale = scale\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(num_hidden)\n",
        "        self.norm2 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
        "\n",
        "    def forward(self, h_V, h_E, mask_V=None, mask_attend=None):\n",
        "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
        "\n",
        "        # Concatenate h_V_i to h_E_ij\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_E.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_E], -1)\n",
        "\n",
        "        # Maybe, length of the message vector can serve as attention\n",
        "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
        "        # the mask attend here is most probably just for zeroing out the padded positions\n",
        "        # I do not think it will matter that much\n",
        "        if mask_attend is not None:\n",
        "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
        "            # why divide by 30 when we are dealing with 48 neighbors in the current version of the model?\n",
        "        # Let me check the messages corresponding to \n",
        "        dh = torch.sum(h_message, -2) / self.scale\n",
        "\n",
        "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
        "\n",
        "        # Position-wise feedforward\n",
        "        dh = self.dense(h_V)\n",
        "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
        "\n",
        "        if mask_V is not None:\n",
        "            mask_V = mask_V.unsqueeze(-1)\n",
        "            h_V = mask_V * h_V\n",
        "\n",
        "        # \"h_message\" can be returned without dividing by \"self.scale\" also\n",
        "        return h_V, (h_message/self.scale) \n",
        "\n",
        "\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, num_hidden, num_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.W_in = nn.Linear(num_hidden, num_ff, bias=True)\n",
        "        self.W_out = nn.Linear(num_ff, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "    def forward(self, h_V):\n",
        "        h = self.act(self.W_in(h_V))\n",
        "        h = self.W_out(h)\n",
        "        return h\n",
        "\n",
        "class PositionalEncodings(nn.Module):\n",
        "    def __init__(self, num_embeddings, max_relative_feature=32):\n",
        "        super(PositionalEncodings, self).__init__()\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.max_relative_feature = max_relative_feature\n",
        "        self.linear = nn.Linear(2*max_relative_feature+1+1, num_embeddings)\n",
        "\n",
        "    def forward(self, offset, mask):\n",
        "        d = torch.clip(offset + self.max_relative_feature, 0, 2*self.max_relative_feature)*mask + (1-mask)*(2*self.max_relative_feature+1)\n",
        "        d_onehot = torch.nn.functional.one_hot(d, 2*self.max_relative_feature+1+1)\n",
        "        E = self.linear(d_onehot.float())\n",
        "        return E\n",
        "\n",
        "# Does not look like this function needs to be modified for now to use the model as sort of an energy function\n",
        "# The only thing that could do something is \"top_k\", which can be changed for considering more or less neighbors\n",
        "# for each of the nodes, but that too I think does not matter if the default value of top_k is updated by parameter passing\n",
        "# This function is called from the model itself with node_features=128, edge_features=128, and top_k=48\n",
        "# ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
        "class ProteinFeatures(nn.Module):\n",
        "    def __init__(self, edge_features, node_features, num_positional_embeddings=16,\n",
        "        num_rbf=16, top_k=30, augment_eps=0., num_chain_embeddings=16):\n",
        "        \"\"\" Extract protein features \"\"\"\n",
        "        super(ProteinFeatures, self).__init__()\n",
        "        self.edge_features = edge_features\n",
        "        self.node_features = node_features\n",
        "        self.top_k = top_k\n",
        "        self.augment_eps = augment_eps \n",
        "        self.num_rbf = num_rbf\n",
        "        self.num_positional_embeddings = num_positional_embeddings\n",
        "\n",
        "        self.embeddings = PositionalEncodings(num_positional_embeddings)\n",
        "        node_in, edge_in = 6, num_positional_embeddings + num_rbf*25\n",
        "        self.edge_embedding = nn.Linear(edge_in, edge_features, bias=False)\n",
        "        self.norm_edges = nn.LayerNorm(edge_features)\n",
        "\n",
        "    # the output of this function MUST be analyzed either directly or via some other function to \n",
        "    # understand how to get \"index/position\" of neighbors\n",
        "    def _dist(self, X, mask, eps=1E-6):\n",
        "        mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
        "        dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
        "        D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
        "        D_max, _ = torch.max(D, -1, keepdim=True)\n",
        "        D_adjust = D + (1. - mask_2D) * D_max\n",
        "        sampled_top_k = self.top_k\n",
        "        D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(self.top_k, X.shape[1]), dim=-1, largest=False)\n",
        "        return D_neighbors, E_idx\n",
        "\n",
        "    def _rbf(self, D):\n",
        "        device = D.device\n",
        "        D_min, D_max, D_count = 2., 22., self.num_rbf\n",
        "        D_mu = torch.linspace(D_min, D_max, D_count, device=device)\n",
        "        D_mu = D_mu.view([1,1,1,-1])\n",
        "        D_sigma = (D_max - D_min) / D_count\n",
        "        D_expand = torch.unsqueeze(D, -1)\n",
        "        RBF = torch.exp(-((D_expand - D_mu) / D_sigma)**2)\n",
        "        return RBF\n",
        "\n",
        "    def _get_rbf(self, A, B, E_idx):\n",
        "        D_A_B = torch.sqrt(torch.sum((A[:,:,None,:] - B[:,None,:,:])**2,-1) + 1e-6) #[B, L, L]\n",
        "        D_A_B_neighbors = gather_edges(D_A_B[:,:,:,None], E_idx)[:,:,:,0] #[B,L,K]\n",
        "        RBF_A_B = self._rbf(D_A_B_neighbors)\n",
        "        return RBF_A_B\n",
        "\n",
        "    # this function will be called with the arguments as forward(), but will return information regarding \n",
        "    # the neighbors which I will figure out a way to parse\n",
        "    def return_neighbor_info(self, X, mask, residue_idx, chain_labels):\n",
        "        b = X[:,:,1,:] - X[:,:,0,:]\n",
        "        c = X[:,:,2,:] - X[:,:,1,:]\n",
        "        a = torch.cross(b, c, dim=-1)\n",
        "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "        Ca = X[:,:,1,:]\n",
        "        N = X[:,:,0,:]\n",
        "        C = X[:,:,2,:]\n",
        "        O = X[:,:,3,:]\n",
        " \n",
        "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
        "\n",
        "\n",
        "    def forward(self, X, mask, residue_idx, chain_labels):\n",
        "        if self.augment_eps > 0:\n",
        "            X = X + self.augment_eps * torch.randn_like(X)\n",
        "        \n",
        "        b = X[:,:,1,:] - X[:,:,0,:]\n",
        "        c = X[:,:,2,:] - X[:,:,1,:]\n",
        "        a = torch.cross(b, c, dim=-1)\n",
        "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "        Ca = X[:,:,1,:]\n",
        "        N = X[:,:,0,:]\n",
        "        C = X[:,:,2,:]\n",
        "        O = X[:,:,3,:]\n",
        " \n",
        "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
        "\n",
        "        RBF_all = []\n",
        "        RBF_all.append(self._rbf(D_neighbors)) #Ca-Ca\n",
        "        RBF_all.append(self._get_rbf(N, N, E_idx)) #N-N\n",
        "        RBF_all.append(self._get_rbf(C, C, E_idx)) #C-C\n",
        "        RBF_all.append(self._get_rbf(O, O, E_idx)) #O-O\n",
        "        RBF_all.append(self._get_rbf(Cb, Cb, E_idx)) #Cb-Cb\n",
        "        RBF_all.append(self._get_rbf(Ca, N, E_idx)) #Ca-N\n",
        "        RBF_all.append(self._get_rbf(Ca, C, E_idx)) #Ca-C\n",
        "        RBF_all.append(self._get_rbf(Ca, O, E_idx)) #Ca-O\n",
        "        RBF_all.append(self._get_rbf(Ca, Cb, E_idx)) #Ca-Cb\n",
        "        RBF_all.append(self._get_rbf(N, C, E_idx)) #N-C\n",
        "        RBF_all.append(self._get_rbf(N, O, E_idx)) #N-O\n",
        "        RBF_all.append(self._get_rbf(N, Cb, E_idx)) #N-Cb\n",
        "        RBF_all.append(self._get_rbf(Cb, C, E_idx)) #Cb-C\n",
        "        RBF_all.append(self._get_rbf(Cb, O, E_idx)) #Cb-O\n",
        "        RBF_all.append(self._get_rbf(O, C, E_idx)) #O-C\n",
        "        RBF_all.append(self._get_rbf(N, Ca, E_idx)) #N-Ca\n",
        "        RBF_all.append(self._get_rbf(C, Ca, E_idx)) #C-Ca\n",
        "        RBF_all.append(self._get_rbf(O, Ca, E_idx)) #O-Ca\n",
        "        RBF_all.append(self._get_rbf(Cb, Ca, E_idx)) #Cb-Ca\n",
        "        RBF_all.append(self._get_rbf(C, N, E_idx)) #C-N\n",
        "        RBF_all.append(self._get_rbf(O, N, E_idx)) #O-N\n",
        "        RBF_all.append(self._get_rbf(Cb, N, E_idx)) #Cb-N\n",
        "        RBF_all.append(self._get_rbf(C, Cb, E_idx)) #C-Cb\n",
        "        RBF_all.append(self._get_rbf(O, Cb, E_idx)) #O-Cb\n",
        "        RBF_all.append(self._get_rbf(C, O, E_idx)) #C-O\n",
        "        RBF_all = torch.cat(tuple(RBF_all), dim=-1)\n",
        "\n",
        "        offset = residue_idx[:,:,None]-residue_idx[:,None,:]\n",
        "        offset = gather_edges(offset[:,:,:,None], E_idx)[:,:,:,0] #[B, L, K]\n",
        "\n",
        "        d_chains = ((chain_labels[:, :, None] - chain_labels[:,None,:])==0).long() #find self vs non-self interaction\n",
        "        E_chains = gather_edges(d_chains[:,:,:,None], E_idx)[:,:,:,0]\n",
        "        E_positional = self.embeddings(offset.long(), E_chains)\n",
        "        E = torch.cat((E_positional, RBF_all), -1)\n",
        "        E = self.edge_embedding(E)\n",
        "        E = self.norm_edges(E)\n",
        "        return E, E_idx \n",
        "\n",
        "\n",
        "\n",
        "class ProteinMPNN(nn.Module):\n",
        "    # \"node_features\" and \"edge_features\" are actually dimensionality of these features (\"hidden_dim\" in the calling script)\n",
        "    # the value is 128 for the version that I am using\n",
        "    def __init__(self, num_letters, node_features, edge_features,\n",
        "        hidden_dim, num_encoder_layers=3, num_decoder_layers=3,\n",
        "        vocab=21, k_neighbors=64, augment_eps=0.05, dropout=0.1):\n",
        "        super(ProteinMPNN, self).__init__()\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.node_features = node_features\n",
        "        self.edge_features = edge_features\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Featurization layers\n",
        "        # The version that I am using considers 48 neighbors for each position\n",
        "        self.features = ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
        "\n",
        "        self.W_e = nn.Linear(edge_features, hidden_dim, bias=True)\n",
        "        # This W_s is for embedding the sequence\n",
        "        self.W_s = nn.Embedding(vocab, hidden_dim)\n",
        "\n",
        "        # Encoder layers\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            EncLayer(hidden_dim, hidden_dim*2, dropout=dropout)\n",
        "            for _ in range(num_encoder_layers)\n",
        "        ])\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            DecLayer(hidden_dim, hidden_dim*3, dropout=dropout)\n",
        "            for _ in range(num_decoder_layers)\n",
        "        ])\n",
        "        self.W_out = nn.Linear(hidden_dim, num_letters, bias=True)\n",
        "\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    # Creating my own versions of forward should be an easy way to get embeddings or attention weights from diffrerent layers of the model\n",
        "    # See here (https://discuss.pytorch.org/t/how-can-i-extract-intermediate-layer-output-from-loaded-cnn-model/77301) in the forums for adding forward\n",
        "    # hooks or manipulating the forward method\n",
        "    # but my easy solution would be to create different versions of the forward method with different namaes, and calling them explicitly\n",
        "    # \"chain_M\" and \"mask\" seem to be the things that I need to understand very well and play-around with \n",
        "    def forward(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn, use_input_decoding_order=False, decoding_order=None):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Concatenate sequence embeddings for autoregressive decoder\n",
        "        # h_S denotes embedding of the sequence itself for use in decoder\n",
        "        h_S = self.W_s(S)\n",
        "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "\n",
        "\n",
        "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
        "        if not use_input_decoding_order:\n",
        "            decoding_order = torch.argsort((chain_M+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for layer in self.decoder_layers:\n",
        "            # Masked positions attend to encoder information, unmasked see. \n",
        "            h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "            h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
        "            # only the last layer decoder-messages will be stored in \"decoder_messages\"\n",
        "            h_V, decoder_messages = layer(h_V, h_ESV, mask)\n",
        "\n",
        "        logits = self.W_out(h_V)\n",
        "        # The probabilities are passed through log() function so that the sequences can be ranked based by summing the respective values \n",
        "        # for each position instead of multiplication \n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        # messages from the last layer decoder will also be returned for extracting neighbor-attention approximation\\\n",
        "        # last layer embeddings can be extracted from the \"h_V\" tensor \n",
        "        return log_probs, decoder_messages, h_V\n",
        "\n",
        "\n",
        "\n",
        "    # Seems like this is the method which is used by the notebook for calculating probabilites and scoring\n",
        "    # Need to dig into it thoroughly\n",
        "    # \"chain_mask\" and \"residue_idx\" seem like the tensors of interest\n",
        "    def sample(self, X, randn, S_true, chain_mask, chain_encoding_all, residue_idx, mask=None, temperature=1.0, omit_AAs_np=None, bias_AAs_np=None, chain_M_pos=None, omit_AA_mask=None, pssm_coef=None, pssm_bias=None, pssm_multi=None, pssm_log_odds_flag=None, pssm_log_odds_mask=None, pssm_bias_flag=None, bias_by_res=None):\n",
        "        device = X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Decoder uses masked self-attention\n",
        "        chain_mask = chain_mask*chain_M_pos*mask #update chain_M to include missing regions\n",
        "        decoding_order = torch.argsort((chain_mask+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        N_batch, N_nodes = X.size(0), X.size(1)\n",
        "        log_probs = torch.zeros((N_batch, N_nodes, 21), device=device)\n",
        "        all_probs = torch.zeros((N_batch, N_nodes, 21), device=device, dtype=torch.float32)\n",
        "        h_S = torch.zeros_like(h_V, device=device)\n",
        "        S = torch.zeros((N_batch, N_nodes), dtype=torch.int64, device=device)\n",
        "        h_V_stack = [h_V] + [torch.zeros_like(h_V, device=device) for _ in range(len(self.decoder_layers))]\n",
        "        constant = torch.tensor(omit_AAs_np, device=device)\n",
        "        constant_bias = torch.tensor(bias_AAs_np, device=device)\n",
        "        #chain_mask_combined = chain_mask*chain_M_pos \n",
        "        omit_AA_mask_flag = omit_AA_mask != None\n",
        "\n",
        "\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for t_ in range(N_nodes):\n",
        "            t = decoding_order[:,t_] #[B]\n",
        "            chain_mask_gathered = torch.gather(chain_mask, 1, t[:,None]) #[B]\n",
        "            bias_by_res_gathered = torch.gather(bias_by_res, 1, t[:,None,None].repeat(1,1,21))[:,0,:] #[B, 21]\n",
        "            if (chain_mask_gathered==0).all():\n",
        "                S_t = torch.gather(S_true, 1, t[:,None])\n",
        "            else:\n",
        "                # Hidden layers\n",
        "                E_idx_t = torch.gather(E_idx, 1, t[:,None,None].repeat(1,1,E_idx.shape[-1]))\n",
        "                h_E_t = torch.gather(h_E, 1, t[:,None,None,None].repeat(1,1,h_E.shape[-2], h_E.shape[-1]))\n",
        "                h_ES_t = cat_neighbors_nodes(h_S, h_E_t, E_idx_t)\n",
        "                h_EXV_encoder_t = torch.gather(h_EXV_encoder_fw, 1, t[:,None,None,None].repeat(1,1,h_EXV_encoder_fw.shape[-2], h_EXV_encoder_fw.shape[-1]))\n",
        "                mask_t = torch.gather(mask, 1, t[:,None])\n",
        "                for l, layer in enumerate(self.decoder_layers):\n",
        "                    # Updated relational features for future states\n",
        "                    h_ESV_decoder_t = cat_neighbors_nodes(h_V_stack[l], h_ES_t, E_idx_t)\n",
        "                    h_V_t = torch.gather(h_V_stack[l], 1, t[:,None,None].repeat(1,1,h_V_stack[l].shape[-1]))\n",
        "                    h_ESV_t = torch.gather(mask_bw, 1, t[:,None,None,None].repeat(1,1,mask_bw.shape[-2], mask_bw.shape[-1])) * h_ESV_decoder_t + h_EXV_encoder_t\n",
        "                    h_V_stack[l+1].scatter_(1, t[:,None,None].repeat(1,1,h_V.shape[-1]), layer(h_V_t, h_ESV_t, mask_V=mask_t))\n",
        "                # Sampling step\n",
        "                h_V_t = torch.gather(h_V_stack[-1], 1, t[:,None,None].repeat(1,1,h_V_stack[-1].shape[-1]))[:,0]\n",
        "                logits = self.W_out(h_V_t) / temperature\n",
        "                probs = F.softmax(logits-constant[None,:]*1e8+constant_bias[None,:]/temperature+bias_by_res_gathered/temperature, dim=-1)\n",
        "                if pssm_bias_flag:\n",
        "                    pssm_coef_gathered = torch.gather(pssm_coef, 1, t[:,None])[:,0]\n",
        "                    pssm_bias_gathered = torch.gather(pssm_bias, 1, t[:,None,None].repeat(1,1,pssm_bias.shape[-1]))[:,0]\n",
        "                    probs = (1-pssm_multi*pssm_coef_gathered[:,None])*probs + pssm_multi*pssm_coef_gathered[:,None]*pssm_bias_gathered\n",
        "                if pssm_log_odds_flag:\n",
        "                    pssm_log_odds_mask_gathered = torch.gather(pssm_log_odds_mask, 1, t[:,None, None].repeat(1,1,pssm_log_odds_mask.shape[-1]))[:,0] #[B, 21]\n",
        "                    probs_masked = probs*pssm_log_odds_mask_gathered\n",
        "                    probs_masked += probs * 0.001\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                if omit_AA_mask_flag:\n",
        "                    omit_AA_mask_gathered = torch.gather(omit_AA_mask, 1, t[:,None, None].repeat(1,1,omit_AA_mask.shape[-1]))[:,0] #[B, 21]\n",
        "                    probs_masked = probs*(1.0-omit_AA_mask_gathered)\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                # Here is where sampling from the multinomial distribution is happening\n",
        "                # this will sample 1 element according to the given distribution, and return the index of that element [from 0 to 20]\n",
        "                S_t = torch.multinomial(probs, 1)\n",
        "                all_probs.scatter_(1, t[:,None,None].repeat(1,1,21), (chain_mask_gathered[:,:,None,]*probs[:,None,:]).float())\n",
        "            S_true_gathered = torch.gather(S_true, 1, t[:,None])\n",
        "            S_t = (S_t*chain_mask_gathered+S_true_gathered*(1.0-chain_mask_gathered)).long()\n",
        "            temp1 = self.W_s(S_t)\n",
        "            h_S.scatter_(1, t[:,None,None].repeat(1,1,temp1.shape[-1]), temp1)\n",
        "            S.scatter_(1, t[:,None], S_t)\n",
        "        output_dict = {\"S\": S, \"probs\": all_probs, \"decoding_order\": decoding_order}\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "    def tied_sample(self, X, randn, S_true, chain_mask, chain_encoding_all, residue_idx, mask=None, temperature=1.0, omit_AAs_np=None, bias_AAs_np=None, chain_M_pos=None, omit_AA_mask=None, pssm_coef=None, pssm_bias=None, pssm_multi=None, pssm_log_odds_flag=None, pssm_log_odds_mask=None, pssm_bias_flag=None, tied_pos=None, tied_beta=None, bias_by_res=None):\n",
        "        device = X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=device)\n",
        "        h_E = self.W_e(E)\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Decoder uses masked self-attention\n",
        "        chain_mask = chain_mask*chain_M_pos*mask #update chain_M to include missing regions\n",
        "        decoding_order = torch.argsort((chain_mask+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "\n",
        "        new_decoding_order = []\n",
        "        for t_dec in list(decoding_order[0,].cpu().data.numpy()):\n",
        "            if t_dec not in list(itertools.chain(*new_decoding_order)):\n",
        "                list_a = [item for item in tied_pos if t_dec in item]\n",
        "                if list_a:\n",
        "                    new_decoding_order.append(list_a[0])\n",
        "                else:\n",
        "                    new_decoding_order.append([t_dec])\n",
        "        decoding_order = torch.tensor(list(itertools.chain(*new_decoding_order)), device=device)[None,].repeat(X.shape[0],1)\n",
        "\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        N_batch, N_nodes = X.size(0), X.size(1)\n",
        "        log_probs = torch.zeros((N_batch, N_nodes, 21), device=device)\n",
        "        all_probs = torch.zeros((N_batch, N_nodes, 21), device=device, dtype=torch.float32)\n",
        "        h_S = torch.zeros_like(h_V, device=device)\n",
        "        S = torch.zeros((N_batch, N_nodes), dtype=torch.int64, device=device)\n",
        "        h_V_stack = [h_V] + [torch.zeros_like(h_V, device=device) for _ in range(len(self.decoder_layers))]\n",
        "        constant = torch.tensor(omit_AAs_np, device=device)\n",
        "        constant_bias = torch.tensor(bias_AAs_np, device=device)\n",
        "        omit_AA_mask_flag = omit_AA_mask != None\n",
        "\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for t_list in new_decoding_order:\n",
        "            logits = 0.0\n",
        "            logit_list = []\n",
        "            done_flag = False\n",
        "            for t in t_list:\n",
        "                if (chain_mask[:,t]==0).all():\n",
        "                    S_t = S_true[:,t]\n",
        "                    for t in t_list:\n",
        "                        h_S[:,t,:] = self.W_s(S_t)\n",
        "                        S[:,t] = S_t\n",
        "                    done_flag = True\n",
        "                    break\n",
        "                else:\n",
        "                    E_idx_t = E_idx[:,t:t+1,:]\n",
        "                    h_E_t = h_E[:,t:t+1,:,:]\n",
        "                    h_ES_t = cat_neighbors_nodes(h_S, h_E_t, E_idx_t)\n",
        "                    h_EXV_encoder_t = h_EXV_encoder_fw[:,t:t+1,:,:]\n",
        "                    mask_t = mask[:,t:t+1]\n",
        "                    for l, layer in enumerate(self.decoder_layers):\n",
        "                        h_ESV_decoder_t = cat_neighbors_nodes(h_V_stack[l], h_ES_t, E_idx_t)\n",
        "                        h_V_t = h_V_stack[l][:,t:t+1,:]\n",
        "                        h_ESV_t = mask_bw[:,t:t+1,:,:] * h_ESV_decoder_t + h_EXV_encoder_t\n",
        "                        h_V_stack[l+1][:,t,:] = layer(h_V_t, h_ESV_t, mask_V=mask_t).squeeze(1)\n",
        "                    h_V_t = h_V_stack[-1][:,t,:]\n",
        "                    logit_list.append((self.W_out(h_V_t) / temperature)/len(t_list))\n",
        "                    logits += tied_beta[t]*(self.W_out(h_V_t) / temperature)/len(t_list)\n",
        "            if done_flag:\n",
        "                pass\n",
        "            else:\n",
        "                bias_by_res_gathered = bias_by_res[:,t,:] #[B, 21]\n",
        "                probs = F.softmax(logits-constant[None,:]*1e8+constant_bias[None,:]/temperature+bias_by_res_gathered/temperature, dim=-1)\n",
        "                if pssm_bias_flag:\n",
        "                    pssm_coef_gathered = pssm_coef[:,t]\n",
        "                    pssm_bias_gathered = pssm_bias[:,t]\n",
        "                    probs = (1-pssm_multi*pssm_coef_gathered[:,None])*probs + pssm_multi*pssm_coef_gathered[:,None]*pssm_bias_gathered\n",
        "                if pssm_log_odds_flag:\n",
        "                    pssm_log_odds_mask_gathered = pssm_log_odds_mask[:,t]\n",
        "                    probs_masked = probs*pssm_log_odds_mask_gathered\n",
        "                    probs_masked += probs * 0.001\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                if omit_AA_mask_flag:\n",
        "                    omit_AA_mask_gathered = omit_AA_mask[:,t]\n",
        "                    probs_masked = probs*(1.0-omit_AA_mask_gathered)\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                S_t_repeat = torch.multinomial(probs, 1).squeeze(-1)\n",
        "                for t in t_list:\n",
        "                    h_S[:,t,:] = self.W_s(S_t_repeat)\n",
        "                    S[:,t] = S_t_repeat\n",
        "                    all_probs[:,t,:] = probs.float()\n",
        "        output_dict = {\"S\": S, \"probs\": all_probs, \"decoding_order\": decoding_order}\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "    # I am not seeing an immediate use of this method when the model is called through notebook\n",
        "    # So, will skip further commenting and digging for now\n",
        "    # But, seems like an interesting way of interacting with the model in a specific way, so\n",
        "    # might get back to this later\n",
        "    def conditional_probs(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn, backbone_only=False):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V_enc = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V_enc, h_E = layer(h_V_enc, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Concatenate sequence embeddings for autoregressive decoder\n",
        "        h_S = self.W_s(S)\n",
        "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V_enc, h_EX_encoder, E_idx)\n",
        "\n",
        "\n",
        "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
        "  \n",
        "        chain_M_np = chain_M.cpu().numpy()\n",
        "        idx_to_loop = np.argwhere(chain_M_np[0,:]==1)[:,0]\n",
        "        log_conditional_probs = torch.zeros([X.shape[0], chain_M.shape[1], 21], device=device).float()\n",
        "\n",
        "        for idx in idx_to_loop:\n",
        "            h_V = torch.clone(h_V_enc)\n",
        "            order_mask = torch.zeros(chain_M.shape[1], device=device).float()\n",
        "            if backbone_only:\n",
        "                order_mask = torch.ones(chain_M.shape[1], device=device).float()\n",
        "                order_mask[idx] = 0.\n",
        "            else:\n",
        "                order_mask = torch.zeros(chain_M.shape[1], device=device).float()\n",
        "                order_mask[idx] = 1.\n",
        "            decoding_order = torch.argsort((order_mask[None,]+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "            mask_size = E_idx.shape[1]\n",
        "            permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "            order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "            mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "            mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "            mask_bw = mask_1D * mask_attend\n",
        "            mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "            h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "            for layer in self.decoder_layers:\n",
        "                # Masked positions attend to encoder information, unmasked see. \n",
        "                h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "                h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
        "                h_V = layer(h_V, h_ESV, mask)\n",
        "\n",
        "            logits = self.W_out(h_V)\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "            log_conditional_probs[:,idx,:] = log_probs[:,idx,:]\n",
        "        return log_conditional_probs\n",
        "\n",
        "\n",
        "    # I am not seeing an immediate use of this method when the model is called through notebook\n",
        "    # So, will skip further commenting and digging for now\n",
        "    # But, seems like an interesting way of interacting with the model in a specific way, so\n",
        "    # might get back to this later\n",
        "    def unconditional_probs(self, X, mask, residue_idx, chain_encoding_all):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_V), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "\n",
        "        order_mask_backward = torch.zeros([X.shape[0], X.shape[1], X.shape[1]], device=device)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for layer in self.decoder_layers:\n",
        "            h_V = layer(h_V, h_EXV_encoder_fw, mask)\n",
        "\n",
        "        logits = self.W_out(h_V)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        return log_probs"
      ],
      "metadata": {
        "id": "HjbVWJkg7zik"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 128\n",
        "num_layers = 3 \n",
        "# Seems like, backbone_noise is set to 0 at inference path which seems logical\n",
        "backbone_noise=0.00\n",
        "mpnn_model = ProteinMPNN(num_letters=21, node_features=hidden_dim, edge_features=hidden_dim, hidden_dim=hidden_dim, num_encoder_layers=num_layers, num_decoder_layers=num_layers, augment_eps=backbone_noise, k_neighbors=checkpoint['num_edges'])\n",
        "mpnn_model.to(device)\n",
        "mpnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "mpnn_model.eval()"
      ],
      "metadata": {
        "id": "QBgBJd3J0N_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint['model_state_dict'].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pYLpMQS-ill",
        "outputId": "2364efeb-15d8-4a08-a4ff-930dbc212b0e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['features.embeddings.linear.weight', 'features.embeddings.linear.bias', 'features.edge_embedding.weight', 'features.norm_edges.weight', 'features.norm_edges.bias', 'W_e.weight', 'W_e.bias', 'W_s.weight', 'encoder_layers.0.norm1.weight', 'encoder_layers.0.norm1.bias', 'encoder_layers.0.norm2.weight', 'encoder_layers.0.norm2.bias', 'encoder_layers.0.norm3.weight', 'encoder_layers.0.norm3.bias', 'encoder_layers.0.W1.weight', 'encoder_layers.0.W1.bias', 'encoder_layers.0.W2.weight', 'encoder_layers.0.W2.bias', 'encoder_layers.0.W3.weight', 'encoder_layers.0.W3.bias', 'encoder_layers.0.W11.weight', 'encoder_layers.0.W11.bias', 'encoder_layers.0.W12.weight', 'encoder_layers.0.W12.bias', 'encoder_layers.0.W13.weight', 'encoder_layers.0.W13.bias', 'encoder_layers.0.dense.W_in.weight', 'encoder_layers.0.dense.W_in.bias', 'encoder_layers.0.dense.W_out.weight', 'encoder_layers.0.dense.W_out.bias', 'encoder_layers.1.norm1.weight', 'encoder_layers.1.norm1.bias', 'encoder_layers.1.norm2.weight', 'encoder_layers.1.norm2.bias', 'encoder_layers.1.norm3.weight', 'encoder_layers.1.norm3.bias', 'encoder_layers.1.W1.weight', 'encoder_layers.1.W1.bias', 'encoder_layers.1.W2.weight', 'encoder_layers.1.W2.bias', 'encoder_layers.1.W3.weight', 'encoder_layers.1.W3.bias', 'encoder_layers.1.W11.weight', 'encoder_layers.1.W11.bias', 'encoder_layers.1.W12.weight', 'encoder_layers.1.W12.bias', 'encoder_layers.1.W13.weight', 'encoder_layers.1.W13.bias', 'encoder_layers.1.dense.W_in.weight', 'encoder_layers.1.dense.W_in.bias', 'encoder_layers.1.dense.W_out.weight', 'encoder_layers.1.dense.W_out.bias', 'encoder_layers.2.norm1.weight', 'encoder_layers.2.norm1.bias', 'encoder_layers.2.norm2.weight', 'encoder_layers.2.norm2.bias', 'encoder_layers.2.norm3.weight', 'encoder_layers.2.norm3.bias', 'encoder_layers.2.W1.weight', 'encoder_layers.2.W1.bias', 'encoder_layers.2.W2.weight', 'encoder_layers.2.W2.bias', 'encoder_layers.2.W3.weight', 'encoder_layers.2.W3.bias', 'encoder_layers.2.W11.weight', 'encoder_layers.2.W11.bias', 'encoder_layers.2.W12.weight', 'encoder_layers.2.W12.bias', 'encoder_layers.2.W13.weight', 'encoder_layers.2.W13.bias', 'encoder_layers.2.dense.W_in.weight', 'encoder_layers.2.dense.W_in.bias', 'encoder_layers.2.dense.W_out.weight', 'encoder_layers.2.dense.W_out.bias', 'decoder_layers.0.norm1.weight', 'decoder_layers.0.norm1.bias', 'decoder_layers.0.norm2.weight', 'decoder_layers.0.norm2.bias', 'decoder_layers.0.W1.weight', 'decoder_layers.0.W1.bias', 'decoder_layers.0.W2.weight', 'decoder_layers.0.W2.bias', 'decoder_layers.0.W3.weight', 'decoder_layers.0.W3.bias', 'decoder_layers.0.dense.W_in.weight', 'decoder_layers.0.dense.W_in.bias', 'decoder_layers.0.dense.W_out.weight', 'decoder_layers.0.dense.W_out.bias', 'decoder_layers.1.norm1.weight', 'decoder_layers.1.norm1.bias', 'decoder_layers.1.norm2.weight', 'decoder_layers.1.norm2.bias', 'decoder_layers.1.W1.weight', 'decoder_layers.1.W1.bias', 'decoder_layers.1.W2.weight', 'decoder_layers.1.W2.bias', 'decoder_layers.1.W3.weight', 'decoder_layers.1.W3.bias', 'decoder_layers.1.dense.W_in.weight', 'decoder_layers.1.dense.W_in.bias', 'decoder_layers.1.dense.W_out.weight', 'decoder_layers.1.dense.W_out.bias', 'decoder_layers.2.norm1.weight', 'decoder_layers.2.norm1.bias', 'decoder_layers.2.norm2.weight', 'decoder_layers.2.norm2.bias', 'decoder_layers.2.W1.weight', 'decoder_layers.2.W1.bias', 'decoder_layers.2.W2.weight', 'decoder_layers.2.W2.bias', 'decoder_layers.2.W3.weight', 'decoder_layers.2.W3.bias', 'decoder_layers.2.dense.W_in.weight', 'decoder_layers.2.dense.W_in.bias', 'decoder_layers.2.dense.W_out.weight', 'decoder_layers.2.dense.W_out.bias', 'W_out.weight', 'W_out.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse and create dictionaries for all the mutations in PremPS 2648\n",
        "# This dictionary will be a dictionary of dictionaries, where outer-dict keys will be pdbid+mutchain and inner-dict keys will be (wild+pos+mut) and ddg\n",
        "# the icodes can be brought to picture later\n",
        "# this \"two_level_dict\" is literally used everywhere throughout this code for storing all the numbers that are compared with each other under feature-specific keys\n",
        "git_url = \"https://raw.githubusercontent.com/SajidAhmeduiu/PremPS/main/Datasets/S2648/S2648.txt\"\n",
        "dataset =  pd.read_csv(git_url,delimiter=\"\\t\")\n",
        "\n",
        "pdbIds = list(dataset[\"PDB Id\"])\n",
        "mutChains = list(dataset[\"Mutated Chain\"])\n",
        "mutations = list(dataset[\"Mutation_PDB\"])\n",
        "ddgs = list(dataset[\"DDGexp\"])\n",
        "\n",
        "two_level_dict = {}\n",
        "\n",
        "for pdbId, mutChain, mutation, ddg in tqdm(zip(pdbIds,mutChains,mutations,ddgs)):\n",
        "    pos = [int(s) for s in re.findall('-?\\d+',mutation)][0]\n",
        "    wild = mutation[0]\n",
        "    mut = mutation[len(mutation)-1]\n",
        "\n",
        "    pdbId = pdbId.lower()\n",
        "\n",
        "    inner_dict = {}\n",
        "    inner_dict[\"mut\"] = f\"{wild}{pos}{mut}\"\n",
        "    inner_dict[\"ddg\"] = float(ddg)\n",
        "    outer_key = f\"{pdbId}{mutChain}\"\n",
        "    if outer_key not in two_level_dict:\n",
        "        two_level_dict[f\"{pdbId}{mutChain}\"] = [inner_dict]\n",
        "    else:\n",
        "        two_level_dict[f\"{pdbId}{mutChain}\"].append(inner_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "a5415aac15024b9b9ce2db5f36ba8512",
            "d2d3ea060b084ef19663b313eef56e46",
            "a77c9deea3714115993ba45cd270bf71",
            "6805ef826c98479a9c48914783f37fbd",
            "94f70e2fb21448c6a9460d05e1f911d3",
            "d298ba5b7b6741e8a506a3ac5c9be404",
            "464bbddda64d420e8148bcffd6b09e5e",
            "4407f21b5f29493b9337ae080a08694a",
            "5ca9823303de4c25bdca2ecf581184e6",
            "e1a54995b0904eb2986c060e3ca4e56e",
            "e3ae24221f944646acb6f20b1e4d2373"
          ]
        },
        "id": "vP_unq7_sXrn",
        "outputId": "0d12ccb7-684d-40d3-ad01-f88d18b50813"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5415aac15024b9b9ce2db5f36ba8512"
            },
            "application/json": {
              "n": 0,
              "total": null,
              "elapsed": 0.019635438919067383,
              "ncols": null,
              "nrows": null,
              "prefix": "",
              "ascii": false,
              "unit": "it",
              "unit_scale": false,
              "rate": null,
              "bar_format": null,
              "postfix": null,
              "unit_divisor": 1000,
              "initial": 0,
              "colour": null
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a seqres to position mapping dictionary\n",
        "# This dictionary will be a dictionary of dictionaries, where outer-dict keys will be pdbid+mutchain and inner-dict key will be (wild+pos) and value of 0-indexed position\n",
        "# the icodes can be brought to picture later\n",
        "mapping_dict = {}\n",
        "pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_2648_PDB_Files\"\n",
        "parser = PDBParser(QUIET=True)\n",
        "# some proteins need to be skipped for now due to ICODE related discrapency\n",
        "proteins_to_skip = []\n",
        "\n",
        "for filename in tqdm(os.listdir(pdbDirectory)):\n",
        "    filepath = os.path.join(pdbDirectory,filename)\n",
        "    structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "    model = structure[0]\n",
        "    inner_dict = {}\n",
        "    outer_key = filename.split(\".\")[0]\n",
        "    skip_flag = False\n",
        "    # single chain-assumption in action again\n",
        "    for chain in model:\n",
        "        for i,residue in enumerate(chain):\n",
        "            inner_key = f\"{three_to_one(residue.get_resname())}{residue.get_id()[1]}\"\n",
        "            if inner_key not in inner_dict:\n",
        "                inner_dict[inner_key] = i\n",
        "            else:\n",
        "                # For \"2immA:N31\" and \"1lveA:S27\", I have been fucked\n",
        "                # Need to think whether this will effect other positions or I can just avoid these two-protein related mutations for now?\n",
        "                # Let me just avoid these two proteins for now\n",
        "                print(\"YOU HAVE JUST BEEN FUCKED BY ICODE\")\n",
        "                print(f\"{outer_key}:{inner_key}\")\n",
        "                skip_flag = True\n",
        "    # The ICODE related problematic proteins will not be considered for now\n",
        "    if not skip_flag:\n",
        "        mapping_dict[outer_key] = inner_dict\n",
        "    else:\n",
        "        proteins_to_skip.append(outer_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "ef679cc2c5ca4c1888209195a708a3bf",
            "dd22f37d91b84c039c37968b5ce21107",
            "f96e29f5059844f9b7c541bee7ffc729",
            "ae4ed4b4dc4644408fbb752646018db9",
            "09bc8981202c4c4798000d58685d1b93",
            "96275151c3bb4fc4a9e7c3927d1943cb",
            "c68818a455074c499c7e9803763349df",
            "c4b6cef1488546a6aadd780f04eb128a",
            "beded96e8cf34afdbd2b7902ad59a6b9",
            "364645da5c84405a9adccbb35d3ae76b",
            "fe1d3c35c04743ceb34a0b4d2538a908"
          ]
        },
        "id": "vxARThyX3VYv",
        "outputId": "caed1ea7-269d-45e3-dc0e-1fe7020c9b31"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/131 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef679cc2c5ca4c1888209195a708a3bf"
            },
            "application/json": {
              "n": 0,
              "total": 131,
              "elapsed": 0.018719911575317383,
              "ncols": null,
              "nrows": null,
              "prefix": "",
              "ascii": false,
              "unit": "it",
              "unit_scale": false,
              "rate": null,
              "bar_format": null,
              "postfix": null,
              "unit_divisor": 1000,
              "initial": 0,
              "colour": null
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "1lveA:S27\n",
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "1lveA:S27\n",
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "2immA:N31\n",
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "2immA:N31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing this \"parse_PDB_biounits()\" function locally for addressing the fucked up integer named chain problem  \n",
        "def parse_PDB_biounits(x, atoms=['N', 'CA', 'C'], chain=None):\n",
        "    '''\n",
        "    input:  x = PDB filename\n",
        "            atoms = atoms to extract (optional)\n",
        "    output: (length, atoms, coords=(x,y,z)), sequence\n",
        "    '''\n",
        "    alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "    states = len(alpha_1)\n",
        "    alpha_3 = ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE',\n",
        "               'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL', 'GAP']\n",
        "\n",
        "    # The following dictionaries are mapping from one-letter to 0-20 index,\n",
        "    # three-letter to 0-20 index,\n",
        "    # 0-20 index to one-letter,\n",
        "    # one-letter to three-letter, and vice-versa\n",
        "    aa_1_N = {a: n for n, a in enumerate(alpha_1)}\n",
        "    aa_3_N = {a: n for n, a in enumerate(alpha_3)}\n",
        "    aa_N_1 = {n: a for n, a in enumerate(alpha_1)}\n",
        "    aa_1_3 = {a: b for a, b in zip(alpha_1, alpha_3)}\n",
        "    aa_3_1 = {b: a for a, b in zip(alpha_1, alpha_3)}\n",
        "\n",
        "    def AA_to_N(x):\n",
        "        # [\"ARND\"] -> [[0,1,2,3]]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 0: x = x[None]\n",
        "        return [[aa_1_N.get(a, states - 1) for a in y] for y in x]\n",
        "\n",
        "    def N_to_AA(x):\n",
        "        # [[0,1,2,3]] -> [\"ARND\"]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 1: x = x[None]\n",
        "        return [\"\".join([aa_N_1.get(a, \"-\") for a in y]) for y in x]\n",
        "\n",
        "    xyz, seq, min_resn, max_resn = {}, {}, 1e6, -1e6\n",
        "    for line in open(x, \"rb\"):\n",
        "        line = line.decode(\"utf-8\", \"ignore\").rstrip()\n",
        "\n",
        "        if line[:6] == \"HETATM\" and line[17:17 + 3] == \"MSE\":\n",
        "            line = line.replace(\"HETATM\", \"ATOM  \")\n",
        "            line = line.replace(\"MSE\", \"MET\")\n",
        "\n",
        "        if line[:4] == \"ATOM\":\n",
        "            ch = line[21:22]\n",
        "            # If the input chain is not in the PDB file, which can be the case if the target chains are named differently in the runner script,\n",
        "            # this line will cause the output to have literally no information, this is the case for integer named chains\n",
        "            # that does not mean that this line is not doing its job correctly, this is just a constraint that input chain names and\n",
        "            # chain names in the PDB file have to be congruent\n",
        "            # If \"ch\" is an integer, map it to alphabet, because input \"chain\" has been converted to alphabet\n",
        "            # In rare cases, some PDB files number chains with 1,2,3 instead of A,B,C\n",
        "            # This \"loc_dict\" dictionary contains integer to alphabet mapping for weird as fuck integer chain names\n",
        "            # This conversion will be done only when  chain name is actually an integer\n",
        "            if ord(ch) >= 49 and ord(ch) <= 57:\n",
        "                loc_dict = {(idx+1):ch for idx,ch in enumerate(ascii_uppercase)}\n",
        "                ch =  str(loc_dict[int(ch)])\n",
        "            if ch == chain or chain is None:\n",
        "                atom = line[12:12 + 4].strip()\n",
        "                resi = line[17:17 + 3]\n",
        "                resn = line[22:22 + 5].strip()\n",
        "                x, y, z = [float(line[i:(i + 8)]) for i in [30, 38, 46]]\n",
        "\n",
        "                if resn[-1].isalpha():\n",
        "                    resa, resn = resn[-1], int(resn[:-1]) - 1\n",
        "                else:\n",
        "                    resa, resn = \"\", int(resn) - 1\n",
        "                #         resn = int(resn)\n",
        "                if resn < min_resn:\n",
        "                    min_resn = resn\n",
        "                if resn > max_resn:\n",
        "                    max_resn = resn\n",
        "                if resn not in xyz:\n",
        "                    xyz[resn] = {}\n",
        "                if resa not in xyz[resn]:\n",
        "                    xyz[resn][resa] = {}\n",
        "                if resn not in seq:\n",
        "                    seq[resn] = {}\n",
        "                if resa not in seq[resn]:\n",
        "                    seq[resn][resa] = resi\n",
        "\n",
        "                if atom not in xyz[resn][resa]:\n",
        "                    xyz[resn][resa][atom] = np.array([x, y, z])\n",
        "\n",
        "    # convert to numpy arrays, fill in missing values\n",
        "    seq_, xyz_ = [], []\n",
        "    try:\n",
        "        for resn in range(min_resn, max_resn + 1):\n",
        "            if resn in seq:\n",
        "                for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k], 20))\n",
        "            else:\n",
        "                seq_.append(20)\n",
        "            if resn in xyz:\n",
        "                for k in sorted(xyz[resn]):\n",
        "                    for atom in atoms:\n",
        "                        if atom in xyz[resn][k]:\n",
        "                            xyz_.append(xyz[resn][k][atom])\n",
        "                        else:\n",
        "                            xyz_.append(np.full(3, np.nan))\n",
        "            else:\n",
        "                for atom in atoms: xyz_.append(np.full(3, np.nan))\n",
        "        return np.array(xyz_).reshape(-1, len(atoms), 3), N_to_AA(np.array(seq_))\n",
        "    except TypeError:\n",
        "        return 'no_chain', 'no_chain'\n",
        "\n",
        "# Took this part out of \"utils.py\", and put here so that smalll changes can be made to address pesky issues like\n",
        "# integer named chain, and shit like those\n",
        "def parse_PDB(path_to_pdb, input_chain_list=None):\n",
        "    c=0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V','W','X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v','w','x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "     \n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list  \n",
        " \n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    # Each of the biounits is a separate PDB file, so for running with a single PDB file like from colab, this loop will be executed only once\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {} \n",
        "        # This loop will be executed only once for single chain DDG type cases\n",
        "        for letter in chain_alphabet:\n",
        "            xyz, seq = parse_PDB_biounits(biounit, atoms=['N','CA','C','O'], chain=letter)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_'+letter]=seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                coords_dict_chain['N_chain_'+letter]=xyz[:,0,:].tolist()\n",
        "                coords_dict_chain['CA_chain_'+letter]=xyz[:,1,:].tolist()\n",
        "                coords_dict_chain['C_chain_'+letter]=xyz[:,2,:].tolist()\n",
        "                coords_dict_chain['O_chain_'+letter]=xyz[:,3,:].tolist()\n",
        "                my_dict['coords_chain_'+letter]=coords_dict_chain\n",
        "                s += 1\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        my_dict['name']=biounit[(fi+1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c+=1\n",
        "    return pdb_dict_list"
      ],
      "metadata": {
        "id": "UzBk27pmlfh7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_func_local(X, mask, eps=1E-6):\n",
        "    mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
        "    dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
        "    D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
        "    D_max, _ = torch.max(D, -1, keepdim=True)\n",
        "    D_adjust = D + (1. - mask_2D) * D_max\n",
        "    top_k = checkpoint[\"num_edges\"]\n",
        "    sampled_top_k = top_k\n",
        "    D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(top_k, X.shape[1]), dim=-1, largest=False)\n",
        "    return D_neighbors, E_idx\n",
        "\n",
        "def return_neighbor_info(X, mask):\n",
        "    b = X[:,:,1,:] - X[:,:,0,:]\n",
        "    c = X[:,:,2,:] - X[:,:,1,:]\n",
        "    a = torch.cross(b, c, dim=-1)\n",
        "    Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "    Ca = X[:,:,1,:]\n",
        "    N = X[:,:,0,:]\n",
        "    C = X[:,:,2,:]\n",
        "    O = X[:,:,3,:]\n",
        "\n",
        "    D_neighbors, E_idx = distance_func_local(Ca, mask)\n",
        "    # Got the indices of the neighbors, E_idx should be the 0-based indexing of the topK closest neighbors\n",
        "    # and D_neighbors should be the distances of those neighbors\n",
        "    return D_neighbors, E_idx"
      ],
      "metadata": {
        "id": "l6pA80oESa7Y"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "from scipy.special import kl_div"
      ],
      "metadata": {
        "id": "5mFg99eN_UqM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the PDB files from the directory where the S_2648 PDB Files are stored, and set-them up one by one for featuirization, and passing through the model\n",
        "pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_2648_PDB_Files\"\n",
        "parser = PDBParser(QUIET=True)\n",
        "\n",
        "pdbId_info = []\n",
        "pos_info = []\n",
        "neighbor_pos = []\n",
        "neighbor_attention = []\n",
        "neighbor_attention_softmaxed = []\n",
        "neighbor_distances_tracking = []\n",
        "\n",
        "import time\n",
        "\n",
        "np.set_printoptions(suppress=True,precision=2)\n",
        "loc_proteins = []\n",
        "for i,filename in tqdm(enumerate(os.listdir(pdbDirectory))):\n",
        "    #ICODE related problematic proteins will be skipped from analysis for now\n",
        "    if (filename.split(\".\")[0] not in proteins_to_skip):\n",
        "        prot_start = time.time()\n",
        "        print(f\"Prot Processing:{i+1}\")\n",
        "        loc_proteins.append(filename.split(\".\")[0])\n",
        "        filepath = os.path.join(pdbDirectory,filename)\n",
        "        structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "        model = structure[0]\n",
        "        \n",
        "        # Since there is only one chain, and that same chain is both fixed designable for different residues, extracting that name, and putting them in pertinent lists\n",
        "        # taking chainname from filename since one of the files \"1rtpA.pdb\" has chain name with \"1\" instead of \"A\"\n",
        "        # fuck you motherfucking fucked up PDB file submitter. Have you shoved your head into your ass?\n",
        "        chain_name = (filename.split(\".\")[0])[-1]\n",
        "        fixed_chain_list = []\n",
        "        # the trick is to put the single chain as designable chain, and then create the \"fixed_positions_dict\" dictionary  \n",
        "        designed_chain_list = [chain_name]\n",
        "        chain_list = list(set(designed_chain_list + fixed_chain_list))\n",
        "\n",
        "        # Using the programs custome PDB parser for processing the PDB files\n",
        "        pdb_dict_list = parse_PDB(filepath, input_chain_list=chain_list)\n",
        "        # tacking max_length parameter value from the original colab notebook since I need to process all residues at the same time\n",
        "        # all the PDB files can technically be processed together and put inside the dataset_valid list-like object, but right now\n",
        "        # I am trying to keep everything consistent and simple\n",
        "        # Each element of dataset_valid is a dictionary \n",
        "        dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=20000)\n",
        "\n",
        "        # Simplying the sequence generation loop\n",
        "        protein = dataset_valid[0]\n",
        "\n",
        "        wildtype_seq = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        # If there are gaps in the wildtype_seq \"seq\", remove those positions from both the \"seq\", \"\" and ('coords_chain_{designed_chain_list[0]}'), \n",
        "        # and ('seq_chain_{designed_chain_list[0]}') of the \"protein\"\n",
        "        # print(protein.keys())\n",
        "        # protein is a dict with keys(['seq_chain_A', 'coords_chain_A', 'name', 'num_of_chains', 'seq'])\n",
        "        # \"seq_chain\" and \"seq_all\" are both strings of the same length where gapped positions need to be identified and removed\n",
        "        seq_chain = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "        seq_all = protein[f\"seq\"]\n",
        "        # \"coordinates_chain\" is a dict with keys(['N_chain_A', 'CA_chain_A', 'C_chain_A', 'O_chain_A'])\n",
        "        coordinates_chain = protein[f\"coords_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        \n",
        "        # The following four variables are lists of length equal to seq_chain and seq_all length\n",
        "        # Therefore, the gapped positions can be retrived from seq_chain and removed from everything accordingly\n",
        "        N_chain = coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"]\n",
        "        CA_chain = coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"]\n",
        "        C_chain = coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"]\n",
        "        O_chain = coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        # delete everything related to gapped positions now\n",
        "        # at first, find out the positions that are gapped\n",
        "        # these gapped positions are absolutely messed up fucked up artifact of some kind of sophistification \n",
        "        # provided by proteinMPNN, FUCK YOU motherfucking oversmart CODERS\n",
        "        N_chain = [v for i,v in enumerate(N_chain) if seq_chain[i] != \"-\"]\n",
        "        CA_chain = [v for i,v in enumerate(CA_chain) if seq_chain[i] != \"-\"]\n",
        "        C_chain = [v for i,v in enumerate(C_chain) if seq_chain[i] != \"-\"]\n",
        "        O_chain = [v for i,v in enumerate(O_chain) if seq_chain[i] != \"-\"]\n",
        "        seq_all = [v for i,v in enumerate(seq_all) if seq_chain[i] != \"-\"]\n",
        "        seq_chain = [v for i,v in enumerate(seq_chain) if seq_chain[i] != \"-\"]\n",
        "\n",
        "        # Now, finally, pack everything back to the dictionary \"protein\"\n",
        "        protein[f\"seq_chain_{designed_chain_list[0]}\"] = seq_chain\n",
        "        protein[f\"seq\"] = seq_all\n",
        "        coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"] = N_chain\n",
        "        coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"] = CA_chain\n",
        "        coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"] = C_chain\n",
        "        coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"] = O_chain\n",
        "        protein[f\"coords_chain_{designed_chain_list[0]}\"] = coordinates_chain\n",
        "\n",
        "        # At this point, probably need to put None values in a lot of parameters that are not relevant to my usecase, but need to be sent to featurizer before running model forward\n",
        "        # For now, I will not tie positions together\n",
        "        tied_positions_dict = None\n",
        "        pssm_dict = None\n",
        "        omit_AA_dict = None\n",
        "        bias_AA_dict = None\n",
        "        tied_positions_dict = None\n",
        "        bias_by_res_dict = None\n",
        "        alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "        bias_AAs_np = np.zeros(len(alphabet))\n",
        "\n",
        "        chain_id_dict = {}\n",
        "        chain_id_dict[pdb_dict_list[0]['name']]= (designed_chain_list, fixed_chain_list)\n",
        "\n",
        "        BATCH_COPIES = 1\n",
        "\n",
        "        batch_clones = [copy.deepcopy(protein) for i in range(BATCH_COPIES)]\n",
        "\n",
        "        # \"muts_for_prot\" is a list with information about all the mutations in \"protein\", whose sequence only version is \"wildtype_seq\" \n",
        "        muts_for_prot = two_level_dict[filename.split(\".\")[0]]\n",
        "        # \"cur_map_dict\" will give the 0-based sequence index for the mutations, which will be almost directly used for masking and then running the model\n",
        "        # 1-based indexing needed for the fixed position\n",
        "        cur_map_dict = mapping_dict[filename.split(\".\")[0]]\n",
        "\n",
        "        for mut_track,mut in enumerate(muts_for_prot):\n",
        "            print(f\"Processing_Mut:{mut_track+1}, From_Prot:{i+1}\")\n",
        "            wild_aa = mut[\"mut\"][0]\n",
        "            alternate_aa = mut[\"mut\"][-1]\n",
        "            # (+1) because we need to pass 1-based indexing to tied_featurize() method\n",
        "            seq_pos = cur_map_dict[mut[\"mut\"][0:-1]] + 1\n",
        "            # only need to mask the mutated position position in \"wildtype_seq\" for now\n",
        "            fixed_positions_dict = {}\n",
        "            fixed_positions_dict[protein[\"name\"]] = {}\n",
        "            f_list = []\n",
        "            for ind_fixed in range(0,len(seq_chain)):\n",
        "                if (ind_fixed + 1) not in [seq_pos]:\n",
        "                    f_list.append(ind_fixed + 1)\n",
        "            fixed_positions_dict[protein[\"name\"]][filename.split(\".\")[0][-1]] = f_list\n",
        "\n",
        "            # finally, had to take chain-name from filename instead of biopython parsing to get rid of chain-name with \"1\" instead of \"A\" in \"1rtpA.pdb\"\n",
        "            X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "            omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "            = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "            randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "            log_probs, decoder_messages, node_embedding_info = mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "            # Adding the log_probs to the same inner dictionary where DDG values exist for easier comparison\n",
        "            mut[\"log_prob\"] = log_probs.cpu().data.numpy()\n",
        "            \n",
        "            # the top_k attention weights will be stored here for weighted sum later\n",
        "            # \"seq_pos\" is 1-based since \"fixed_positions_dict\" above needs to hold 1-based indices for the mutation,\n",
        "            # but accessing the tensors will require 0-based indexing\n",
        "            seq_index = seq_pos - 1\n",
        "            # \"dim = 1\", because decoder_messages[0,seq_index,:,:] should be (48,128), and we want to take norm of each of the 48 vectors across the last dimension,\n",
        "            # get 48 norm values, and fetch out the k highest values from there\n",
        "            message_norms = (torch.linalg.vector_norm(x=decoder_messages[0,seq_index,:,:],ord=2,dim=1))\n",
        "            local_distances, local_neighbors = return_neighbor_info(X, mask)\n",
        "            # \"top_k_attended_neighbor_indices\" is the indices from [0,47] corresponding to the highest attended neighbors\n",
        "            # top_(k-1) can technically be extracted from top_k, but currently just for simplicity and easier debugging, extracting everything separately\n",
        "            top_15_attention_vals, top_15_attended_neighbor_indices = torch.topk(message_norms,k=15)\n",
        "            top_10_attention_vals, top_10_attended_neighbor_indices = torch.topk(message_norms,k=10)\n",
        "            top_5_attention_vals, top_5_attended_neighbor_indices = torch.topk(message_norms,k=5)\n",
        "            # now, using \"local_neighbors\" to get the original indices of the neighbors corresponding to the top_k attended positions\n",
        "            # taking both top_5 and top_10 for now\n",
        "            top_15_attended_neighbor_indices = local_neighbors[0,seq_index,top_15_attended_neighbor_indices]\n",
        "            top_10_attended_neighbor_indices = local_neighbors[0,seq_index,top_10_attended_neighbor_indices]\n",
        "            top_5_attended_neighbor_indices = local_neighbors[0,seq_index,top_5_attended_neighbor_indices]\n",
        "            top_15_closest_neighbor_indices = local_neighbors[0,seq_index,1:16]\n",
        "            top_10_closest_neighbor_indices = local_neighbors[0,seq_index,1:11]\n",
        "            mut[\"top_15_attention_weights\"] = top_15_attention_vals.cpu().data.numpy()\n",
        "            mut[\"top_10_attention_weights\"] = top_10_attention_vals.cpu().data.numpy()\n",
        "            mut[\"top_5_attention_weights\"] = top_5_attention_vals.cpu().data.numpy()\n",
        "            # the neighbor indices corresponding to the top_k attention weights will be stored here for entropy calculation later\n",
        "            # 0-based indices of the neighbors will be saved so that corresponding log-probability vectors can be extracted readily from \"log_prob\" keyed value\n",
        "            mut[\"top_15_neighbor_indices\"] = top_15_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_10_neighbor_indices\"] = top_10_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_5_neighbor_indices\"] = top_5_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_15_closest_neighbor_indices\"] = top_15_closest_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_10_closest_neighbor_indices\"] = top_10_closest_neighbor_indices.cpu().data.numpy()\n",
        "\n",
        "            # The lines below are mostly for printing purposes to do external analysis with PyMol,and ROSETTA with Cristina\n",
        "            loc_pos_scores = []\n",
        "            for enum_val,(neighbor_p, neighbor_s, neighbor_distance) in enumerate(zip(local_neighbors[0,seq_index,1:15].cpu().data.numpy(),\n",
        "                                                                 (torch.linalg.vector_norm(x=decoder_messages[0,seq_index,1:15,:],ord=2,dim=1)).cpu().data.numpy(),\n",
        "                  \n",
        "                                                               local_distances[0,seq_index,1:15].cpu().data.numpy())):\n",
        "                # skippoing the first neighbor since it is the mutated position itself\n",
        "                if enum_val == 0:\n",
        "                    continue\n",
        "                pdbId_info.append(filename)\n",
        "                pos_info.append(seq_index+1)\n",
        "                neighbor_pos.append(neighbor_p+1)\n",
        "                neighbor_attention.append(neighbor_s)\n",
        "                loc_pos_scores.append(neighbor_s)\n",
        "                neighbor_distances_tracking.append(neighbor_distance)\n",
        "            # since softmax has to be done over all the neighbors, taking the softmax, and later adding it to the data generation list after\n",
        "            # neighbor enumeration loop\n",
        "            loc_pos_scores = softmax(np.array(loc_pos_scores))\n",
        "            for s in loc_pos_scores:\n",
        "                neighbor_attention_softmaxed.append(s)\n",
        "\n",
        "            # take (\"neighbor_attention\"-weighted sum/average) of the entropies of the top 5 attended neighbors\n",
        "            # are the neighbors with highest message passing values always among the closest 10?\n",
        "            # point to be noted that the closest, therefore the first neighbor of every position is the neighbor itself\n",
        "            # check correlation between distance and attention values since a possible manual edge feature would be distance\n",
        "            # let us see if the model attends to distant neighbors more, or attention value is inversely proportional to distance?\n",
        "            # take L2-norms of the message vectors instead of attention\n",
        "            # take the softmax of L2-norms to approximate attention, although technically the positions are not constrained by each other, this can be considered a sigmoid attention\n",
        "            # where having neighbors with large messages will effect differently than having neighbors with small messages\n",
        "            # can this be correlated with position-entropy?\n",
        "            # the L2-norms should be able to approximate how much each of the neighbors are effecting the mutated position\n",
        "            # This information can be stored for checking the effect of center mutation on those positions afterwards\n",
        "            # Identify major interacting partners (neighbors that are important for center prediction, and also which take center into consideration for its own prediction)\n",
        "            # then check how much the major neighbor position deviates from wildtype due to the mutation\n",
        "            # another much more simples thing can be to check the deviation for top 10 neighbors\n",
        "            # this deviation can be calculated using the log(W) for the neighbor before center mutation, and log(W) for the neighbor after center mutation \n",
        "\n",
        "            # Now, take top_k most attended positions, make them designable, mutate center, and take change in -log(p) of the wildtype at each of the neighbor positions\n",
        "            # take weighted sum of these neighbor energy changes, see if there is any correlation\n",
        "            # next, go for \"strong\" neighbor positions (both way strong attention)\n",
        "            # Many of the tensors will take on new values after running the model again with different fixed positions\n",
        "            \n",
        "            # the \"fixed_positions_dict\" has to be repopulated now since neighbor positions will be masked one by one\n",
        "            # here, \"n_ind\" is the 0-based index corresponding to one of the \"top_k\" attended neighbors \n",
        "            # these lists will contain the log_probabilities for the top_k most attended neighbors serially\n",
        "            # before and after making the center mutation currently at hand, these probabilities will be used later for calculating\n",
        "            # attention_weighted change in neighbor_wildtype probability, attention_weighted_change in KL, and all those things \n",
        "            neighbor_w_log_probs = []\n",
        "            neighbor_m_log_probs = []\n",
        "            # the following array will contain the identities of the neighbors serially so that specific wildtype neighbor positions in the probability\n",
        "            # distribution can be extracted later\n",
        "            neighbor_aa_identities = []\n",
        "            # \"top5\" and \"top10\" should be extractable from \"top15\", since the neighbor\n",
        "            neighbor_w_message_vector_coming_from_center = []\n",
        "            neighbor_m_message_vector_coming_from_center = []\n",
        "            # I will pick out the neighbor embeddings, and put them inside the lists below\n",
        "            # But, do I need to access them one by one, or can I just take a slice out of the embedding tensor across the seq_pos dimension?\n",
        "            # what more information will I get if I fetch out the embeddings one by one?\n",
        "            # if I want to do a slicing, I might have to make all the neighbors designable at the same time, which will \n",
        "            # for one, I can take out the embeddings for each of the neighbors while they are designable, before and \n",
        "            # okay, lets say we will fetch the neighbors out, one by one; we can do that right inside the next loop\n",
        "            # what will be the significance of those neighbor embeddings, in that case?\n",
        "            # they will see everything around them, expcept the mutated position, will they change much due to that?\n",
        "            # neighbor embedding difference in that case might actually catch something about the new interactions that have\n",
        "            # been formed, interesting...very, very interesting\n",
        "            neighbor_w_embedding_info = []\n",
        "            neighbor_m_embedding_info = [] \n",
        "            # informations are stored serially in the lists\n",
        "            for n_ind in mut[\"top_15_neighbor_indices\"]:\n",
        "                neighbor_aa_identities.append(seq_chain[n_ind])\n",
        "                # Some sequence-input manipulation is done later in this loop, so the wildtype aa is placed in the position, so that\n",
        "                # previous iteration manipulations do not cause trouble in this iteration\n",
        "                alpha_tok = \"ACDEFGHIKLMNPQRSTVWYX\"\n",
        "                aa_1_N = {a:n for n,a in enumerate(alpha_tok)}\n",
        "                aa_N_1 = {n:a for n,a in enumerate(alpha_tok)}\n",
        "\n",
        "                # adding (+1) to n_ind, since fixed positions are 1-indexed in the original implementation\n",
        "                n_pos = n_ind + 1  \n",
        "                fixed_positions_dict = {}\n",
        "                fixed_positions_dict[protein[\"name\"]] = {}\n",
        "                f_list = []\n",
        "                for ind_fixed in range(0,len(seq_chain)):\n",
        "                    # Fixing everything except the \"n_pos\" neighbor position\n",
        "                    if (ind_fixed + 1) not in [n_pos]:\n",
        "                        f_list.append(ind_fixed + 1)\n",
        "                fixed_positions_dict[protein[\"name\"]][filename.split(\".\")[0][-1]] = f_list\n",
        "\n",
        "                # Extracting \"n_ind\" 21-way log probabilities when the center is wildtype \n",
        "                X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "                omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "                = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "                randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "\n",
        "                # we want to store the 128-length message vector coming from the center to the neighbor at \"n_ind\"\n",
        "                # for this, at first, we need to find which neighbor of \"n_ind\" is our center so that we can pull out the message vector coming from \n",
        "                # the center to the neighbor at \"n_ind\" \n",
        "                loc_local_distances, loc_local_neighbors = return_neighbor_info(X, mask)\n",
        "                # \"neighbor_neighbor_index\" is the index of the center with respect to the neighbor at \"n_ind\"\n",
        "                # if len(neighbor_neighbor_index) is 0, center is not among the spatially close 48 neighbors of the neighbor at \"n_ind\"\n",
        "                # in that case, message vector passed from center to that neighbor can be considered as a 128 length all 0 vector for now\n",
        "                # for now, it is important to note that if len(neighbor_neighbor_index) is not zero, then the index can be retrived by neighbor_neighbor_index[0][0]  \n",
        "                neighbor_neighbor_index = (loc_local_neighbors[0,n_ind,:] == seq_index).nonzero(as_tuple=False)\n",
        "                neighbor_neighbor_index =  neighbor_neighbor_index[0][0] if (len(neighbor_neighbor_index) == 1) else torch.tensor(-1,device=neighbor_neighbor_index.device)\n",
        "\n",
        "                # calling \"mpnn_model\" \"forward\" function three times below for getting the three tensors is definitely not efficient,\n",
        "                # but, doing it this way for now, since I am getting CUDA out-of-memory errors due to some unsolved (for now) reason   \n",
        "                n_log_probs  = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[0][0,n_ind,:].cpu().data.numpy()\n",
        "                decoder_message = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[1][0,n_ind,neighbor_neighbor_index,:].cpu().data.numpy()\n",
        "                node_embedding_info = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[2][0,n_ind,:].cpu().data.numpy()\n",
        "\n",
        "                neighbor_w_log_probs.append(n_log_probs)\n",
        "                neighbor_w_embedding_info.append(node_embedding_info)\n",
        "\n",
        "                if neighbor_neighbor_index >= 0:\n",
        "                    neighbor_w_message_vector_coming_from_center.append(decoder_message)\n",
        "                else:\n",
        "                    # Adding all-0 vector of length 128 if the center is not among the closest 48 neighbors of center\n",
        "                    neighbor_w_message_vector_coming_from_center.append(np.zeros(128)) \n",
        "                 \n",
        "                # Now, make mutation, and process the corresponding probabilities\n",
        "                X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "                omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "                = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "                randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "                # seems like passing mutant sequence through the model will be a bit more difficult that expected since PDB file is read in by the underlying parser\n",
        "                # How, do I only change the amino acids identity in the sequence, but keep the PDB backbone and everything same?\n",
        "                # At first, just try to manipulate the input \"S\"\n",
        "                S[0,seq_index] = aa_1_N[alternate_aa]\n",
        "                n_log_probs  = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[0][0,n_ind,:].cpu().data.numpy()\n",
        "                decoder_message = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[1][0,n_ind,neighbor_neighbor_index,:].cpu().data.numpy()\n",
        "                node_embedding_info = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[2][0,n_ind,:].cpu().data.numpy()\n",
        "\n",
        "                neighbor_m_log_probs.append(n_log_probs)\n",
        "                neighbor_m_embedding_info.append(node_embedding_info)\n",
        "\n",
        "                if neighbor_neighbor_index >= 0:\n",
        "                    neighbor_m_message_vector_coming_from_center.append(decoder_message)\n",
        "                else:\n",
        "                    # Adding all-0 vector of length 128 if the center is not among the closest 48 neighbors of center\n",
        "                    neighbor_m_message_vector_coming_from_center.append(np.zeros(128))           \n",
        "            mut[\"w_n_log_prob\"] = neighbor_w_log_probs\n",
        "            mut[\"m_n_log_prob\"] = neighbor_m_log_probs\n",
        "            mut[\"neighbor_aa_identities\"] = neighbor_aa_identities\n",
        "            mut[\"neighbor_w_message_vector_coming_from_center\"] = neighbor_w_message_vector_coming_from_center\n",
        "            mut[\"neighbor_m_message_vector_coming_from_center\"] = neighbor_m_message_vector_coming_from_center\n",
        "            mut[\"neighbor_w_neighbor_embedding\"] = neighbor_w_embedding_info\n",
        "            mut[\"neighbor_m_neighbor_embedding\"] = neighbor_m_embedding_info\n",
        "        prot_end = time.time()\n",
        "        print(f\"Took {prot_end-prot_start} for {filename} with {mut_track+1} forward-mutations\")\n",
        "        print(\"....................\")"
      ],
      "metadata": {
        "id": "b8cEsTK1EQ9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the incomplete \"two_level_dict\" as pickle file for a quick dirty comparison\n",
        "# import pickle\n",
        "# with open(\"S_2648_pmppn_info_dict_V2.pickle\",\"wb\") as f:\n",
        "#     pickle.dump(two_level_dict,f)"
      ],
      "metadata": {
        "id": "rXvc5PDmIQyF"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# with open(\"S_2648_pmppn_info_dict_V2.pickle\",\"rb\") as f:\n",
        "#     two_level_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "T8iPDaqrZg4U"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import entropy\n",
        "from scipy.special import expit\n",
        "alpha_list = list(\"ACDEFGHIKLMNPQRSTVWYX\")\n",
        "# The following dictionary will be used for fetching out the log-probabilities corresponding to the wild-type and mutated residues at the mutation positions\n",
        "aa_to_N = {a:n for n,a in enumerate(alpha_list)}\n",
        "# This list will contain the experimental ddg values for the mutations for which two-level dict contains information regarding log_probabilities\n",
        "true_vals = []\n",
        "# This list will contain (wild_proba,mut_proba) tuples for the mutations for which two-level dict contains information regarding log_probabilities\n",
        "wild_mut_log_probabilities = []\n",
        "# saving max probabilites for debugging\n",
        "max_log_probabilities = []\n",
        "# Want to add entropy of the position with some kind of weight (maybe, just a for loop for checking weight combinations that sum to 1?)\n",
        "position_entropies = []\n",
        "weighted_neighbor_entropies = []\n",
        "# This \"weighted_neighbor_energy_changes\" will be ((-log(m))-(-log(w))) for each of the topk neighbors, weighted summed by corresponding attention weights   \n",
        "weighted_neighbor_energy_changes = []\n",
        "#\n",
        "backward_weighted_neighbor_energy_changes = []\n",
        "V2_backward_weighted_neighbor_energy_changes = []\n",
        "# the neighbor-forward-KL will at this point treat the center-wildtype conditioned neighbor distributions as true, \n",
        "# and center-mutated conditioned neighbor distributions as approximation\n",
        "weighted_neighbor_forward_KL = []\n",
        "# the neighbor-backward-KL will treat the center-mutated conditioned neighbor distributions as true, \n",
        "# and center-wildtype conditioned neighbor distributions as approximation\n",
        "weighted_neighbor_backward_KL = []\n",
        "#\n",
        "backward_weighted_neighbor_backward_KL = []\n",
        "V2_backward_weighted_neighbor_backward_KL = []  \n",
        "# # This \"weighted_neighbor_entropy_changes\" will be ((entropy(p(nieghbor|m))-(entropy(p(nieghbor|w))) for each of the topk neighbors, weighted summed by corresponding attention weights \n",
        "weighted_neighbor_entropy_changes = []\n",
        "## the weights will now be based on change in center->neighbor message vector L2-norm due to mutation, instead of neighbor->center message norm \n",
        "## however, I think a softmaxing across all those weights will now be a must since scales could be crazily different\n",
        "backward_weighted_neighbor_entropy_changes = []\n",
        "V2_backward_weighted_neighbor_entropy_changes = []\n",
        "# the two arrays below are being saved for checking correlations of (m/w) and (w/m) attention weight changes to ddgs\n",
        "# this debugging-type correlation analysis could reveal significant insights into the best weighing mechanism, and even provide a way to differentiate\n",
        "# between neighbors that have established new connections with the center, and neighbors whose connections with the center has been severed (kinda severed,maybe or weakened?..whatever)  \n",
        "center_neighbor_weight_check_m_w = []\n",
        "center_neighbor_weight_check_w_m = []\n",
        "\n",
        "sum_neighbor_embedding_change_m_w = []\n",
        "# putting the dictionary here since we are going to need positions corresponding to alternate amino acid 1-letter codes\n",
        "alpha_tok = \"ACDEFGHIKLMNPQRSTVWYX\"\n",
        "aa_1_N = {a:n for n,a in enumerate(alpha_tok)}\n",
        "for i,(prot,muts) in enumerate(two_level_dict.items()):\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for ind_track, mut in enumerate(muts):\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            # where the fuck is \"log_prob\" coming from, but \"top_5_attention_weights\" and \"top_5_neighbor_indices\" are not there?\n",
        "            if (\"log_prob\" in mut) and (\"w_n_log_prob\" in mut):\n",
        "                wild = mut[\"mut\"][0] \n",
        "                alternate = mut[\"mut\"][-1]\n",
        "                true_vals.append(mut[\"ddg\"])\n",
        "                sequence_index_of_mutation = cur_map_dict[mut[\"mut\"][0:-1]]\n",
        "                position_log_probabilities = mut[\"log_prob\"][0,sequence_index_of_mutation,:]\n",
        "                wild_mut_log_probabilities.append((position_log_probabilities[aa_to_N[wild]],position_log_probabilities[aa_to_N[alternate]]))\n",
        "                max_log_probabilities.append(position_log_probabilities.max())\n",
        "                position_entropies.append(entropy(np.exp(position_log_probabilities)))\n",
        "                # These 0-based neighbor indices will be used for extracting the log-probabilities corresponding to the neighbor positions\n",
        "                n_indices= mut[\"top_15_neighbor_indices\"]\n",
        "                # The neighbor weights will be used here for multiplying \n",
        "                n_weights = mut[\"top_15_attention_weights\"].reshape(-1,1)\n",
        "                # Take entropy while taking care of the dimension along which entropy is calculated\n",
        "                # Taking entropy across last axis, because the shape of the input is (k,21), where 21 is the 21-way probability distribution \n",
        "                n_entropies = entropy(np.exp(mut[\"log_prob\"][0,n_indices,:]),axis=-1).reshape(-1,1)\n",
        "                # I think this element-wise product is getting wrong \n",
        "                weighted_neighbor_entropies.append((n_entropies*softmax(n_weights)).sum())\n",
        "                # weighted_neighbor_entropies.append((n_entropies*softmax(n_weights)).sum())\n",
        "                # weighted_neighbor_entropies.append((n_entropies*n_weights).sum())\n",
        "\n",
        "                # Now, calculate neighbor energy changes, and then weighted sum them after extracting specific log_probabilities\n",
        "                # for mutant center, and wildtype center impacted versions for the top neighbor positions\n",
        "                neighbor_w_log_probabilities = mut[\"w_n_log_prob\"]\n",
        "                neighbor_m_log_probabilities = mut[\"m_n_log_prob\"]\n",
        "                neighbor_amino_a_identities = mut[\"neighbor_aa_identities\"]\n",
        "                neighbor_w_message_vector_coming_from_center = mut[\"neighbor_w_message_vector_coming_from_center\"]\n",
        "                neighbor_m_message_vector_coming_from_center = mut[\"neighbor_m_message_vector_coming_from_center\"]\n",
        "                neighbor_w_neighbor_embedding = mut[\"neighbor_w_neighbor_embedding\"]\n",
        "                neighbor_m_neighbor_embedding = mut[\"neighbor_m_neighbor_embedding\"]\n",
        "                # The \"local_neighbor_log_prob_vals\" will be a list of negative log-probability differences(a.k.a. energy differences)\n",
        "                local_neighbor_log_prob_vals = []\n",
        "                local_neighbor_forward_KL_vals = []\n",
        "                local_neighbor_backward_KL_vals = []\n",
        "                local_neighbor_entropy_change_vals = []\n",
        "                local_neighbor_attention_change_vals = []\n",
        "                # the two lists below are for debugging, and insight-revelation purposes, mostly\n",
        "                local_center_neighbor_weight_check_m_w = []\n",
        "                local_center_neighbor_weight_check_w_m = []\n",
        "                # the neighbor_embedding change features is being added below\n",
        "                local_neighbor_embedding_changes = []\n",
        "                # For example, selecting the numbers from the first 5 iterations of this loop will give neighbor energy change corresponding to the first 5 neighbors\n",
        "                for neighbor_w, neighbor_m, neighbor_aa, neighbor_w_message, neighbor_m_message, neighbor_w_embedding, neighbor_m_embedding  in \\\n",
        "                zip(neighbor_w_log_probabilities,neighbor_m_log_probabilities,neighbor_amino_a_identities,neighbor_w_message_vector_coming_from_center,neighbor_m_message_vector_coming_from_center,\n",
        "                    neighbor_w_neighbor_embedding,neighbor_m_neighbor_embedding):\n",
        "                    # get the amino acid identity for the neighbor position, run it through the mapping dictionary, get the log probabilities from those positions,\n",
        "                    # \"neighbor_w\" and \"neighbor_m\" arrays will directly give the log probabilities that need to be substracted to get the energy (put (-1) before thoese numbers?...think a bit)\n",
        "                    neighbor_index = aa_1_N[neighbor_aa]\n",
        "                    local_neighbor_log_prob_vals.append((-1*neighbor_m[neighbor_index])-(-1*neighbor_w[neighbor_index]))\n",
        "                    # summing the output of \"kl_div\", because one number comes for every positions in the currently processing neighbor distribution,\n",
        "                    # and I want to take the total deviation in that distribution \n",
        "                    local_neighbor_forward_KL_vals.append(kl_div(np.exp(neighbor_w),np.exp(neighbor_m)).sum())\n",
        "                    local_neighbor_backward_KL_vals.append(kl_div(np.exp(neighbor_m),np.exp(neighbor_w)).sum())\n",
        "                    local_neighbor_entropy_change_vals.append(entropy(np.exp(neighbor_m))-entropy(np.exp(neighbor_w)))\n",
        "                    # lets just put the absolute value of the difference between the L2-norms for now (taking sign into consideration will require\n",
        "                    # taking care of the correct direction of change, which might make things a bit ncomplicated for now, and have unintended effects)\n",
        "                    # But, having a direction can definitely help with stabilization vs. de-stabilization figuring out\n",
        "                    # some kind of \n",
        "                    # usiung only the norm would more like predict the magnitude of DDG\n",
        "                    # local_neighbor_attention_change_vals.append()\n",
        "                    neighbor_w_message = neighbor_w_message.reshape((-1,1))\n",
        "                    neighbor_m_message = neighbor_m_message.reshape((-1,1))\n",
        "                    # Adding the small numbers for numerical stability, which hopefully will not change the information content of these features\n",
        "                    neighbor_w_message_norm = np.linalg.norm(neighbor_w_message,ord=2,axis=0) + 0.00000001\n",
        "                    neighbor_m_message_norm = np.linalg.norm(neighbor_m_message,ord=2,axis=0) + 0.00000001\n",
        "                    # taking average of two ratios for kind of capturing the change in both (mutant->wild) and (wild->mutant) directions with the same measure \n",
        "                    # the ratio should help to avoid any neighbor to neighbor variability related-scale\n",
        "                    # but scale could also be important, right? since, the same transformation is applied for calculating the numbers for every position in the proteins \n",
        "                    # local_neighbor_attention_change_vals.append((0.5*(neighbor_w_message_norm/neighbor_m_message_norm))+(0.5*(neighbor_m_message_norm/neighbor_w_message_norm)))\n",
        "                    local_neighbor_attention_change_vals.append((neighbor_w_message_norm/neighbor_m_message_norm))\n",
        "                    # the two list-appending lines below are mostly for debugging purposes at the moment,\n",
        "                    # might be something more than that in a few minutes?\n",
        "                    local_center_neighbor_weight_check_m_w.append(neighbor_m_message_norm/neighbor_w_message_norm)\n",
        "                    local_center_neighbor_weight_check_w_m.append(neighbor_w_message_norm/neighbor_m_message_norm)\n",
        "                    # can take PCA of the below as well\n",
        "                    # currently, taking the norm of division vector (-1 to discourage (+1) from contributing to the norm)\n",
        "                    local_neighbor_embedding_changes.append(np.linalg.norm((neighbor_m_embedding[15:20]/neighbor_w_embedding[15:20])-1))\n",
        "                # The energy change approximation can be constrained to the top few neighbors by just indexing the arrays below\n",
        "                # So, it looks like a better idea to save log_probs for atleast the top_20 neighbors since we can always fetch the first few from there\n",
        "                weighted_neighbor_energy_changes.append((np.array(local_neighbor_log_prob_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_forward_KL.append((np.array(local_neighbor_forward_KL_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_backward_KL.append((np.array(local_neighbor_backward_KL_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_entropy_changes.append((np.array(local_neighbor_entropy_change_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                # versions of neighbor features, just weighted by backward weights (center->neighbor attention change due to mutation) instead of forward weights (neighbor->center attention)\n",
        "                # sum() of these (m/w) weight-change is apparently positively correlated with DDGs\n",
        "                backward_weighted_neighbor_energy_changes.append((np.array(local_neighbor_log_prob_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_m_w))[0:15])).sum())\n",
        "                backward_weighted_neighbor_backward_KL.append((np.array(local_neighbor_backward_KL_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_m_w))[0:15])).sum())\n",
        "                backward_weighted_neighbor_entropy_changes.append(((np.array(local_neighbor_entropy_change_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_m_w)))[0:15]).sum()))\n",
        "                # the two list-appending lines below are mostly for debugging purposes at the moment,\n",
        "                # might be something more than that in a few minutes?\n",
        "                center_neighbor_weight_check_m_w.append(np.array(local_center_neighbor_weight_check_m_w).sum())\n",
        "                center_neighbor_weight_check_w_m.append(np.array(local_center_neighbor_weight_check_w_m).sum())\n",
        "                # dividing by 128, because the norm comes from 128 neighbors\n",
        "                sum_neighbor_embedding_change_m_w.append((np.array(local_neighbor_embedding_changes)*expit(n_weights[0:15])).mean())\n",
        "                # weighted_sum_neighbor_embedding_change_m_w.append((np.array(local_neighbor_embedding_changes).sum())/128)\n",
        "                # now, let us add features weighted by the other version of attention changes\n",
        "                # sum() of these (w/m) weight-change is apparently negatievly correlated with DDGs\n",
        "                V2_backward_weighted_neighbor_energy_changes.append((np.array(local_neighbor_log_prob_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_w_m))[0:15])).sum())\n",
        "                V2_backward_weighted_neighbor_backward_KL.append((np.array(local_neighbor_backward_KL_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_w_m))[0:15])).sum())\n",
        "                V2_backward_weighted_neighbor_entropy_changes.append(((np.array(local_neighbor_entropy_change_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_w_m)))[0:15]).sum()))\n",
        "\n",
        "\n",
        "                # let us also save the features in the \"mut\" dictionary, so that \"two_letter_dict\" containing all the features for every mutation\n",
        "                # can be saved after this cell in pickle format, and later be accessed from any other script\n",
        "                # print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "                # print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "                # energies (negative log probabilities of the most_probable,wild,and mutated residue, respectively, at the center position)\n",
        "                e_max = (-1*(max_log_probabilities[-1]))\n",
        "                e_wild = (-1*((wild_mut_log_probabilities[-1])[0]))\n",
        "                e_mut = (-1*((wild_mut_log_probabilities[-1])[1]))\n",
        "                mut[\"center_mut_wild_energy\"] = e_mut - e_wild \n",
        "                mut[\"center_mut_max_energy\"] = e_mut - e_max\n",
        "                mut[\"center_entropy\"] = (position_entropies[-1] * (-1))\n",
        "                mut[\"weighted_neighbor_entropies\"] = weighted_neighbor_entropies[-1] \n",
        "                mut[\"weighted_neighbor_energy_changes\"] = weighted_neighbor_energy_changes[-1]\n",
        "                mut[\"backward_weighted_neighbor_energy_changes\"] = backward_weighted_neighbor_energy_changes[-1]\n",
        "                mut[\"V2_backward_weighted_neighbor_energy_changes\"] = V2_backward_weighted_neighbor_energy_changes[-1]\n",
        "                mut[\"weighted_neighbor_forward_KL\"] = weighted_neighbor_forward_KL[-1] \n",
        "                mut[\"weighted_neighbor_backward_KL\"] = weighted_neighbor_backward_KL[-1]\n",
        "                mut[\"backward_weighted_neighbor_backward_KL\"] = backward_weighted_neighbor_backward_KL[-1]\n",
        "                mut[\"V2_backward_weighted_neighbor_backward_KL\"] = V2_backward_weighted_neighbor_backward_KL[-1]  \n",
        "                mut[\"weighted_neighbor_entropy_changes\"] = weighted_neighbor_entropy_changes[-1]\n",
        "                mut[\"backward_weighted_neighbor_entropy_changes\"] = backward_weighted_neighbor_entropy_changes[-1]\n",
        "                mut[\"V2_backward_weighted_neighbor_entropy_changes\"] = V2_backward_weighted_neighbor_entropy_changes[-1]  \n",
        "                mut[\"center_neighbor_weight_check_m_w\"] = center_neighbor_weight_check_m_w[-1]\n",
        "                mut[\"center_neighbor_weight_check_w_m\"] = center_neighbor_weight_check_w_m[-1]\n",
        "                mut[\"sum_neighbor_embedding_change_m_w\"] = sum_neighbor_embedding_change_m_w[-1]\n",
        "                # print(mut[\"center_neighbor_weight_check_w_m\"])\n",
        "                # print(mut[\"neighbor_embedding_change_m_w\"])\n",
        "                # print(mut[\"ddg\"])\n",
        "                # print(\"....................\")"
      ],
      "metadata": {
        "id": "7m4jsITsJHmE"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "TwMx2ZMs60Pz"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experimental_energies = []\n",
        "mut_wild_predictions = []\n",
        "mut_min_predictions = []\n",
        "entropy_predictions = []\n",
        "neighbor_entropy_predictions = []\n",
        "neighbor_energy_change_predictions = []\n",
        "backward_weighted_neighbor_energy_changes = []\n",
        "V2_backward_weighted_neighbor_energy_changes = []\n",
        "center_neighbor_weight_check_w_m = []\n",
        "V2_backward_weighted_neighbor_backward_KL = []\n",
        "sum_neighbor_embedding_change_m_w = []\n",
        "\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        for mut in muts:\n",
        "            if \"center_mut_wild_energy\" in mut:\n",
        "                experimental_energies.append(mut[\"ddg\"])\n",
        "                mut_wild_predictions.append(mut[\"center_mut_wild_energy\"])\n",
        "                mut_min_predictions.append(mut[\"center_mut_max_energy\"])\n",
        "                entropy_predictions.append(mut[\"center_entropy\"])\n",
        "                neighbor_entropy_predictions.append(mut[\"V2_backward_weighted_neighbor_entropy_changes\"])\n",
        "                neighbor_energy_change_predictions.append(mut[\"weighted_neighbor_energy_changes\"])\n",
        "                backward_weighted_neighbor_energy_changes.append(mut[\"backward_weighted_neighbor_energy_changes\"])\n",
        "                V2_backward_weighted_neighbor_energy_changes.append(mut[\"V2_backward_weighted_neighbor_energy_changes\"])\n",
        "                center_neighbor_weight_check_w_m.append(mut[\"center_neighbor_weight_check_w_m\"])\n",
        "                V2_backward_weighted_neighbor_backward_KL.append(mut[\"V2_backward_weighted_neighbor_backward_KL\"])\n",
        "                sum_neighbor_embedding_change_m_w.append(mut[\"sum_neighbor_embedding_change_m_w\"])\n",
        "\n",
        "print(len(experimental_energies),len(mut_wild_predictions))\n",
        "\n",
        "print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "print(pearsonr(experimental_energies,entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_energy_change_predictions))\n",
        "print(pearsonr(experimental_energies,backward_weighted_neighbor_energy_changes))\n",
        "print(pearsonr(experimental_energies,V2_backward_weighted_neighbor_energy_changes))\n",
        "print(pearsonr(experimental_energies,center_neighbor_weight_check_w_m))\n",
        "print(pearsonr(experimental_energies,V2_backward_weighted_neighbor_backward_KL))\n",
        "print(pearsonr(experimental_energies,sum_neighbor_embedding_change_m_w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StvbASTsfta0",
        "outputId": "6aec1978-f4d3-4c15-edb7-5e6de1459a40"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2620 2620\n",
            "(0.5049684488471481, 1.4027058079310365e-169)\n",
            "(0.47039449312864723, 2.2111342555144222e-144)\n",
            "(0.3519475616882619, 2.947105748280627e-77)\n",
            "(0.3050125687548716, 1.564797082165145e-57)\n",
            "(0.2841900584324013, 7.301627242651772e-50)\n",
            "(0.28701744947179203, 7.235780646022193e-51)\n",
            "(0.28046965924246936, 1.468245039265636e-48)\n",
            "(-0.15591934694856951, 1.005365458421583e-15)\n",
            "(0.24401695016852246, 7.995063835673139e-37)\n",
            "(-0.004696046712171694, 0.8101301264044068)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let me get PSSM values and do some comparison quickly\n",
        "# getting the PSSM extraction functions from my custom model data processing scripts\n",
        "from string import ascii_uppercase\n",
        "\n",
        "# In rare cases, some PDB files number chains with 1,2,3 instead of A,B,C\n",
        "def convertChainFromAlphabetToNumber(alphabet):\n",
        "    mappingDict = {ch:(idx+1) for idx,ch in enumerate(ascii_uppercase)}\n",
        "    return str(mappingDict[alphabet])\n",
        "\n",
        "# Before executing this function, the PSSM files with naming format \"pdbIdchain.pssm\" needs to be stored\n",
        "# in the pssm_dir\n",
        "def returnPSSMArray(pdbIdPlusChain,pssm_dir=\"train_pssm_dir\",convert_upper = False):\n",
        "#     Currently, assuming that the pssm file names contain pdbId in upper case\n",
        "    if convert_upper:\n",
        "        fileName = pdbIdPlusChain.upper() + \".pssm\"\n",
        "    else:\n",
        "        fileName = pdbIdPlusChain + \".pssm\"\n",
        "    try:\n",
        "        fullPath = os.path.join(pssm_dir,fileName)\n",
        "        f = open(fullPath)\n",
        "    except:\n",
        "        fileName = pdbIdPlusChain[0:4].upper() + str(convertChainFromAlphabetToNumber(pdbIdPlusChain[4])) + \".pssm\" \n",
        "        fullPath = os.path.join(pssm_dir,fileName)\n",
        "        f = open(fullPath)\n",
        "        \n",
        "# #     all the target lines in the PSSM files have (2+20+20+2=44) strings after line.split()\n",
        "    target_lines = [line.split() for line in f.readlines() if (len(line.split()))==44]\n",
        "    number_of_residues = len(target_lines)\n",
        "    \n",
        "    pssm_features = np.zeros((number_of_residues,20))\n",
        "\n",
        "    for idx,line in enumerate(target_lines):\n",
        "        pssm_features[idx,:] = line[2:22]\n",
        "\n",
        "    f.close()\n",
        "    \n",
        "    return pssm_features\n",
        "\n",
        "# This function also seems necessary for extracting the two pssm values\n",
        "# Must review the three pssm feature functions (this one and the two above) later\n",
        "# These functions seem to be taking up a lot of time....must review\n",
        "def returnPSSMMapping(residue):\n",
        "    pssm_letter_to_index_dict = {\"A\" : 0,   \n",
        "    \"R\" : 1,\n",
        "    \"N\" : 2,\n",
        "    \"D\" : 3,\n",
        "    \"C\" : 4,\n",
        "    \"Q\" : 5,\n",
        "    \"E\" : 6,\n",
        "    \"G\" : 7,\n",
        "    \"H\" : 8,\n",
        "    \"I\" : 9,\n",
        "    \"L\" : 10,\n",
        "    \"K\" : 11,\n",
        "    \"M\" : 12,\n",
        "    \"F\" : 13,\n",
        "    \"P\" : 14,\n",
        "    \"S\" : 15,\n",
        "    \"T\" : 16,\n",
        "    \"W\" : 17,\n",
        "    \"Y\" : 18,\n",
        "    \"V\" : 19}\n",
        "\n",
        "    return pssm_letter_to_index_dict[residue]\n",
        "\n",
        "\n",
        "# I will add PSSM values to the two-level dictionary for places where log_prob is available\n",
        "pssmDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_2648_pssm_dir\"\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                wild = mut[\"mut\"][0] \n",
        "                alternate = mut[\"mut\"][-1]\n",
        "                sequence_index_of_mutation = cur_map_dict[mut[\"mut\"][0:-1]]\n",
        "                pdbId = prot[0:-1]\n",
        "                mutChain = prot[-1]\n",
        "                pssm_array = returnPSSMArray(pdbId + mutChain,pssm_dir=pssmDirectory,convert_upper = False)\n",
        "                position_pssm = pssm_array[sequence_index_of_mutation]\n",
        "                wild_pssm = position_pssm[returnPSSMMapping(wild)] \n",
        "                alternate_pssm = position_pssm[returnPSSMMapping(alternate)]\n",
        "                mut[\"wild_pssm\"] = wild_pssm\n",
        "                mut[\"alternate_pssm\"] = alternate_pssm"
      ],
      "metadata": {
        "id": "eBgpxQx4ispc"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pssm_predictions = []\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                pssm_predictions.append((mut[\"wild_pssm\"]-mut[\"alternate_pssm\"]))"
      ],
      "metadata": {
        "id": "xOkQhEQzn32m"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experimental_energies = []\n",
        "mut_wild_predictions = []\n",
        "mut_min_predictions = []\n",
        "entropy_predictions = []\n",
        "neighbor_entropy_predictions = []\n",
        "neighbor_energy_change_predictions = []\n",
        "backward_weighted_neighbor_energy_changes = []\n",
        "V2_backward_weighted_neighbor_energy_changes = []\n",
        "center_neighbor_weight_check_w_m = []\n",
        "V2_backward_weighted_neighbor_backward_KL = []\n",
        "pssm_predictions = np.array(pssm_predictions)\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        for mut in muts:\n",
        "            if \"center_mut_wild_energy\" in mut:\n",
        "                experimental_energies.append(mut[\"ddg\"])\n",
        "                mut_wild_predictions.append(mut[\"center_mut_wild_energy\"])\n",
        "                mut_min_predictions.append(mut[\"center_mut_max_energy\"])\n",
        "                entropy_predictions.append(mut[\"center_entropy\"])\n",
        "                neighbor_entropy_predictions.append(mut[\"V2_backward_weighted_neighbor_entropy_changes\"])\n",
        "                neighbor_energy_change_predictions.append(mut[\"weighted_neighbor_energy_changes\"])\n",
        "                backward_weighted_neighbor_energy_changes.append(mut[\"backward_weighted_neighbor_energy_changes\"])\n",
        "                V2_backward_weighted_neighbor_energy_changes.append(mut[\"V2_backward_weighted_neighbor_energy_changes\"])\n",
        "                center_neighbor_weight_check_w_m.append(mut[\"center_neighbor_weight_check_w_m\"])\n",
        "                V2_backward_weighted_neighbor_backward_KL.append(mut[\"V2_backward_weighted_neighbor_backward_KL\"])\n",
        "\n",
        "print(len(experimental_energies),len(mut_wild_predictions))\n",
        "\n",
        "print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "print(pearsonr(experimental_energies,entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_energy_change_predictions))\n",
        "print(pearsonr(experimental_energies,backward_weighted_neighbor_energy_changes))\n",
        "print(pearsonr(experimental_energies,V2_backward_weighted_neighbor_energy_changes))\n",
        "print(pearsonr(experimental_energies,center_neighbor_weight_check_w_m))\n",
        "print(pearsonr(experimental_energies,V2_backward_weighted_neighbor_backward_KL))\n",
        "print(pearsonr(experimental_energies,pssm_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tyw_4erpj1C",
        "outputId": "b27e99aa-c3cb-47f6-8f9e-3264f7401e36"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2620 2620\n",
            "(0.5049684488471481, 1.4027058079310365e-169)\n",
            "(0.47039449312864723, 2.2111342555144222e-144)\n",
            "(0.3519475616882619, 2.947105748280627e-77)\n",
            "(0.3050125687548716, 1.564797082165145e-57)\n",
            "(0.2841900584324013, 7.301627242651772e-50)\n",
            "(0.28701744947179203, 7.235780646022193e-51)\n",
            "(0.28046965924246936, 1.468245039265636e-48)\n",
            "(-0.15591934694856951, 1.005365458421583e-15)\n",
            "(0.24401695016852246, 7.995063835673139e-37)\n",
            "(0.2752044285125163, 9.492115203744281e-47)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now combine \"mut_wild_predictions\" and \"pssm_predictions\" using weight combinations from 0 to 1 in 0.05 increments so that they some to one\n",
        "# so, when one weight is x, the other weight is automatically (1-x)\n",
        "# The keys of this dictionary will be (term1_coeff,term2_coeff) tuples, and values will be the observed correlations \n",
        "coefficient_result_dictionary = {}\n",
        "for i in np.arange(0.0,1.000001,0.005):\n",
        "    term1_coeff = round(i,2)\n",
        "    term2_coeff = round((1.000001 - i),2)\n",
        "    local_preds = (term1_coeff*neighbor_energy_change_predictions) + (term2_coeff*neighbor_backward_KL_predictions)\n",
        "    coefficient_result_dictionary[(term1_coeff,term2_coeff)] = round(pearsonr(experimental_energies,local_preds)[0],2) "
      ],
      "metadata": {
        "id": "nP6x7ym_10QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefficient_result_dictionary"
      ],
      "metadata": {
        "id": "fQ6lfx3VunPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "df_Ssym = pd.DataFrame(\n",
        "    {'P_DP': mut_wild_predictions,\n",
        "     'P_ET': entropy_predictions,\n",
        "     'P_DEC': pssm_predictions,\n",
        "     'Neighbor_Entropy' : neighbor_entropy_predictions,\n",
        "     'Neighbor_Energy_Change' : neighbor_energy_change_predictions,\n",
        "     'Backward_Weighted_Neighbor_Energy_Change' : backward_weighted_neighbor_energy_changes,\n",
        "     'V2_Backward_Weighted_Neighbor_Energy_Change' : V2_backward_weighted_neighbor_energy_changes,\n",
        "     'Neighbor_forward_KL' : neighbor_forward_KL_predictions,\n",
        "     'Neighbor_backward_KL' : neighbor_backward_KL_predictions,\n",
        "     'Backward_Weighted_Neighbor_backward_KL' : backward_weighted_neighbor_backward_KL,\n",
        "     'V2_Backward_Weighted_Neighbor_backward_KL' : V2_backward_weighted_neighbor_backward_KL,\n",
        "     'Neighbor_Entropy_Change' : neighbor_entropy_change_predictions,\n",
        "     'Backward_Weighted_Neighbor_Entropy_Change' : backward_weighted_neighbor_entropy_changes,\n",
        "     'V2_Backward_Weighted_Neighbor_Entropy_Change' : V2_backward_weighted_neighbor_entropy_changes,\n",
        "     'neighbor_attention_change_m/w' : center_neighbor_weight_check_m_w,\n",
        "     'neighbor_attention_change_w/m' : center_neighbor_weight_check_w_m\n",
        "    })\n",
        "corr = df_Ssym.corr()\n",
        "\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(corr, \n",
        "        xticklabels=corr.columns,\n",
        "        yticklabels=corr.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "QlQuGW7f7KDy",
        "outputId": "5ec51726-2650-4a87-f08d-f498d5668124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1f195abb10>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwQAAAKECAYAAAC5PP2OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd1gU1/oH8C+9g1RBjWJdFZYqooCCIKLYMYolSLMDFtQgGkuCCiFGUbCAFaxEYone2GK8GI1iAhhLvGL0aoQoCkiXvr8/+O1chl1gl1ms7+d55nnYKWfOHAZ2zpz3nCMnEAgEIIQQQgghhHyU5N92BgghhBBCCCFvD1UICCGEEEII+YhRhYAQQgghhJCPGFUICCGEEEII+YhRhYAQQgghhJCPGFUICCGEEEII+YhRhYAQQgghhBApPHnyBKtWrcLYsWPRt29fjBo1SuJjT5w4geHDh4PP52PkyJH48ccfRfaprq7Gt99+CycnJ1haWuKzzz7DvXv3ZHkJLFQhIIQQQgghRAoPHjxAamoqunTpgu7du0t83NmzZxEWFgZ3d3fs3LkTAwcORGhoKFJTU1n7RUZG4uDBg5g/fz62bdsGJSUl+Pn5ITc3V9aXAgCQo4nJCCGEEEIIkVxdXR3k5evfqy9btgx37tzB6dOnWzxuxIgR6NWrFzZv3sysCwgIQHFxMVJSUgAAubm5GDJkCFasWIFp06YBAEpLS+Hm5oYJEybg888/l/n1UAsBIYQQQgghUhBWBqTx9OlTPHr0CCNHjmStHzVqFG7fvo2CggIAwJUrV1BbWwtPT09mH01NTQwZMgSXL1/mlvEmUIWAEEIIIYSQNvbo0SMAEAkx6tGjB2v7w4cPYWBgAF1dXZH9Hj9+jLq6OpnnTVHmKRJCCHkjYmNjERcXx3zW1dUFj8dDSEgI+vXrJ9XxcnJy0NDQQIcOHWBnZ4dp06aJfGn5+Pjgxo0bzP7GxsawtbVFaGgoOnbsKMMrI4SQN6+4uBjFxcUi67W1taGtrc05/aKiIia9hnR0dFjbi4uLoaWlJXK8jo4OqqurUV5eDk1NTc75aYgqBIQQ8h5TVVVFYmIigPq4023btsHPzw/Hjh1Dr169pDq+rKwMWVlZSE5OxnfffYd169Zh7NixrP1tbGwQFhaGuro63L9/HzExMbh16xZ++OEHqKmpSZTn6rxHUl4lW1X8Gk7HA8Czg9w65mkaVHLOQ2meCuc05GTQzl9bK8fp+OevRB9cpKWtwr08lRVrOR1fVqHMOQ+9J1RzTkMmariVRe6/ub+BHpdfxDmNO7nXOachzf+bxMP/Yr1kEQoODkZISAjnvLzLqEJACCHvMXl5eVhZWTGf+Xw+XF1dceTIEaxatUrq4x0dHTF16lTMmjULK1asgI2NDT755BNmu7a2NrO/jY0N1NTUEBYWhtTUVAwfPlyGV0YIITJQJ3nlyNfXF+PHjxdZL4vWAeB/LQHFxcUwNDRk1gtbBoTbtbW1UVJSInJ8UVERlJSUoK6uLpP8NER9CAgh5APSoUMH6OnpITs7u9VpqKioYOXKlaiursbRo0eb3ZfP5wMAp/MRQkibEdRJvGhra6NTp04ii6wqBN26dQPwv74CQg8fPmRt7969O/Lz81FYWCiyn6mpaas6NLeEKgSEEPIBKS0tRWFhIYyMjDil06NHD7Rv3x6ZmZnN7iesCHA9HyGEtIm6OsmXNvbJJ5+gW7duIhORnT59Gnw+H3p6egAAJycnyMvL48yZM8w+ZWVl+PnnnzF48OA2yRuFDBFCyHuupqYGQH0fgq+//hq1tbXw8PDgnK6JiQny8vJY6wQCAWpqalBXV4esrCxER0dDW1sbDg4OnM9HCCGyJhC0zYP+69evmcnEcnJyUFpairNnzwKobznt2LEjli9fjhMnTuDPP/9kjps/fz4WLVqEzp07w8HBARcvXsTVq1cRHx/P7NO+fXtMnjwZGzZsgKKiIjp06IA9e/YAqA9ragtUISCEkPdYeXk5zMzMmM/a2tpYtWoVBg0axDltgUAAOTl2h9PU1FTW+UxNTREbGwsDAwPO5yOEEJlrozf/+fn5WLBgAWud8HNkZCS8vLxQV1eH2lp2H4YRI0agoqICO3bswO7du9G5c2d8++23cHZ2Zu0XHh4OdXV1xMTEoKSkBHw+H3v37kX79u3b5HqoQkAIIe8xVVVVHDhwAHJyctDV1YWJiYnM4kufP38OU1NT1jpbW1uEh4dDQUEB7du3h76+vkzORQghbaK2bUZ+6tSpE+7fv9/sPlFRUYiKihJZP378eLGdlxtSUlLCkiVLsGTJEk75lBRVCAgh5D0mLy/PdOyVpQcPHiA3N1fkS0tLS6tNzkcIIW2ijUKGPjRUISCEEMJSWVmJiIgIKCsrY+LEiW87O4QQ0npvoLPwh4AqBIQQ8hGrq6vDzZs3AdT3RxBOTPb06VNERUWhU6dObzmHhBDSem3VqfhDQxUCQgj5iFVUVMDb2xtycnJQV1dHx44dMXDgQMTFxaF79+5vO3uEEMINtRBIRE4gEAjediYIIYR8PKrzHrW8UzOq4tdwzsOzg7mcjtc0qOSch9I8Fc5pyMmg/3htrVzLOzXj+SstznnQVuFensqKks9IK05ZhTLnPPSe0DYdWKVWw60scv/N/SF6XH4R5zTu5F7nnEZl1hWJ91Xp5cT5fO8raiEghBBCCCEfpjYaZehDQxUCQgh5j8XGxiIuLo75rKurCx6Ph3nz5sHW1rbJ4xQVFcUe39DMmTPRrVs3hIeHt5iPixcvStzfgOsbfuXZ3I4HgFuxX3A6fthY7m+0b+1R4pyGHLg38leDWwuBLB4kFCq5v52vqOb2VruiVoFzHh6e5PZmHgAUFbi/na+o4tb6pK7C/SG6o7Iu5zRkgkKGJEIVAkIIec+pqqoiMTERQP1sxdu2bcP06dObPabhA3zD4xtq3749VFRUkJyczKz797//je3bt2PXrl3Q0vpfqIiRkZEsLoUQQmSLOhVLhCoEhBDynpOXl4eVlRXzmc/nw9XVFR4eHpgxY4bYYxo+wDc+vjE9PT3m50eP6uP/zczMWOsJIeSdRC0EEqEKASGEfGA6dOgAPT09vH79miYRI4R81AQC7mFcHwOqEBBCyAemtLQUhYWFUoXx1NTUiKxTUFCAnBy3+HJCCHmrakX/txFRVCEghJAPgPCBPjc3F19//TVqa2vh4eEh0bHl5eUwMzMTWb9jxw4MGTJEpvkkhJA3ivoQSIQqBIQQ8p5r/ECvra2NVatWYdCgQRIdr6qqigMHDoisNzU1lVUWCSHk7aijkCFJUIWAEELec8IHejk5Oejq6sLExATy8pLPWCUvL099DQghHyZqIZAIVQgIIeQ9Rw/0hBDSBBplSCJUISCEEEIIIR8maiGQCFUICCHkI1dXV4ebN2+KrNfV1UWXLl3eQo4IIURGxIygRkRRhYAQQj5yFRUV8Pb2Flnv6emJTZs2vYUcEUKIbNA8BJKhCgEhhLzHQkJCEBIS8saO9/LygpeXV6vPRwghbxT1IZAIVQgIIeQdERsbi7i4OOazrq4ueDweQkJC0K9fP6mOl5OTg4aGBjp06AA7OztMmzYN3bt3Z+3v4+ODGzduiE1r586dGDx4MPP5+fPniI+Px+XLl5GbmwsVFRX07dsXY8eOxfjx46GgoNCaSyaEkLZFfQgkQhUCQgh5h6iqqiIxMRFA/SRj27Ztg5+fH44dO4ZevXpJdXxJSQnu37+PlJQUfPfdd4iIiMDo0aNZ+9vY2CAsLEwknYaVhzt37iAwMBCamprw8/NDr169UFFRgWvXrmHdunVo164dhg4dKvE1PjuYK/G+4tyK/YLT8QAw+s5aTscf46/knIdKRe6zQMviUUfyAWrFM5JBjHahQIlzGjV13MpTEQLOeaioeDcqxlzvizyBJuc8jOJ6Y8kKtRBIhCoEhBDyDpGXl4eVlRXzmc/nw9XVFUeOHMGqVaukOt7V1RU5OTnMtmXLlmHZsmXMZ0tLS+jq6rLO11hVVRXmz58PfX19HDlyBNra2sw2Z2dnfPbZZygtLZXqGgkh5I2hFgKJUIWAEELeYR06dICenh6ys7OlPnb79u2oqqoCADx9+hSLFi3C+PHjMW3aNABAVFRUi2mcPXsWOTk52Lp1K6syINSpUyep80UIIW9MLY0yJAmqEBBCyDustLQUhYWFMDIykvpYHo/H/Mzn8xEVFYWcnBxmEjN5eXkIBALUiAn5UFSs/3pIS0uDgoICnJycWnkFhBDyFrVhyNDjx48RERGBjIwMqKioYOTIkViyZAnU1NSaPCY7Oxtubm5Nbv/ll1+Y//eNW3mFrl27Bj09Pe4X0ABVCAgh5B0jfEDPzc3F119/jdraWnh4eHBO18TEBHl5eax1qampMDMzE9k3IyMDGhoayM3NhZ6eHlRVVTmfnxBC3rg2qhAUFxdj+vTp6NChAzZv3oyCggJERkaioKCg2eGajYyMkJycLLI+NDQUOjo6Ii9/PDw8EBAQwFonrrWWK6oQEELIO6S8vJz1gK6trY1Vq1Zh0KBBnNMWCASQk2N3vLS1tUV4eLjIvs294SKEkPdGG/UhOHLkCIqLi3HixAnmbb2CggKWLFmCefPmoWfPnmKPU1ZWFum39fDhQ+Tk5MDHx0dkfwMDg2b7eckKVQgIIeQdoqqqigMHDkBOTg66urowMTGBvLxshut4/vw5TE1NWeu0tLSYECJx2rdvj2vXrqGyshIqKioyyQchhLwxbdRCcPnyZQwYMIAVuuPh4YHly5fj8uXLTVYIxPnhhx+goKCAkSNHtkVWJfKuDApFCCEE9XH9fD4f5ubm6Nixo8wqAw8ePEBubi6sra2lOm7AgAGoqanB1atXZZIPQgh5o2prJF+k8PDhQ/To0YO1TllZGZ07d8ajR48kTkcgEODUqVMYMGCA2L5ip06dAp/Ph5WVFQIDA3H37l2p8ikpaiEghJAPXGVlJSIiIqCsrIyJEydKdayHhwc2bdqEjRs3ws7ODlpaWqzt//zzD0pKSlgdmAkh5J0hRchQcXExiouLRdZra2uLxO0XFxeLjeXX1tZGUVGRxOdMT09HTk4O5s+fL7LN1dUVFhYW6NChA3JycpCQkIBp06YhJSVFpDLCFVUICCHkA1JXV4ebN28CqO+PkJWVheTkZDx9+hRRUVEiw4QWFxcz+zf0ySefQF9fH8rKytiyZQsCAwPh5eUFX19fZmKytLQ0HD58GNHR0VQhIIS8m6QIGUpMTGTNFi8UHByMkJAQWeaK8cMPP0BNTQ3u7u4i27744n+TMPbr1w+DBw/GiBEjkJCQgOjoaJnmgyoEhBDyAamoqIC3tzfk5OSgrq6Ojh07YuDAgYiLi2PNPiyUkZEBb29vkfVr1qzBlClTAADm5uY4ceIEEhISsGfPHrx48QIqKiro27cvvvjiC7i6urb5dRFCSKtIUSHw9fXF+PHjRdY31RIgrjWhuLgY3bp1k+h8VVVVOHfuHNzc3KChodHi/rq6uhgwYECbhA1RhYAQQt4RISEhnN5CSXv8/v37Jd7XxMQEq1evbk22CCHk7REIJN5VXGhQU7p3746HDx+y1lVVVeHvv/+Gl5eXRGlcvnwZhYWFGDNmjMR5bCvUqZgQQgghhHyY6uokX6QwePBgXL9+Ha9evWLWXbhwAVVVVXB2dpYojR9++AH6+vpwdHSUaP+CggJcu3at2ZHhWotaCAghEouNjUVcXBysra1x5MgRkW179uxBZmamVOlJewwAHDt2DOHh4S3O1rhs2TLcuXMHp0+flip9WUpLS8P06dPFbrO0tMR3330nUTq1tbUQCATYunUrHBwcREYLEs4s/D7QNKjkdPywsdyOB4Bj/JWcjve6HcE5DzutV3FOQxZv9aQbW0WUthz3XKjLYKx4VY5pVEKu5Z1a8K68ZeVamup1kr9Vb8pRBck71jZFJlH7Uo4eJKnJkyfjwIEDmDdvHubNm4f8/HxERUXB09OT1eF3+fLlOHHiBP7880/W8SUlJfj3v/+NSZMmif3/ffr0aVy6dAmDBw9G+/btkZOTg507d6KqqgozZ86U+fW8P98ghJB3RmZmJq5evSrxW42mTJw4UeI3Ke+7yMhIkbhSSWJGhdzd3Zkp7Ldt2yay/eLFiyIdhgkh5KPXRvMQaGtrIzExEWvXrkVISAhUVFQwcuRILF26tNHp61BbWyty/Llz51BZWdlkuFCnTp3w4sULREVFobi4GJqamujfvz+2bNkitj8YV1QhIIRIRV1dHT179kRcXBznCoGxsTGMjY1llLM3T5rJunr27MmpmXf79u2oqqrCp59+Ch8fH4wdO5a1vfH41RUVFVBVVW31+Qgh5IMgRR8CaXXt2hW7d+9udp+oqChERUWJrP/000/x6aefNnmclZWVVP28uHpXWrcIIe+RoKAgZGRk4Nq1a03uU1VVhZiYGLi6usLc3BweHh5ITk5m7RMbGysS+vLXX3/Bx8cHFhYWcHV1RXJyMpYtW4ZRo0aJnCM3NxezZ8+GlZUVhg4dioMHD4rNyy+//ILRo0eDz+fDy8tLJESprq4OO3bsgJubG8zNzeHu7o59+/aJzeudO3cwZcoUWFhYYNeuXc0Vk1R8fHwwe/ZsnD9/HiNGjICVlRWmTJmCrKwsAACPx2O+PPbv3898mZSXl4PP54PP5yMhIQGbNm2Ck5MTbG1tAdRXWr7++msMGjQI5ubmGDVqFE6ePMk6t7B8myuntWvXwsXFBXWN3rZlZGSAx+MhIyNDZmVBCCEy00Z9CD401EJACJGas7Mz+Hw+4uLiMHDgQLH7hIaGIi0tDUFBQejVqxeuX7+ONWvWQENDQ+zDPVD/Vtvf3x8aGhqIioqCoqIitm/fjlevXkFTU1Nk/8WLFzNj4586dQpfffUVevfuzTwMA8DLly+xevVqhISEQEtLCwkJCQgMDMSFCxegr68PAIiOjkZiYiJmzZoFOzs7XLt2DVFRUSgrK0NQUBCTVnV1NRYuXIjp06dj4cKFYvPUlLq6OtTUsGNZ5eXlWTMR37t3Dzt27MCCBQugqKiI6OhohISE4MyZM5CXl0dycjK8vb3h4+PDlGHDWNWkpCSYm5sjIiIC1dXVAIAlS5YgNTUVCxYsQK9evXD27Fl8/vnnEAgEGDdunMTl5O3tjf379+Pq1asYNGgQc1xKSgq6d+8OGxsbicuCEELemI/8QV9SVCEghLRKcHAwZs+ejevXr2PAgAGsbWlpabhw4QISEhKYPgIODg4oLCzE5s2bm6wQfP/998jLy8PBgwfRuXNnAICNjQ2GDBki9uF76tSp+OyzzwAAdnZ2uHTpEs6ePcuqEBQWFiImJoapuNjZ2cHFxQX79u3D4sWLUVBQgAMHDsDf3x+LFi0CADg5OaGsrAy7du2Cn58fE+tfXV2NBQsWYPTo0VKX16RJk0TWBQQEICwsjPlcXFyMY8eOwcDAgFkXFBSE+/fvo0+fPrCysgJQPwSo8OeGtLS0sG3bNqaS8Z///Afnz5/HqlWrMG3aNADAoEGD8OLFC2zZsoVVIWipnHr27Alra2ukpKQwFYKysjKcOXOmzSbsIYQQrgRi4veJKAoZIoS0iouLC8zMzLB161aRbVevXoWOjg4cHR1RU1PDLA4ODvj7779RWFgoNs07d+6gV69eTGUAAAwMDJp8++zk5MT8rKSkBFNTU+Tm5rL20dLSYrVi6OjowN7eHn/88QcA4NatW6iuroanpyfrOE9PT5SXl+PevXus9a2dhOvrr79GSkoKa/H19WXt07t3b1ZlQNhx7Pnz5xKdw8XFhdXikJ6ezlxLQ56ensjJycGzZ8+YdS2VEwB4e3vj4sWLzDB7P/74I6qrq1kVC0IIeadQyJBEqIWAENJqwcHBmDt3Ln777TfW+oKCAhQVFcHMzEzscc+ePUO7du1E1r948ULsMKL6+vrIz88XWd94AhklJSVUVrKHpBSXnoGBAfOwXFRUPzSeoaGhyDkBsCovampqUo0M1FD37t1b7FSso6PD+qykpAQAItfUFGGehYqKiqCoqAhdXV2x+xUVFcHExARAy+UEACNGjMD69etx8uRJ+Pn54ejRo3B1dW126FdCCHmrZDCk7ceAKgSEkFZzdXWFmZkZ4uLi0K9fP2a9jo4OdHV1sXPnTrHHmZqail1vZGQkMlYzALGVAUkVFBSIrMvLy2MqAMKKSV5eHtq3by9yzoYVFzk57uOUt6XG+dPR0UFNTQ0KCwtZ1yG8toYVkJbKCQBUVVUxZswYfP/993B0dMQff/zB6mNBCCHvHBnMqfAxoJAhQggnQUFBuH79OutNsqOjI169egVFRUVmBJyGi5qamti0zM3NkZWVhb///ptZl5eXx2kEm5KSEtZoSEVFRUhLS4OlpSUAgM/nQ0lJCWfOnGEdd+bMGairq6Nv376tPndbENcK0hRhXwpx19axY0emdQBouZyEJk2ahKysLHz55ZcwMTFhdTAmhJB3DoUMSYRaCAghnLi5uaFv3764du0a1NXVAdR3IB46dChmzpyJwMBA9O7dG5WVlXj06BFu3bqFmJgYsWlNmDABO3bswKxZs7BgwQIoKChg+/bt0NPTa/Xb+Xbt2mHFihUICQmBtrY24uPjAYCJ39fT04OPjw/27NkDZWVl2NjYIC0tDYcPH0ZISAhzTVw9ePBAZHIaJSWlJsOqmtKtWzf89NNP6NevH9TU1NC1a9cmRzvq3bs3PDw8EBUVhYqKCvTo0QPnzp1Damoqvv76a9a+LZWTEI/Hg5WVFX777TfMmzeP1WeBEELeOR/5g76kqEJACOEsKChIJHQkJiYGu3fvRnJyMrKzs6GhoYFu3bo1O0KPqqoq9u7diy+//BKff/459PX1ERgYiOvXrzMdWaVlaGiIpUuXIjo6Gk+ePEHPnj2xa9cuVufdpUuXQltbG0ePHkVCQgKMjY0RFhYGf3//Vp1TnPDwcJF1BgYGuHr1qlTprFq1CuvXr8fMmTNRUVGBpKQk2NvbN7n/N998g02bNmH37t0oLCxEly5dEB0dLTKxmSTlJOTu7o4//vgDEyZMkCrvhBDyxtEoQxKREwjacAo3QgjhqLy8HMOGDYOHhwdWrlz5trPzQVq2bBnu3LmD06dPS7T/9OnToaioiD179rTqfM8Hu7TqOCFNR/2Wd2rBv/Zxm8XZ63YE5zzstF7FOQ1ZtM/UtLxLszpVc38Dqy6Djp8K4PY4UwnufYTelbesXH+n5fIKnPOQqFTEOY1Tf0v2P6k55RtmSLyv+hLZTTb5vqG2XkJaKTY2FjweD5MnTxa7rfEMvJKkJ+0xAHDs2DHweDyxnUIbamq23zcpLS0NPB5P7CIcpz8hIQHff/890tLS8OOPPyIgIABFRUWYOnXqW827LPzyyy+YOXMm7O3tYW5uDmdnZyxduhR37txh9nF1dcVXX331FnPZtNu3b2Pfvn1IS0sTCSUihJB3kqBO8uUj9q5UZgl5b2VmZuLq1atwdHTklM7EiROZSbw+dJGRkejWrRtrnXA4TwUFBcTHx+P58+eQl5eHubk59u7dy4zJ/y6pq6tDXTPxqQoKCkzfh9jYWMTFxcHNzQ1r1qyBgYEB/vnnH5w6dQr+/v4iQ7e+iz799FNoampi9uzZnO7V0jwVTvm4tUeJ0/EAUKnI7W2wLN7uz8x8Nyt+0nrlLbvQOi4Etdx+pwoq3AMm7tw04pxGnQxaKlTluF3Ln0rcHw/7y+m0vNObQKMMSYQqBIRwoK6ujp49eyIuLo5zhcDY2BjGxsYyytmbV1lZCRUVyR70evbs2eSY/IGBgQgMDJRl1kRIk9fmLF++HMePH29ye2RkJLy8vHDlyhXExcVh9uzZCA0NZe0zduxYXLx4kXNeuIiKipJov/v377dxTgghRLYE1KlYIhQyRAhHQUFByMjIYA3Z2FhVVRViYmLg6uoKc3NzeHh4IDk5mbWPuJChv/76Cz4+PrCwsICrqyuSk5ObDP3Jzc3F7NmzYWVlhaFDh+LgwYNi8/LLL79g9OjR4PP58PLyQmZmJmt7XV0dduzYATc3N5ibm8Pd3R379u0Tm9c7d+5gypQpsLCwwK5dsou99PHxwezZs3H+/HmMGDECVlZWmDJlCrKyslj7CQQC7Nu3D8OHD4e5uTlcXFywfft2NOwa1Vxe09PT4eXlBT6fD09PT/z000/MuQHgzz//BI/HE9vx18PDA1VVVSKzDzdchgwZAgDYvXs39PX1ERISIvZ63dzcRNYdPnwYrq6usLGxwYwZM1izCgPAxo0bMXr0aFhbW8PJyQnz588X2UfSciwpKUFYWBhsbGxgb2+PdevW4ciRIyKhaJLcx4QQ8k6pE0i+fMSohYAQjpydncHn8xEXF4eBAweK3Sc0NBRpaWkICgpCr169cP36daxZswYaGhpNxvVXVFTA398fGhoaiIqKgqKiIrZv345Xr16JHWZy8eLF8PLygq+vL06dOoWvvvoKvXv3ZsaiB4CXL19i9erVCAkJgZaWFhISEhAYGIgLFy4ws9dGR0cjMTERs2bNgp2dHa5du4aoqCiUlZWxRhKqrq7GwoULMX36dCxcuLDJoS/FqaurQ00Nu9ubvLw8awjLe/fuYceOHViwYAEUFRURHR2NkJAQnDlzhtkvKioKhw8fxqxZs2BjY4O7d+8iNjYW8vLyzEN9U3l98eIFZsyYAR6Ph02bNuH169eIjo5GeXk5MxRo3759YW5uzkzEJfT777/j8ePH+Oabb1qcfbimpgbp6elwd3dnZh5uyaVLl/Do0SN88cUXKCsrQ2RkJMLDw1kVs/z8fMyaNQtGRkYoLCxEYmIipkyZgrNnz0JV9X8dZiUpx/DwcPz6669YvHgxPvnkExw/fhwXLlwQyVdr7mNCCHmraJQhiVCFgBAZCA4OxuzZs3H9+nUMGDCAtS0tLQ0XLlxAQkICE3ft4OCAwsJCbN68uckHqe+//x55eXk4ePAgOnfuDACwsbHBkCFDxD58T506FZ999hkAwM7ODpcuXcLZs2dZFYLCwkLExMQwFRc7Ozu4uLhg3759WLx4MQoKCnDgwAH4+/qfgAgAACAASURBVPtj0aJFAAAnJyeUlZVh165d8PPzY2L9q6ursWDBgmaHEW2KsANxQwEBAQgLC2M+FxcX49ixY6xhL4OCgnD//n306dMHT58+RVJSElauXMl0OHZwcIBAIEB8fDx8fHyYOQTE5TU6Ohry8vLYtWsXU549evTAuHHjWPny9vZGREQEa7bfo0ePolevXrCwsGjxWgsLC1FZWYkOHTpIWjyora1FfHw8E9aUn5+PyMhIFBcXQ1tbGwCwbt061v79+/eHg4MDLl++jGHDhklcjn/99RcuXLjAhDcBwODBgzFu3DhWi0Nr72NCCHmrKGRIIhQyRIgMuLi4wMzMDFu3bhXZdvXqVejo6MDR0RE1NTXM4uDggL///huFhYVi07xz5w569erFVAaA+nHrbWxsxO7v5OTE/KykpARTU1Pk5uay9tHS0mK1Yujo6MDe3h5//PEHAODWrVuorq6Gp6cn6zhPT0+Ul5fj3r17rPWurq5i89KSr7/+WiS8pvGoNb1792Y9xAo7FT9//hwA8Ouvv0IgEGD48OGsch04cCBKS0vx3//+t9m83r59G/b29qzKVZ8+ffDJJ5+w9hs5ciSUlJRw6tQpAEBpaSnOnTuHTz/9VKprlmZiNTs7O1Yfhx49egD437UDQGpqKiZPnox+/fqhb9++GDBgAOrq6vD48WNWWi2V4+3btwEAQ4cOZR3n7u7O+tza+5gQQt4qChmSCLUQECIjwcHBmDt3rshoMQUFBSgqKmpyRtpnz54xb54bevHiBfT09ETW6+vrIz8/X2S98M2xkJKSEiorK1nrxKVnYGCA9PR0AEBRUf240YaGhiLnBMB66FNTU2NaC6TVvXv3FkNtdHTYI1QIw22E11RQUACBQNBkmNazZ8+YMheX15cvX6JLly4ixwmvVUgYDpOSkgIfHx+cOnUKNTU1GDNmTLP5F2rXrh1UVFTwzz//SLQ/0PK137p1C/PmzcOQIUMwY8YMGBgYQEFBAVOmTBH5nbeU1suXL6GkpCRy/zQuh9bex4QQ8lZ95MOJSooqBITIiKurK8zMzBAXF4d+/fox63V0dKCrq4udO3eKPc7U1FTseiMjI/z5558i68VVBiQlbq6CvLw8pgIgfKDLy8tD+/btRc7Z8IFPmjfebUFHRwdycnI4dOiQ2Nj8hi0r4vJqaGgotjzy8/NFHmwnTZqE5ORk3LlzBykpKRg6dCh0dXUlyqeioiL69euHa9euobq6WuJ+BM356aefoKmpic2bN0NBoX4CoVevXqG6ulrqtAwNDVFdXc0KRwJE77PW3seEEPJWfeRv/iVFIUOEyFBQUBCuX7/OvHEHAEdHR7x69QqKiorg8/kii5qamti0zM3NkZWVhb///ptZl5eXh4yMjFbnr6SkhDUaUlFREdLS0mBpaQkA4PP5UFJSwpkzZ1jHnTlzBurq6ujbt2+rzy1rwpaBgoICseXa+M14Y3w+H9evX0dpaSmz7t69e3j69KnIvubm5jAzM0NUVBTu3LmDiRMnSpXXgIAA5OXliQ0pA+o7EUujoqICioqKrE7YwpAmaZmbmwOor2Q01LhTcWvvY0IIeZsENbUSLx8zaiEgRIbc3NzQt29fXLt2jenQ6uDggKFDh2LmzJkIDAxE7969UVlZiUePHuHWrVuIiYkRm9aECROwY8cOzJo1CwsWLICCggK2b98OPT29Vr+db9euHVasWIGQkBBoa2sjPj4eAJj4fT09Pfj4+GDPnj1QVlaGjY0N0tLScPjwYYSEhDDXxNWDBw9Q22jkByUlpSbDUcTp2rUrfHx8EBYWBn9/f1hbW6O2thZPnz7FhQsXRIZKbczPzw+HDx/GjBkzMGPGDLx+/RqxsbEwNDQUW76TJk3C6tWr0bFjxybDlJri5OSE4OBgxMXF4a+//sKoUaNgYGCAZ8+e4V//+hcyMjJw48YNidNzdHREYmIivvzyS3h4eOD27dv47rvvWtX60LNnT7i7u2Pt2rV4/fo1M8rQq1evAICpdLT2PiaEkLeKWggkQhUCQmQsKCiINTwnAMTExGD37t1ITk5GdnY2NDQ00K1bt2ZH6FFVVcXevXvx5Zdf4vPPP4e+vj4CAwNx/fp15mFNWoaGhli6dCmio6Px5MkT9OzZE7t27WJ1Ol26dCm0tbVx9OhRJCQkwNjYmHnolpXw8HCRdQYGBmLH+2/O8uXL0a1bNxw5cgTx8fFQVVVF586dmfH/m2NkZISdO3di/fr1WLhwITp27IiFCxciISEBWlpaIvsPGzYMq1evhpeXF+vNvKRCQkJgaWmJpKQkrF69GqWlpTAwMIC9vX2LlZfGnJ2dsXTpUuzfvx/Hjx+HhYUFtm/fLnb0JklERkYiIiICGzZsgKKiIjw9PTFt2jRs3LiR1feiNfcxIYS8VdSHQCJygoYz+BBC3mnl5eUYNmwYPDw8sHLlyrednQ9Obm4u3N3dsXDhQgQEBLC2nThxAsuXL8fFixdhYmLylnL45syZMwc5OTmtDkVqzl99PTgd/yhfsv4bzXmuyO19WKkMAm5nZn7FPZF3wCtv2b0s4EJQy61fk4IK98ehOzeNOKdRB+79sxTluF3LDWXuM7m/5pgHAFj5RPwEm9IoDZVsAAgA0Nz4A+fzva+ohYCQd1hCQgL09fXRqVMn5OfnIykpCUVFRcy4+4SbDRs2gMfjwcjICM+ePcPOnTuhpqbGmosgOzsbT548wZYtWzBs2LAPsjJw7tw5/PPPP+DxeKisrMT58+dx6dIl1lwHhBDyPhK0YcjQ48ePERERgYyMDKioqGDkyJFYsmRJi32qfHx8xIaJpqSksEbgq66uxpYtW3D8+HGUlJSAz+djxYoV6NOnj8yv5b3pVBwbGwsej8cs5ubm8PDwQFxcHKqqqmR6ruzsbPB4PJw9e1am6baFY8eOgcfjiR0tpTHhF/6hQ4fErhc3jOLMmTNFxqSXVX4aSktLA4/HY8ZEb26/HTt2SJV2S6TNszCv1tbWIqE7kl5HU2k2Pk5BQQHx8fGYOXMmli9fDkVFRezdu5cZS17Se7W1vxdpCGcfbmoRCASsv+HGS+PhMt+E2tpabNy4EYGBgYiIiEDHjh2xf/9+1vCscXFxmDVrFkxMTLB8+XKxaTR33UIPHz5EWFgYnJ2dYW5uDnt7e8yYMQPnz59n9lm2bNlbmeBLXV0dp06dQlBQEEJCQnD79m1ERERIPdeCpOTkOS4QcF7qAE6LvAyWd0ZtNadFUAfOi0zICTgttVXcr0NejvuiKCfgvHD9+1ARgPNSISfgvMhEG81DUFxcjOnTp6OsrAybN2/GsmXLcPr0abHfE+LY2NggOTmZtQi/24UiIyNx8OBBzJ8/H9u2bYOSkhL8/PxE5hiShfeqhUBVVRWJiYkA6sfQzszMRGxsLMrKylgznBLxOnToAGNjY6Snp7PeMGdkZEBNTQ0PHjxASUkJEz8tEAhw8+ZNDB8+XOJzuLi4IDk5WWRMc1m5ceMG9uzZgzlz5rRJ+tIoLy/Hvn37mBl9uTAzMxP7zyAwMBCBgYGc038Tli9fjuPHjze5PTIyEkD9mxFxD73KysptlremhIWFtfi/IyoqClFRUU1ud3d3R05OTpPbL168iIcPH2L+/PkwNTVFcHAwTE1NUVRUhNTUVISGhiIlJQW9e/du9XVwNWjQIAwaNOitnZ+Qd4H8e/VERCTWRqMHHTlyBMXFxThx4gTzEklBQQFLlizBvHnz0LNnz2aP19bWhpWVVZPbc3NzceTIEaxYsYLpH2ZpaQk3NzckJibi888/l93F4D2rEMjLy7MKz97eHk+ePMH58+c/6ApBRUUFVFVVZZKWra0tMjMzWesyMjLg5uaGK1euIDMzE4MHDwZQPxJMcXExbG1tJU5fT09P7ORXH6IBAwZg//798Pf35zwhk6amZrP/GN51FRUVCA4OxrRp05rcp1OnTgAAExOTt3qtsvx7AoDt27c320op/IKwsLDA7t27WRWfoUOHYurUqW1WgSaEkI9eG4UMXb58GQMGDGA983h4eGD58uW4fPlyixWClly5cgW1tbWsKA1NTU0MGTIEly9flnmF4J1qtWwNDQ0NVrP8vn37MGHCBNja2mLAgAEIDAzEgwcPRI7LzMxEQEAAbGxsYG1tjYkTJzY7wsn9+/fh5OSEBQsWoLq6Gr6+vggNDWW2P3r0CDwejzUSS0FBAXr37s2M7/3o0SOEhobCxcUFFhYWGDFiBOLj41n5F4aAHD9+HKtXr4a9vT0zgkdpaSnCw8NhY2MDe3t7rF27VupwKVtbW+Tk5LCamzIyMmBjYwMrKyvW+PnC8e6FFQKBQIB9+/Zh+PDhMDc3h4uLC7Zv346G/dLFhabk5uZi7ty5sLS0hJOTE7Zt24YtW7bA2tpaJH8lJSVYsmQJrK2t4ezsjM2bN6Ourr49OTY2FnFxcSgvL2fCTHx8fFi/g+DgYNjZ2cHS0hL+/v4iv3tZlKFQQEAAUyYtOXnyJMaOHQs+nw9HR0dERkayzisuZKikpARhYWFMXtetW4cjR46IDf2pqqrC2rVr0b9/fzg4OGDNmjViQ3Cys7Ph5+cHS0tLuLq64ujRoyL7/PTTTxg/fjz4fD6TVllZmUheU1NTsWjRItja2mLOnDno1KmT2PHphYukE3nFxsbC2toaDx48wLRp02BpaYkRI0bg3LlzIvtevnwZkydPhqWlJfr374/w8HAUFxe3mFeg5fuyqqoKAwcOxKZNm0TOu3LlSnh41HeM5fF4zV73iRMnUFxcjBUrVohtBenTpw86dOjAWvfbb79h/PjxsLS0xLhx40Rmvz558iSmTp0Ke3t79OvXD1OnTsXvv//eqnIUCATYtm0bnJycYGVlhTlz5iA9PV1sKFpL9zEhhLxrBAKBxEtxcTGys7NFlobfK0IPHz5Ejx49WOuUlZXRuXNnPHr0qMV83bhxA9bW1uDz+ZgyZQprjiBh+gYGBiLfnT169MDjx4+ZZyNZea9aCAAwD8/CkKGTJ09i/PjxzPbnz59j2rRp6NChA16/fo3vvvsOkydPxpkzZ2BkVN/7Pz09Hb6+vrC0tMTatWuhra2NO3fu4J9//hF7zj/++AMzZ87E0KFDsXbtWsjLy8POzg7JycnMPr/99htUVFRw8+ZN1NTUQFFRkfmCFj5Qv3z5El26dMHIkSOhqamJrKwsxMbGorCwUKSF49tvv8WgQYOwYcMGZrz2lStX4t///jcWLVqELl264PvvvxeZPKglNjY2TBl4enqitLQUWVlZsLGxQUlJCatSlJGRASMjI3zyyScA6kMnDh8+jFmzZsHGxgZ3795FbGws5OXlMXv2bLHnEwgEmDt3Ll68eIE1a9agXbt2SExMxOPHj8Xuv2rVKowcORJbt27FlStXsG3bNpiammLs2LGYOHEinj9/jtOnTzOhY5qamgDqH3SnTJmCrl27Yu3atVBSUsKePXswffp0nD9/ngmDkkUZCunp6WHKlClMK0FTE2ElJSUhKioKPj4+WLp0KZ4+fYpNmzbh9evX+OqrpkcZCQ8Px6+//orFixczY8M3ldeYmBgMHjwYGzduxJ9//omYmBgYGRlh3rx5rP0WLlyISZMmITAwEKdPn8YXX3wBIyMjODs7A6gPbwkODoaHhwcWLlyI7OxsbNy4EY8fPxap+KxcuRIjR45EbGysVPMiCPsaNCQnJ8fMuAvUd6QKDQ3FtGnTMHfuXOzfvx+hoaE4d+4c09Lw008/ISQkBOPGjcPcuXPx6tUrxMTEYNGiRdi9e3ezeZXkvlRWVsa4ceNw/PhxzJ8/n8lfeXk5/vWvf2Hu3LkSXW9aWhqMjIwkDgl6+fIlvvrqKwQGBkJXVxdxcXEICgrCzz//zNzvOTk5GDNmDLp06YLq6mqcPXsWvr6++P7771nnkaQc9+/fjy1btsDf3x+Ojo5IT0/H0qVLRfLV2vuYEELeKilaCBITExEXFyeyPjg4GCEhIax1jWd3F9LW1kZRUVGz57Gzs8OYMWNgamqKvLw8JCYmIiAgAHv27GHmuSkuLhY7BLaOjg6qq6tRXl7OfCfIwntVISgvLxeZuGjw4MFYvHgx83nZsmXMz7W1tXB0dISzszP+9a9/MW/vv/nmG3Tp0gVJSUnMl7yTk5PYc167dg3z5s3Dp59+iuXLlzMPPv3790dsbCyePHmCLl264MaNGxg7dixOnjyJO3fuwMrKCjdu3EDPnj2Z2p29vT3s7e0B1D8o29raoq6uDrGxsfj8889ZD1W9evViYq6B+primTNn8NVXXzGxZIMHD8a4cePw/PlzicuQx+NBU1OTqRDcvHkTqqqq6NWrF4qLi7Fjxw5UV1dDSUkJ6enpTAXi6dOnSEpKwsqVK5n+Bw4ODhAIBIiPj4ePj4/YSasuX76Mu3fvIikpibl2R0fHJseJd3d3Z2LyHRwccPXqVZw7dw5jx46FsbExjI2NRULHgPqOnxoaGti3bx8TDtK/f38MHToU+/fvx7x582RWhg0FBgbi0KFDSExMxPz580W2l5aWIiYmBv7+/qyHLG1tbSxduhSzZs1iHswa+uuvv3DhwgVERkbCy8uLlddnz56J7G9ubo41a9YAqL+Xb968iXPnzolUCMaOHcu8IR80aBCePHmCbdu2MRWCuLg48Pl8bN68mTlGV1cXixYtQlpaGvM7BOrHwm9NqN6GDRuwYcMG1jozMzMcO3aM+Sx8kBXeJ2ZmZnB0dMRPP/0EPz8/CAQCrF+/Hh4eHqy/E1NTU3h7e+P3339Hv379msxramqqRPelt7c39uzZgytXrjBldObMGVRWVrJeRDQnNzdXpAWgOUVFRUhKSgKPxwNQP1/CuHHjcP36dQwdOhQAWL/Xuro6ODg44D//+Q9SUlLwxRdfMNtaKsfa2lokJCRg3LhxTPk4OTmhtLQUSUlJTDqtvY8JIeStk6JC4OvrK/Z/u6zDOhs/L7i5uWHMmDGIi4uTeuJLWXmvQoZUVVWRkpKClJQUHDlyBGvXrsW9e/cQFBTEhK3cvHkTAQEBsLe3R9++fcHn81FQUID//ve/AIDXr1/jjz/+wLhx41hvJMVJTU3F7Nmz4evrixUrVrAe2C0tLaGsrMwMG/X777/D0dERlpaWzLrffvsNdnZ2zDGVlZXYsmUL3N3dwefzYWZmhvXr16OkpAR5eXmsc7u6urI+37p1CwKBgAlTAOrfqrq7u0tVhsKHaWE4UEZGBqysrKCgoAALCwtUV1fj3r17ePHiBbKzs5nWjV9//RUCgQDDhw9njaAycOBAlJaWMuXb2O3bt6GlpcV6kFRWVmYerhprXDHr0aOHRA/rV65cgZubGxQVFZm8qaqqwsrKCrdu3QIguzJsSF9fn2klKCkpEdl+8+ZNlJWVwdPTU6Tcamtr8eeff4pNVxg6JHwAFGoqr5KWW+PjPTw8cPfuXdTW1qKsrAz37t3DiBEjRPZp2OIl1PgeldT06dOZv2Ph8s0337D2kZeXh6OjI/NZV1cXenp6TKjb48ePkZOTg5EjR7LK1dzcHJqamiKjNTXOq6T3pampKfr374+UlBRmXUpKClxcXFiTubVEmhYUQ0NDpjIAgOlo3vD3+fDhQwQHB8PR0RF9+vSBmZkZ7t69K/J32FI5Pn/+HC9fvhS5zxr+jQCtv48JIeRtE9QJJF60tbXRqVMnkaWplgBxoUTFxcVNRgw0RVlZGW5ubrh79y4rfXHPFUVFRVBSUhL7EpaL96qFQF5enjU+q7W1NbS1tTF//nykpqaiV69eCAgIgJmZGdasWQMjIyMoKytjwYIFTJxrcXEx6urqmPCh5vz8889QVFRkjUkupKKiAgsLC/z+++8YMGAAnj9/jv79+yMrKwu///47Jk+ejKysLNZoON988w2+++47BAUFwdzcHFpaWvj111+xadMmkXhvfX191ueXL19CSUlJ5CaT5qFEyMbGBlu3bkVpaSkyMjKYN6lqamro3bs30tPTmbHWhRWCgoICCASCJmuuz549E2m9AYAXL16I7WTc+PqEGv/RKSkpSRSj/OrVKyQlJbHeagoJQyhkWYYNBQYG4vDhw0hMTGRVAAEwsf7Ct/yNNRWmJsxr4/LgWm6Nj9fX10d1dTVevXrFDA3auDwUFBTQrl07kSbQpvLSEmNjY9bfsTiqqqoi8fbKysrM34mwXIODg8Ue37hcG+dVmvvS29sby5YtQ0FBAV69eoWMjAyphr5t3769RPGkQo3vT2E5CK+9tLQUAQEBaNeuHT7//HN07NgRKioqWLduncjvvKVyfPnyJQCIxKg2LpvW3seEEPLW1bRNp+Lu3bvj4cOHrHVVVVX4+++/m/xfKW36+fn5KCwsZA1c8vDhQ5iamkJeXrbv9N+rCoE4wg4dWVlZyM3NRXl5OeLi4lhfqoWFhczPWlpakJeXx4sXL1pMe9myZUhJSYGvry8OHDjAxNIL2dnZ4YcffsCNGzfQo0cP6Onpwc7ODomJibhx4wbq6upYD4hnz56Ft7c3K96+8VtXocZvFA0NDVFdXY2ioiLWtTVuWZCEra0tamtrkZ6ezvSPELK2tkZ6ejo6dOgADQ0N5mFaR0cHcnJyOHToEJSUlETS7Ny5s9hzGRkZiR37Pj8/X+p8N0dHRwfOzs5iJ+wShhDJsgwbMjAwwOTJk5GUlCQyWYjwPLGxsWIntGpqkithXhvHKHItt/z8fLRv3571WUlJCbq6uqioqICcnJzIOWpra1FYWCjyoCrNW29ZE/5zXLVqFSwsLES2N36wb5xXae7LYcOGISIiAidOnMDLly9hZGTEjMQliQEDBuDatWu4f/8+681/a928eRPPnz/Hjh07WPdbWVmZ1KNdGRoaAoDIfBqNy6a19zEhhLxtbTUx2eDBg7F9+3a8evWKealy4cIFVFVVNRkF0ZSqqir89NNPrJdlTk5OkJeXx5kzZzBlyhQA9f/nf/75Z0yYMEF2F/L/3quQIXHu378PoP6NlvCBRrHBlPQXL15kjZCirq4OKysrnDx5kums2xQ1NTXEx8fD2NgYvr6+IrHbdnZ2yMnJwYkTJ5gHfysrK1RWViIxMRFdu3ZlvW2trKxkva0TCAQ4ffq0RNdpYWEBOTk51gghAoGgVR1iLS0toaioiEOHDqGyshKWlpbMNhsbG2RkZLBCiQAwLQMFBQViR1JpqnmMz+ejpKQEaWlpzLqqqiqkpqZKnW/gf2++G45sBNT3N8jKymLCxBouwqG/ZFmGjQUGBqKyshL79+9nrbexsYG6ujqePXsmttyaap0wNzcHAGaEKiGueW18/Llz52BmZgYFBQVoaGigT58+OHPmDGuf8+fPo6amhhWT/7Z169YNJiYmePLkidhybSlmX5r7UllZGePHj8fRo0dx8uRJeHl5tRhu2NDEiROhra2N9evXi221+c9//iPVG/aKigomXw3TEDeaWkuMjY1haGgocp81HomotfcxIYS8dW00MdnkyZOhpaWFefPm4ZdffsGJEycQEREBT09P1uhDy5cvR9++fZnPv//+O+bMmYPvv/8e169fx+nTp/HZZ58hOzub1erdvn17TJ48GRs2bMDRo0dx9epVpu+Br68vx0IR9V61ENTV1eHmzZsA6kcbevDgAeLi4mBoaAh3d3cmxjY8PByTJ0/Gf//7XyQkJIg0fy9evBh+fn7w8/PD1KlToaOjg7t370JXV1dkZk5NTU3s2rWL2X///v1MuJG1tTUUFRVx48YNpvampqYGc3Nz3LhxA97e3qy0HBwckJycjG7dusHAwADfffddiz3Rhbp37850oKysrESXLl2QkpIi8mZPEmpqaujTpw9SU1PRu3dvVi91Gxsb5Ofno6CggHVjdu3aFT4+PggLC4O/vz+sra1RW1uLp0+f4sKFC00OvTl48GCYmZlh8eLFWLx4MTOai6KiYqveMHfv3h01NTVITEyEjY0NNDU10a1bNyxYsACffvop/P394e3tDUNDQ+Tl5SEzMxNdu3bF1KlTZVqGjRkaGsLb25sZ/UhIS0sLCxYswIYNG/D8+XMMGDAASkpKyM7OxqVLl7B69WoYGxuLpNezZ0+4u7tj7dq1eP36NTPKkDCvrW0qPHnyJFRUVGBmZobTp08jMzMTCQkJzPbg4GAEBQUhNDQU48aNQ05ODr799lsMHDiQFW/PxbNnz5i/44b69OkDFRUVidKQk5PD8uXLsWjRIrx+/RouLi7Q0NDAs2fPcOXKFUyfPp1V0W1M2vty0qRJ2Lt3L+Tk5KR+M6Ovr48NGzYgJCQE3t7emDp1KkxNTVFSUoLLly8z/Sgk7XhsZWUFdXV1rFmzBrNmzUJ+fj62bNki9j5qiYKCAmbNmoX169dDV1cXTk5OSE9Px8WLFwH87z5r7X1MCCFvnWxH52Roa2sjMTERa9euRUhICFRUVDBy5EiRUdrq6upYL6CFEQCbNm1CYWEhVFVVYWlpiaSkJJF5n8LDw6Guro6YmBiUlJSAz+dj7969rJZ+WXmvKgQVFRXMQ7aCggKMjY0xaNAghISEQEdHBzo6OoiKikJcXBzmzJmDXr164dtvv2VGXxHq168fkpKSEBMTg/DwcMjLy6Nnz55YuHCh2PNqaWlhz5498PX1hZ+fHw4cOAA9PT2oq6vD3NwcN2/eZIUG2dnZITMzU+SN6qpVq7B69WqsX78eysrKGD16NDw8PMQO8SfOunXrEBERgY0bN0JRURGjRo3CvHnzsHr1ailKsZ6trS1u374tMheAsbExOnTogH/++Ufkxly+fDm6deuGI0eOID4+HqqqqujcuXOTIwYB9Q9u27Ztw5o1a7BmzRpoaGhg0qRJ6NGjR6vedg8ZMgRTp07Fzp07kZ+fDzs7O+zfvx+ffPIJjh49is2bN2Pt2rUoKSmBoaEhrKysMGbMGOZ4WZZhYzNmzMCRI0dEbmg9MwAAIABJREFU+oP4+fnB2NgYe/fuxaFDh6CgoICOHTti8ODBzY5cEBkZiYiICGzYsAGKiorw9PTEtGnTsHHjRmhoaLQqjxs3bsTGjRuxbds26OvrIyIigtW06ebmhtjYWGzduhXz5s2DlpYWRo0ahSVLlrTqfOLs379fpCUFAH788UeRmZqbM2zYMOzatQs7duzAkiVLIBAIYGJiAgcHB3Ts2LHZY6W9L7t168aEBTYVHtccZ2dnHD9+HAkJCdiyZQsKCgqgqakJCwsLxMTESDVLsYGBAbZs2YLo6GgEBQWhc+fOCA8PR0pKCsrLy6XOm4+PD0pKSnDo0CEcOnQI/fr1w4oVK5jfv1Br72NCCHmb2ipkCKh/Wdp4mOvGGs9236VLlxaPEVJSUsKSJUtk+h3cFDlB49gLQtpYXV0dxo8fDxMTE6k6ZxJgzpw5yMnJwalTp952Vj44zd2X2dnZcHd3R3R0NDNR4Idsz549+Oabb3DlypVWdx5vzkNzj5Z3asajl9xmBgeAHEXRvlDSqJBBwG1g5jsyf0NtNafDCybP4pwFORmUp4Djm2B5GbwivXe75QFL3gQ5cHu0u6nEfTb35wrcX82ve3yIcxoF4yWP59c73rpw5g/Be9VCQN5PycnJqK2tRdeuXVFWVoaUlBTcv3+fNWcEEXXu3Dn8888/4PF4qKysxPnz53Hp0iWsW7fubWftgyDJffnq1Ss8fvwYW7duRfv27UWG4/wQPHz4ECdPnoS1tTVUVFSQkZGBnTt3YvTo0W1SGSCEkDeqjUKGPjStqpPPmTOn2THIT5w4AR6Phxs3biA6Ohpjx46FtbU1nJycMH/+fDx58kSq88XGxoLH4zGLubk5PDw8EBcXJ9GQlNLKzs4Gj8fD2bNnZZ62rB07dgw8Hg8FBQXMDLBNLTk5OeDxeDh0iF3jFj50NgytEZo5cyY8PT1blR8hFRUVHDx4EHPnzkVoaChevnwpMvlGWloaeDyeyPjxjaWlpcm8VUGaMhQIBExera2tRfofSHodjYk7Tl1dHadOnUJQUBBCQkJw+/ZtREREsPq5SHqvivu9yJJAIGi23IRTrDf8O268NA61amuS3JeXLl3ClClT8PTpU3zzzTciQ3hKcr8IPXz4EGFhYXB2doa5uTns7e0xY8YMnD9/ntln2bJlGDVqVNtffAOqqqq4desWli1bhpkzZyIlJQVTp05FREREm52ztlaO01IN7os8wGmpkcEim8Ks5r4oKHFa5BXBeZEFQa0cp0VOEZyXGoEc56VSIM95qRXIcVqK5QWcF906ec6LTO6LOsmXj1mr/gzHjBmDRYsWISMjg5nJtqFTp06hS5cuKCsrw/nz5zFhwgRYWVmhuLgY8fHxmDhxIn744QepOqGpqqoyHTYrKyuRmZmJ2NhYlJWVtWq21A/R8uXLcfz48Sa3R0ZGwtjYGOnp6azhOTMyMqCmpoYHDx6gpKSEiRsWCAS4efMmhg8fLnEeXFxckJyczIopHjdunNi5HFrjxo0b2LNnD2t+B1mSpAyF8enl5eXYt28fM7MyF2ZmZkhOTmbF0A8aNAiDBg3inPabcPz4cYSHhze5ffz48UwMpY+Pj9iH3sYP221NkvvSy8ur2fGkJblfvLy8kJqaivnz58PU1BTBwcEwNTVFUVERUlNTERoaipSUFKn6EchSx44dmxwUgBBC3nsf+YO+pFpVIXB1dYWGhgZOnz4tUiHIz8/H9evXMWfOHNja2uLs2bOsYUDt7OwwePBgpKSkNDmpkDjCGXaF7O3t8eTJE5w/f/6DrxBUVFQwY+k3Jzg4GNOmTWtye6dOnXDlyhVkZmay1mdkZMDNzY3ZJhxj/cGDByguLhbpXNwcPT09sRM+vS8kKcOsrCwA9ePL79+/H/7+/lKP/96YpqYm6/5+3wwcOJA1m29jDSe+MjExeavXKunfkyQkuV/y8/OxZMkSWFhYYPfu3ayKz9ChQzF16lTqlEsIIW3kY3/zL6lWtceoqqpi2LBhOHv2LGpq2A2fZ86cQU1NDUaPHg1tbW1WZQCof2A0NjaWaGKwlmhoaIicf9++fZgwYQJsbW0xYMAABAYGih2fOzMzEwEBAbCxsYG1tTUmTpyIq1evNnmu+/fvw8nJCQsWLEB1dTV8fX0RGhrKbH/06BF4PB78/f2ZdQUFBejduzczxvejR48QGhoKFxcXWFhYYMSIEYiPj2ddgzAE5Pjx41i9ejXs7e2ZToylpaUIDw+HjY0N7O3tsXbtWlbIVKdOncSOES5cdHV1YWtri5ycHOTm5jLHCVt6rKyskJ6ezloP/G+2YoFAgH379mH48OEwNzeHi4sLtm/fzgqLEBeakpubi7lz58LS0hJOTk7Ytm0btmzZIjLCEQCUlJRgyZIlsLa2hrOzMzZv3syEm8TGxiIuLg7l5eVMmImPjw/rdxAcHAw7OztYWlrC399f5HcvizIUCggIYMqkJSdPnsTYsWPB5/Ph6OiIyMhI1nnFhQyVlJQgLCyMyeu6detw5P/YO++oqI73cT90pYoKIZagWNAsXUEFC7GEqDFqiqB+lZZYAEUlFjSWBFQ+VhRsxAYaFUvUSKJGE6OxohQNxARLNGpEBURQFIHd3x+cveGyiy4lP028zzn3nN17587MfXd2d96Zt2zbptb05+nTp0RGRuLm5oa7uztz5sxRa4Jz8+ZN/Pz8cHR0pGfPnuzYsUOlzOHDhxk8eDD29vZCXRVzeSj7evToUSZOnEiHDh0IDw9/ptyaNWv2XBkpiYmJwdnZmUuXLjF8+HAcHR3p27evSmx8gGPHjuHj44OjoyNubm6Eh4eLUsmr66tyd+l54/Lp06d06dKFpUuXqrQ7c+ZMvLy8NBov27dvp6CggBkzZqjdBWnfvr1KyNGzZ88yePBgHB0dGTRoEGfPnhVd37t3L8OGDaNTp0507NiRYcOGqSQ51FSOCoWClStX0rVrV5ycnBgzZgwpKSlqTdGeN44lJCQkXjrk1TheYWpsuTdgwAB2797NyZMnRVk7k5KSsLe3p0WLFmrvu337Nn/99Rc2NjbVblM5cVaaDO3du5fBgweLymRnZzN8+HCaNGnC48eP2b59Oz4+Puzfv1/IH5CSkoKvry+Ojo5ERkZiampKRkZGlcmBlNl8e/fuTWRkJNra2ri6upKYmCiUOXv2LAYGBqSnp1NaWoqurq7wB62cUN+7dw9ra2v69++PsbExWVlZxMTEkJ+fr7LLsXjxYrp168aiRYuE+LUzZ87kp59+YuLEiVhbW7Nr165qh+5U7uikpKTQr18/Hj58SFZWFi4uLhQWFoqUotTUVCwtLYUMzVFRUWzdupVRo0bh4uJCZmYmMTExaGtri7IvV0ShUDB27Fju3r3LnDlzhHjv165dU1t+1qxZ9O/fnxUrVnD8+HFWrlxJixYtGDhwIB999BHZ2dkkJSUJ5mPKHAo3b95k6NChtGzZksjISPT09Fi/fj0jR47k+++/F8yg6kKGSho2bMjQoUOFXYKqkrMlJCQQFRXFiBEjmDx5Mjdu3GDp0qU8fvyYL76oOspIeHg4J0+eJCwsTMhDUFVfo6Oj6d69O0uWLOHXX38lOjoaS0tLgoKCROUmTJjAkCFDCAwMJCkpic8++wxLS0sh9OgPP/xASEgIXl5eTJgwgZs3b7JkyRKuXbumovjMnDmT/v37ExMTU62cEkq7+4poaWmJkn2VlJQwadIkhg8fztixY9m0aROTJk3i4MGDgnJx+PBhxo0bx6BBgxg7diz3798nOjqaiRMnqoR0q9xXTcalvr4+gwYNYvfu3YwfP17oX1FREd9++y1jx47V6HnPnDmDpaWlxiZB9+7d44svviAwMBBzc3NiY2MJDg7mxx9/FMb7rVu3eO+997C2tqakpIQDBw7g6+vLrl27RO1oIsdNmzaxfPly/P398fDwICUlRW0o5JqOYwkJCYkXibzOHHb+29RYIejcuTMWFhZ8++23gkJw48YN0tLSmD59epX3KSfglSfyz6OoqAiZTCY61717d8LCwkTnKkYIKSsrw8PDgx49evDtt98Kq/cLFy7E2tqahIQE4U++a9euats9deoUQUFBfPjhh0yfPl2Y+Li5uRETE8P169extrYmOTmZgQMHsnfvXjIyMnByciI5OZk2bdoIq8qdOnUSkjspFAo6dOiAXC4nJiaGKVOmiCZVbdu2Zf78+cL7K1eusH//fr744guGDBkiPP+gQYOEhGyaYGtri7GxsaAQpKenU69ePdq2bUtBQQGrV6+mpKQEPT09UlJSBAXixo0bJCQkMHPmTMH/wN3dHYVCwZo1axgxYgSGhoYq7R07dozMzEwSEhKEZ/fw8Kgyd0GfPn0Em3x3d3dOnDjBwYMHGThwIFZWVlhZWamYjwHExsZiZGTExo0bBXMQNzc3evfuzaZNmwgKCqozGVYkMDCQLVu2EB8fL2QQrMjDhw+Jjo7G399fNMkyNTVl8uTJjBo1Su3q+eXLlzl06JBgg16xr5UzZkN5ZmNlvo2uXbuSnp7OwYMHVRSCgQMHCivk3bp14/r166xcuVJQCGJjY7G3t2fZsmXCPebm5kycOJEzZ86IkpP16NGjRuZ6ixYtYtGiRaJzMpmMr7/+WnivnMgqx4lMJsPDw4PDhw/j5+eHQqFg3rx5QqI5JS1atMDb25tz586J8oBU7uvRo0c1Gpfe3t6sX7+e48ePCzLav38/xcXFGv+G3blzR+OkYwAPHjwgISEBW1tbACwtLRk0aBCnT5+md+/eAKLPVS6X4+7uzm+//cbOnTv57LPPhGvPk2NZWRlxcXEMGjRIkE/Xrl15+PAhCQkJQj01HccSEhISLxrJZEgzauzCraOjQ//+/Tl06JBgmpCUlCScV8eaNWv48ccfmTdvXpWrqVVRr149IaPntm3biIyM5OLFiwQHB4tMVtLT0wkICKBTp068+eab2Nvbk5eXxx9//AHA48ePOX/+PIMGDRKtSKrj6NGjjB49Gl9fX2bMmCGasDs6OqKvr09ycjJQnoraw8MDR0dH4dzZs2dFCcuKi4tZvnw5ffr0wd7eHplMxrx58ygsLCQnJ0fUduUoThcuXEChUIjCHmppadGnT5/qiFGYTCvNgVJTU3FyckJHRwcHBwdKSkq4ePEid+/e5ebNm8LuxsmTJ1EoFLzzzjuiKCpdunTh4cOHgnwr88svv2BiYiKaSOrr64uSYVWksmLWunVrjSbrx48fp1evXujq6gp9q1evHk5OTly4cAGoOxlWpFGjRsIuQWFhocr19PR0Hj16RL9+/VTkVlZWxq+//qq2XqXpkHICqKSqvmoqt8r3e3l5kZmZSVlZGY8ePeLixYv07dtXpUzFHS8lz4o09ixGjhwpfJeVx8KFC0VltLW18fDwEN6bm5vTsGFDwdTt2rVr3Lp1i/79+4vkamdnh7GxsUqUp8p91XRctmjRAjc3N5F/xM6dO/H09KRx48YaP3N1dlAsLCwEZQAQHM0rfp5XrlwhJCQEDw8P2rdvj0wmIzMzU+V7+Dw5Zmdnc+/ePZVxVjm8ak3HsYSEhMQLR6Gl+fEKU6tgXwMGDGDjxo38+OOP9O3bl2+//ZYuXbqo/aPcvXs3S5cuZebMmTWaSGhra2Nvby+8d3Z2xtTUlPHjx3P06FE8PT3566+/CAgIQCaTMWfOHCwtLdHX1yc0NFSwcy0oKEAulwvmQ8/ixx9/RFdXV20kEgMDAxwcHDh37hydO3cmOzsbNzc3srKyOHfuHD4+PmRlZYmi4SxcuJDt27cTHByMnZ0dJiYmnDx5kqVLl6rYe1eO/33v3j309PRUFKnqTEqUuLi4sGLFCh4+fEhqaqqwklq/fn3atWtHSkoKr7/+OvC3uVNeXh4KhUIUkrEit2/fVtnBAbh7965aJ+Oq4ptXdq7U09PTyEb5/v37JCQkiFY1lShNKOpShhUJDAxk69atxMfHixRAQLD1rypSTVVmasq+VpZHbeVW+f5GjRpRUlLC/fv3hTCZleWho6NDgwYNePDggUZ9eR5WVlai77I66tWrp2Jvr6+vL3xPlHKtKjBBZblW7mt1xqW3tzfTpk0jLy+P+/fvk5qaWq3Qt6+99hpXr17VuHzl8amUg/LZHz58SEBAAA0aNGDKlCk0bdoUAwMD5s6dq/KZP0+O9+7dA8RO34CKbGo6jiUkJCReNNIOgWbUSiGws7PDxsaGpKQkWrZsyaVLl/j4449Vyv3www989tlnjB49+pkROapL69atAcjKysLT05Off/6ZoqIiYmNjRX+q+fn5wmsTExO0tbU1cmqeNm0aO3fuxNfXl82bNwu29EpcXV355ptvSE5OpnXr1jRs2BBXV1fi4+NJTk5GLpeLJogHDhzA29tbZG9fedVVSeUVRQsLC0pKSnjw4IHo2SrvLGhChw4dKCsrIyUlRfCPUOLs7ExKSgpNmjTByMhImEybmZmhpaXFli1b0NNTzfD5xhtvqG3L0tJSbez73Nzcavf7WZiZmdGjRw9ROFUlShOiupRhRRo3boyPjw8JCQm0b99epV9Q7uCpVLIqou5cxb4WFBSIJvu1lVtubi6vvfaa6L2enh7m5uY8efIELS0tlTbKysrIz89XmahWZ9W7rlFGdZo1axYODg4q1ytP7Cv3tTrj8u233yYiIoI9e/Zw7949LC0tRX5Tz6Nz586cOnWK33//XbTyX1PS09PJzs5m9erVovH26NGjake7srCwAFDJp1FZNjUdxxISEhIvGoX81V7515RaZ30YMGAAx44dY8uWLdSrV09l6zk5OZmJEycycODAOonXXpHff/8d+Hs1SzmhqRjZ6IcffhBFSDE0NMTJyYm9e/cKzrpVUb9+fdasWYOVlRW+vr4qttuurq7cunWLPXv2CBN/JycniouLiY+Pp2XLlqLV1uLiYtFqnUKhICkpSaNndXBwQEtLSxQhRKFQ1Mgh1tHREV1dXbZs2UJxcTGOjo7CNRcXF1JTU0WmRICwM5CXl6c2mkpVJmD29vYUFhZy5swZ4dzTp085erRm6cGVK98VzcSg3N8gKytLMBOreLRp0waoWxlWJjAwkOLiYjZt2iQ67+LigqGhIbdv31Yrt6p2J+zs7ACECFVKatvXyvcfPHgQmUyGjo4ORkZGtG/fnv3794vKfP/995SWlops8l80NjY2vP7661y/fl2tXJ9ns1+dcamvr8/gwYPZsWMHe/fu5f3333+uuWFFPvroI0xNTZk3b57aXZvffvutWivsT548EfpVsQ510dSeh5WVFRYWFirjrHIkopqOYwkJCYkXjZSYTDNqnR9wwIABLFu2jO3bt9O3b18hCgaU27kGBQXRvHlzPvjgA9LT04VrxsbGwgq/JsjlcuH+0tJSLl26RGxsLBYWFoJddOfOnYHy6Cw+Pj788ccfxMXFqWx/h4WF4efnh5+fH8OGDcPMzIzMzEzMzc1FWWCV/Vy7dq1QftOmTYK5kbOzM7q6uiQnJzN06FCgXImws7MjOTkZb29vUV3u7u4kJiZiY2ND48aN2b59u4oZRlW0atVKcKAsLi7G2tqanTt3qqzsaUL9+vVp3749R48epV27dqLPzMXFhdzcXPLy8kTmGC1btmTEiBFMnToVf39/nJ2dKSsr48aNGxw6dKjK0Jvdu3dHJpMRFhZGWFiYEM1FV1e3RivMrVq1orS0lPj4eFxcXDA2NsbGxobQ0FA+/PBD/P398fb2xsLCgpycHNLS0mjZsiXDhg2rUxlWxsLCAm9vbyH6kRITExNCQ0NZtGgR2dnZdO7cGT09PW7evMmRI0eYPXu22gR9bdq0oU+fPkRGRvL48WMhypCyr9raNdPl9+7di4GBATKZjKSkJNLS0oiLixOuh4SEEBwczKRJkxg0aBC3bt1i8eLFdOnSRWRvXxtu374t+i1Q0r59ewwMDDSqQ0tLi+nTpzNx4kQeP36Mp6cnRkZG3L59m+PHjzNy5EiRoluZ6o7LIUOGsGHDBrS0tPjggw80f1jKdysWLVrEuHHj8Pb2ZtiwYbRo0YLCwkKOHTsm+FFo6njs5OSEoaEhc+bMYdSoUeTm5rJ8+fJqJXpUoqOjw6hRo5g3bx7m5uZ07dqVlJQUfvjhB+DvcVbTcSwhISHxopGXSTsEmlBrhaB58+Y4OzuTlpYmxMtXcv78eQoLCyksLFQx5XBzc1NZTX0WT548ESbYOjo6WFlZ0a1bN8aNGyesTtva2hIVFUVsbCxjxoyhbdu2LF68WIi+oqRjx44kJCQQHR1NeHg42tratGnThgkTJqht28TEhPXr1+Pr64ufnx+bN2+mYcOGGBoaYmdnR3p6usg0yNXVlbS0NJUV1VmzZjF79mzmzZuHvr4+AwYMwMvLS22IP3XMnTuXiIgIlixZgq6uLu+++y5BQUHMnj1bUzEKdOjQgV9++UUlF4CVlRVNmjThr7/+UklINn36dGxsbNi2bRtr1qyhXr16vPHGG1VGDILyidvKlSuZM2cOc+bMwcjIiCFDhtC6desarXa/9dZbDBs2jC+//JLc3FxcXV3ZtGkTzZs3Z8eOHSxbtozIyEgKCwuxsLDAycmJ9957T7i/LmVYmY8//pht27ap+IP4+flhZWXFhg0b2LJlCzo6OjRt2pTu3bs/MyHV/PnziYiIYNGiRejq6tKvXz+GDx/OkiVLMDIyqlEflyxZwpIlS1i5ciWNGjUiIiJC5Ejbq1cvYmJiWLFiBUFBQZiYmPDuu+/y6aef1qg9dWzatEntd/+7774TZWp+Hm+//TZr165l9erVfPrppygUCl5//XXc3d2FbNJVUd1xaWNjI5gFVmUe9yx69OjB7t27iYuLY/ny5eTl5WFsbIyDgwPR0dHVylLcuHFjli9fzoIFCwgODuaNN94gPDycnTt3UlRUVO2+jRgxgsLCQrZs2cKWLVvo2LEjM2bMED5/JTUdxxISEhIvEslkSDO0FJVtLyQk/mHkcjmDBw/m9ddfr5ZzpgSMGTOGW7dusW/fvhfdlf8czxqXN2/epE+fPixYsEBl4eO/yPr161m4cCHHjx+vsfP4s8hq/06t7r+cV7vM4AA5urVbDyuotcEtjE6rg/wNZSW1r0NH1S+sOuQP9X9+oedQF+Ya8pLaTfx0jWo/HbqQ+trzCz2HMmo/gdWrZZatE/VUkyhWF4M6iNrz6Z+ba13Hnx17aVz2jXM/1Lq9fyt18JMmIfFsEhMT2bJlC6dOneLw4cMEBQXx+++/4+vr+6K79lJz8OBBNmzYwMmTJzly5Ajh4eEcOXJErdxiYmKwtbXFx8dH7TV1WaGfRU3uAfWZqtUxbdo03n333WrXX5ckJiYSERFBr169kMlktG/fXmVc3r9/n7S0NObMmcNrr72mEo7zZUXTzwHKTTs//fRTbG1t+eqrr4iNjWXZsmUMGDCAjIwM7O3tGT9+PKWlpWozaktISEi8zCjkWhofrzK1NhmqLWVlZSoOohXRreUqzquEXC5HLq96VUBHR+eFRIYxMDDgyy+/5NatW8jlctq0aUNsbGyVIUxfJC+TDA0NDdm3bx/Lly+npKSEFi1aEBERoeLnUpG0tDROnDghij1fEz766KMqc0WoQ6FQUFZWJjjql5WVibIRa2tr19jv4Z/CwMCArVu3olAo0NHRwcbGhrCwMNG4PHLkCNOnT8fa2pqFCxeqhPB8mcZLTalXrx5XrlwByk3qLC0tGTZsGB07diQkJARPT0/BxK6uyL5v8vxCz6AuemJZWrv0paZatR/P971fjpV17VoKtMHWDbXug+Lh85XX59bx9Emt7tfSr1frPph2jax1Hdpatd+pkNdydb6RXDN/rmdRF7todcGrPtHXlBc+2+7Tpw+3bt2q8voPP/wgZcDUkOnTp7N79+4qr1fMevv/k0GDBqnN5fAy8jLJsFu3bnTr1k3j8oaGhoKyVVuFQJkVWlN2795NeHi48L5yorTBgwcTFRVVqz5Vh+Li4uc6KPfs2ZOysjLmzp1bpZL1/vvvP/PzfpHj5cmTJ0JI3drQtGlTpk2bxsiRI0lMTMTe3p7jx48TFBREjx49WLp0qbQwIyEh8a9FcirWjBf+K79q1apnJp7SJIGYRDkhISHPzPMgKVbP598uw+DgYEaNGsWpU6eq3IF5+vQpK1eu5JtvvuHu3bs0bdqUgIAAUVSsmJgY1q9fT1pamnDu8uXLfP7555w/f57GjRszevRo0tLSyMjIYNOmTezcuZMjR46wYsUKFi5cyNatW8nMzKRBgwZVyu3nn39mwYIFXLt2jTZt2jBz5kyRqZJcLicuLo4dO3Zw584dXn/9dYYPH46fn59KXzdt2sTcuXPJzMxk9OjRBAcHVymnr7/+WlBgZsyYwYwZMwSlpTptLl68mIsXL3L16lUGDx5MZmYmZmZmQojlsrIybG1tcXd3Z8OG8lXUvLw83N3diY2NpXfv3ly9epXY2FhSU1PJy8ujadOmDBo0iMDAQGEifvPmTXr16kVUVBTp6ekcOHAAU1NTDh06xMOHD5k7dy4HDx5ET0+PAQMGVCuCW2VOnjxJUFAQ3bp1k5QBCQmJfz2KVzwDsaa88F/6ukjUI1FOs2bNXvoJ68vOv12GPXr0wN7e/pkmWZMmTeLMmTMEBwfTtm1bTp8+LUTaqcqu/8mTJ/j7+2NkZERUVBS6urqsWrWK+/fvY2xsjLm5Oebm5kIs/NWrV/P+++8zbtw49u3bR0xMDF26dBFFrrp37x6zZ89m3LhxmJiYEBcXR2BgIIcOHRIcWRcsWEB8fDyjRo3C1dWVU6dOERUVxaNHj0QT/pKSEiZMmMDIkSOZMGGCKJSuOjw9PVm7di0ff/wxY8eOxdPTUwhPXJ02582bx8iRI7G1tcXY2JgjR44Iq+xQ7qdgYGBAeno6paWl6OrqCskIlbK4d+8e1tbW9O/nWm6aAAAgAElEQVTfH2NjY7KysoiJiSE/P5+pU6eK+r148WK6devGokWLBPOsmTNn8tNPPzFx4kSsra3ZtWtXjfNVnDp1ihUrVtC1a1eio6PVJiGUkJCQ+DfxqucX0JQXrhBISEjULSEhIYwePZrTp08LuTmUnDlzhkOHDhEXFyf4CLi7u5Ofn8+yZcuqVAh27dpFTk4OX331lRB208XFhbfeekvt5HvYsGH83//9H1AehvfIkSMcOHBApBDk5+cTHR0tKC6urq54enqyceNGwsLCyMvLY/Pmzfj7+wsr7l27duXRo0dCbhBl+NWSkhJCQ0M1jgDUsGFDZDIZUJ5l28nJCaDWbT569IiYmBiuX7+OtbU1ycnJDBw4kL1795KRkYGTkxPJycm0adMGc3NzADp16iTkeFAoFHTo0AG5XE5MTAxTpkwR+SC0bduW+fPnC++vXLnC/v37+eKLLxgyZAhQnmNh0KBBZGdnaySLiixevJgWLVpIyoCEhMR/htr6U7wqvCQuHxISEnWFp6cnMpmMFStWqFw7ceIEZmZmeHh4UFpaKhzu7u78+eef5Ofnq60zIyODtm3bimLwN27cGBcXF7XlK/oQ6Onp0aJFC+7cuSMqY2JiItrFMDMzo1OnTpw/fx6ACxcuUFJSQr9+/UT39evXj6KiIi5evCg637NnT7V9qQ61bdPR0RF9fX2Sk5MBOHfuHB4eHjg6Ogrnzp49K8pbUlxczPLly+nTpw/29vbIZDLmzZtHYWEhOTk5z2zvwoULKBQKUfQjLS0tIVljdenWrRvXrl2rMtGghISExL8NhUJL4+NVRtohkJD4DxISEsLYsWM5e/as6HxeXh4PHjwQVscrc/v2bRo0UI3xfvfuXZWM31CehTc3N1flfOVEVXp6eioJ29TV17hxY1JSUgCELN4WFhYqbQIi5aV+/fo1TtZWkdq2aWBggIODA+fOnaNz585kZ2fj5uZGVlYW586dw8fHh6ysLMaMGSPcs3DhQrZv305wcDB2dnaYmJhw8uRJli5dqiKzyjkB7t27h56enpCcUUnjxo1r9PyhoaG8/vrrLF68GDMzM5Vs6xISEhL/Nv7JKEPXrl0jIiKC1NRUDAwM6N+/P59++in169ev8p6HDx+yYcMGjh07xh9//IGuri4ymYxJkyap/DerM6s3NDQU+ffVFZJCICHxH6Rnz57IZDJiY2NFGbPNzMwwNzfnyy+/VHtfixYt1J63tLTk119/VTmvThnQFHUx8nNycoTJuFIxycnJ4bXX/k72o2yzouJSV6E966JNV1dXvvnmG5KTk4Xsxq6ursTHx5OcnIxcLhftEBw4cABvb29Gjx4tnFP6GVSmcpsWFhaUlJTw4MEDkVJQeWehOnz++ecUFhYyZ84cTExMVHZLJCQkJP5N/FNRhgoKChg5ciRNmjRh2bJl5OXlMX/+fPLy8li6dGmV9/31118kJibywQcfCDleEhIS8PHxYdu2bSpKwYgRI0TmvP9UCG9JIZCQ+I8SHBxMUFCQaBLp4eHB2rVr0dXVpX379hrXZWdnx549e/jzzz8Fs6GcnBxSU1OxtrauUf8KCwtF0ZAePHjAmTNnBN8De3t79PT02L9/v+gHcv/+/RgaGvLmm2/WqN1nURdturq6smrVKvbs2SNM/J2cnCguLiY+Pp6WLVuKVvCLi4tF+Q0UCgVJSUka9dfBwQEtLS0OHjwo+BAoFIoaOxVD+Z/NwoULefjwIVOmTMHY2Jju3bvXuD4JCQmJF8k/5UOwbds2CgoK2LNnj7DjraOjw6effkpQUBBt2rRRe1+zZs04dOiQaBfB3d2dXr16sXnzZpGfGMDrr78u+Ln9k0gKgYTEf5RevXrx5ptvcurUKQwNDYHyH53evXvzySefEBgYSLt27SguLubq1atcuHCB6OhotXV98MEHrF69mlGjRhEaGoqOjg6rVq2iYcOGNV6db9CgATNmzGDcuHGYmpqyZs0aACFTcMOGDRkxYgTr169HX18fFxcXzpw5w9atWxk3bpzwTHVJXbTp7OyMrq4uycnJDB06FCg3L7KzsyM5OVnFDMfd3Z3ExERsbGxo3Lgx27dvF0yXnkerVq3w8vJi/vz5FBcXY21tzc6dO7l//371H74Cenp6xMTEEBAQwPjx41m3bp3IIfz06dMq+WOsrKz+v/xpSUhISFSHf8o34NixY3Tu3Flk/url5cX06dM5duxYlQqBuv8RAwMDWrVqxd27d/+RvmqCpBBISPyHCQ4OVonHHx0dzbp160hMTOTmzZsYGRlhY2PzzAg99erVY8OGDXz++edMmTKFRo0aERgYyOnTp2s8+bSwsGDy5MksWLCA69ev06ZNG9auXStaPZ88eTKmpqbs2LGDuLg4rKysmDp1Kv7+tc/wWhW1bdPQ0BA7OzvS09NFpkGurq6kpaWJTLgAZs2axezZs5k3bx76+voMGDAALy8vJk+erFF7c+fOJSIiQsgm/O677xIUFMTs2bM1f2g11K9fn7i4OEaMGMHo0aPZtGmTcG3RokUq5b28vFi+fHmt2pSQkJCoaxS1T/yslitXrvDBBx+Izunr6/PGG29w9erVatWlDFoxcOBAlWtxcXEsWbKE+vXr06VLFyZPniwK8FFXaCkU/5SoJCQk/ssUFRXx9ttv4+XlxcyZM190dyT+RRyz+qhW9z9R6NS6D7UNTf5Eq/Z2vO6yW88v9BzqIsa6di2XBhts3VDrPigeqvoUVbuOp09qdb+Wfu0zf1/oGlnrOrS1aj8tq62ZzDmtZ+dy0YSCOjB1n3J9c63rSLd+T+OyNr9spqCgQOW8qampSrAMmUxGaGgoo0aNEp0fOnQojRo1IjY2VuN2582bx9atW0lKShKZ4U6dOhVPT08sLCy4cuUKq1atoqSkhL1799Y4eERVSDsEEhISGhEXF0ejRo1o1qwZubm5JCQk8ODBA4YNG/aiuyYhISEhIaGW6pgMxcfHq53Ih4SEMG7cuLrslsC+ffuIj49n1qxZKj55//vf/4TXHTt2xM3NjQEDBvDVV18RGhpap/2QFAIJiZeAmJgYYmNjcXZ2Ztu2bSrX1q9fX60wYzW5B+Drr78mPDycU6dOqYQF1dHRYc2aNWRnZ1NaWoq+vj4bNmygVatW1WqjrnhWX+VyOXJ51UunOjo61fZ9GDFiBIaGhoKvw8uMra0tU6ZMITAwUCNZ9OrVC09PT2bNmiWcz8/Px8/Pj5ycHOLj42nVqhU9e/ZUKVcTTA2Kn1/oGegU6z+/0HPIV9Qu8ZrhS5L+tA42Kmq9y1AXq/taxqphiKtdh7ys1nXUFqumqqvLL4Lahto0u1X7MM43dV4OA5SyasjC19eXwYMHq5yvvDugPKduN6GgoAAbGxuN2jtx4gTh4eEEBgYyfPjw55Zv2bIl7du3JzMzU6P6q4OkEEhIvESkpaVx4sQJPDw8alXPRx99JGQirisCAwMJDAwEYNq0aWRkZKjYw78sTJ8+nd27d1d5ff78+bz//vv/H3v04tBEFpXJz8/H39+fe/fukZCQ8MKUPgkJCYnaUp0dAnWmQVXRqlUrrly5Ijr39OlT/vzzT43+Xy5cuEBISAh9+/bV2Gfsn0RSCCQkXhIMDQ1p06YNsbGxtVYIrKyssLKyqqOe/f+nuLgYAwODGt8fEhLyzNWWZs2a1bjul4GysjLKyspE4UqrQhNZVNwif/DgAQEBAdy5c0dSBiQkJP71/FNhR7t3786qVau4f/8+5ubmABw6dIinT58+d0HuypUrfPLJJ7i4uDBv3jyNd6yvXr3KxYsXRXlr6op/JruBhIREjQgODiY1NZVTp05VWebp06dER0fTs2dP7Ozs8PLyIjExUVQmJiYGZ2dn0bnLly8zYsQIHBwc6NmzJ4mJiUybNk2U8ETJnTt3GD16NE5OTvTu3ZuvvvpKbV9+/vlnBgwYgL29Pe+//76KiZJcLmf16tX06tULOzs7+vTpw8aNG9X2NSMjg6FDh+Lg4MDatWufJSYRN2/exM/PD0dHR3r27MmOHTto1qwZ9vb22NvbI5fLWblyJWPHjmXEiBFMnz5dbZz+goICIiIi6N69O3Z2dvTs2ZPFixdX2e7Tp08ZN24c3bp14/Lly+zZsweZTEZRUZFQxtvbG1tbW+7cuSOcGzNmDEFBQcL7JUuWMGDAAJydnenatSvjx4/n9u3boraUkX6++eYb3nnnHezt7blw4QIAu3btolevXjg4ODB8+HAuXbokureiLNQdyj8ypQwCAgLIzs4mPj6e1q1ba/gpSEhISLycKKpxVAcfHx9MTEwICgri559/Zs+ePURERNCvXz/Rb+f06dNFOWxyc3MJDAxET0+Pjz/+mMzMTNLT00lPTxclAF23bh2zZ8/mu+++4/Tp03z11Vf4+vpibm7+j/juSTsEEhIvET169MDe3p7Y2FghYVdlJk2axJkzZwgODqZt27acPn2aOXPmYGRkpHZyD/DkyRP8/f0xMjIiKioKXV1dYWXD2Fg1mkRYWBjvv/8+vr6+7Nu3jy+++IJ27dqJYtHfu3eP2bNnM27cOExMTIiLiyMwMJBDhw7RqFEjABYsWEB8fDyjRo3C1dWVU6dOERUVxaNHj0ThUEtKSpgwYQIjR45kwoQJavtUFRMmTGDIkCEEBgaSlJTEZ599hqWlpbBCc+vWLZydnfH29qZevXqcP3+eiIgISkpKhJXzp0+f4uvry61btwgKCsLW1pbs7GxSUlLUtllUVERISAjXr19ny5YtNG/eHENDQ0pLS0lLS8PDw4OioiIyMjIwMDDg7NmzvPvuu8jlclJSUkTPnpuby6hRo7C0tCQ/P5/4+HiGDh3KgQMHqFfv76gnmZmZ3Lhxg5CQEMzNzWnWrBlHjx5l+vTpvPfeewwYMIBLly6phJnVlMLCQgICAvjrr79ISEioMoa2hISExL+Jf2qHwNTUlPj4eCIjIxk3bhwGBgb0799fxfxHLpdTVva3f8vly5eFRR8/Pz9R2aZNm/Ljjz8C5f4C33//PQcOHODhw4eYm5vj4eHBhAkThP/YukRSCCQkXjJCQkIYPXo0p0+fpnPnzqJrZ86c4dChQ8TFxQkTXnd3d/Lz81m2bFmVCsGuXbvIycnhq6++EuIXu7i48NZbb6mdfA8bNkzIGOzq6sqRI0c4cOCASCHIz88nOjpaUFxcXV3x9PRk48aNhIWFkZeXx+bNm/H392fixIkAdO3alUePHrF27Vr8/PwwMip3XCspKSE0NPSZuRCqYuDAgYwZMwaAbt26cf36dVauXCnIp1+/fkJZhUJBx44dycvLY9u2bYJCsGfPHn799Ve2bdsm2llR51xWUFDAqFGjKCgoYMuWLbz22msANGnShKZNm5KcnIyHhwdpaWnUr1+fXr16kZyczLvvvstvv/1GQUGByPdi7ty5wuuysjLc3Nxwd3fn2LFjvP322yJ5JyYm0rRpU+FcaGgozs7OLFy4ECjfwtbW1iYqKqracvzmm28AJGVAQkLiP0XZP6QQQPmkfd26dc8sExUVJfpN7tSpE7///vtz6+7Zsyc9e/asdR81RTIZkpB4yfD09EQmk7FixQqVaydOnMDMzAwPDw9KS0uFw93dnT///JP8/Hy1dWZkZNC2bVtRMpPGjRvj4uKitnzXrl2F13p6erRo0UJk9gJgYmIi2sUwMzOjU6dOnD9/Hih3mCopKRFNyKF8gq5MwlKRmv7w9enTR/Tey8uLzMxMYUXmwYMHREZG0rNnT2QyGTKZjI0bN3Lt2jXhnlOnTtGqVSsVM6vK3L9/n5EjR1JcXMzmzZsFZUCJq6srZ8+eBSA5OZkOHTrQuXNn0TljY2Pat28v3HP06FF8fHzo2LEjb775Jp07d0Yul4v6B9C2bVuRMlBWVkZGRgbvvPOOyvPXBBcXFwwNDVm4cCGPHj2qUR0SEhISLxsKtDQ+XmUkhUBC4iUkJCSE5ORkYSKpJC8vjwcPHggTW+WhjEdc2fZcyd27d1VCcwJVbjtWjrKgp6dHcbE4VKS6+ho3bsy9e/eA8ok4lGckVtdmReWlfv36wm5Bdan8DI0aNaKkpETIoDxt2jT27duHn58f69atY+fOnfzf//0fT58+Fe7Jz8/H0tLyuW1du3aNixcv0rdvX7XP7+rqyi+//EJxcTHnzp3D1dWVjh07cvXqVXJzczl37hwdOnRAR6c8sdaFCxcICgqicePGREVFkZiYyM6dO9XKu3ISmry8PEpLS1X6UdNkNe3bt2flypX8/vvvBAUFieQjISEh8W9FrtD8eJWRTIYkJF5ClKvZsbGxIvMSMzMzzM3N+fLLL9Xe16JFC7XnLS0tRc5KSnJzc2vcx7w81djjOTk5ggLQoEED4VzFlXRlm8rrQLVzAlQkNzdXpX49PT3Mzc0pLi7mp59+YurUqYwcOVIos2fPHlEdDRo00GgL19nZGQ8PD+bNm0eDBg0YMmSI6LqbmxtPnz7l9OnTXLhwgalTp9K8eXOsrKwEBU8ZuhXg8OHDGBsbs2zZMkFJuH//PiUlJSptV5ZRw4YN0dXVVfkccnJynvscVdGlSxeWLl3K+PHjmTBhAsuXL0dXV/qbkJCQ+Pcif8VX/jVF2iGQkHhJCQ4O5vTp0yLHVg8PD+7fv4+urq7aiDH169dXW5ednR1ZWVn8+eefwrmcnBxSU1Nr3L/CwkJRNKQHDx5w5swZHB0dAbC3t0dPT4/9+/eL7tu/fz+GhoaiqAu1oXLEoIMHDyKTydDR0eHp06fI5XJReM7i4mIOHjwousfd3Z0rV64I5k7PYuTIkUyePJnZs2erKBZvvPEGr732GmvXrkVPTw+ZTAaU7xxs2bKF/Px83NzchPJPnjxBV1cXbe2/f4r37dun0XPr6Oggk8k4cOCAyvPXht69ezN37lx+/PFHZsyYgULxii+bSUhI/KuRTIY0Q1r6kZB4SenVqxdvvvkmp06dwtDQECifuPbu3ZtPPvmEwMBA2rVrR3FxMVevXuXChQtER0erreuDDz5g9erVjBo1itDQUHR0dFi1ahUNGzas8ep8gwYNmDFjBuPGjcPU1FTI4Ovr6wuUr2CPGDGC9evXo6+vj4uLC2fOnGHr1q2MGzdOeKbasnfvXgwMDJDJZCQlJZGWlkZcXBxQ7udgb29PXFwcDRo0ELIrV85xMHDgQLZs2cKoUaOE6E137tzh3LlzREREqLQZGBjI06dPmT59Ovr6+iI/CVdXV5KSkujevbuw6u/q6sqsWbMwNDTEzs5OKOvh4UF8fDyff/45Xl5e/PLLL2zfvh09Pc2y6AYFBTF69GgmT57Me++9x6VLl9i6dWu1ZViZwYMHU1hYyNy5czExMeGzzz4Trv35558qSgiU+3Ion1dCQkLiZeHlyCn+8iMpBBISLzHBwcEqYSSjo6NZt24diYmJ3Lx5EyMjI2xsbJ4ZoadevXps2LCBzz//nClTptCoUSMCAwM5ffq0YGtfXSwsLJg8eTILFizg+vXrtGnThrVr14ps2CdPnoypqSk7duwgLi4OKysrpk6dir+/f43aVMeSJUtYsmQJK1eupFGjRkRERIiSwixevJjZs2czY8YMTExM8PHxQV9fX4jMA6Cvr8/GjRtZunQpcXFx5OfnY2VlRf/+/atsd+zYsZSUlDB58mT09fXp3bs38LdC4OrqKpRVvnZychKZ4PTo0YPJkyezadMmdu/ejYODA6tWrVIxRaoKT09PIiMjWbVqFQcOHBDMzN577z3NhPcMRo4cSUFBATExMZiZmTFu3DigPPfEzz//rFI+NTW1xn4gEhISEv8UZa/4yr+maCmk/WAJiVeSoqIi3n77bby8vJg5c+aL7o7EK0S6de0UlkfFz8/Q/DzyFZrtwlSFXrXTGKniZKc+CMC/jQbrqk7gpylaxqpO+tVGXvb8Mv8wdwbUfQbZmqCQ124SfPxW7TPdZ+rX/jsSeW1Lrev47jUfjcv2u7Ot1u39W3llfQhiYmKwtbUVDmXG19jY2DqPrnHz5k1sbW3VbrO/bHz99dfY2tqqdRitzF9//YWtrS1btmxRe17dKuUnn3yiEoayrvpTkTNnzmBra8svv/zy3HKrV6+uVt3Po7p9VvbV2dlZZbVe0+eoqs6K98XFxbFr1y7OnDnDd999R0BAAA8ePBBlPNR0rNb0c6lL/n9/r9Rlf35ZUWY21hR1GavlcjnTpk0T+SlUldlaQkJC4mVF8iHQjFfaZKhevXrEx8cD5Y6GaWlpxMTE8OjRI6ZOnfqCe/fy06RJE6ysrEhJSRFNKlNTU6lfvz6XLl2isLAQExMToDwpVHp6ukrc9Gfh6elJYmKiShjMuiI5OZn169cLia1eJEVFRWzcuFFI4lUbZDIZiYmJtGrVSjino6PDmjVryM7ORltbGzs7OzZs2CAq87Igl8uRy6u2/JRs1TVDoVCIMmRWRktLS60s5XI5M2bMYN++fSxatKha31lN0Net3Uruk5LaWwWX1nIFtZ6i9n1QlNXBBESr9quwte2H4umTWvdBqy5W97Vr97ugeFL7/Bu6BrUfF1o6tf9MS5/UThaWZaW17sNPL4n1fi2/6q8Mr7RCoK2tjZOTk/C+U6dOXL9+ne+///4/rRA8efKEevXq1UldHTp0IC0tTXQuNTWVXr16cfz4cdLS0ujevTsAly5doqCgQJTt9nk0bNhQbbz3/yKdO3dm06ZN+Pv7i0Jy1gRjY2PR2IZyR9iKIS9fZqZOnSpkzlXH/PnzRdF6XkWKi4tVnKMrk5ycLAq3Whk3Nzc2bdokOqdQKJg5cyZ79+5l0aJF9O3bt076KyEhIfEikMKOasYrazJUFUZGRpSW/q0Zb9y4kQ8++EDIOBoYGMilS5dU7ktLSyMgIAAXFxecnZ356KOPOHHiRJXt/P7773Tt2pXQ0FBKSkrw9fVl0qRJwvWrV69ia2srcr7My8ujXbt2HD58WCgzadIkPD09cXBwoG/fvqxZs0bUf6VZxe7du5k9ezadOnUSnE8fPnxIeHg4Li4udOrUicjIyGqbS3Xo0IFbt26Jstimpqbi4uKCk5OTKGSmMsSlUiFQKBRs3LiRd955Bzs7Ozw9PVm1apUozKE605Q7d+4wduxYHB0d6dq1KytXrmT58uVqzTkKCwv59NNPcXZ2pkePHixbtkxYeY6JiSE2NpaioiLBdGzEiBGizyAkJARXV1ccHR3x9/dX+ezrQoZKAgICBJk8j7179zJw4EDs7e3x8PBg/vz5onbVmQwVFhYydepUoa9z585l27Ztak1/nj59SmRkJG5ubri7uzNnzhyVRFlQPr78/PxwdHSkZ8+e7NixQ6XM4cOHGTx4MPb29kJdFTPhKvt69OhRJk6cSIcOHbh58yY7d+6s8njrrbeE+x8/fsxnn31Gx44dcXNzY968eaI4/jk5OUyfPp1evXrh4OBAnz59+N///seTJ+JVTblczoYNG+jbty92dnZ4eHgwfvx4CgsLq/wc1q5di52dHd999x23b9/G1tZW5HC7ePFibG1tRcrN+vXrcXNzE8bh3r17GTZsGJ06daJjx44MGzaMc+fOidpRmitlZGQwdOhQHBwcWLt2LQDp6el88MEH2Nvb07dvX77//nvhPplM9kw5fv7556J2FAoFs2bNYvfu3SxcuLBa5n0SEhISLyNl1TheZV7pHQJAmDwrTYb27t3L4MGDhevZ2dkMHz6cJk2a8PjxY7Zv346Pjw/79+8XMpumpKTg6+uLo6MjkZGRmJqakpGRwV9//aW2zfPnz/PJJ5/Qu3dvIiMj0dbWxtXVlcTERKHM2bNnMTAwID09ndLSUnR1dYVJgnJCfe/ePaytrenfvz/GxsZkZWURExNDfn6+yg7H4sWL6datG4sWLRJMCGbOnMlPP/3ExIkTsba2ZteuXSox3Z+Hi4uLIIN+/frx8OFDsrKycHFxobCwUKQUpaamYmlpSfPmzQGIiopi69atjBo1ChcXFzIzM4mJiUFbW7tK+2eFQsHYsWO5e/cuc+bMoUGDBsTHx3Pt2jW15WfNmkX//v1ZsWIFx48fZ+XKlbRo0YKBAwfy0UcfkZ2dTVJSkmA6ZmxsDJRPdIcOHUrLli2JjIxET0+P9evXM3LkSL7//nvBDKouZKikYcOGDB06VNglMDMzU1suISGBqKgoRowYweTJk7lx4wZLly7l8ePHfPHFF1XWHx4ezsmTJwkLC6N58+bs3r27yr5GR0fTvXt3lixZwq+//kp0dDSWlpYEBQWJyk2YMIEhQ4YQGBhIUlISn332GZaWlkKUnx9++IGQkBC8vLyYMGECN2/eZMmSJVy7dk1F8Zk5cyb9+/cnJiYGLS0t7O3tnykvpVKxdOlS3N3dWbp0KRkZGcTGxqKvr8+nn34KlGchNjU1JTw8HFNTU65fv87KlSu5desWy5cvF+qLiIggMTERX19f3N3dKSoq4qeffqKoqEj4vCuydOlSNm7cyIoVK4TnbdasGefOnaNbt27A39/jc+fOCT41ycnJdOjQQcg9cOvWLd577z2sra0pKSnhwIED+Pr6smvXLtq1aye0V1JSwoQJExg5ciQTJkzA2NiY3NxcAgICaNWqFUuXLqWoqIgFCxbw5MkTZDIZxsbGz5WjEoVCwezZs9m1axcLFix4ZoQlCQkJiX8L8lokvnyVeKUVgqKiIiFxkJLu3bsTFhYmvJ82bZrwuqysDA8PD3r06MG3334rrN4vXLgQa2trEhISBHvcrl27qm3z1KlTBAUF8eGHHzJ9+nQhBrybmxsxMTFcv34da2trkpOTGThwIHv37iUjIwMnJyeSk5Np06YN5ubmQLmJU6dOnYDyP/MOHTogl8uJiYlhypQpovjybdu2Zf78+cL7K1eusH//fr744gshxGH37t0ZNGgQ2dnZGsvQ1tYWY2NjQSFIT0+nXr16tBoxrnQAACAASURBVG3bloKCAlavXk1JSQl6enqkpKQICsSNGzdISEhg5syZgv+Bu7s7CoWCNWvWMGLECLVx6o8dO0ZmZiYJCQnCs3t4eIhWjCvSp08fwSbf3d2dEydOcPDgQQYOHIiVlRVWVlYqpmMAsbGxGBkZsXHjRsG8ys3Njd69e7Np0yaCgoLqTIYVCQwMZMuWLcTHxzN+/HiV6w8fPiQ6Ohp/f38mT54snDc1NWXy5MmMGjWKZs2aqdx3+fJlDh06xPz583n//fdFfb19WzXSiZ2dHXPmzAHKx3J6ejoHDx5UUQgGDhwo+F9069ZNmGwrJ8ixsbHY29uzbNky4R5zc3MmTpzImTNnhM8QykNw1sRUr3nz5kRFRQl9ePz4MQkJCXzyySeYmZnRunVr0ffYxcUFc3NzQkJCuH//Pubm5vzxxx9s3bqViRMnipRRLy8vlfYUCgURERHs2bOHL7/8UmS65ObmRnJyMlC+c5GRkYGPjw/Hjx8HynchUlJSGDt2rHBPRZnK5XLc3d357bff2Llzpyj+f0lJCaGhoaLwsosXL0ahULB27VpBgWzVqpXwGVeHy5cvc/nyZUJCQiTHYQkJif8MUihNzXilTYbq1asnbJ1v27aNyMhILl68SHBwsGC2kp6eTkBAAJ06deLNN9/E3t6evLw8/vjjD6D8T//8+fMMGjTouY6OR48eZfTo0fj6+jJjxgzRhN3R0RF9fX1hMnHu3Dk8PDxwdHQUzp09e1YU27y4uJjly5fTp08f7O3tkclkzJs3j8LCQnJyckRt9+zZU/T+woULKBQK0YRHS0uLPn36VEuGysm00hwoNTUVJycndHR0cHBwoKSkhIsXL3L37l1u3rwp7G6cPHkShULBO++8Q2lpqXB06dKFhw8fCvKtzC+//IKJiYloIqmvry+KO1+RyopZ69atNZqsHz9+nF69eqGrqyv0rV69ejg5OXHhwgWg7mRYkUaNGgm7BOpMVdLT03n06BH9+vVTkVtZWRm//vqr2nqVpkPKWPlKquqrpnKrfL+XlxeZmZmUlZXx6NEjLl68qGKD7uXlJdrxUlJ5jGqKuj48fvyYrKws4G/TtH79+uHg4IBMJhO+49evXwfg9OnTKBQKPvzww2e2pVAomDZtGt9++y0bN25U8WPo2LEjv/zyC0+ePCEtLQ0DAwN8fX35448/yMnJ4ffff6egoED0Pb5y5QohISF4eHjQvn17ZDIZmZmZar8DlWWUnp5O586dRbtJMplMrVL4PJo0aULr1q3ZvHkzly9frvb9EhISEi8j8mocrzKv9A6Btra2aDvd2dkZU1NTxo8fz9GjR2nbti0BAQHIZDLmzJmDpaUl+vr6hIaGCvbaBQUFyOVywXzoWfz444/o6uoyaNAglWsGBgY4ODhw7tw5OnfuTHZ2Nm5ubmRlZXHu3Dl8fHzIysoSRcNZuHAh27dvJzg4GDs7O0xMTDh58iRLly5Vsfdu1KiR6P29e/fQ09NTMUupmFRKU1xcXFixYgUPHz4kNTWVjh07AlC/fn3atWtHSkoKr7/+OvC3uVNeXh4KhYIuXbqorfP27dsquzcAd+/eVetkXPn5lFSOTqSnp6eRjf/9+/dJSEggISFB5ZrSjKMuZViRwMBAtm7dSnx8vGjiCAi2/lWtAFdlpqbsa2V51FZule9v1KgRJSUl3L9/n9LSUhQKhYo8dHR0aNCgAQ8ePNCoL8+j8nhQtnfv3j0A4uPjiYqKIjAwUJg8X758mfDwcOF7kp+fj66u7nP7UFJSwuHDh+nYsaPa8enm5kZJSQnp6emcPXuWDh060Lx5c5o0acLZs2e5d+8eRkZGvPnmm0D5jk9AQAANGjRgypQpNG3aFAMDA+bOnasi7/r166sk/lKaDVamJmPQyMiIdevWMXToUPz9/dm6dWuNFAsJCQmJlwkpypBmvNIKgTpat24NQFZWFnfu3KGoqIjY2FjRpC8/P194bWJigra2Nnfv3n1u3dOmTWPnzp34+vqyefNmwZZeiaurK9988w3Jycm0bt2ahg0b4urqSnx8PMnJycjlctEE8cCBA3h7e4tMHCqvuirRqmRDZ2FhQUlJCQ8ePBA9W+WdBU3o0KEDZWVlpKSkCP4RSpydnUlJSaFJkyYYGRkJk2kzMzO0tLTYsmULenqqCYLeeOMNtW1ZWlqqjX2fm5tb7X4/CzMzM3r06CEKp6pEaUJUlzKsSOPGjfHx8SEhIYH27dur9AvKnUyVSlZF1J2r2NeCggLRZL+2csvNzeW1114TvdfT08Pc3JwnT56gpaWl0kZZWRn5+fkqilTlMaoplceDUv4WFhZA+fekZ8+eIhOrymZSDRo0oLS0lNzc3GcqBfr6+nz55ZcEBgYSHh5OVFSU4AsA5eZLVlZWnD17lrNnz+Lp6QmU7xwoFQIXFxdhNzE9PZ3s7GxWr14t+qwfPXqkEmlKnXwsLCzUfoY5OTk1ilT12muvsWHDBoYPH05AQABfffWVIEcJCQmJfyNSlCHNeKVNhtTx+++/A+WrjsoJja7u33rTDz/8IIqQYmhoiJOTE3v37n1mvG8oX+Fbs2YNVlZW+Pr6qkxKXF1duXXrFnv27BEm/k5OThQXFxMfH0/Lli1FK3/FxcXo6/+dsVOhUJCUlKTRczo4OKClpcXBgwdF99fEIdbR0RFdXV22bNlCcXExjo6OwjUXFxdSU1NFpkSAsDOQl5eHvb29ylGVQ629vT2FhYWcOXNGOPf06VOOHj1a7X7D3yvflRN2u7u7k5WVJZiJVTzatGkD1K0MKxMYGEhxcbFKSEgXFxcMDQ25ffu2WrlVtTJsZ2cHIESoUlLbvla+/+DBg8hkMnR0dDAyMqJ9+/bs379fVOb777+ntLRU2EmqLer6UL9+fdq2bQuUh9mt+D0B2Ldvn+h9586d0dLSYteuXc9tz8XFhbi4OL7//ntmz56tMnY6duzI8ePHOX/+vGBSpPQtOHv2rMjMSBnpqGL/fvvtN7WRzNTh6OjI6dOnRbstmZmZ3Lx5U6P71WFtbc3atWu5f/8+gYGBFBQU1LguCQkJiRdNmZbmx6vMK71DIJfLSU9PB8qjDV26dInY2FgsLCzo06ePYDMdHh6Oj48Pf/zxB3FxcSomCmFhYfj5+eHn58ewYcMwMzMjMzMTc3NzFZtkY2Nj1q5dK5TftGmTYG7k7OyMrq4uycnJDB06FChXIuzs7EhOTsbb21tUl7u7O4mJidjY2NC4cWO2b9+uYoZRFa1atcLLy4v58+dTXFyMtbU1O3fuVMmUqwn169enffv2HD16lHbt2gmReqB88pSbm0teXh4hISHC+ZYtWzJixAimTp2Kv78/zs7OlJWVcePGDQ4dOlRl6M3u3bsjk8kICwsjLCxMiDKkq6tboxXmVq1aUVpaSnx8PC4uLhgbG2NjY0NoaCgffvgh/v7+eHt7Y2FhQU5ODmlpabRs2ZJhw4bVqQwrY2Fhgbe3txD9SImJiQmhoaEsWrSI7OxsOnfujJ6eHjdv3uTIkSPMnj0bKyvVlPNt2rShT58+REZG8vjxYyHKkLKvFVe5q8PevXsxMDBAJpORlJREWloacXFxwvWQkBCCg4OZNGkSgwYN4tatWyxevJguXbqI/EBqw40bNwgPD6dfv35kZGSwbt06fH19BaXS3d1dMP+ysbHhwIEDXLx4UVRHy5Yt8fHxYdmyZTx48IAuXbrw5MkTfvrpJ8aNGyfaBYFy5X3VqlWMHj0afX19Zs6cKVxzc3MjKSkJIyMjwayoY8eOgoNwxV0+JycnDA0NmTNnDqNGjSI3N5fly5er/QzV4efnx1dffcXHH3/M6NGjKSoqYvny5bU2W2vXrh1xcXEEBAQwatQo1q9fLzj5P3z4UG126A4dOki7CRISEi8dr7pvgKa80jsET548wdvbG29vb0aOHMmXX35Jt27dSExMxMzMDFtbW6Kiorh48SJjxoxh9+7dLF68WMWkoGPHjiQkJKClpUV4eDghISEcPnyYpk2bqm3XxMSE9evXU79+ffz8/ASTB0NDQ2Elt+KkQfm68orqrFmz6Ny5M/PmzWPatGk0bdqU0NBQjZ9/7ty5vP322yxZsoSwsDAaNWqkEkVGUzp06IBCoVDJBWBlZUWTJk2EKEgVmT59Op9++imHDh1izJgxhIWF8fXXXz9z5VhLS4uVK1cKUXBmzJiBk5MTffr0URsa8nm89dZbDBs2jC+//JIhQ4Ywe/ZsoNz0Y8eOHVhYWBAZGUlAQAALFy4kJydH5HdSlzKszMcff6w28ZSfnx8LFy4kNTWV8ePHExISwqZNm7CxsXlmRuf58+fTu3dvFi1aRFhYGKampgwfPhwtLS0V23RNWbJkCSdPniQ4OJjk5GQiIiJEDt69evUiJiaGq1evEhQUxPLly3n33XeJjY2tUXvqUEaRmjBhAuvXr2fo0KGibM/BwcG89957rFixgokTJ1JSUkJERIRKPbNmzWLixIkcPnyYMWPGCPkSqpJNly5diI2NZfv27fzvf/8Tziu/rxVNg1q2bImFhYWg4Ctp3Lgxy5cvJz8/n+DgYNauXUt4eDi2trYaPXvjxo1Zt24dZWVlTJgwgRUrVhAWFoaNjY1G9z8LZ2dnYmJiyMjIYNy4cYJPw+3btwkNDVU5MjIyat2mhMT/Y+/M42rK/z/+at9LUZM1RS5TaVNSSkqTfSfLt91eFNkyQ4bI2KJbRiEtM8hEkqGyG1vRgjBCGG2oUNpU9/7+6HHOr3PPre7tXqaZOU+P+3jorJ/zPufc+3l/Pq/3+83AIG64Qnz+y0hweee7GRj+YXA4HEyZMgXdu3fH/v37/+7m/KNYtGgRioqKaBIaBoYvyaN+otU4qKxtu0KzILzhiFatXZkrehkjw0Fv2t+oPSRE/wnniqiVUD8YLHIbJLt80/5G7R6k7Ux/7cGtq25/o3aomLNU5GNISIl+TxvrRLPFnwWiz/YdVxB9bD7yJb3YpbAc6vU/gbf1LvxF5PP9U/lPS4YY/pkkJCSgqakJurq6qK6uRmJiIp48eULJNc9AJy0tDcXFxWCxWKivr0d6ejouX76MLVu2/N1NY2BgYGBg+CIwkiHB6BQOwaJFi5Cfn49Lly7xXX/q1CmsWbMG8fHxuHLlCm7cuIG//voLSkpKMDMzQ0BAAN/Ue63BZrMpkgUZGRn07NkTEyZMwIIFC2gBiKJSWFgIR0dH7N27F6NHjxbrscXNyZMnERgYiFu3bqFLly7gcFp/ld68eQMHBwcEBQVRsvEUFxdj5MiRYLFYOH36NGWf+fPno6ioCGfPnhW6PUTshpycHA4cOICioiJwOBzo6+sjPDycksI0IyMDbm5uSExMbLNSa0ZGBnJycijpXEVFGBtKSUkhMzMTbm5uUFRUxKVLl8jCc8JcBy/89lNUVERKSgrCwsLQ0NCAvn37YvPmzZQ4F0GfVX73RZxwudw2g/QlJSVRXFz8Vd8rNpuN6Oho5OTkfPFziQpR2C8yMpKsxt4a0tLSWLt2LfLy8ihJCTgcDtatW4eUlBTs2rULo0eP5rtdR6iuE+07tq5JtNFPAJAWUSBQL4bMJVJyYhjdF0NvR0JetHZIyIo22yIuxDHCLyHfMfkkQe1HetY8YeGKIU+mhKRo9/SRrOjXYSj6JJpYYBwCwegUDsHEiROxfPlyZGdnk5VsW5KSkgIdHR1UV1cjPT0d06ZNg4mJCSorKxEZGYkZM2bg9OnTAgfiAc2pI4mAzfr6euTk5IDNZqO6urpD1VL/jaxbtw5JSUmtrg8JCYG2tjaysrIoDkF2djYUFBTw9OlTVFVVkdp+LpeL3NxcoTpv9vb2SEhIoGjjJ0+ezLeWQ0fIzMxEdHS0WB2ClghiQyLWpKamBjExMRT9e0cxMDBAQkIC+vXrRy6ztbWFra2tyMf+GiQlJSEwMLDV9VOmTKEEqTO0Dr96CS0hMqu1hMPh4Pvvv0dKSgp27tzZ6QcyGBjEgajOAEPn5L+ePUhQOoVD4ODgACUlJZw5c4bmEJSXl+P27dtYtGgRzM3NkZqaSkkDamFhATs7OyQmJgrVQSAq7BIMHToUr169Qnp6+r/eIairqyNz6beFr68v5s6d2+r6Xr164fr167QR0+zsbDg6OpLr7OzsAABPnz5FZWUlLbi4LTQ0NL7ICPTXQhAbEhV1raysEB8fD09Pzw7lkG+JsrIy5fn+pzFs2DAkJia2ur7lLMp/lfr6er5B57y0ZUd+cLlcrF+/HsnJydi5cyet0jQDAwPDP4kvOUPw8uVLbN68GdnZ2ZCTk8O4ceOwcuVKKCgotLvvqVOnsH//fhQVFaFPnz7w8fHB2LFjKds0NDQgLCwMSUlJqKqqgpGREb7//ntajSJx0CmyDMnLy+O7775DamoqbXr73LlzaGxsxIQJE6CqqkpxBoDmDqO2trZAhcHaQ0lJiXb+mJgYTJs2Debm5rCysoK3tzffHOE5OTnw8vKCmZkZTE1NMWPGDNy4caPVcz158gTDhw+Hn58fGhoa4O7ujhUrVpDrCwoKwGKx4OnpSS6rqKjAwIEDyVzyBQUFWLFiBezt7TF48GCMGTOGJhEoLCwEi8VCUlISgoKCMHToUEyYMAFAc/rAwMBAmJmZYejQoQgODqZUR+3VqxffXPfER11dHebm5igqKsKbN/8fHEfM9JiYmCArK4uyHPj/asVcLhcxMTEYPXo0DA0NYW9vj59//pmS1/3kyZNgsViU4lNv3rzB4sWLYWxsjOHDh2Pfvn0ICwujZTgCgKqqKqxcuRKmpqYYMWIE9u7dS0p4COlYTU0NWCwWWCwWXF1dKffA19cXFhYWMDY2hqenJ+3ei8OGBF5eXqRN2iM5ORmTJk2CkZERbGxsEBISQjlvRkYGWCwWHjx4QLHFmjVryLZu2bIFx44do9kXaK7tEBwcDEtLS1hbW2Pjxo206tdA8/Pl4eEBY2NjODg44Lff6AFgFy5cwJQpU2BkZEQeq2UtD6KtV69exfLly2Fubo7AwMA27daygm5tbS1++OEHDBkyBJaWlti6dSsaGhrI9WVlZVi3bh0cHR0xePBgODk54aeffiJrABBwOBwcPnwYY8aMgaGhIWxsbLBs2TJUVVW1eh8OHjwIQ0NDnD17FiUlJWCxWPjjjz/I9bt27aJJ56Kjo2FpaUk+h8nJyZgzZw6GDh2KIUOGYM6cObQCg2w2G6ampsjLy8Ps2bMxePBgHDx4EEBzcbNp06bByMgIY8aMQXp6OmXftuzIK0PjcrnYsGEDkpKSsGPHDtqPEwMDA8M/jS+VZaiyshJubm6orq7G3r17sXbtWpw5cwbr1q1rd9/U1FSsWbMGTk5OOHDgAIYNG4YVK1bQaiqFhITg119/xbJly7Bv3z7IyMjAw8OD0ucSF51ihgAAJkyYgKSkJNy8eZMcUQaAM2fOwMjICH379uW7X0lJCYqLizuUZo/oOBOSoeTkZEyZMoWyTWlpKebOnYsePXqgtrYWx48fx6xZs3Du3DmyfkBWVhbc3d1hbGyM4OBgqKqqIi8vD8XFxXzPS1TzHTVqFIKDgyEpKQkLCwskJCSQ29y5cwdycnLIzc1FY2MjpKWlyU4C0aF+9+4ddHR0MG7cOCgrKyM/Px9sNhsfPnygzXLs2rULtra22LlzJ6nNXr9+Pa5cuYLly5dDR0cHJ06cELpQFTGjk5WVhbFjx+LTp0/Iz8+HmZkZqqqqKE5RdnY2tLS0yArN27Ztw9GjR7FgwQKYmZnh4cOHYLPZkJSUpFRfbgmXy8XixYvx9u1bbNy4kaxD8PLlS77bb9iwAePGjUNERASuX7+Offv2oW/fvpg0aRJmzJiB0tJSnDlzhpSPETUUCgsLMXv2bOjq6iI4OBgyMjKIjo6Gm5sb0tPTSRmUOGxIoKGhgdmzZ5OzBK0VZ4uLi8O2bdvg6uqKVatW4fXr1wgNDUVtbS02bdrU6vEDAwNx8+ZNBAQEkHUIWmvrnj17YGdnh927d+PRo0fYs2cPtLS0aClV/f39MXPmTHh7e+PMmTP44YcfoKWlRaYevXjxInx9feHs7Ax/f38UFhZi9+7dePnyJc3xWb9+PcaNGwc2my1UTYnQ0FBYW1sjNDQUeXl5CA8Ph6ysLFauXAmgubK4qqoqAgMDoaqqilevXmHfvn0oKipCWFgYeZzNmzcjISEB7u7usLa2Rk1NDa5cuYKamhq+KW1DQ0MRExODiIgI8np79eqFu3fvktIs4j2+e/cuJk6cCKBZpmZubk7WfigqKsLEiROho6ODhoYGpKamwt3dHSdOnCArewPNI0X+/v5wc3ODv78/lJWVUV5eDi8vL/Tr1w+hoaGoqanB9u3bUVdX165UiBcul4ugoCCcOHEC27dvx7hxomUCYmBgYOgMiCEkgy/Hjh1DZWUlTp06RSoZpKSksHLlSixZsoQsYsoPIvYtICAAQLNCoKCgAGw2m/w9efPmDY4dO4bvv/8eM2fOBNBcjNLR0RGxsbFYvXq1WK+n0zgEVlZW0NTUxO+//046BK9fv0ZOTk6b3hbRAeftyLdHTU0N7QfTzs6OvDkELTPXNDU1wcbGBiNGjMDvv/9Ojt7v2LEDOjo6iIuLI/OODx8+nO95b926hSVLlmD69OlYt24d2fGxtLQEm83Gq1evoKOjg8zMTEyaNAnJycnIy8uDiYkJMjMzoa+vT44qDx06lCzuROT553A4YLPZWL16NaVTNWDAAISEhJB/P3/+HOfOncOmTZvIB83Ozg6TJ08mC7IJAovFgrKyMukQ5ObmQl5eHgMGDEBlZSX279+PhoYGyMjIICsri3QgXr9+jbi4OKxfv56MP7C2tgaXy0VkZCQZFMnLtWvX8PDhQ8TFxZHXbmNjg5EjR/Jtn5OTE6nJt7a2xo0bN5CWloZJkyZBW1sb2traNPkYAISHh0NJSQkxMTGkvMrS0hKjRo1CfHw8lixZIjYbtsTb2xtHjhxBbGwsli1bRlv/6dMn7NmzB56enli1ahW5XFVVFatWrcKCBQsoo+cEz549w/nz5xESEoKpU6dS2spbMRsAWecBaH6Wc3NzkZaWRnMIJk2aRMZf2Nrakp1t4gstPDwcRkZG2Lt3L7mPuro6li9fjoyMDEpxshEjRnRIrte7d29s27aNbENtbS3i4uIwf/58qKmpoX///pT32MzMDOrq6vD19cX79++hrq6OFy9e4OjRo1i+fDnFGXV2dqadj8vlYvPmzTh16hQOHDhAqTxMVCQGmmcu8vLyMGvWLFy/fh1A8yxEVlYWFi9eTO7T0qYcDgfW1tb4888/kZiYSBYzA5odAj8/P3KGD2h29LlcLg4ePEg6kP369SPvsTA8e/YMz549g6+vL8aPHy/0/gwMDAydkS8lGbp27RqsrKwosmZnZ2esW7cO165da9UheP36NQoKCmjxguPHj0dgYCAqKiqgoaGB69evo6mpiTJTq6ysjJEjR+LatWtidwg6hWQIaPaqxo0bh/Pnz5PShDNnzpDL+REZGYlLly5h69atrY6mtoa8vDwSExORmJiIY8eOITg4GI8fP4aPjw9FspKbmwsvLy8MHToU3377LYyMjFBRUYEXL14AaP7Rv3fvHiZPnkw6A61x9epVLFy4EO7u7vj+++8pHXZjY2PIysqSnYm7d+/CxsYGxsbG5LI7d+5QCpbV19cjLCwMTk5OMDIygoGBAbZu3YqqqiqUlZVRzu3g4ED5+/79++ByuZQOj4SEBJycnIQxI9mZJuRA2dnZMDExgZSUFAYPHoyGhgY8fvwYb9++RWFhITm7cfPmTXC5XIwePRqNjY3kZ9iwYfj06RNpX14ePHgAFRUVSkdSVlaWUgyrJbyOWf/+/QXqrF+/fh2Ojo6QlpYm2yYvLw8TExPcv38fgPhs2JKuXbuSswT8pCq5ubmorq7G2LFjaXZramrCo0eP+B6XkA6NGjWKsry1tgpqN979nZ2d8fDhQzQ1NaG6uhqPHz+madCdnZ0pM14EvM+ooPBrQ21tLRmbQciwxo4di8GDB8PAwIB8z1+9egUAuH37NrhcLq2yOC9cLhdr167F77//jpiYGIozADQXD3zw4AHq6uqQk5MDOTk5uLu748WLFygrK8OTJ09QWVlJeY+fP38OX19f2NjYYNCgQTAwMMDDhw/5vgO8NsrNzYWVlRXl+8/AwICvU9gePXr0QP/+/fHLL7/g2bNnQu/PwMDA0BlpEuIjDM+fP0f//v0py2RlZdGnTx8UFBS0uh+xrmXSDwDksYj1z58/R7du3Wgxc/3798fLly/bzGDYETrNDAHQLBuKiYnBpUuXMGbMGPz+++8YNmwYunXrRts2KSkJoaGhWL9+fYc6EpKSkhT9rKmpKVRVVbFs2TJcvXoV9vb2KC4uhpeXFwwMDLBx40ZoaWlBVlYWfn5+pF67srISHA6HlA+1xaVLlyAtLc03Q46cnBwGDx6Mu3fvwsrKCqWlpbC0tER+fj7u3r2LWbNmIT8/n5INZ8eOHTh+/Dh8fHxgaGgIFRUV3Lx5E6GhoTS9N2915Xfv3kFGRobmSPGzdXuYmZkhIiICnz59QnZ2NllpWEFBAQMHDkRWVha6d+8O4P/lThUVFeByuZRUoS0pKSnhK3l4+/Yt3yBj3usj4K3cKyMjQ9Hat8b79+8RFxeHuLg42jpCxiFOG7bE29sbR48eRWxsLKXjCIDU+rc2AtyaTI1oK689RLUb7/5du3ZFQ0MD3r9/j8bGRnC5XJo9pKSk0KVLF3z8+FGgtrQH7/NAnO/du3cAgNjYWGzbtg3e3t5k5/nZs2cIDAwk35MPHz5AWlq63TY0NDTgwoULGDJkCN/n09LSEg0NDcjNzcWdO3dgbm6O3r17o0ePHrhz5w7evXsHJSUlfPvttwCaZ3y8vLzQpUsXrF69Gj179oScnBy2bNlCDbnYxwAAIABJREFUs7eCggKtajIhG+SlI8+gkpISDh06hNmzZ8PT0xNHjx7tkGPBwMDA0JkQRjJUWVmJyspK2nJVVVXa72JlZSVtGbEt7+9bS4h1vPsSfQlifWVlJV+5qpqaGhoaGlBTU0PKnMVBp3IIDA0NoaenhzNnzkBXVxdPnz7FvHnzaNtdvHgRP/zwAxYuXNhmBhdhIbyz/Px82Nvb448//kBNTQ3Cw8Mpnb4PHz6Q/1dRUYGkpKRAQc1r165FYmIi3N3d8csvv5BaegILCwucPn0amZmZ6N+/PzQ0NGBhYYHY2FhkZmaCw+FQOoipqalwcXGhSBx4R10JeDXZmpqaaGhowMePHynXxjuzIAjm5uZoampCVlYWGR9BYGpqiqysLPTo0QNKSkpkZ1pNTQ0SEhI4cuQIZGTo+Y779OnD91xaWlq0AFigORuVOFFTU8OIESMo6VQJCAmROG3Ykm7dumHWrFmIi4ujZRIgzsNms0knqyX8lrVsK+8XmKh2Ky8vxzfffEP5W0ZGBurq6qirq4OEhATtHE1NTfjw4QPNkRImbqAlvM8DYX9NzeZKm6mpqXBwcKBIrHhlUl26dEFjYyPKy8vbdApkZWVx4MABeHt7IzAwENu2bSNjAYBm+ZK2tjbu3LmDO3fuwN7eHkDzzAHhEJiZmZGzibm5uSgtLcX+/fsp97q6upqWaYqffTQ1Nfnew7Kysg5lqvrmm29w+PBhzJ07F15eXvj1119JOzIwMDD8ExFmHD02NpZSp4rA19cXS5eKXoW6M9NpJEMEEyZMwLVr13DkyBHIy8vTJA6ZmZlYvnw5Jk2aJJZ87S0h8nETI45Eh6ZlZqOLFy9SMqQoKirCxMQEycnJbRZSAppH+CIjI6GtrQ13d3dap8TCwgJFRUU4deoU2fE3MTFBfX09YmNjoaurSxn5q6+vpxRR43K5AhcMGjx4MCQkJJCWlkbZvyMBscbGxpCWlsaRI0dQX18PY2Njcp2ZmRmys7MpUiIA5MxARUUF38wnrUnAjIyMUFVVhYyMDHLZ58+faZH5gkKMfLeUiQHN8Qb5+fmkTKzlh9AFitOGvHh7e6O+vh7x8fGU5WZmZlBUVERJSQlfu7U2MmxoaAgAZIYqAlHbyrt/WloaDAwMICUlBSUlJQwaNAjnzp2jbJOeno7GxkZyJklU+LVBQUEBAwYMAND8HvMWG0xJSaH8bWVlBQkJCZw4caLd85mZmSEqKgrp6ekICgqiPTtDhgzB9evXce/ePVJSRMQW3LlzhyIzIjIdtWzfn3/+yTeTGT+MjY1x+/ZtymjUw4cPUVhYKND+/NDR0cHBgwfx/v17eHt78x0tY2BgYPinIEyWIXd3d1y8eJH2cXd3px1XVVWV7/djZWVlmzJ2Yh3vvsT3OLFeVVWVr3T448ePkJGR4RtnKQqdaoYAaHYI9u7di+PHj2PMmDGU6ZDnz59jyZIl6N27N6ZNm4bc3FxynbKyMk3L1RYcDofcv7GxEU+fPkV4eDg0NTVJTbKVlRWA5uwss2bNwosXLxAVFUWTKAQEBMDDwwMeHh6YM2cO1NTU8PDhQ6irq9M0ycrKyjh48CC5fXx8PCk3MjU1hbS0NDIzMzF79mwAzU6EoaEhMjMz4eLiQjmWtbU1EhISoKenh27duuH48eNtTlO1pF+/fnB2dkZISAjq6+uho6ODxMREvH//XmAbEigoKGDQoEG4evUqBg4cSLlnZmZmKC8vR0VFBaVOhK6uLlxdXbFmzRp4enrC1NQUTU1NeP36Nc6fP99q6k07OzsYGBggICAAAQEBZJYhaWnpDo0w9+vXD42NjYiNjYWZmRmUlZWhp6cHPz8/TJ8+HZ6ennBxcYGmpibKysqQk5MDXV1dzJkzR6w25EVTUxMuLi5k9iMCFRUV+Pn5YefOnSgtLYWVlRVkZGRQWFiIy5cvIygoiG+BPn19fTg5OSE4OBi1tbVkliGirS1HuYUhOTkZcnJyMDAwwJkzZ5CTk4OoqChyva+vL3x8fLBixQpMnjwZRUVF2LVrF4YNG0aJAxGF169fIzAwEGPHjkVeXh4OHToEd3d38kvV2tqalH/p6ekhNTUVjx8/phxDV1cXs2bNwt69e/Hx40cMGzYMdXV1uHLlCpYuXUqZBQGanfeff/4ZCxcuhKysLNavX0+us7S0xJkzZ6CkpETKioYMGUIGCLec5TMxMYGioiI2btyIBQsWoLy8HGFhYQIXWfTw8MCvv/6KefPmYeHChaipqUFYWJjIsrWBAwciKioKXl5eWLBgAaKjo8kfn0+fPiE1NZW2j7m5OTObwMDA0OngCJFQlJ80qDX69euH58+fU5Z9/vwZf/31V5uJHYismAUFBZQ4AuJYxPp+/fqhvLwcHz58oMz4Pn/+HH379u3w73ZrdLoZgt69e8PU1BRcLpeSTQNoTtdZVVWFZ8+eYc6cOXBxcSE/P/74o1DnqaurI/d1c3PDgQMHYGtri4SEBLIjwWKxsG3bNjx+/BiLFi1CUlISdu3aRZMUDBkyBHFxcZCQkEBgYCB8fX1x4cIFsgItLyoqKoiOjoaCggI8PDxIyYOioiI5ktuy00D8n3dEdcOGDbCyssLWrVuxdu1a9OzZE35+fgLbYMuWLfjuu++we/duBAQEoGvXrrQsMoJibm4OLpdLqwWgra2NHj16kFmQWrJu3TqsXLkS58+fx6JFixAQEICTJ0+2OXIsISGBffv2kVlwvv/+e5iYmMDJyYmv1q49Ro4ciTlz5uDAgQOYOXMmgoKCADQ/h7/99hs0NTURHBwMLy8v7NixA2VlZZTYE3HakJd58+bxLTzl4eGBHTt2IDs7G8uWLYOvry/i4+Ohp6fX5hdZSEgIRo0ahZ07dyIgIACqqqqYO3cuJCQkaNp0Qdm9ezdu3rwJHx8fZGZmYvPmzZQAb0dHR7DZbBQUFGDJkiUICwvD+PHj+U7JdhRiptDf3x/R0dGYPXs2ZfbQx8cHEydOREREBJYvX46GhgZs3ryZdpwNGzZg+fLluHDhAhYtWkTWS2jNNsOGDUN4eDiOHz+On376iVxOvK8tpUG6urrQ1NQkHXyCbt26ISwsDB8+fICPjw8OHjyIwMBAsFgsga69W7duOHToEJqamuDv74+IiAgEBAR0KA0zL6ampmCz2cjLy8PSpUvJmIaSkhL4+fnRPnl5eSKfk4GBgUHccIT4CIOdnR1u375NGQQ8f/48Pn/+3GqiE6C5f6Gnp4ezZ89SlhNp9olB5+HDh0NSUpIyy15dXY1Lly5R0vOLCwku73w3A8M/DA6HgylTpqB79+7Yv3//392cfxSLFi1CUVERTULDwPAludNTuDTRvFQ3ij65XS3iBLmE0GWM6Fia0FP+CgtXDIlGJEQ0p+rPu0Rvg6JwmQL5wf1c1/5GbbVBvmMDIy0pdORfQ0cYuGJInC8hKdrzeabim/Y3+gosff2LyMfYqCN4rOnGV78KvG1lZSXGjx+Pnj17YsmSJSgvL8e2bdswbNgwhIaGktutW7cOp06domQBPHfuHJnm2traGhcvXkRcXBwiIyMpzsSmTZuQnJyMtWvXokePHoiOjkZeXh5Onz5Nm7kWlU4nGWJgaI+EhAQ0NTVBV1cX1dXVSExMxJMnTyi55hnopKWlobi4GCwWC/X19UhPT8fly5exZcuWv7tpDAwMDAwMX4QvVZhMVVUVsbGxCA4OxtKlSyEnJ4dx48ZRElgAzYOWvDGmY8aMQV1dHfbv349Dhw6hT58+2LVrF21mITAwEIqKitizZw+qqqpgZGSEw4cPi90ZAP6FMwRNTU20IL+WtAwQZmgbDofTZp5bKSmpDmeGEQWiIFRRURE4HA709fWxePFiWgC6uGCz2QgPD4epqSmOHTtGWxcdHY2cnBy++/KzYUREBA4fPoy7d+8KZcOTJ08iMDAQt27d4pt6lWDt2rXIy8ujBZj/8ccfCA0NxYsXL9DQ0IC+ffvCzc2NLKomTjIyMuDm5sZ3nbGxMY4fP97m/lwul/IFGhERAWtra1KSJikpKXb95JeGKJh29uxZvHr1ClwuFzo6Ovjuu+/g5uYGVVVV0m6JiYkUaZooEBXZW+Pv+E6sWiZa4bPnyaLf+9I60QLyxPH0yQqd+ZxPO8TwFdzIFe0gqjLtp3JuD+2eogevS8uJNl1S+5Ge8U5Yel2MFPkY4Ij+XIhKoZPo0lfPctG7l1cKL7S/UTv80JeeLbA1gl8eEfl8/1T+db1jJycnFBUVtbr+4sWLTG5tAVm3bh2SkpJaXd+y6u3XZPLkyXxrOXxpcnJycOPGDdjY2Ai8T1s2NDAw+Ko2tLW1ha2t7Vc5F0FISAhNzy5IvEJSUhICAwMpy/bt20f+f8qUKWR14n8CHz9+hIeHB169egVXV1dYWFhASkoKeXl5OHLkCCorK9usyC4K/OoltITIrsbAwMDwb+RfNer9BfnXOQQ///xzm4WnBCkgxtCMr69vm3Ue/kuOlaKiIvT19REeHi6UQ/BvtGF9fT3fYGd+6Ovrd2ike+TIkUhMTCT/nj59OlxdXTFp0iQAoFVuJKirqyPrRHQmNm3ahIKCAiQkJJC1OIDmwGRXV1ey0veXoKUdGRgYGP5riLee77+Xf9acuwCwWCy++dmJD28+cobW6dWrV5u2bK1T9m/Fx8cH2dnZuHXrVqvbfP78GXv27IGDgwMMDQ3h7e2NR48eUex25coVuLm5UWz47NkzuLq6YvDgwXBwcEBCQgLWrl2L8ePp0oo3b95g4cKFMDExwahRo/Drr/yDoP744w9MmDABRkZGmDp1Kk3WxOFwsH//fjg6OsLQ0BBOTk60dK9sNhumpqbIy8vD7NmzMXjwYBw8eFBIy7WOq6srFi5ciPT0dIwZMwYmJiaYPXs23r17R9qLSN0bHx+P6dOnY/r06eQsIIvFQlRUFEJDQzF8+HAyk1V9fT1++ukn2NrawtDQEOPHj0dycjLl3IR927JTcHAw7O3tabKv7OxssFgsgTryJSUlOHv2LFxcXCjOAIG8vDysra0py6qqqrBy5UqYmppixIgR2Lt3L6UNBQUFWLFiBezt7TF48GCMGTMGkZGRFHlQYWEhWCwWXrx4geTkZHh7e2PhwoU4ceIEBgwYQNoXALKysjB16lQYGRlh7NixuHDhAnlvWlJQUABfX19YWFjA2NgYnp6eAtdMYGBgYPg74IAr8Oe/zL9uhoCB4UsxYsQIGBkZITw8nCysxsuKFSuQkZEBHx8fDBgwALdv38bGjRuhpKTEt3MPNI9qe3p6QklJCdu2bYO0tDR+/vlnvH//nm9Z8oCAAEydOhXu7u5ISUnBpk2bMHDgQEpa13fv3iEoKAhLly6FiooKoqKi4O3tjfPnz5Npc7dv347Y2FgsWLAAFhYWuHXrFrZt24bq6mr4+PiQx2poaIC/vz/c3Nzg7+8vVKl0DodD07Dz6v8fP36M/fv3w8/PD9LS0ti+fTuWLl2Kc+fOQVJSEgkJCXBxcYGrqytpw5Y1R+Li4mBoaIjNmzejoaEBALBy5UpcvXoVfn5+GDBgAFJTU7F69WpwuVyK3Kw9O7m4uCA+Ph43btygyK0SExPRr18/mJmZtWsDosp4W2noeNmwYQPGjRuHiIgIXL9+Hfv27UPfvn3JGZJ3795BR0cH48aNg7KyMvLz88Fms/HhwwesWbOGcqw9e/bAzs4Ou3fvxqNHj7Bnzx5oaWmR6XHfvn2LefPmgcViITQ0FLW1tdi+fTtqamoocqPCwkLMnj0burq6CA4OhoyMDKKjo+Hm5ob09PQOpf1lYGBg+NL8/REZ/wwYh4CBQQh8fX2xcOFC3L59myxcR5CRkYHz588jKiqK7PxZW1vjw4cP2Lt3b6sOwYkTJ1BWVoZff/0Vffr0AdCcw37kyJF8O99z5szB//73PwDNOe8vX76M1NRUikPw4cMH7Nmzh3RcLCwsYG9vj5iYGAQEBKCiogK//PILPD09yZz9w4cPR3V1NVk4j9D6NzQ0wM/Pj1YXRBD4BSx7eXlROq2VlZU4efIkpZiWj48Pnjx5gkGDBsHExAQA0L17d/L/LVFRUcG+fftIJ+PPP/9Eeno6NmzYQMq1bG1t8fbtW4SFhVEcgvbspK+vD1NTUyQmJpIOQXV1Nc6dOydwGfs3b96Q7RcUJycn8r5YW1vjxo0bSEtLIx2CoUOHkoXdiBofHA4HbDYbq1evpgSqEzU7gOZ7nJubi7S0NNIhiImJgaSkJA4ePEg+b/3796fF6YSHh0NJSQkxMTGkLMvS0hKjRo1CfHy82OpvMDAwMIiT//rIv6AwDgEDgxDY29vDwMAAERERNIfgxo0bUFNTg42NDWVUnKgozVttkCAvLw8DBgwgnQGgueAUUeWZl+HDh5P/l5GRQd++fclOJ4GKigplFkNNTQ1Dhw7FvXv3AAD3799HQ0MDxo4dS9lv7NixOHr0KB4/fkwpEOfg4NCmXVrjp59+olRiBECrZjtw4ECKM0BsX1paikGDBrV7Dnt7e8qMQ1ZWFgDwvba1a9eipKSE7Jy3ZycAcHFxwfr16/H+/Xuoq6vj7NmzaGhoEDqwXZiMXC3vMdDcQX/x4gX5d319PSIjI5GSkoKSkhJyZgQAysrKKDbmdyzCRgDw4MEDDB06lOJ8Dho0CL1796bsd/36dYwZMwbS0tLk8y0vLw8TExPcv39f4GtjYGBg+Jow7oBgMA4BA4OQ+Pr6YvHixbhz5w5leUVFBT5+/NhqVpeSkhK+DsHbt2/5phHt2rUrX4eAtxqxjIwM6uvrKcv4Ha9bt25kR/Djx48A6J1zQk704cMHcpmCgkKHKxn369ev3aBiojI4gYxMc+o/3mtqDd7K4R8/foS0tDQtxoXY7uPHj6RD0J6dgOZ80Vu3bkVycjI8PDzw22+/wcHBoc3Ury0h8kWXlJRAV1dXoH343eOWyRJ27NiB48ePw8fHB4aGhlBRUcHNmzcRGhpKs1t7xyLkR7zw2vX9+/eIi4tDXFwcbVt+sREMDAwMnQEmqFgwGIeAgUFIHBwcYGBggPDwcMooupqaGtTV1XHgwAG++/Xt25fvci0tLUoFQwJ+zoCgVFRU0Ja1HDkmHJOysjJKgRPinC0dl7+j1oQw8LZPTU0NjY2NtBkZ4tpaOiDt2QloHgWfOHEiTpw4ARsbG9y7d48SY9EelpaWkJSUxLVr12jBwx0lNTUVLi4ulKDfu3fvduhYmpqafO1QXl5OsZ+amhpGjBiBOXPoOb07Y2YnBgYGBgDgMnMEAvGvyzLEwPA18PHxwe3btykjyTY2Nnj//j2kpaX5ZmVSUFDgeyxDQ0Pk5+fjr7/+IpeVlZWJlIqyqqqKkg3p48ePyMjIgLGxMQDAyMgIMjIyOHfuHGW/c+fOQVFREd9++22Hz/0l4DcL0hpELAW/a+vZsydFy9+enQhmzpyJ/Px8/Pjjj+jevbtQ9Ry6d++OsWPH4tixY3xz/tfX17eZuYof9fX1lIxpXC6XVohOUIyMjHD79m18+vSJXPb48WO8fv2asp21tTXy8/Px7bff0p5tfX39Dp2bgYGB4UvTCK7An/8yzAwBA0MHcHR0xLfffotbt25BUbG54qm1tTVGjRqF+fPnw9vbGwMHDkR9fT0KCgpw//597Nmzh++xpk2bhv3792PBggXw8/ODlJQUfv75Z2hoaHR4dL5Lly74/vvvsXTpUqiqqiIysrl6pru7O4BmqYyrqyuio6MhKysLMzMzZGRk4OjRo1i6dCl5TaLy9OlTWsl2GRmZdotl8aKnp4cLFy5gyJAhUFBQgK6ubqvZjgYOHAhnZ2ds27YNdXV16N+/P9LS0nD16lX89NNPlG3bsxMBi8WCiYkJ7ty5gyVLlghdJXnDhg14/vw55syZAzc3N1hYWEBCQgKPHz/Gr7/+CkdHx1YzV/GDiEvR09NDt27dcPz4cVIGJiweHh44evQo5s2bh3nz5qG2thZsNhuampqU58/Pzw/Tp0+Hp6cnXFxcoKmpibKyMuTk5EBXV5fvzAEDAwPD381/u5svOIxDwMDQQXx8fGjSkT179uDQoUNISEhAYWEhlJSUoKen12aGHnl5eRw+fBg//vgjVq9eja5du8Lb2xu3b9/G+/fvO9Q2TU1NrFq1Ctu3b8erV6+gr6+PgwcPUoJ3V61aBVVVVfz222+IioqCtrY21qxZA09Pzw6dkx+81YaBZo3+jRs3hDrOhg0bsHXrVsyfPx91dXWIi4sjs+zwY8eOHQgNDcWhQ4fw4cMH6OjoYPv27WSWHgJB7ETg5OSEe/fuYdq0aUK1HWiW2xw9ehSxsbE4e/YsoqOjweVyoaurS6aQFYYNGzYgKCgIW7duhaysLCZMmABnZ2esWrVK6LZpaWnhwIED2Lp1K/z9/dGzZ0/4+/sjKiqKkkq0d+/e+O2337B3714EBwejqqoKmpqaMDExwcSJE4U+LwMDA8PXgMkyJBgSXC6XsRQDQyejpqYG3333HZydnbF+/fq/uzn/StauXYu8vDyBpTZubm6QlpZGdHT0F27Z38+bN2/g5OQEf39/eHl5if34Vcv4p+AVlOfJoqtdS+tEmwUTh95WVgwZ0iXFEOLTyBXtIKoyn9vfqB20e1aKfAxpOdHCR2s/yojchl4XI0U+Bjh/f+b8QifR0wh7lovevbxSeEHkY8zvO0PgbQ+8/E3k8/1T6ZQxBGw2GywWi/wYGhrC2dkZ4eHhlOwY4oCo5pmamirW434JTp48CRaLxTcAkJfi4mKwWCwcOXKE73J+I3rz58+npWoUV3takpGRARaLhQcPHrS73f79+4U6dnsI22airaamprTRekGvo7VjttwvKioKJ06cQEZGBs6ePQsvLy98/PiRIsMQ9Fnt6H0RNy3fYd6PoPEABCdPnkRKSsoXamnbPHjwADExMcjIyBB6JJ+XlJQUuLq6wsLCAoaGhnB0dMSGDRvw8uVLchsWi4VDhw6J2Grh2LlzJ1JSUpCRkYFTp07By8sLCgoKQqdWZWBgYOhscIX491+m00qG5OXlERsbC6A5gC4nJwdsNhvV1dW0SpwMdHr06AFtbW1kZWVROpXZ2dlQUFDA06dPUVVVRUoCuFwucnNzMXr0aIHPYW9vj4SEBFpaQ3GRmZmJ6OhoLFq06IscXxhqamoQExNDFosSBQMDAyQkJFDy80tJSSEyMhKlpaWQlJSEoaEhDh8+TMvh3xngcDjgcFofiZOSkiK15y2rC7ekZUCsICQlJUFRUbFDxdFEZfr06VBWVsbChQtp1Ya5XC4tRqIlEhISkJKSAtAsn0pKSsLkyZPh7u4ONTU1vHz5EidOnIC/vz9OnTr1Ra+jLZqamrB79268e/cOcnJyMDc3R2hoqMCpVb820lL/jkSCHIg+vC8phk5Mk4jtkJToHB0pCSnR2sHliGG6RRyj+5JSIh+C+7lWpP1VtEUffK15J/IhxMK/49viy9NpHQJJSUlKVdKhQ4fi1atXSE9P/1c7BHV1dWJL4Wdubo6cnBzKsuzsbDg6OuL69evIycmBnZ0dgObgz8rKSkq12/bQ0NDotB0GcWNlZYX4+Hh4enryrSUgDMrKyrSKu97e3vD29hbpuF+LNWvW4PTp062uDwkJwdSpUwG0Xl34S9HU1ISmpiaBHI5t27YJdEx+mYEIMjMz4ebm1up6S0tLxMfHIyEhASdPnsSmTZvg4uJCrrewsMCMGTNw6dIlgdrypVizZs2/+nuVgYHhv0vTf3zkX1A6pWSoNZSUlCgVYGNiYjBt2jSYm5vDysoK3t7eePr0KW2/nJwceHl5wczMDKamppgxY0abQY1PnjzB8OHD4efnh4aGBri7u2PFihXk+oKCArBYLErwZUVFBQYOHIgLFy6Q26xYsQL29vYYPHgwxowZg8jISEr7CQlIUlISgoKCMHToUHIE9NOnTwgMDISZmRmGDh2K4OBgoeVS5ubmKCoqolSxzc7OhpmZGUxMTCgpM4kUl4RDwOVyERMTg9GjR8PQ0BD29vb4+eef0TLkhJ805c2bN1i8eDGMjY0xfPhw7Nu3D2FhYTA1NaW1r6qqCitXroSpqSlGjBiBvXv3kiPPbDYb4eHhqKmpIWUmrq6ulHvg6+sLCwsLGBsbw9PTk3bvxWFDAi8vL9Im7ZGcnIxJkybByMgINjY2CAkJoZyXn2SoqqoKa9asIdu6ZcsWHDt2jK/05/PnzwgODoalpSWsra2xceNGvhKcwsJCeHh4wNjYGA4ODvjtN7o28sKFC5gyZQqMjIzIY1VXV9PaevXqVSxfvhzm5uYoLCxEYmJiq5+RI0cKYlIAzffZ1NQUT58+xdy5c2FsbIwxY8YgLS2N3MbV1RWZmZm4cuUK+Syw2Wxy3cKFC3H69GmMHj0aRkZGZNXchIQEjBkzhnx+Q0NDKe8f8fzev3+/VTudP38eLBaLIukBmh33IUOGICMjo01b/PjjjwCAQ4cO4dtvv6U4Ay3hrQTN5XIRHh6O4cOHw9LSEsuXL6dkEaqrq8PmzZsxevRoGBsbY+TIkVi3bh2loBxx3E2bNuHo0aNwcHCAmZkZ5s2bh5KSEsp2gr63nz59QnBwMGxtbWFoaIgJEyaQ33kMDAwMnREOlyvw579Mp50hAED+eBOSoeTkZEyZMoVcX1pairlz56JHjx6ora3F8ePHMWvWLJw7dw5aWloAgKysLLi7u8PY2BjBwcFQVVVFXl4eiouL+Z7z3r17mD9/PkaNGoXg4GBISkrCwsICCQkJ5DZ37tyBnJwccnNz0djYCGlpabIoENGhJqp/jhs3DsrKysjPzwebzcaHDx9oI3G7du2Cra0tdu7cScoP1q9fjytXrmD58uXQ0dHBiRMncP78eaHsZ2ZmRtpg7Nix+PTpE/Lz82FmZoaqqiqKU5SdnQ0tLS307t0bQPPo6dGjR7FgwQKtpgagAAAgAElEQVSYmZnh4cOHYLPZkJSUpBRDagmXy8XixYvx9u1bbNy4EV26dEFsbCytM0WwYcMGjBs3DhEREbh+/Tr27duHvn37YtKkSZgxYwZKS0tx5swZUjpGpJksLCzE7Nmzoauri+DgYMjIyCA6Ohpubm5IT08nZVDisCGBhoYGZs+eTc4S8FbXJYiLi8O2bdvg6uqKVatW4fXr1wgNDUVtbS02bdrU6vEDAwNx8+ZNBAQEoHfv3khKSmq1rXv27IGdnR12796NR48eYc+ePdDS0sKSJdQgMH9/f8ycORPe3t44c+YMfvjhB2hpaZGyl4sXL8LX1xfOzs7w9/dHYWEhdu/ejZcvX9Icn/Xr12PcuHFgs9mQkJBot/owAYfDoXTCAaqMBgAaGhqwYsUKzJ07F4sXL0Z8fDxWrFiBtLQ09OrVC0FBQVi1ahXk5eXJd0dbW5vc/+HDh3j9+jV8fX2hrq6OXr16IT4+HsHBwZg9ezbWrVuHx48fIywsDO/evcPWrVsFttPIkSOhqamJEydOICAggNwnNTUVNTU1cHFxoRR240dpaSlevXollPTt119/hbGxMbZs2YKSkhL89NNP2L59O7Zs2QKg2SFoaGiAn58funXrhtLSUkRFRWHevHlITEykHOvy5csoKCjADz/8gOrqaoSEhCAwMJC8x4K+tw0NDfDy8kJpaSmWLl2Knj17Ii0tDUuXLsUvv/wi1OwiAwMDw9fiv93NF5xO6xDU1NTQcpXb2dlRfpTXrl1L/r+pqQk2NjYYMWIEfv/9d3L0fseOHdDR0UFcXBzZCRk+fDjfc966dQtLlizB9OnTsW7dOlIHbWlpCTabjVevXkFHRweZmZmYNGkSkpOTkZeXBxMTE2RmZkJfXx/q6uoAmiVORFpELpcLc3NzcDgcsNlsrF69mpLfe8CAAQgJCSH/fv78Oc6dO4dNmzZh5syZ5LVPnjwZpaWlAtuQxWJBWVmZdAhyc3MhLy+PAQMGoLKyEvv370dDQwNkZGSQlZVFOhCvX79GXFwc1q9fT8YfWFtbg8vlIjIyEq6urnzz1F+7dg0PHz6kpIS0sbFpdcTYycmJ1ORbW1vjxo0bSEtLw6RJk6CtrQ1tbW2adAwAwsPDoaSkhJiYGFJeZWlpiVGjRiE+Ph5LliwRmw1b4u3tjSNHjiA2NhbLli2jrf/06RP27NkDT09PSvpHVVVVrFq1CgsWLECvXr1o+z179gznz5+nSG2ItvKO5ALNhcw2btwIoPlZzs3NRVpaGs0hmDRpEtkJtbW1xatXr7Bv3z7SIQgPD4eRkRH27t1L7qOuro7ly5cjIyODktZzxIgRHZKU7Ny5Ezt37qQsMzAwwMmTJ8m/CYeAeE4MDAxgY2ODCxcuwMPDA/3794eysjIUFRX5yo8+fPiAhIQE9OzZE0Dzd0FERARGjx5N2snW1hYSEhLYtWsXFi9eTDq+7dlJWloa06ZNI3X+xHdIYmIi7Ozs2nUGAJAzdC0LorWHhoYGpW7F8+fPkZSURDoEXbp0oTiYjY2N6N+/PyZPnoyHDx9SvjubmpoQGRkJOTk5AM0ViENCQlBZWQlVVVWB39uUlBTk5eUhKSkJLBaL3K6oqAhsNlug2TMGBgaGrw2TdlQwOq1kSF5enpx2P3bsGIKDg/H48WP4+PiQspXc3Fx4eXlh6NChZPXMiooKvHjxAgBQW1uLe/fuYfLkyZQRSX5cvXoVCxcuhLu7O77//ntKh93Y2BiysrLIzMwEANy9exc2NjYwNjYml925cwcWFhbkPvX19QgLC4OTkxOMjIxgYGCArVu3oqqqCmVlZZRz88oF7t+/Dy6XC2dnZ3KZhIQEnJychLIh0Zkm5EDZ2dkwMTGBlJQUBg8ejIaGBjx+/Bhv375FYWEhOcJ38+ZNcLlcjB49Go2NjeRn2LBh+PTpE2lfXh48eAAVFRVKR1JWVpYWiEnA65j1799foM769evX4ejoCGlpabJt8vLyMDExIeUi4rJhS7p27UrOElRVVdHW5+bmorq6GmPHjqXZrampCY8ePeJ7XEI6NGrUKMry1toqqN1493d2dsbDhw/R1NSE6upqPH78GGPGjKFt03LGi4D3GRUUNzc3moxmx44dlG0kJSVhY2ND/q2urg4NDQ2K1K0tBgwYQDoDQLOc7P3797SMWWPHjgWXy6VI5YC27QQAM2bMQFlZGa5evQoAePnyJe7cuYPp06cL1D4CYYrM8bvHVVVVFDnXqVOnMGXKFJiamsLAwIDMCMQ7sm9hYUE6A8SxAJDPjKDv7Y0bNzBgwAD069eP8nzb2NgInWmLgYGB4WvBZBkSjE47QyApKUmRJZiamkJVVRXLli3D1atXMWDAAHh5ecHAwAAbN26ElpYWZGVl4efnR+q1KysrweFwSPlQW1y6dAnS0tJ80+zJyclh8ODBuHv3LqysrFBaWgpLS0vk5+fj7t27mDVrFvLz8ymSgB07duD48ePw8fGBoaEhVFRUcPPmTYSGhtL03l27dqX8/e7dO8jIyNBkKfyKJbWHmZkZIiIi8OnTJ2RnZ2PIkCEAAAUFBQwcOBBZWVnkyCXhEFRUVIDL5bZaObWkpIRvpdm3b9/yDTLmvT4C3uxEMjIyAmn8379/j7i4OMTFxdHWDRw4EIB4bdgSb29vssBUSwcQAKn1J0b5eWlNpka0ldceotqNd/+uXbuioaEB79+/R2NjI7hcLs0eUlJS6NKlC63qbWttaQ9tbe125UXy8vK0IGBZWVmBU5PyXgPRdt7lxN/tXVtLO3Xr1g29evWCjY0NEhMT4eDggMTERHTr1g329vYCtY+YRWjt/vOD3z0GmgcalJSUcP78eaxZswYzZsyAv78/unTpgsrKSsybN49mN953oOWxAMHf24qKCjx+/LjVKtPEjAMDAwNDZ4LJMiQYndYh4AcxspWfn483b96gpqYG4eHhlB+8lkF1KioqkJSUxNu3b9s99tq1a5GYmAh3d3f88ssvFEkB0DzKdvr0aWRmZqJ///7Q0NCAhYUFYmNjkZmZCQ6HQ+kgpqamwsXFhaK35x11JeAdOdTU1ERDQwM+fvxIuTbemQVBMDc3R1NTE7Kyssj4CAJTU1NkZWWhR48eUFJSIjvTampqkJCQwJEjR8jOQ0v69OnD91xaWlp8c9+Xl5cL3e62UFNTw4gRIyjpVAkICZE4bdiSbt26YdasWYiLi8OgQYNo7QKaA2X5yUNak4wQbeXtUIlqt/Lycoqkpby8HDIyMlBXV0ddXR0kJCRo52hqasKHDx9onUhhRre/NrxtI7JA8V4bce95r60tOxHMnDkTK1asQGlpKU6dOoXJkydDWlqwr09tbW307dsXf/zxh1jS1gLN3y8DBw5EcHAwuSwvL69DxxL0vVVTUwOLxSJlS7zwkxEyMDAw/N00MS6BQHRayRA/iPR/GhoaZIem5Y/yxYsXKVPqhOY4OTm5zVzhQPOIeWRkJLS1teHu7k7TbltYWKCoqAinTp0iO/4mJiaor69HbGwsdHV1KSOS9fX1lFFPLpcrcEXUwYMHQ0JCgpJphcvldigg1tjYGNLS0jhy5Ajq6+thbGxMrjMzM0N2djZFSgSAnBmoqKiAkZER7dNaQK2RkRGqqqqQkZFBLvv8+TMptRAWYuSbt5i2tbU18vPzSZlYy4++vj4A8dqQF29vb9TX1yM+Pp6y3MzMDIqKiigpKeFrt9ZmJwwNDQGAlq1F1Lby7p+WlgYDAwNISUlBSUkJgwYNwrlz5yjbpKeno7GxkZxJ6izIyMgIPGOgq6sLDQ0N2rWdO3cOEhIStODXtuxE4ODggC5dumDlypV49+6d0HIhLy8vPHz4kG+mJ6A58FcY6urqaLMqHS3cJuh7a2Njg9evX0NLS4vv8y2og8TAwMDwNeEI8fkv02m/wTkcDnJzcwE0B8w9ffoU4eHh0NTUhJOTE6l/DQwMxKxZs/DixQtERUXRpr4DAgLg4eEBDw8PzJkzB2pqanj48CHU1dVpP+rKyso4ePAguX18fDwpNzI1NYW0tDQyMzMxe/ZsAM1OhKGhITIzM2npBK2trZGQkAA9PT1069YNx48fp0kVWqNfv35wdnZGSEgI6uvroaOjg8TERFqlXEFQUFDAoEGDcPXqVQwcOJDM1AM0d2DLy8tRUVEBX19fcrmuri5cXV2xZs0aeHp6wtTUFE1NTXj9+jXOnz/favCgnZ0dDAwMEBAQgICAADJbibS0dIdGmAmtcmxsLMzMzKCsrAw9PT34+flh+vTp8PT0hIuLCzQ1NVFWVoacnBzo6upizpw5YrUhL5qamnBxcSGzHxGoqKjAz88PO3fuRGlpKaysrCAjI4PCwkJcvnwZQUFBlOw4BPr6+nByckJwcDBqa2vJLENEWyUlO+a3JycnQ05ODgYGBjhz5gxycnIQFRVFrvf19YWPjw9WrFiByZMno6ioCLt27cKwYcMoenJRKCkpId/jlgwaNIiia28PPT09JCUl4eLFi9DS0oKWllarAb1SUlLw8fHB5s2boaGhgZEjR+LRo0cICwvD1KlTabN/7dkJaHZIpk6diqioKAwZMgS6uroCtx0AXFxckJOTgw0bNiA7OxujRo2Cqqoq/vrrL5w4cQI1NTVCpWu1trbGpk2bwGazYW5ujps3b3a4loGg7+2kSZNw/Phx/O9//4OXlxf09PRQVVWF/Px8vHv3DkFBQR06PwMDA8OXhHdQkYE/ndYhqKurIzvZUlJS0NbWhq2tLZYuXQo1NTWoqalh27ZtCA8Px6JFizBgwADs2rWLzCpCMGTIEMTFxWHPnj0IDAyEpKQk9PX14e/vz/e8KioqiI6Ohru7Ozw8PPDLL79AQ0MDioqKMDQ0RG5uLkUaZGFhgZycHNqI6oYNGxAUFIStW7dCVlYWEyZMgLOzMyX7TFts2bIFmzdvxu7duyEtLY3x48djyZIlHfrRNTc3x4MHD2g5xbW1tdGjRw8UFxfTRk3XrVsHPT09HDt2DJGRkZCXl0efPn3a7LRISEhg37592LhxIzZu3AglJSXMnDkT/fv379Bo98iRIzFnzhwcOHAA5eXlsLCwQHx8PHr37o3ffvsNe/fuRXBwMKqqqqCpqQkTExNMnDiR3F+cNuRl3rx5OHbsGG3U2sPDA9ra2jh8+DCOHDkCKSkp9OzZE3Z2dm3qq0NCQrB582bs3LkT0tLSGDt2LObOnYvdu3dDSUmpQ23cvXs3du/ejX379qFr167YvHkzJVDU0dERbDYbERERWLJkCVRUVDB+/HisXLmyQ+fjR3x8PG0mBQDOnj0rVBXm+fPn46+//sLatWtRWVkJX19fLF26tNXt//e//0FGRgaHDx9GQkICNDQ04OXlxXef9uxE4OTkhKioKKFnBwi2bdsGGxsbJCQkYPXq1aivr4e2tjaGDx8OLy8voY41a9YsFBYW4tixY4iOjoaVlRXCwsL4xkC1h6DvraysLGJiYhAREYEDBw7g7du3UFNTw4ABAzBjxgyhz8vAwMDwNehMWYbu37+PkJAQPHz4EGpqapgxYwZ8fHzaTHzz9u1bxMTE4MaNG/jrr7+gpKQEMzMzBAQEQEdHh9yusLAQjo6OtP319fUFUqhIcBnXieELwuFwMGXKFHTv3h379+//u5vzj2LRokUoKirqsBSEoW1OnjyJwMBA3Lp1S6CK2+Hh4YiJicEff/wBBQWFr9DCv48v/d5WLRsv0v6vBFNftklhtXL7G7WBOPS20mIQKUhLiP4TXs8V7Wq6ytaJ3AatHvTMbcIio9i2NLg9qssEn7Vsjd4XI0Q+BiTbzoooCNzPtSLtX+m5pP2N2mGsGJKPZRZ3THLckgl9BP++SflLDF8urfD69WtMmjQJlpaWcHd3R0FBAbZv3w5XV9c2B+IuX76MLVu2YNq0aTAxMUFlZSUiIyNRWFiI06dPk8oDwiFYsWIFZZZfXl6ejBFti047Q8DwzyQhIQFNTU3Q1dVFdXU1EhMT8eTJE0rNCAY6aWlpKC4uBovFQn19PdLT08kvAYa/l4KCArx48QKxsbFwcXH5VzoDzHvLwMDwb6WzBBUfPHgQqqqqCAsLg6ysLIYNG4aqqipERERg3rx5ZEIMXszNzZGamkqJ07KwsICdnR0SExMpkm8A0NHR4Vuzpz3adAgWLVqE/Pz8VrWpp06dwpo1axAfH48rV660O53RHmw2G+Hh4eTfMjIy6NmzJyZMmIAFCxbQguhEhfCm9u7di9GjR4v12OKGdzSTw+GAw+H/kBcXF8PJyQlBQUGUTDzFxcUYOXIkWCwWTp8+Tdln/vz5KCoqwtmzZzvUHgI5OTkcOHAARUVF4HA40NfXR3h4OBmonJGRQeambysdZUZGBnJycoSq7ipsm9uyIdCcFcrd3R2Kioq4dOkSJeuMoNfBS2v7KSoqIiUlBWFhYWhoaEDfvn2xefNmUp4i6LMq7Kh3R+ByuW0G6UtKStIyMLXk/v37QsUPnDx5EjIyMpgwYYJQ7RQXQUFByM3NhY2NDa34GwBaJWZeiC/xlJQUHD9+HH/++Sdqa2vxzTffwMbGBl5eXujbty+A5mKCq1evhre3t9ivoy3ae2/FTqNoI7l1n0UfyRW1iyCOLoa8GEb3JcQgh5AR8Wo4XNGzkHE5oh+jsU60kXUJyc4hmBB1dB8AJGRFG7j46xH/zqkwqEu1n0b8a9BZhDDXrl3DqFGjKH3Z8ePHIzQ0FLdv3271t52f3FhDQwPa2toCZdEUlDYdgokTJ2L58uXIzs4mq9i2JCUlBTo6OqiurkZ6ejptOmPGjBmU6QxBkJeXJ4M16+vrkZOTAzabjerq6g5VSv23sm7dOiQlJbW6Xk1NDVlZWRSHIDs7GwoKCnj69CmqqqqgoqICoPllyc3NFcopsre3R0JCAu1BnTx5cod0zLxkZmYiOjparA4BL+3ZkEjRWlNTg5iYGLGkjDQwMEBCQgJNP29rawtbW1uRj/81SEpKQmBgYKvrp0yZAgBwdXXF+PH0qVphHfukpCQoKiqK3SGYOnVqqzUjWsIvBqIlreXlJ3jy5AkCAwORlJSEyZMnw93dHWpqanj58iVZAfnUqVNCtV3ciOu9ZWBgYOhsdIb5gZqaGhQXF9N++3v16gUFBQUUFBQIdbySkhIUFxdDT0+Ptu7HH3/EihUroKKiAgcHB6xcuVKgWkJtOgQODg5QUlLCmTNnaA5BeXk5bt++jUWLFgk9ndEWRHVdgqFDh+LVq1dIT0//1zsEdXV1ZB799vD19cXcuXNbXR8ZGYmcnBzKsuzsbDg6OuL69evIycmBnZ0dAODp06eorKykBRa3hYaGxhcbgf5atGdDolKulZUV4uPj4enp2eqUnqAoKyt3aCqvs1BXV4eRI0ciMTGx1W3U1dWRlJSE7t27f9VrbWpqQlNTk9hnEtujLVvg/9g797iYs/+Pv7pMpatEksuSlNVNUbrnnly22EXWthRLKlJY6reEQmuV0oWyS2WXxFcuWSpJ2NBFrVUIYbu6dDGl+zS/P3rM59unmZqZxqX97nn2mD/mfM7nnPM5c6Z5v895X9BhjnPmzBns3LmTFo3M2NgYCxcu7HV0IAKBQCDwR5gMxEwmE0wmk6tcUVFRpMSLdXV1VDu82hY0CiWHgIAAKCoqUhtwQMdm25IlS2BpaQlFRUUUFBTg0KFDyM/PR2JiIl/5skdPIhkZGcycOROXL1/mOha/dOkS2traMG/ePCgqKnLFoH6fxxlycnJc/cfExODLL7/EhAkTYGpqihUrVuDx48dc9+bl5cHFxQVGRkYwNDTEwoUL8ccff3Tb16NHj2BpaQlPT0+0trZi2bJl8Pb2pq4XFxdDW1sbzs7OVFl1dTXGjh1LxZEvLi6Gt7c3Jk+eDH19fdjZ2SEqKor2DKWlpdDW1kZiYiL8/PwwadIkage0vr4ePj4+MDIywqRJkxAQEMCViXbYsGE8Y4FzXmZmZigrK6OEWgDUSc/48eORm5tLKwf+m6mYzWYjJiYGs2bNgq6uLiZPnoyDBw/Sjt3OnDkDbW1tWkKjly9fYs2aNTAwMIClpSUiIyNx4MABruhGQMeXY+PGjTA0NISNjQ1CQ0Mp8x2O6VhDQwO0tbWhra0NJycn2mfg4eEBY2NjGBgYwNnZmeuzfx9zyDlBcXFxoeaEH+fOnYO9vT309PRgYWGBPXv20Pq9c+cOtLW18ddf//W2qqurw+bNm6mx7tq1C/Hx8VzzC3TEhw8ICICJiQnMzc2xfft2nvH5S0tLsXz5chgYGGDq1Kk8499fuXIF8+fPh56eHtVW5zwenLFmZGTAy8sLEyZMgKurK5SVlXuct2HDhvGdJ6DjczY0NMTjx4+xdOlSGBgYwM7OjpY7wsnJCVlZWbh27Rq1FsLCwqhrq1evxvnz5zFr1izo6enh3r17ADqEcDs7O2r97t+/n/b946zfe/fudTtPqamp0NbWxvPnz2njbmpqwsSJEyln257mQk9PD7/88gvGjRvHFZqYw9SpU2nv2Ww2wsPDYWlpCRMTE3h5edF+LJqamuDv749Zs2bBwMAAU6ZMga+vLy0pI6fdnTt34sSJE5g6dSqMjIywcuVKrhwrgn5v6+vrERAQACsrK+jq6mLevHlcuTMIBAKhr9EOtsCv2NhYTJs2jevVNcw40PHb/fTpU76vxkbRTcA6ExUVhatXr2L37t20vFCqqqrYvn07pk+fDhMTEzg7OyMsLAzFxcUCRRni61Q8b948JCYmIjMzk9pRBoCkpCTo6elRtq9d6ek4gx+cH26OydC5c+doWhAAVFZWYunSpVBXV0djYyMSEhLg6OiIS5cuUbkDcnNzsWzZMhgYGFDa1P3791FeXs6zX04m3+nTpyMgIADi4uIwNjbGyZMnqTrZ2dmQlpZGfn4+2traICkpSWUg5gjUr1+/xmeffYY5c+ZAXl4eRUVFCAsLQ21tLdcpR1BQEKysrLBv3z7KLnvr1q24du0avLy88Nlnn+E///mP0GE7OSc6ubm5mD17Nurr61FUVAQjIyPU1dXRlKK7d+9CVVWVis8eGBiIEydOYNWqVTAyMkJBQQHCwsIgLi5Oy7zcGTabjTVr1uDVq1fYvn07Fcu8qzDFYdu2bZgzZw4iIiJw8+ZNREZGYuTIkbC3t8fChQtRWVmJpKQk6kvIyZ9QWlqKJUuWYNSoUQgICACDwcCRI0fw7bffIiUlhRLi38ccchgwYACWLFlCnRJ0l5gtLi4OgYGBcHJywqZNm1BSUoL9+/ejsbERO3fu7LZ9Hx8fZGZmYsOGDVQOgu7GGhISAmtrawQHB6OwsBAhISFQVVXlsm1fv349Fi1ahBUrViApKQk//PADVFVVqXCaaWlp8PDwgK2tLdavX4/S0lIEBwfj+fPnXIrP1q1bMWfOHISFhQmVT6K9vZ1LkRcTE6OFV2ttbYW3tzeWLl2KNWvW4NixY/D29kZycjKGDRsGPz8/bNq0CTIyMtR3p7MJYkFBAUpKSuDh4QFlZWUMGzYMx44dQ0BAAJYsWQJfX188ePAABw4cwOvXr7F7926B52nKlCkYNGgQ/vOf/2DDhg3UPZcvX0ZDQwPX/yReVFZW4sWLF0KZvv32228wMDDArl27UFFRgR9//BF79+6lHMybmprQ2toKT09PDBw4EJWVlYiOjsbKlSu5TivS09NRXFyMH374Ae/evcOePXvg4+NDfcaCfm9bW1vh4uKCyspKrF27FkOHDkVycjLWrl2LX3/9VajTRQKBQPiYCONDsGzZMp7/23nt7KempvZoPsshLi6O8hnkdfrAZDK7lSu6kpiYiP3792Pr1q1cm0m8MDExgYqKCgoKCviGzOarEJiammLQoEG4ePEipRCUlJQgLy8Pvr6+3d7H6zhDEBoaGrhscq2trWk/yABo0S9YLBYsLCxgY2ODixcvUrv3P/30Ez777DPExcVRQoilpSXPfm/dugU3Nzd89dVX8PX1pQQfExMThIWF4cWLF/jss8+QlZUFe3t7nDt3Dvfv38f48eORlZWFMWPGUE6nkyZNokI+sdlsTJgwAe3t7QgLC8P3339PE6q0tLSwZ88e6v3Tp09x6dIl7Ny5E4sWLaKe38HBgUrGJgja2tqQl5enFIL8/HzIyMhAS0sLTCYThw4dQmtrKxgMBnJzcykFoqSkBHFxcdi6dSvlf2Bubg42m42oqCg4OTlBVlaWq7/r16+joKAAcXFx1LNbWFh0m7dgxowZlE2+ubk5/vjjDyQnJ8Pe3h5qampQU1PjMh8DOkI/ysnJISYmhjr+MjExwfTp03Hs2DG4ubm9tznszIoVK3D8+HHExsZi3bp1XNfr6+sREhICZ2dnWq4JRUVFbNq0CatWreK5c/7kyROkpqZiz549lD07Z6xdd3KBjqzGnFwblpaWyM/PR3JyMpdCYG9vTwmhVlZWePHiBSIjIymFIDw8HHp6eggNDaXuUVZWhpeXF+7cuUMLWWZjY9Mrc719+/Zh3759tDIdHR2cOXOGes9RCDjrREdHBxYWFrhy5QqWL18OTU1NyMvLU1nHu1JbW4uTJ09i6NChADr+F0RERGDWrFnUPFlZWUFMTAxBQUFYs2YNLTFZT/MkKSmJL7/8krLz5/wPOX36NKytrbtNjNYZzgndkCFDBJ02DBgwACEhIdT7p0+fIjExkVII+vfvT1Mw29raoKmpCQcHBxQUFND+f7JYLERFRVFO3FVVVdizZw+YTCYUFRUF/t5euHAB9+/fR2JiIrS1tal6ZWVlCAsLE+j0jEAgED4FwkQZEsY0SFA/NA7q6up4+vQpraysrAyNjY0CbZ6npaXhhx9+wOrVq3s0d+4tfIMPS0hIYM6cOUhNTaVME5KSkqhyXnR3nCEIMjIyOH36NE6fPo34+HgEBATgwYMHcHd3p2l5+fn5cHFxwaRJkzBu3JzlNxQAACAASURBVDjo6emhuroaz549AwA0Njbizz//hIODQ48JHwAgIyMDq1evxrJly/B///d/NIHdwMAAUlJSyMrKAtARecbCwgIGBgZUWXZ2Ni1ZWXNzMw4cOIAZM2ZAT08POjo62L17N+rq6vDmzRta3101vHv37oHNZsPW1pYqExMTw4wZM4SZRkqY5pgD3b17F+PHj4eEhAT09fXR2tqKBw8e4NWrVygtLaV2+DIzM8FmszFr1iy0tbVRLzMzM9TX11Pz25W//voLCgoKNEFSSkqKZ4IngFsx09TUFEhYv3nzJqZNmwZJSUlqbDIyMhg/fjxlLvK+5rAzKioq1CkBxxawM/n5+Xj37h1mz57NNW8sFguFhYU82+WYDk2fPp1W3t1YBZ23rvfb2tqioKAALBYL7969w4MHD2BnZ8dVp/OJFwdBdiF4wYmm1Pn1008/0eqIi4vDwsKCeq+srIwBAwbQTN16QktLi1IGgA5zspqaGsyePZtWb/bs2WCz2TRTOaDneQKAhQsX4s2bN8jI6IiF/fz5c2RnZwudnEyYkxVen3FdXR3NnOvs2bOYP38+DA0NoaOjQzkEd93ZNzY2pkV00tTUBABqzQj6vf3jjz+gpaVFZQ/nvCwsLGjmbwQCgdDXaGezBX59SKytrZGWlkYzI7548SIVgrQnsrKy4OXlBXt7e6ECnNy+fRtVVVUCRUMUKA/BvHnzEBMTg6tXr8LOzg4XL16EmZkZBg4cyFVX2OOMroiLi9MGbmhoCEVFRaxbtw4ZGRmYPHkyysvL4eLiAh0dHWzfvh2qqqqQkpKCp6cnNdFMJhPt7e2U+VBPXL16FZKSkjyjbEhLS0NfXx85OTkwNTVFZWUlTExMUFRUhJycHDg6OqKoqIhmEvDTTz8hISEB7u7u0NXVhYKCAjIzM7F//34ue++unt+vX78Gg8HgUqR4zTU/jIyMEBERgfr6ety9e5fKptyvXz+MHTsWubm51M4lRyGorq4Gm83udnFWVFTwjKry6tUrnk7G3Xm2d9XAGQwGl40/L2pqahAXF4e4uDiua5zEG+9zDjuzYsUKnDhxArGxsTQFEABl69/dbkF3ZmqcsXadD1Hnrev9KioqaG1tRU1NDdra2sBms7nmQ0JCAv379+dybhIkOgEv1NTU+P4TkpGR4XIClpKS4ukXwYuuz8AZe9dyznt+z9Z5ngYOHIhhw4bBwsICp0+fxtSpU3H69GkMHDgQkydPFmh8nFOE7j5/XvD6jIGOjQY5OTmkpqZi8+bNWLhwIdavX4/+/fuDyWRi5cqVXPPW9TvQuS1A8O9tdXU1Hjx40G1EJc6JA4FAIPQ1+kbQUWDlypW4cOEC1q9fDycnJxQXFyMyMpKKPMdh2bJlKC8vp0yHnz59Cjc3NwwfPhxffvkl8vPzqbry8vLURk9gYCDExMQwfvx4ykQ+OjoaWlpa3W7gd0YghUBXVxcaGhpISkrCqFGj8PjxY6xcuZKr3oc6zuA8bFFRESZPnowbN26goaEB4eHhtEns7FSnoKAAcXFxgZyat2zZgtOnT2PZsmX49ddfaSYFQMcu2/nz55GVlQVNTU0MGDAAxsbGiI2NRVZWFtrb22kC4uXLl7F48WKavX3XXVcOXXcOBw0ahNbWVrx9+5b2bF1PFgRhwoQJYLFYyM3NpfwjOBgaGiI3Nxfq6uqQk5OjhGklJSWIiYnh+PHjlPDQmREjRvDsS1VVlcsBFugwUXifKCkpwcbGhhZOlQPHhOh9zmFnBg4cCEdHR8TFxXHF2ef0ExYWxtM8pDuTEc5YuwpUos5bVVUVzaSlqqoKDAYDysrKaGpqgpiYGFcfLBYLtbW1XEKkMLvbH5uuY+NEger6bJzPvuuz9TRPHBYtWgRvb29UVlbi7NmzcHBw4Aqi0B1qamoYOXIkbty48V7C1gId/1/Gjh2LgIAAquz+/fu9akvQ762SkhK0tbW7TZTHy4yQQCAQ+gLtfUQlGD58OGJiYrB7926sWrUKSkpKcHZ25orE2d7eTsv18+eff6Kurg51dXVcso+JiQkVGnv06NE4ceIETp06hcbGRqiqquKLL77AunXrBMr9I3Cm4nnz5uHgwYNQUVGBjIwMl4lDb48zBOHRo0cAQO1kcQSazj/KaWlptCN1js3xuXPn4OLi0qPZUL9+/RAVFYUVK1Zg2bJl+O2332gCnLGxMQ4ePIizZ89Sgv/48ePR3NyM2NhYjBo1irYj2dzcTNv1ZLPZAnl4A4C+vj7ExMSQnJxM2b+z2exeOcQaGBhAUlISx48fR3NzMwwMDKhrRkZGCAgIQGVlJWVKBIA6Gaiurub6jHtCT08PdXV1NPvzlpYWytRCWDg732w2myb0mZubo6ioCOPGjev2M32fc9gVzilB19j0RkZGkJWVRUVFBWbOnClwe7q6ugA6Iv50Pl0QdaypqakYN24c9T45ORk6OjqQkJCAnJwcPv/8c1y6dIkWLSslJQVtbW3USVJfgcFgCHxiMGrUKAwYMACXLl2ifQ6XLl2CmJgYl/NrT/PEYerUqejfvz82btyI169fC20u5OLigm3btuHUqVNYuHAh1/X09PRufW140dTUxHWqcuHCBaHGxEHQ762FhQUyMjKgqqoqkO8EgUAg9BX6ikIAdMgn8fHxPdbpKl8I6quwcOFCnr8xgiKUQhAaGoqEhATY2dlRUV8AwY8zBKG9vZ26v62tDY8fP0Z4eDgGDRpE2fuampoC6IjO4ujoiGfPniE6Oprr6HvDhg1Yvnw5li9fjq+//hpKSkooKCiAsrIy14+6vLw8fv75Z6r+sWPHKHMjQ0NDSEpKIisrC0uWLAHQoUTo6uoiKyuLK5ygubk5Tp48CQ0NDQwcOBAJCQkCx5gdPXo0bG1tsWfPHjQ3N+Ozzz7D6dOnUVNTI/AccujXrx8+//xzZGRkYOzYsbTPzMjICFVVVaiurqZpp6NGjYKTkxM2b94MZ2dnGBoagsVioaSkBKmpqd06D1pbW0NHRwcbNmzAhg0bqGglkpKSvdph5tgqx8bGwsjICPLy8tDQ0ICnpye++uorODs7Y/HixRg0aBDevHmDvLw8jBo1Cl9//fV7ncOuDBo0CIsXL+YKQaagoABPT0/s27cPlZWVMDU1BYPBQGlpKdLT0+Hn58czQd+YMWMwY8YMBAQEoLGxkYoyxBmruDhfNx+enDt3DtLS0tDR0UFSUhLy8vIQHR1NXffw8IC7uzu8vb3h4OCAsrIyBAUFwczMjGZPLgoVFRW0/wUcPv/8c6EyFWtoaCAxMRFpaWlQVVXtUSiVkJCAu7s7/P39MWDAAEyZMgWFhYU4cOAAFixYwHX6x2+egA6FZMGCBYiOjsbEiRMxatQogccOAIsXL0ZeXh62bduGu3fvYvr06VBUVMTff/+N//znP2hoaBBKITA3N8fOnTsRFhaGCRMmIDMzs9e5DAT93trb2yMhIQHffPMNXFxcoKGhgbq6OhQVFeH169fw8/PrVf8EAoHwoWGx+0Jqsr6PwArB8OHDYWhoiLy8PK6MoYIeZwhCU1MTJWBLSEhATU0NVlZWWLt2LXXcr62tjcDAQISHh8PV1RVaWloICgqioopwmDhxIuLi4hASEgIfHx+Ii4tjzJgxWL9+Pc++FRQUcOTIESxbtgzLly/Hr7/+igEDBkBWVha6urrIz8+nmQYZGxsjLy+Pa0d127Zt8PPzw+7duyElJYV58+bB1taWFn2mJ3bt2gV/f38EBwdDUlISc+fOhZubW69+dCdMmIC//vqLK6a4mpoa1NXVUV5ezrVr6uvrCw0NDcTHxyMqKgoyMjIYMWJEj0KLmJgYIiMjsX37dmzfvh1ycnJYtGgRNDU1e7XbPWXKFHz99dc4fPgwqqqqYGxsjGPHjmH48OE4deoUQkNDERAQgLq6OgwaNAjjx4/HF198Qd3/PuewKytXrkR8fDzXrvXy5cuhpqaGo0eP4vjx45CQkMDQoUNhbW3do331nj174O/vj3379kFSUhKzZ8/G0qVLERwcDDk5uV6NMTg4GMHBwYiMjISKigr8/f1pjqLTpk1DWFgYIiIi4ObmBgUFBcydOxcbN27sVX+8OHbsGM/v/u+//86VrbEnvvvuO/z999/YsmULmEwmPDw8sHbt2m7rf/PNN2AwGDh69ChOnjyJAQMGwMXFhec9/OaJw4wZMxAdHS306QCHwMBAWFhY4OTJk/j+++/R3NwMNTU1WFpawsXFRai2HB0dUVpaivj4eBw5cgSmpqY4cOBArzINC/q9lZKSQkxMDCIiInD48GG8evUKSkpK0NLSEmlHikAgED40wiQm+zcjxhYmQCuBIATt7e2YP38+hgwZQiVxIgiGq6srysrKem0KQuiZM2fOwMfHB7du3RIo43Z4eDhiYmJw48YN9OvX7yOM8NPxMb63dW52/Cv1wKPzgp8wdcerVsGywn9I5MVY/CvxQew9CDsstmh+QvKMVpHHMHgId/Q2YRGXFG0uWhp6jkgoCMNSI0Vug93GP8AGP8SkRPs/9Zeh6KbfPhD9OZJLLoncxsQhVgLXzam4IXJ//1R6Z49AIPDg5MmTOH78OG7duoUrV67Azc0Njx49wrJly95bH7wy/QoCJzP05cuXe6zHKwPzhyY5ORlHjx5FZmYm0tPT4ePjg/T0dL7zdubMGZ4KQ3fl75M7d+7wFBY/xfwJAye7saAUFxcjLS0NsbGxWLx48f+kMtD1e7tgwQI8fPgQ33777aceGoFAIIiMMJmK/80IbDIkKiwWq8dscYJG7SB07OC1t3dvEychIfFJIsNIS0vj8OHDKCsrQ3t7O8aMGYPw8HC+8XWFQUdHBydPnhTK5IQX3c1hZ8/+j4WsrCwuXLiAAwcOoLW1FSNHjoS/vz9f85TExETIyspymfB1V/4+YLPZYLFYuH37No4ePcoVbcza2honT578nwlB6efnh/z8fFhYWHAlfwPAlYm5K/+E/2tdv7fS0tIwNzeHubn5B+vz5TXRbHplpUXfkX7DludfqacxtIsuPBQyRF8f0u9BhmGKi9aISrvoJzZKZb0zj+yMKqvn7yM/CqW4I+sJy9wZ3P8nhEVBTfSd9b8L+4t0v17efpHHkKYu+M78h4QYwgjGR/u1mjFjBsrKyrq9npaWxjOTK4EbX19fJCYmdnu9c9bbj4mDg0Ov7JiFQV5enmfGWmHhN4cXL16Ek5OTyP10pampiQqPysHKygpWVn3jHyc/EhMTaanau8alnz9/PgIDAz/2sIRG0KgN/PyfuovLz4ETIa0v0/l729LSAlNT0w+SBZNAIBA+Bf/2nX9B+WgKwcGDB3tMPCVIAjFCBx4eHj3+YPdFxWrLli24f/8+5WxdXFyMUaNG4f/+7/9ojtrnzp3DkSNHUFxcDEVFRcydOxcbNmygwizeuXOHyoDLSXpVV1eHgIAApKamgsFg4IsvvsDo0aPh5+fHZSPe0tKCgIAAXLlyBUpKSjA1NcWyZcuo9tPT0xEREYFRo0Zh+fLlyMvLg4qKCtasWcPlPHnlyhVERETgyZMnUFBQwMyZM7Fp0ybKEZgz1ujoaJw9exbXr1+Hnp5et5GaOhMcHIz09HSUlpZCTk4ORkZG8PHxocLhOjk5UZmytbW1AXSsi6ysLJ7lHIfa69evIzIyEg8ePIC0tDSmTZsGHx8fakefM+ajR4/izJkzSEtLg6KiIhYsWIC1a9diypQpWLhwIU6dOkUb77hx47Bz507KpKvzvNfW1uKnn37C1atXUV9fDy0tLaxfv56mBDk5OUFWVhZffvkl9u/fj4qKCnz++efYsWMHtLS0+M4XByaTidDQUKSmpqK6uhqqqqqYM2cONmzYQKuXkpLSYz8xMTG4cOECnj9/DgaDAR0dHWzZsgVjxoyh6mzZsgXDhw/Hd999h6NHj6KsrAzq6upwcXGhhTJtaWnBTz/9hPPnz6O1tRXTp0/HzJkz4e7uTlvHbDYbsbGxiI+PR2lpKQYOHIjFixfD1dVV4BM/zjza29sjNDQUlZWVmDBhAn788Uew2Wz4+fnh9u3bUFVVxcaNG7kyNWdnZ1MZiHNycrB06VJcunQJGhoaAABvb29cvHgRx48fp4IR+Pv7IycnB+fOnRP4cyIQCISPBYkyJBgfTSHgCCcE0Rk2bFifFPr58fr1a+zcuRMrVqyAsrIywsPD4e7ujqtXr0JeXh5xcXEIDAyEk5MTNm3ahJKSEuzfvx+NjY3YuXNnt+36+PggMzMTGzZsoMJ2dhfZKCQkBNbW1ggJCUFhYSFCQkIwduxYyhzk8ePHADoiRS1atAgrVqxAUlISfvjhB6iqqlIRaNLS0uDh4QFbW1usX78epaWlCA4OxvPnz7kE/q1bt2LOnDkICwsTWLCrqqrCqlWroKqqitraWsTGxmLJkiW4fPkyZGRk4Ofnh02bNkFGRgabN28G0BE5ys7Ojmc50KHArF27Fg4ODlizZg1qamoQEhICLy8v/PLLL7T+t23bhjlz5iAiIgI3b95EZGQkRo4cCXt7e3h4eFC5NTjhVznhhTnzx4HFYlFRgry9vaGmpoaTJ09i9erVVIQcDg8ePMChQ4fg6ekJSUlJ7N27F2vXrsWlS5cECr/a0tKCZcuWoaysDG5ubtDW1kZlZSVyc3Np9QTpp7KyEkuXLoW6ujoaGxuRkJAAR0dHXLp0ibZ5UVdXh19//RWurq7Umg4KCqLWNAAEBQXhxIkT8PDwgK6uLq5evUpLKsYhMDAQJ06cwKpVq2BkZISCggKEhYVBXFxcKL+HwsJCVFVVYdOmTWhoaMCuXbvg6+uLuro6zJgxA9988w1+++03eHt7U6FcOaSnp8PU1BT9+vWDvr4+pKWlkZOTQykEWVlZVBlHIcjKynpvoWoJBALhfUOiDAlG3zdwJfzP8PbtW8TFxVHKoaqqKhwcHHD79m2YmpoiJCQEzs7OtPCsioqK2LRpE1atWsVTCXry5AlSU1NpZlLW1tZwcHBARUUFV31dXV0qPK2lpSXy8/ORnJzMZR9ub28PV1dXAB0mPS9evEBkZCSlEISHh0NPTw+hoaHUPcrKyvDy8qIleQIAGxsbSjgXlM4ZYVksFkxMTGBubo7r169j5syZ0NTUhLy8PJWArzO8ytlsNnbv3k3lZ+AwcuRILF68GDk5ObTwuTNmzKASDJqbm+OPP/5AcnIy7O3toaamBjU1NYiLi/M137p27Rru3buH6Ohoau6srKzwxRdfICIigqYQMJlMnDlzhpbkz93dHY8ePeLKDM2Ls2fPorCwEPHx8bQwu/Pnz6fVE6SfLVu2UNdYLBYsLCxgY2ODixcv0pK59bSmp0+fjtraWpw4cQKrV6+m1pOlpSUqKytp67OkpARxcXHYunUrFbrZ3NwcbDYbUVFR1M6/INTV1eHs2bNQUVEBALx48QLh4eHYuHEjVqxYAaAjF4SZmRmuXr0KR0dH6t6rV69SGc2lpKRgYGCArKwsLFq0CM+fP8ebN2+wdOlSZGVlYfXq1aipqcHjx4+5Mm0SCARCX6Gd+BAIBIkyRPhoDBo0iHZSxHEMrqysRH5+Pt69e4fZs2ejra2NepmZmYHFYqGwsJBnm5xoQ12zKnc1heBgaWlJe6+pqYnKykquel3vt7W1RUFBAVgsFt69e4cHDx7Azs6Oq46kpCRycnJo5VOnTuU5lp7IyMiAo6MjJk6ciHHjxsHU1BTt7e14/vy50G0BwPPnz1FWVoY5c+bQ5ldXVxfy8vJcUZsEnSd+5OTkQE5OjhbbX1xcHLNmzUJeXh7NiXvs2LE0Ib3z+hCEW7duYfTo0Vw5N7oiSD/5+flwcXHBpEmTMG7cOOjp6aG6uhrPnj2jtdXTmgaAoqIiNDc3c63PrtmsMzMzwWazMWvWLK71X19fz9Uvv+fjKANAh9IH0D/TAQMGQElJiaaUFBUVoaysjJZvxNjYmFrP2dnZ0NTUhK2tLe7evQsWi4Xc3Fyw2Wya2R+BQCD0JdhC/P2bIScEhI8GJ7EcB47dfnNzMxWmsjtHz/Lycp7lr1+/BoPB4Ipq01kg6kzXegwGg6dvS9f7VVRU0NraipqaGrS1tYHNZtOESqAjulP//v25slJ3N5buuHfvHtzc3DBlyhSsXLkSAwcOhISEBJYsWcKVDE1QOPPb3U5u1/kVdJ74wWQyueYJ+O98NjQ0QEFBAQD3+mAwOiJ+CPrMtbW1Avki8eunvLwcLi4u0NHRwfbt26GqqgopKSl4enpyzUFPaxroWJ8AuHIddF0T1dXVYLPZ3Ubkqqio4OvAzO/5OPPcubzz86Snp2PcuHG0jNrGxsaIiIhASUkJsrOzYWxsDAMDA7S1taGgoIBSEgTJ5UAgEAifAnJCIBhEISD0CThCTFhYGOU42xleZUDHDm1rayuYTCZNiK2qqhJpPFVVVRg8eDDtPYPBgLKyMpqamiAmJsbVB4vFQm1tLZdAJmwI2CtXrkBeXh6hoaGQkOhIlFNTU4PW1t6HWuzfvyME3bZt26Cvr891XVilRVCUlJTw5s0brnLOfApqBiMI/fv3fy9RfW7cuIGGhgaEh4fTPsva2lqh2xo0aBCADoG/63rqjJKSEsTExHD8+HFKgO/MiBEjhO5bWNLT07mykRsaGoLBYCA7OxvZ2dn4/vvvIS0tDT09Paqsa6Z2AoFA6Ev823f+BYWYDBH6BEZGRpCVlUVFRQX09PS4Xrx2mYEOnwCgQ4juTHdOxYLS9f7k5GTo6OhAQkICcnJy+Pzzz3HpEj2DYkpKCtra2kQWkJqamiApKUlzpOWVaIzBYPDcPedVrqGhgSFDhuDFixc851ddXV2oMXJ2l/nFd54wYQLevXuH69evU2VsNhvJyckwNDSkFJ73gbm5OZ4+fYo///xTpHY4Cl/nHAJpaWl49+6d0G2NGTMG0tLSXOszJSWF9p5zMlBdXc3z8+mqZL5vqqur8eeff3IpBDIyMtDV1UViYiLKy8thYmICoOPk4OrVq3jw4AFVRiAQCH0RFrtd4Ne/GXJCQOgTKCgowNPTE/v27UNlZSVMTU3BYDBQWlqK9PR0+Pn50UwZOIwZMwYzZsxAQEAAGhsbqShDNTU1ACBQdBpenDt3DtLS0tDR0UFSUhLy8vIQHR1NXffw8IC7uzu8vb3h4OCAsrIyBAUFwczMTOSIKxYWFoiNjcWOHTtga2uLv/76CwkJCVw7xxoaGkhMTKQixaiqqmLw4MHdlvv6+sLLywuNjY2YPHky5OTkUFFRgZs3b+Lbb7+FgYGBwGMcPXo02traEBsbCyMjI8jLy1ORaDozefJk6Ovr4/vvv4e3tzcGDx6MhIQEPH36FEePHhVpnrpib2+P48ePY9WqVXB3d4eWlhZevnyJnJwc+Pv7C9wOx9HZx8cHjo6OePbsGaKjo3tlFqOsrIwlS5YgKioKDAaDijJUUFAA4L/rc9SoUXBycsLmzZvh7OwMQ0NDsFgslJSUIDU1VaBQtaJw7do1qKioUAp2Z0xMTBAVFYXRo0dTJ0nGxsZUpmriP0AgEPoy7H+5oC8oRCEg9BmWL18ONTU1HD16FMePH4eEhASGDh0Ka2vrHjPf7tmzB/7+/ti3bx8kJSUxe/ZsLF26FMHBwVROAGEJDg5GcHAwIiMjoaKiAn9/f5pj7LRp0xAWFoaIiAi4ublBQUEBc+fOxcaNG3vVX2dsbGywadMmHDt2DImJidDX18fBgwexaNEiWj1OOM8tW7aAyWRS+Qa6K585cyZ+/vlnHDp0CBs3bgSbzcaQIUNgbm6OoUOHCjXGKVOm4Ouvv8bhw4dRVVUFY2Njnkm8JCQkcPjwYezduxdBQUFoaGiAlpYWDh069N5DVUpJSSEmJgb79+9HdHQ0amtroaamhjlz5gjVjra2NgIDAxEeHg5XV1doaWkhKCiIik4lLBs2bACLxcKRI0fQ2toKGxsbrFu3Dr6+vjS7fl9fX2hoaCA+Ph5RUVGQkZHBiBEjuHbtPwQccyFe5m3GxsaIioqiCf6GhoaQlJTE0KFDSQ4ZAoHQpyGJyQRDjE1yOhP+B3F1dUVZWRlPUxsC4VPj7++P8+fP4/bt2+/VbKo3tLS0YNKkSdi3bx+mTZv2Ufp8Ms5WpPtbmkXfy8ppUhbpftl20X86nzOE8y/ihfR7+AVniovWiEq76M+hxBL9QVRZbSLdXyjF7b8jLHMHvBS5DQU14QM4dOXvwv4i3a+Xt1/kMfRTt+JfiQ9tLWUitzFigJ7Adf+u/ot/pf9RyAkB4R9PcnIyysvLoa2tjebmZqSkpCA9PZ0Wy59A+FRkZWUhNzcXOjo6EBMTw82bN6ncBJ9aGQA6Tlby8vI+9TAIBALhg0BOCASDKASEfxR37tzBt99+i9OnT0NPr0Prl5WVxYULF3DgwAG0trZi5MiR8Pf3x1dffUXdV1paimnTpiE0NBSzZs3qtv0zZ87Ax8cHt27d+iChFNlsNi32flfExcUF9ns4c+YMGAwG5s2bJ1D5++TOnTvIy8ujkm117vtDzF97ezva27u3AxV03jgJvqKiot7b2PghKyuLjIwM/PLLL2hqasKQIUPg6elJJQATlLa2nnc/OztB94Zvv/0Wenp6tMSAHwqHqrf8K/XAUCnRdvcBYK6IITVOSYj2DABgIia6s3iNiLv7AKDcLtpkMN9DeJJSCdGf4xpEtRVvhi5LWqQWnKtEf46G1yI3AWUJ0U4Z0t7D7n5j+Q2R23gfsHr47SD8F6IQEP5R6Ojo4OTJk1QCKKAj862Vlej/vD4GiYmJ8PHx6fb6/PnzERgYKHBbsrKyXIJ/d+Xvk6ysLBw5coRLIZg8eTJOnjzZo89Hb4iIiEB4eHi31zl+En0RXV1dxMfHi9wOvzwEooRcZTKZyM3Nxbp163rdBoHwT0dUZYDQNyFhRwWDKASEfxTy8vIYP378px5GrzEzN9/OwQAAIABJREFUM8Pp06e7va6sLPrO56dkwIABH+RkZdGiRZg8eXK31/8Njq09rRtRuXHjBuTl5flmeSYQCIR/GsRVVjBIHgLCR2HLli2YO3cusrOzMX/+fBgYGMDBwQHZ2dm0eufOnYO9vT309PRgYWGBPXv20LKp3rlzB9ra2vjrr/86/tTV1WHz5s0wMjLCpEmTsGvXLsTHx0NbW5vK0MuhpaUFAQEBMDExgbm5ObZv384zln9paSmWL18OAwMDTJ06FadOneKqc+XKFcyfPx96enpUW51j1XPGmpGRAS8vL0yYMAE+Pj4848xzXsOGDQPQEeVo3rx5MDQ0hKWlJdatW4eKigqqbScnJ2RlZeHatWvQ1taGtrY2wsLCui3ncP36dTg6OsLAwAAmJibw8fEBk8nkGnNmZiY2btwIQ0ND2NjYIDQ0lDLZCQsLQ3h4OBoaGqg+nJycAHSYDHWd99raWvzf//0fzMzMoKenhy+//BI3btCPkp2cnLB69WqkpKTAzs4O48ePx5IlS1BUVAQAGDx4cI/zxkn6xWQy4e/vD2tra+jq6mLq1KkICgri+uy664dDTEwMvvzyS0yYMAGmpqZYsWIFHj9+TKsj6JpuaWnBrl27MGnSJBgZGeH777/HlStXuNYxm81GTEwMZs2aBV1dXUyePBkHDx6kfsx6en49PT2cPXsWOjo6aGhooNpcvHgxtLW18fLlfx0dXV1d4ebmRhvj1atXYWNjQ/k0aGtr4/DhwwgJCYGFhQWMjIywY8cOsFgs3L17F1999RXGjx+PxYsX4+nTp1zzSyAQCH2FdrAFfv2bIScEhI/G69evsXPnTqxYsQLKysoIDw+Hu7s7rl69Cnl5ecTFxSEwMBBOTk7YtGkTSkpKsH//fjQ2NmLnzp3dtuvj44PMzExs2LCBykPQXWKykJAQWFtbIzg4GIWFhQgJCYGqqiqXgLR+/XosWrQIK1asQFJSEn744QeoqqpSoUfT0tLg4eEBW1tbrF+/HqWlpQgODsbz58+5YsZv3boVc+bMQVhYmMBZi6uqqrBq1SqoqqqitrYWsbGxWLJkCS5fvgwZGRn4+flh06ZNkJGRwebNmwEAampqsLOz41kOdCgwa9euhYODA9asWYOamhqEhITAy8sLv/zyC63/bdu2Yc6cOYiIiMDNmzcRGRmJkSNHwt7eHgsXLkRlZSWSkpIQGxsLoOPkhhcsFosKg+rt7Q01NTWcPHkSq1evxpEjR6iY/wDw4MEDHDp0CJ6enpCUlMTevXuxdu1aXLp0SSD/gJaWFixbtgxlZWVwc3ODtrY2KisrkZubS6snSD+VlZVYunQp1NXV0djYiISEBDg6OuLSpUu00wh+axoAgoKCcOLECXh4eFB5CAICArjGHxgYiBMnTmDVqlUwMjJCQUEBwsLCIC4ujtWrV/N9fhMTE7S1tSEvLw8WFhZoaGjA/fv3IS0tjezsbMydOxft7e3Izc2Fu7s7dV9bWxtu3LiBHTt20Nr79ddfMXHiRAQGBuLBgwcIDg6GuLg4bt++jVWrVkFRURE//vgjvLy8cP78eb7jIxAIhE8BOSEQDKIQED4ab9++RVxcHLS1tQF0mHk4ODjg9u3bMDU1RUhICJydnWlOjYqKiti0aRNWrVpF7Z535smTJ0hNTcWePXuwYMECAIC1tTUcHBxoO+ocdHV1qXjylpaWyM/PR3JyMpdCYG9vT9nHW1lZ4cWLF4iMjKQUgvDwcOjp6SE0NJS6R1lZGV5eXrhz5w4txr6NjQ0lnAtK5whJLBaLOtG4fv06Zs6cCU1NTcjLy0NWVpbLhIpXOZvNxu7du2Fra4s9e/ZQ5SNHjsTixYuRk5NDy7A8Y8YMeHl5AejIAPzHH38gOTkZ9vb2UFNTg5qaGsTFxfmab127dg337t1DdHQ0NXdWVlb44osvEBERQVMImEwmzpw5Q8tK7e7ujkePHuHzzz/nO2dnz55FYWEh4uPjaaYv8+fPp9UTpJ8tW7ZQ11gsFiwsLGBjY4OLFy/C2dmZutbTmp4+fTpqa2upiEKc9WRpaYnKykra+iwpKUFcXBy2bt2Kr7/+GkDHvLPZbERFRVHO0D2hrq6OoUOHIisrCxYWFsjLy0O/fv0wbdo0ZGVlYe7cuXj48CGYTCbts7579y4aGhq4/HAGDhxIna5YWVnhxo0b+PXXX3Hq1Cno6+sDAJqbm+Hp6Yni4mKeiekIBALhU9NOFAKBICZDhI/GoEGDKMEJAOUYXFlZifz8fLx79w6zZ89GW1sb9TIzMwOLxUJhYSHPNjkmF9OnT6eVz5gxg2d9S0tL2ntNTU1UVlZy1et6v62tLQoKCsBisfDu3Ts8ePAAdnZ2XHUkJSWRk5NDK586dSrPsfRERkYGHB0dMXHiRIwbNw6mpqZob2/H8+fPhW4LAJ4/f46ysjLMmTOHNr+6urqQl5enma4Ags8TP3JyciAnJ0dL6iYuLo5Zs2YhLy+PFnFp7NixNCG98/oQhFu3bmH06NF87eAF6Sc/Px8uLi6YNGkSxo0bBz09PVRXV+PZs2e0tnpa0wBQVFSE5uZmrvU5c+ZM2vvMzEyw2WzMmjWLa/3X19dz9dsdxsbGlMlSVlYWZfLUuUxeXp6mYKWnp8PY2JjrlKfrGhg5ciQUFBQoZYBT1vl5CQQCoa/BYrcL/PrQ3Lt3D0uWLIG+vj6srKxw4MCBHiMPcpg6dSplotv51dUsur6+Htu2bcOkSZNgaGgIV1dXlJaWCjQ2ckJA+GgoKdFD7ElJSQHo2GXkLGrOLn9XysvLeZa/fv0aDAaDK6qNiooKz/pd6zEYDJqPQnf3q6iooLW1FTU1NWhrawObzaYJlUBHVt7+/fvj7du3XPcKw7179+Dm5oYpU6Zg5cqVGDhwICQkJLBkyRKe/g6CwJlfDw8Pnte7zq+g88QPJpPJNU/Af+ezoaGBytbbdX0wGB1JggR95traWoGci/n1U15eDhcXF+jo6GD79u1QVVWFlJQUPD09ueagpzUNdKxPAFyO1l3XRHV1NdhsNszMzHiOuaKigm+UIaBDIfj999/R3NyMnJwcTJkyBRMnTsSWLVtQVVWFnJwcTJgwgZb/4OrVq1i6dClXW7zWAK+yzs9LIBAIfY2+YjJUUlKC5cuXw8TEBFFRUSguLsbevXvR0tKCjRs38r3f1tYWLi4utLKu/5M3bNiAgoICbN26FfLy8jhw4ACWL1+OCxcuoF+/fj22TxQCQp+AI1iFhYVhyJAhXNd5lQEdO7Stra1gMpm0L0ZVVZVI46mqqqIcVTnvGQwGlJWV0dTUBDExMa4+WCwWamtruYREQf0GOFy5cgXy8vIIDQ2lBLeamhq0trb28mmA/v07slZu27aNtsPLQVilRVCUlJTw5s0brnLOfPIzgxGG/v37ixR6k8ONGzfQ0NCA8PBw2mdZW1srdFuDBg0C0CHwd11PnVFSUoKYmBiOHz9OCdmdGTFihED9mZiYoKWlBbdv38a9e/ewefNmDB8+HGpqasjKykJ2djZWrFhB1X/27BmeP3+OKVOmCP1sBAKB8E+gr5gM/fzzz1BUVMSBAwcgJSUFMzMz1NXVISIiAitXrqR+p7tj4MCBPZrp/vnnn7h27RrNRFdLSwszZszAmTNneG78dIaYDBH6BEZGRpCVlUVFRQXPCCq8dpmBDp8AoEOI7kx3TsWC0vX+5ORk6OjoQEJCAnJycvj8889x6dIlWp2UlBS0tbXR7LN7Q1NTEyQlJWmOtBcuXOCqx2AweO7M8irX0NDAkCFD8OLFC57zq66uLtQYOScG/HZeJkyYgHfv3uH69etUGZvNRnJyMgwNDd9rpl5zc3M8ffoUf/75p0jtcBS+zom+0tLSaBGkBGXMmDGQlpbmWp8pKSm095yTgerqap6fT1clsztGjBiBwYMH4+effwaDwaBOFYyNjXH8+HHU1tbCxMSEqp+eno4xY8Zg+PDhQj8bgUAg/BNgC/H3Ibl+/TqmT59OnSQDwNy5c6lNHFHJyMiAgoICzR9MXV0dRkZGtN/g7iAnBIQ+gYKCAjw9PbFv3z5UVlbC1NQUDAYDpaWlSE9Ph5+fHxUtpzNjxozBjBkzEBAQgMbGRirKUE1NDQAInPW3K+fOnYO0tDR0dHSQlJSEvLw8REdHU9c9PDzg7u4Ob29vODg4oKysDEFBQTAzM6M5FPcGCwsLxMbGYseOHbC1tcVff/2FhIQErp1jDQ0NJCYmIi0tDaqqqlBVVcXgwYO7Lff19YWXlxcaGxsxefJkyMnJoaKiAjdv3sS3334LAwMDgcc4evRotLW1ITY2FkZGRpCXl+fpVDp58mTo6+vj+++/h7e3NwYPHoyEhAQ8ffoUR48eFWmeumJvb4/jx49j1apVcHd3h5aWFl6+fImcnBz4+/sL3A7H0dnHxweOjo549uwZoqOje5VfQVlZGUuWLEFUVBQYDAYVZaigoADAf9fnqFGj4OTkhM2bN8PZ2RmGhoZgsVgoKSlBamoqV+SqnjA2NkZSUhKsra0phcvY2Bjbtm2DrKwspUQDHQoBOR0gEAj/ywhzQsBkMmmhuDkoKiqKlHCzoaEB5eXltKSqADBs2DD069cPxcXFfNu4cOECTp06BQkJCUyYMAHe3t40U9KnT59CQ0ODS+7R1NTEzZs3+bZPFAJCn2H58uVQU1PD0aNHcfz4cUhISGDo0KGwtrbu8Yu4Z88e+Pv7Y9++fZCUlMTs2bOxdOlSBAcHQ05OrldjCQ4ORnBwMCIjI6GiogJ/f3+aY+y0adMQFhaGiIgIuLm5QUFBAXPnzhXIDpAfNjY22LRpE44dO4bExETo6+vj4MGDWLRoEa0eJ5znli1bwGQyqWy93ZXPnDkTP//8Mw4dOoSNGzeCzWZjyJAhMDc3x9ChQ4Ua45QpU/D111/j8OHDqKqqgrGxMY4dO8ZVT0JCAocPH8bevXsRFBSEhoYGaGlp4dChQyIrTl2RkpJCTEwM9u/fj+joaNTW1kJNTQ1z5swRqh1tbW0EBgYiPDwcrq6u0NLSQlBQEBWdSlg2bNgAFouFI0eOoLW1FTY2Nli3bh18fX0p/wkA8PX1hYaGBuLj4xEVFQUZGRmMGDFCaIGdoxAYGxvTygBg/Pjx1MnH27dvcffuXSqaFIFAIPwvIowPQWxsLMLDw7nKOb+jvaWurg4At80/p6yr72FXpk6dCn19fairq6OsrAzR0dFYunQpTp8+DU1NTQAdykzn3xRh2gcAMXZf8bYgEN4jrq6uKCsr42lqQyB8avz9/XH+/Hncvn37vZpNCcOFCxewa9cuZGZm9vokrbfoDjblX6kHhkqJntF7LkTzm0kRE96npCsmYoKZgvVEk5joP+HK7aJ9/u3CuUnxhCkmeoSX1+i9nxUA6LKkRR7Df9iiR9xqaBftOQBAWUI0/6y0l/dEHkNj+Q3+lfjAGCh6OGMpae6Q5d3x5nWhwCcEdXV1ePXqFd821dXVwWQyqRxIXTeprK2tYWdnBx8fH4HHWVNTAzs7O1hbW2Pv3r0AAGdnZ4iLi3PlFdq/fz9OnDiBrKysHtskJwSEfzzJyckoLy+HtrY2mpubkZKSgvT0dFosfwLhU5GVlYXc3Fzo6OhATEwMN2/epHITfCplAADmzZuHefPmfbL+CQQC4WMgzL63MKZBqampAgnxcXFx0NPTAwCeygaTyRTYT4yDsrIyTE1NKfNToGPsvPIvCdo+UQgI/3hkZWVx4cIFHDhwAK2trRg5ciT8/f3x1VdffeqhccFms3uMOSwuLv7Rd2v/CbS3t6O9vfsdxL48b7KyssjIyMAvv/yCpqYmDBkyBJ6envjuu++Eaqetra3H652doPs691+K7kD3qem98QDhfxmyLvoerS1lH6TdBQsWdBsqnRfq6up4+vQpraysrAyNjY3vJbHj6NGjqZw2naMbPnnyRKD2/zm/IARCN1hZWXFlWe2rJCYm9rijMH/+fAQGBn7EEf0ziIiI4GnXyUFU+84Pia6uLuLj40Vuh18egvcRcpVAIBAIHwZra2ukpaXh+++/pyINXbx4kQpBKgzV1dW4desWzcfMxsYGERERuHHjBqytrQF05LC5e/cufH19+bZJfAgIhI9ITU1Nj1kDlZWVMWyY4PaO/xZevnzZo60mJ5LS/zJds0l3hXMkTSAQCIS+R0lJCezt7WFqagonJycUFxfjp59+wjfffEMLSLJs2TKUl5dT4c+TkpKQnp4Oa2trDB48GGVlZTh8+DBevnyJ06dP0yIXrV69GoWFhdiyZQuVz4jJZAqUmIwoBAQCgUAgEAgEwgfm3r172L17NwoKCqCkpISFCxfCw8OD5k/m5OSEsrIyXL16FQCQn5+PoKAgPHnyBEwmE/Ly8jAxMcHatWuhpaVFa7++vh579+7F5cuX0dLSgkmTJuGHH34QKNcMUQgIBAKBQCAQCIR/MX3TC49AIBAIBAKBQCB8FIhCQCAQCAQCgUAg/IshCgGBQCAQCAQCgfAvhigEBAKBQCAQCATCvxiiEBAIBAKBQCAQCP9iiEJAIBAIBAKBQCD8iyEKAYFAIBAIBAKB8C+GKAQEAoFA+MdRXl6O1tbWTz2M/1nKy8tx5coVxMXFobq6GkBHxvCmpqZPPDKAzWajsbHxk47hzZs3yMjI+KRj6C319fVob2//1MMg9DGIQkAgEAiET0JzczNSUlJw5MgRJCUlUYKnIEybNg0PHjwQqf/29nZcvXoVRUVF3dYpKiqiMobyIz8/X6TxdIXJZOLhw4dobm4W+t7eCvQtLS3w8/PDzJkz4eHhgT179qCiogIAsGPHDkRERAj/IF34888/4enp2ev7U1JSYGRkJNIYRBXoc3Nz4erqKtIYektvBPq8vDy4uLjA2NgYJiYm1HfH398fly9f/hDDJPzDIAoBgUAgED465eXl+OKLL+Dp6Ym9e/di48aNsLOzQ3Z2tkD3s9lskceQmJiIjRs3Ql5evts6CgoK2LRpE86ePcu3PUdHR8ydOxcxMTGoqanp9bh+//132NraYtKkSZg/fz6ePHkCAPDy8kJ8fHyP94oq0AcHB+Py5cvYu3cvMjMzafM8efJkXL9+vdfPxaGyshIpKSkityMKH1ugr6+vx6FDh+Dm5ob58+fj6dOnAID4+HgUFBTwvV8Ugf7KlStYunQpxMXFsWbNGpoyMXDgQJw6dUqgZ5g/fz52796N1NRUkdY3ADx//hy3bt1CRkYG14vwaSAKAYFAIBA+OsHBwXj79i0CAwNx8eJFREVFYeDAgfDz8/toYzh79iwWL14MdXX1busMGTIEjo6OOHPmDN/2jh8/Dn19fRw4cADW1tbw9PTEzZs3hRpTQkICNm7cCFNTU+zfv58mkOvr6+PChQs93i+qQJ+UlARvb2/Mnj0bSkpKtGvDhw9HWVmZUM9DAJ48eQJbW1vExsaCzWbj4cOH1ElNcXExjhw50uP9ogr0Bw4cwMKFC/Hzzz/j22+/pV3T0tLCo0ePBHoOIyMj3L59G+vWrYO5uTnmzZuHHTt24Pfff8ebN28EaqO4uBgODg6ws7ODs7MzVq9eTXt9qlMXAiD5qQdAIBAIhH8fubm58PLygr29PQBg9OjRUFFRwcKFC1FdXY0BAwbwbaO+vh61tbUC9de/f3+usgcPHuC7777je6+pqSkSEhL41jMyMoKRkRF++OEHXLx4EadPn8bKlSuhrq6OBQsWYMGCBT0qHwDwyy+/4LvvvoOXlxdYLBbtmoaGBoqLi3u8v7NA3/V+QQR6JpOJ4cOH87zW0tLC1SaBP7t374aGhgaioqIgJSUFXV1d6pqhoSF++umnHu/nCPQ7duxAW1sb9u7dS13T0tLCb7/91uP9z549g4+PDwBATEyMdk1BQQFv374V6Dm2bt0KAKitrUVOTg5ycnKQlZWFhIQEtLe347PPPuN7WuHr64vm5maEhIRg5MiRYDAYAvVN+PAQhYBAIBAIH53Kykpoa2vTyrS1tcFms/Hq1SuBFIIVK1YI3B8vf4Pm5mb069eP770yMjJC2fHLyspi4cKFWLhwIZ48eUKZ6kRGRsLMzAzOzs6wtLTkeW95eTlMTU15XpOWlkZ9fX2PfYsq0GtoaODGjRswNzfnunbnzh2uz4zAn7t37yIkJASysrJc8z9w4EC+u+uiCvTKysrdKoLFxcUYPHgwv0eg0b9/f0ybNg1qampQVVWFrKwscnJyUFpayvfeR48eISQkBDY2NkL1SfjwEIWAQCAQCB8dNpsNcXG61SrnvaAOk66urhgxYkSvxzB48GAUFRXB2Ni4x3pFRUVQVVUVqu23b9/i3LlzOH36NIqKijB+/HjMmDEDGRkZ+O6777B69WqsX7+e6z5VVVU8fvwYZmZmXNcePnzYrbDPQVSB3tnZGb6+vmAwGLCzswMAVFRU4O7du/jtt9963M0WxBYeAEpKSniWBwQECHT/33//LVC93jBv3jyB6vFTzDojJSWFtrY2ntdev34NBQWFHu8XVaCfOXMmwsPDMX78eIwaNQpAh2Lx6tUrHDlyBLNmzRLgKTr8GLKzs5GdnY3c3FywWCzo6elh4sSJWLNmDQwNDfm2oampibq6OoH6I3xciEJAIBAIhE/Cjz/+yFMY2r17N83RV0xMDAcPHuSqN2XKFOjr6/e6fysrK8TExMDe3r5bx+L6+nrExsYKvKP5xx9/4PTp00hLS4OMjAy++OIL7Nu3D1paWgA6TjViYmIQERHBUyGYN28eIiIioKGhQSkFYmJiePjwIU8b8K6IItADgL29Pd6+fYvQ0FAcPnwYAODh4QFZWVl4e3tj5syZ3d775Zdfcu1g84LNZvOsJ2g0J6DDt4MXogr0Ojo6Aj2DMJiYmOCXX36BtbU1JCQkAHR8pmw2GydPnuSp/HVGVIF+/fr1uHfvHhwcHKh16Ovri5KSEowePRru7u4CPceSJUsgIyODr776CqtXr4a+vj6kpKQEupeDj48P/Pz8MHLkSJrpFOHTI8Z+H6EaCAQCgUAQAicnJ6HqHzt2jPZ+7NixSEhIEEkhePnyJezt7TFo0CB4e3vDwsKCEnBaWlqQmZmJoKAgvH79GufOneO7EztlyhRUVlZi/PjxWLx4Mezs7CAtLc1V7/79+/jqq6/w8OFDrmutra3w8vLClStXoKSkhLdv32LAgAGoqanBtGnTEBoaSgmV3REXF4fQ0FA0NDRQTsWysrLw9PTEsmXLBJqbd+/eIT8/H9XV1VBSUoKRkVGP0ZgAICsrS6C2OZiYmAhVXxC2bNkilEC/Z8+eXvfV1tYGSUn++6rPnj2Do6MjFBQUMG3aNMTFxWHBggUoKipCSUkJTp061ePJT319PVxcXFBYWAgtLS0UFhZi7NixlEAfGxvL1/Stra0N58+fxx9//IGamhooKSnB3NwcDg4OAtvxe3t7Izs7G2/evIGmpiZMTEwwadIkTJw4USATP6Dj9G/37t347bffoKCgwLUhICYmhitXrgjUFuH9QhQCAoFAIPzjeB8KAdAhnK9btw4VFRWQkJCAsrIyxMTEUF1dDRaLBXV1dRw4cAA6Ojp829q1axcWL14MTU1NkcYEdJj3ZGZmUgK5hYUF353kzvRGoBeV9vZ2LjOw7nj48CHGjh1LK3v27Bm1A86P8PBweHh4CD3GzvAS6FNSUno8BeHQ2NiItWvX4ueffxaor7KyMoSFhXEJ5OvWreNrBsYZq6gC/fvixYsXyMrKQk5ODrKzs1FRUYHRo0fDxMQE27Zt6/HenTt34sSJE5g4cSJGjRrFc+wc52XCx4UoBAQCgUD4x5GYmIjJkydDWVlZ5LZaWlpw+fJlZGVl4eXLlwA6/AtMTU0xc+ZMoc0i/sn0lB9AXFwc8vLy0NLS4rkj7Onpif379/NVCu7evQtXV1euEwUrKyvExcXxVQp27dqFX3/9f/bOOyqq63v7z1BFUQiCBNSokcggIEhVUBGwxI5I0VgoasAoRLAhilKiJlEICkaBIIlJVAQR0djAXgOoiA0sgA1BmoAo/bx/8GNex7lTmBk03+R81spacM/d+547gyvPvneXPxgLxSUV9AYGBoiIiBDo4/Xr11iwYAHu3r2L3Nxcodf6t/L8+XNkZmYiJSUFWVlZYLFYQocFmpqawtvbW6TuXpQPC60hoFAoFMpH49mzZ0hKSkJOTg7Ky8vBYrGgrq4OExMTODk58W3TWVhYyFM4e+7cOZiamnI9CX/y5Am2bt2K8PBwvntQUFDA1KlTMXXqVInvp7KyEr/99htu3ryJsrIyaGhowMjICG5ubiKlVQhqoyojI4Nu3boJTBmSRNADgK+vLyfl5t3nhe8ek5WVxdSpUxESEsIVLJ05cwZ+fn4Cg4KLFy/Cx8eHUfT37NkTc+fOxe7du/H555/zrLe2tmLNmjU4ePAg37cD/v7+HRL07zN58mT4+/sjPDwc48eP51mvqKjA/Pnz8fjxY8a6ln8iQ4cO5ZtGJSMjg+7du4PNZsPd3R2WlpZ8/RQVFXGKirOzs/HixQvIy8tDX18fXl5eQovzAUBJSQmDBw8W+14onQd9Q0ChUCiUj8Lhw4exZs0aNDY2QlNTE1paWiCEoKSkBKWlpVBUVMSmTZswceJEHls9PT0kJiZyUoZaWlpgYGCA5ORkrvSemzdvYubMmYxPLi9evAhjY2OuAOLt27c8+diVlZVIT0+Hq6urwPvJycnBggUL0NLSgmHDhnFaSl69ehUyMjKIj4+HsbGxQB9sNltgDjyLxYKOjg48PDwwffp0gfYdFfRA29P7FStWwN7eHuPGjUPPnj1RUVGBEydO4NSpUwgKCkJhYSG2bduGOXPmYPny5Rzbc+fOwcfHB6NHj8ZPP/3EE7gcP34cy5cvx5AhQxAbG8uTwlRdXQ13d3eUlZXht99+w8CBAzlr7bUVp06dQmBgIN/ZXTdLAAAgAElEQVQalICAABw5ckQkQR8dHQ1ra2uudUIIAgMDcfjwYWzevJlTmA20tYT18PBAVVUVYmNjhX6X7QgattUuyPX09DBt2jTGN16SCvpt27bh4MGDaGpqgo2NDec7PXfuHOTl5TFmzBhkZWXh/v37iI6Ohp2dHeO12Gw2FBUVYWRkBHNzc5ibm2Po0KGMdTL82Lp1K549eya0uJ3y4aFvCCgUCoXywXn06BECAwNhamqKoKAgLvEHAA8ePEBYWBgCAgKgp6fH80SZ6VlWR59vLVy4kCeoMDEx4Qkqnj59iuDgYKEBQWhoKHR0dBAbG4sePXpwjldXV2PhwoUICwvDgQMHBPoIDg5GTEwMVFVVMXbsWPTs2RPl5eVIT0/Hq1evMHv2bFy7dg2BgYFoaWmBk5MTl/2ePXtEFvQ9e/bkEvQAEBcXBwcHB/j4+HCODRgwAGZmZujRowf27t2L2NhYvHnzBikpKVz2NjY2iI6Oho+PD+dNQXtQkJSUhPXr18Pa2hpRUVHo0qULz72rqKjg119/hYeHB9zc3DhBwdu3b/HNN98gMzMTmzZtgoODA9/Pb9OmTWCxWFi2bBlaW1v5CvqEhARGQc9isbBx40bIyMhgxYoVIIRg4sSJePToETw9PdHS0oLff/+9Q/MY6urqUFhYiPLycvTt25fznTx9+hQaGhpQV1fH8ePHERsbi927d/PUoHh4eIgk6D08PBgFvby8PAYMGICdO3dyBYCNjY3w8vJC9+7dcfDgQSxatAg7duzgGxD88ccfYnUWepdu3bohOzsbLi4usLKy4pmGzWKx4O7uLrZ/igQQCoVCoVA+MKGhoWTChAmkoaGB7zkNDQ1kwoQJJCwsjGdNV1eX3Lx5k/N7c3Mz0dXVJbdv3+Y6Lycnh7DZbEb/0vDxLoaGhuTUqVOMaxkZGcTQ0FCojw0bNhB/f3/GNT8/PxISEkIIISQgIIBMnjyZ5xxvb2+ybds2Rvtt27aRhQsXEkIIiYqKIra2tjznGBsbk0uXLjHaX7p0iRgbGxNCCLl8+TLR19dnPO/ChQtkyJAhZMmSJaSpqYnExsYSXV1dsnTpUtLU1MRo8y6vXr0ijo6OxMrKimRmZhInJydiaGhIMjIyhNoSQkhraysJDAwk+vr65K+//iKEEPLw4UMyatQoYm1tTfLy8kTys3btWqKvr0+ioqKIpaUlsbOzI48fPxbJ9l3S09PJuHHjyL1797iO3717l4wbN44cO3aMlJSUkEmTJhEvLy8e+59//pl4eHjw/FtpaGgg7u7uZOvWraS1tZV4eXkRJycnHvuRI0eSs2fPMu7t9OnTxNramrNPIyMjrnVra2uydu1acvr0aVJfX9+h+2ZCV1dX4H+i/DujdA6itQOgUCgUCkWKZGVlwcXFReDTRgUFBbi4uHS4neXHol+/fnyHLtXW1oo0RC0tLY0xFQgApk+fjr/++gtAW2/6x48f85xz9epVmJqaMtqbmpoiKyuL8/PLly95zlFWVsbly5cZ7S9evIhu3boBaJvyzK9r0YgRI7Bjxw5cuHABkydPRkREBFxcXBARESFSm872NwXa2tqYN28eCgoKEBcXB3t7e6G2QNtT5g0bNmD69OlYuXIloqOjMXv2bMjJyWHPnj0iP90PCwvDjBkzsH37dmhoaGDv3r1iDcKLjIyEr68vT1clPT09LFmyBJGRkdDU1MSCBQtw7do1Hvu9e/fCzc2N59+KgoIC5s2bh/3794PFYsHJyQkPHjzgsa+pqeFbm1JdXY26ujoAbd/9+6lJy5cvR01NDZYvXw5LS0t4e3sjMTGRU3zfUfLy8gT+J6womdJ50JQhCoVCoXxwiouLRRJmurq6KC4uFtmvtIdKdYRVq1YhODgYWlpaXD32//77b0RHR2P9+vVCfTQ1NfGd5PvkyRPOxNsuXbowtmxsF/RMk4pFEfSzZs1CVFQUKisrYW9vDzU1NVRWViIjIwOpqanw9fUF0Da1Vk9Pj8v23UnFKioqWLx4McLDwzFq1Ci4urryFPG+38r1/UnFAwYMwK1bt8Bms5Geno709HSu9bVr1/Ls/13CwsIgIyOD7du3Q0dHB/Hx8UInTjMNNiOEoK6uDvPnz+c6zmKxkJaWJtAf0Pa9de3alXGta9eunL9vbW1tNDQ08JwjiaAHgOHDh2PLli3o3bs3zMzMOMezsrIQHh7OaWdbWFiIPn36cNk6ODjAwcEBTU1NyMzMxJkzZxAbG4vg4GDo6enBzs4Otra2AtvyhoeHw87ODsbGxh/13ydFMDQgoFAoFMoHp66ujiNOBdG1a1e8efOGcc3NzY1HYMyePZvrGBGjb4a4ouWHH35AbW0t3Nzc0L17d3zyySeoqqpCbW0tevTogR9//BE//vgj5xpMYnLMmDEIDw+HkpISxowZA2VlZbx+/RoZGRmIiIjA2LFjAQD5+fno168fj70kgh4AvvnmGygrKyMuLg4pKSmcibrq6upcxbxTp07lqangN6n4/PnzuHDhAud38n+Tit9/Gsw0qVhbWxsvXrzAixcvuI6zWCzGgEBSQc80qVjSibo6OjqIi4uDpaUlV2BQV1eHuLg4fPHFFwCAly9fQl1dncdeEkEPtNWlLFq0CHPnzuX5u9TT0+MEqrKysliwYAHjPcjLy8Pa2hrW1tZYu3Yt7t+/j7Nnz+L06dP4+eefoa6ujtGjR8POzg6jR4/msr158yYSEhLQvXt32NjYwNbWFiNGjBDp3z/lw0G7DFEoFArlgyPqYDF+XYKio6M7dD2mNpVsNhumpqZc01LPnj0LMzMzrqfntbW1uH79utB0BmlMyX39+jUCAgKQkZEBFosFOTk5NDc3gxCCsWPHYtOmTVBWVsbJkyfRtWtXjBgxgsfH7t27ERcXh7KyMi5B7+XlxRH0jx49gpKSEt+2rq2trSgpKeG0Tv3000+Fzhf4r00qFpVr165hwYIFkJOTg6WlJSdIu3r1KlpaWhAfHw8TExOEh4ejubkZq1at4rIvLS3FokWLcO/ePUZBv2PHDmhqamL//v1QVFTEtGnTGPdx7tw53Lp1i/OdGhoawsbGRuL7q6ysxNmzZ3HmzBlcvnyZMe2ptrYW58+fx5kzZ3DhwgW8efMGFhYWsLW1ha2tLXr37i3xPiiSQQMCCoVCoXxw2Gw2lJSUhIo3Qgjq6+ulmltcXFyMXr16wcPDo0N2v//+u9T2IIxHjx4hNzcXZWVl6NWrFwwMDDo0AVkcQf8xSU1Nha2tLU/XGVFobW2Fu7s7QkND0b9/f+lvTgT4tb1tp6ysDAkJCbh9+zaXIHd3d4eGhoZI1+gsQS9NmpqahE5ObmlpwbVr13DmzBmcOXMGjx8/ho6ODuzs7GBnZwcjI6MPtFvKu9CAgEKhUCgfHGk84RcHYcJNWpSWluLVq1dQVVWFpqZmp12nMyguLkZGRgZKSkrQ2NjIsy4sd7+jSPqdtLS0QF9fHwcOHBD7O/0n7KGzef36NUpKShjrFETdc3l5OU6fPo0XL17w+GGxWFixYkWH91VYWMhJP7px4wZ69OjBt7Cd0nnQGgIKhUKhfHAkEfjtT/hF6VjDRGc+B0tLS8PWrVu5CqG1tbWxdOlSxvx2fuTl5aG0tJRRvAmawgtIJuhPnjwJf39/EEKgpqbG87SXX+6+pPwTnk3+E/YgCHEFfUlJCQIDA3HlyhWeNX71HExkZGRg2bJlaGhogIqKCuObAHECggEDBmDAgAHw8PBAdXU1V70J5cNBAwIKhUKh/M/Q0tICe3t7qT7hf/bsGZKSkpCTk4Py8nKwWCyoq6vDxMQETk5OfPPs3yctLQ0rV67EqFGj4OPjwxkgdfToUaxcuRIsFguTJ08W6OPBgwfw9fVFUVERo0AVJt4kFfSRkZEYMWIEvv/+e6iqqgq5Y4ooNDY2YteuXThx4gSjoGexWIx59+1IKuiDgoKQn5+PgIAA6OjoCE3p4cfmzZsxYsQIhIWFQU1NTSwfS5YsgYWFBczMzKCnp8eTMqiioiL03wilc6ABAYVCoVD+p5Dmk9zDhw9jzZo1aGxshKamJrS0tEAIQWFhIa5evYr4+Hhs2rQJEydOFOorLi4Ozs7OCAsL4zru4OCAtWvXIiYmRqjYWb9+PVpbWxEVFSWWeJNU0BcXF2Pt2rU0GJAimzZtwv79+zF69GiMGjWqw9+ppIL++vXrCA0NxaRJkzpk9z4vX75EcHCw2MEAADQ3NyM6Ohq1tbVQVlaGqakpzMzMYGFhAQMDg390ncu/HRoQUCgUCuU/yaNHjxAYGAhTU1MEBQVh4MCBXOsPHjxAWFgYAgICoKenhwEDBgj0V1RUhICAAMa1L7/8EocOHRK6p3v37mHLli0iD+F6H0kFvYGBAZ49eyaWLYWZkydPws/Pj29LT2FIKuhVVFSk0uJz+PDhyMvL47Q5FYedO3eCEIJ79+4hMzMT165dwy+//MJptTt06FDEx8dLvFdKx6GhGIVCoVD+k+zZswd9+/ZFbGwsTzAAAF988QV++eUX9OnTB3/++adQf5988gnjpFgAePjwIT755BOhPrS0tNDa2ip883yQVNAHBwfjjz/+wLlz59DU1CS2n/8i/DpmNTc3Y/DgwWL7lVTQf/3119i9e7fE32dISAhOnDiBXbt2IS8vD8XFxTz/iQKLxcLgwYPh7u6OkJAQBAcHw8zMDG/evKHFxB8R+oaAQqFQKP9JsrKy4OLiAgUFBb7nKCgowMXFBSkpKUL9TZo0CZGRkejSpQsmTJgAFRUV1NTU4NixY9i6dStmzpwp1Iefnx9iYmJgamoqVmpGcHAw/P39oampCSsrqw6nlzg7O6O5uRne3t6QkZGBoqIi17qwfPf/ZSSdossvlW3q1KnIyMhgnB4tCu2C3traWqz8/wcPHqCoqAhjx46Fubk5Y2tXUQrFZWRkOAP23v+sRC1OfvnyJbKzs5GZmYmsrCwUFBTg008/hZmZGUJDQ2Fubt6xm6NIDRoQUCgUCuV/kocPH2Lfvn149uwZevXqhS+//FKo6GKxWNDW1oaCggKKi4uhq6sr9Dq6uroiPf308/PDs2fPEBwcjJCQEMjKyqKlpQWEEIwbNw5+fn5CfRw4cABlZWWwt7eHnp4eevTowbP/HTt28LWXVNB7enpKLIw7ioyMDKZPny7SGxQmZGVlsXv3bqEpXcKQpDZFVlYWeXl5jGtDhgxBZGQkli5dCmtra0ZBLqhzlKSC/syZMwDaPmem717UzlErV67E3bt3sWTJEvTv31+s4GTUqFGcgHnhwoUwMzNjnK5M+fDQOQQUCoVC+Z+hvd/7d999h5CQEDQ3N0NNTQ2vXr1Ca2sr1q1bh1mzZonkS09PD4mJiSJNS541axbu3r0rkt/8/HxkZ2ejpqYGKioqMDU1FSnwAMCZJCwIQQPSoqKihAp6ac10eJ9Xr1516Pz36xwSEhJEtmWxWHB3d+/Q9UTB29u7Q+fv3LlT6DlsNlvgurAn63Z2dkLtT506JXQfkmJsbIzvvvtOoi5Arq6uuHPnDrp27QoTExNYWFjA0tISgwcP/uCBKIUbGhBQKBQK5aMgzhP+1tZWjBkzBurq6mhsbMSOHTugpaWF169fIzAwEH///Tf+/vtvka7PZrOxf/9+kQKCmTNnChRtDQ0NMDU1RWRkJMaMGSPS9f9tsNnsDom69z/P94Uzi8XieWr/rn+m70NSQf9+QFZYWIjy8nL06dMH6urqKC8vx7Nnz6Curo7PP/8cu3fvFnqN58+fCz2nd+/eHdr3x+DLL7/EihUrxC54b+ft27e4ceMGMjMzkZ2djdzcXCgoKMDU1BQWFhaYP3++lHZM6Qg0ZYhCoVAoH5zs7Gx4eHhwPeFPSkoS+oRfRkYGp0+fxvDhwxEaGgotLS0AgLKyMlatWgV7e3u8ePGCc1wYbm5uQkWsKM/NFBUV8cknn4jd4/2fRH5+PpKTk1FUVMQ4BIufCN64cSPns2wP1lRVVTF27Fioq6ujrKwM6enpePXqFRYvXsxj/27KzcOHD7F48WLMmjUL48eP58x0OH78OPbu3Yvt27cz7qGuro7rd2GC/n3effuSnp6OH3/8ESkpKVxFwXfu3MHSpUsxe/Zsxj28zz9F7N+7dw+FhYWMw+ocHByE2vv6+iImJgYmJiZip3cBgJKSEqysrGBlZYXGxkZcvXoVcXFxOHfuHM6fP08Dgo8EDQgoFAqF8sGJjo7GwIEDeZ7wR0ZGipTyU1VVBU1NTa5jn376KWdNlIBA2qkzjo6O2LdvH2xsbCTy09jYiPPnz6OwsJBRkAvbt7iCHgCuXbsGNzc3DBo0CPfu3YORkRHq6urw8OFDaGlpYdCgQXxtHR0dOT9/9913MDY2RmRkJM/ev/32W+Tn5wu8h5CQEMycOZMrLUhLSwseHh4A2oqnmTo/SVPQR0ZG4ttvv+XpEKSvrw8fHx9ERkZi/PjxAn28T0VFBeN3IsrwO3EFfXV1NRYuXIjc3Fyuty7vBsKiBARpaWkoKSmBnZ2dWPUtAFBfX895O5CVlYVbt26hsbERvXr1wqRJk2BhYSF0H5TOgQYEFAqFQvng5OfnS+UJvyRIEhAUFxejV69ekJP7//8b7datG+7cuYPJkydj1KhRUFdX5xJdouS9l5SUYNasWSgtLQUhBHJycpx2kQoKCpCTkxO4b0kEPQBERETAwcEBISEh0NfXR1BQEPT19ZGXl4dvvvkGTk5OInw6wJEjR7B582bGNScnJyxfvhxBQUF87XNzc+Hl5cW49sUXX/AEGkxIKuifPn2Krl27Mq5169ZNpFQgoK3uJSIiAklJSaitrWU8R1A6mqSC/scff0R9fT1SU1Ph4OCA+Ph4qKqqIi0tDWfOnMG2bdtEuo+6ujr069eP6/eOYmZmhpaWFmhra8Pc3BzTp0+HhYUF+vbt22FfFOlCAwIKhUKhfHCk8YSfX7rP7NmzeYS4NFtltrS0wN7eHsnJydDX1+ccj4iIANDWWvHhw4c8dqIEBBs3bkTv3r2RkpKC4cOHY9++fejduzfS0tLw+++/Cy1ilVTQ379/H4sWLeJMjK2vrwfQlt/v6+uLrVu3ilQj0dTUhCdPnjCuPX78GM3NzQLtNTQ0cOTIEYwYMYJnLS0tDRoaGkL3IKmg/+KLLxAbGwsLCwsoKytzjtfW1iImJkZocNVOfHw8kpOTsWTJEmzcuBF+fn6Ql5fHkSNHUFNTg6VLlwq0l1TQX7lyBcuWLcMXX3wBAOjevTv09fWhr68PBQUFREdHIzo6Wuh9CCpmF5UNGzbAwsLigwT8lI5BAwIKhUKh/M/RWZ1yRIWproBf28mOcOPGDaxbt47TWrKlpQWqqqqYN28e6uvrERYWhl9//ZWvvaSCXkZGBnJycmCxWFBXV0dxcTFMTU0BAOrq6nj69KlI9zFu3DiEh4dDUVER48ePR/fu3VFbW4vjx48jIiJCaKrNokWLsGbNGjx9+hTjxo3j1BCcOHEC169fx4YNG4TuQVJBHxQUhPnz58PGxgbDhg3j7OHq1asghGDXrl0ifRapqanw9fXFzJkzsXHjRlhbW8PAwACenp5YsmQJbt++LbBzj6SCvrKyEpqampCVlUXXrl25ukFZWVlhz549It1HR2hpaYGBgQFP0Dxt2jSJfVA6BxoQUCgUCuWjIMkT/o8dEDCRlZWFwYMHM06VffPmDe7cuSN08NLr16+hqqoKGRkZdO/eHeXl5Zw1Q0NDoTnakgp6HR0dPHnyBMOGDYOxsTF27dqFQYMGQV5eHjExMfjss88E2rezdu1a1NfXIygoCEFBQZCTk+O8FRg/frzQvvczZsyAuro6duzYgc2bN6O5uRlycnLQ19dHTEyMSHUakgp6Y2NjpKenIyEhATdv3kRBQQE0NDTw1Vdfwd3dHT179hTps3j+/DkGDRoEWVlZyMvLc6UNOTs7IzAwEAEBAXztJRX0WlpaqKysBAD0798fGRkZGDVqFIC2FDMlJSWR7qOjSKOJJW2E+eGgAQGFQqFQPjj/REEvKfPmzeM716CgoADz5s0TOsm1b9++KCsrA9AmzlNTUzl96E+ePMnTu/99JBX0rq6unCFsfn5+8PT05OSnKykpISoqSqB9O926dcNPP/0EHx8f5Obm4uXLl+jVqxcMDQ0xcOBAgbZNTU3Izc0Fm83Gvn370NraisrKSqipqXHefIiCJIK+sbER8fHxGD16NJYtWybyNZlQU1Pj5NtraWnh9u3bGD58OIC2ImOmIuF3kVTQW1tb4/Llyxg3bhzmzZuHgIAA3Lp1CwoKCsjNzYWnp6dE90f5d0ADAgqFQqF8cP6NAYGgp5lv375Fly5dhPqwtbXFlStXMHHiRHh7e2Px4sUYNmwY5OTkUFFRgRUrVgi0l1TQT506lfPzwIEDcfToUdy4cQMNDQ0wNjYW6al4Q0MDpk6disDAQNjY2DC29xSErKws3NzcEBcXB01NTcjIyEBdXb1DPiQV9AoKCti5cyfMzMw6bPs+JiYmuHXrFkaPHo3Jkydj+/btqKiogLy8PBITEznBAT8kFfQrVqzgpI45ODigW7duOH78OBoaGhAUFISZM2dKfI+U/31oQEChUCgUipjk5OTgxo0bnN8PHz7Mk97U0NCA9PR0kYSxn58f52cbGxvs2bMHp06dQn19PaysrISmykhD0L9Lt27dGAt7BaGoqIjq6mquDkwdQUZGBn379kVVVZVY9oB0BL2+vj7y8/OFpnkJY8mSJZy3Pt7e3qipqcFff/2FhoYGWFlZYd26dQLtJRX0ioqKUFRU5Pw+duxYjB07VqJ7ovz7oAEBhUKhUChicvHiRU5BJ4vFYuzEIicnh4EDB2L9+vUd9j9kyBChk5QFIY6gf/PmDa5cuYKSkhKedBZROiUBbVNt//rrL1hbW3fo2u188803+Pnnn2FiYsLpPtVRJBX0a9asgZ+fH9TU1GBrayt2rv2AAQMwYMAAAG2Bytq1a4XWULyLNAX927dvGecgCEtFo/z7oQEBhUKhUP6zPHz4EPv27cOzZ8/Qq1cvfPnll7CyshJow2KxoK2tDQUFBSxZsoST/sRms7F//36JBHw7r1+/RklJCaN4E9ZxRRJBn52djcWLF6O6uppxXdSAwNjYGBEREViwYAFsbW15ZjIAbZ2I+PHXX3/h1atXGDt2LHR1dXlShkQZgiWpoJ8zZw6ampo4KUddunTp1Ha2oiCOoK+trcWPP/6IEydOiDUHQVyETQD/UD4ookEDAgqFQqH8J8nOzoaHhweam5uhpqaGV69eISkpCevWrRM4LVlGRganT5/mOS6NtqMlJSUIDAzElStXeNYIIWCxWALFm6SCfsOGDejXrx9CQ0MxcOBAyMvLd/geAHC65rx8+RIXL15k3Ieg+6irq+M8VW//vaNIKug9PT2lJkgPHz6MEydOMAZ5LBYLaWlpfG0lFfTr16/HmTNn4OzsDB0dHbG/045Cuwz9b8Ei9NOmUCgUyn8Qd3d3vHr1Cjt27ICWlhZev36NwMBA/P333/j777/F9puXl4fS0lLGJ7mCnooDwMKFC3H37l18/fXXfMWbhYUFX/vp06dDXl5ebEFvbGyMqKgojBw5skN27yPKFN/evXtLdA1hREVFCRX0H6K4fdu2bfj555/BZrMxcOBAKCgo8JyzadMmvvb+/v5CBf306dP52ltaWmLZsmVwcXER7wbeo76+HoWFhSguLoaFhQW6d+/+UXxQpAt9Q0ChUCiU/yT5+fkIDQ3lTE1VVlbGqlWrYG9vjxcvXnR4muqDBw/g6+uLoqIixiebwp6KA8D169cRGhqKSZMmdeja7RQWFiIqKgpsNlss+88//5yrz724dLbYFwUfH5+PvQUAQEpKChYsWIDly5eLZX/p0iWsXr1abEEvLy8vtcnAsbGxiIuLQ21tLVgsFmdomIeHBywsLLBo0aIP4oMifWhAQKFQKJT/JFVVVdDU1OQ61l7AWlVV1WERtX79erS2tiIqKkrs1AwVFRXGwWaiIqmgDwwMRGhoKPT09KCjoyO2n3epqKhgfFuira0t0K6xsRHnz59HYWEho/2HeLqfn5+P5ORkFBUVMe5h9+7dQn3U1NSIXVwNSC7oZ82ahYMHD0r81mfnzp3YsWMHFi9ejOHDh8PZ2ZmzNmbMGKSmpgoV89LwQekcaEBAoVAoFIoUuHfvHrZs2QJ7e3uxfXz99dfYvXs3rK2txQooxBH0U6ZM4fq9rKwMU6dOhYaGBnr06MG1JizfvZ2WlhZEREQgKSlJrLz3kpISzJo1C6WlpSCEQE5ODk1NTQDaOvXIycmJFBBIIuivXbsGNzc3DBo0CPfu3YORkRHq6urw8OFDaGlpYdCgQUKvDwD29vbIzMwUOm+AH+II+oSEBM7PSkpKyMnJgYuLC6ysrKCiosJ1rqiF4omJifD19cX8+fPR0tLCtfbZZ5/hyZMnH8QHpXOgAQGFQqFQ/rO4ubkx5pnPnj27wx1ltLS00Nra2uE9fPfdd1y/FxUVYezYsTA3N+cRbwB4WlZKKuj19fWl3s0lPj4eycnJWLJkCTZu3Ag/Pz/Iy8vjyJEjqKmpwdKlSwXab9y4Eb1790ZKSgqGDx+Offv2oXfv3khLS8Pvv/+OnTt3Ct2DpII+IiICDg4OCAkJgb6+PoKCgqCvr4+8vDx88803cHJy4mt7584dzs+Ojo5Yv349GhsbMWLECJ7vBODtHCWpoP/hhx94rlFcXIzc3Fye46IGBOXl5Rg8eDDjmqysLGdWQmf7oHQONCCgUCgUyn8Saaec+Pn5ISYmBqamplBTUxPZjqljkYyMDGMAwmKxeAICSQX9999/L7YtP1JTU+Hr64uZM2di48aNsLa2hoGBATw9PbFkyRLcvn0bkydP5mt/48YNrFu3jiN+W1paoKqqinnz5qG+vh5hYeeUTgAAACAASURBVGH49ddfBe5BEkEPAPfv38eiRYsgIyMDAByxymaz4evri61bt2LMmDGMtjNmzOD6TgghiI+PR3x8PM9xptoSSQW9NDpevU+fPn2Qk5PD+Kbjxo0bIg3ek4YPSudAAwIKhUKh/CeRdkBw4MABlJWVwd7eHnp6eoxP55l65zMFBB1BGoI+Pz8fKioqfIeAlZSUoLq6Grq6uiL5e/78OQYNGgRZWVnIy8tzpQ05OzsjMDCQ05qUidevX0NVVRUyMjLo3r07ysvLOWuGhoZCZxAAkgl6oC0ok5OTA4vFgrq6OoqLi2FqagoAUFdXx9OnT/nailJbIIjOEPSS4urqisjISKipqWH8+PEAgObmZpw+fRoJCQlYsWLFB/FB6RxoQEChUCgUihSoq6vDZ599xvX7h0ISQZ+eng5/f38kJSXxta+uroazszMiIyNhZ2cndD9qamqc+9fS0sLt27c5T4UrKip4Bqa9T9++fVFWVgYA0NHRQWpqKue6J0+eFGmyriSCvv26T548wbBhw2BsbIxdu3Zh0KBBkJeXR0xMDNd3/T6CWsN+CB4/fgw/Pz/4+vpi9OjRjOecPXsW27Ztw9atW9G3b1+hPt3d3fHixQuEhIQgJCQEADjzOubMmQNXV9cP4oPSOdCAgEKhUCgUKfD777+LZXfnzh14enri+++/h62tLeM5Z8+exapVq/Dbb7/xtBSVVNDv378f06dPF9iqVFdXF46OjkhMTBQpIDAxMcGtW7cwevRoTJ48Gdu3b0dFRQXk5eWRmJgotMDW1tYWV65cwcSJE+Ht7Y3Fixdj2LBhkJOTQ0VFhUhPkiUR9EDb0+zi4mIAbelgnp6ecHBwANCW1x8VFcXXtra2Ftu3b4eNjQ3fe71y5QrOnTsHHx8fns5Skgr6Xbt2QVFRka8tAIwePRpxcXFISEjAunXr+J73LqtXr8acOXNw+fJlVFVVQUVFBcOHD0f//v1FspeWD4r0oYPJKBQKhUL5iKxcuRJVVVWIi4sTeJ63tzdUVVV5UoQWLlwILS0thIaGCrQPDg7GixcvEBMTw3Xc0tISmzZtEir0z5w5g9WrV+Pq1asCzwPa5iGUlZXBwsICjY2NnEm7DQ0NsLKywrp16zpUZ3Hr1i1kZGSgvr4eVlZWsLGxEWqTlpaG4uJieHt749GjR/D09MTLly8B/H9B35F2oHV1dcjJyUF9fT2MjY3Rs2dPvudGR0cjJSUFx48fZxxEBrS1VZ04cSKcnJzg7e3NtbZ+/Xrcv38fe/fuFbin2bNnQ1dXl0fQjxkzBt7e3kLrJFJSUrBz506cPHlS4HmUfz/0DQGFQqFQKGIyc+ZMbNiwAQMHDgTQViS6efNmuLm5cc04aJ8+fPHiRR4fmZmZWLZsmdBrTZ48GeHh4TzHc3NzOWkXgrCxscHq1at5jtfV1TF2vnmf7t274/Xr10LPA4ABAwZgwIABANrahK5du5anGLojGBoawtDQsEM2U6dO5fw8cOBAHD16VGRBz0S3bt1EDiDS09Mxe/ZsvsEA0Pa5fPXVVzh8+DBPQHDp0iWeY0zMmDGDseNSaWmpSE/cP/vsM7x48ULoeQB356T3kZGRgbKyMvr06SOwwF0aPiidAw0IKBQKhUIRk5ycHK5agdbWViQkJGDSpElcAUFTUxMqKioYfZSXl4s0eOrTTz/l5NW/i6SCXl1dHUVFRTAzMxNoX1RUJLKIPnXqFMzMzBjbporCkiVLYGFhATMzM+jp6UlFIHZE0ANtb07MzMxgbm4Oc3NzDB48WOR9PH78mKeVKBODBw/Gtm3beI5LKuiVlJRQU1Mj1L6mpgZdunQReh7A2zmJiR49emDu3Ll8C/al4YPSOdCAgEKhUCgUKdLRTFxlZWW+wcK7VFRUQFlZmee4pILe0tISf/75J6ZNm8Z3GFpTUxP27NkDKysrofsE2gQ9i8WCjo4OLCwsOKJa1DSh5uZmREdHo7a2FsrKyjA1NYWZmRksLCxgYGDA6RwkCEkEPQB4eXkhKysLP//8M2pqaqCsrAwTExOYm5tz9iErK8toy2KxRJpJ0d529H0kFfS6urrIyMgQmgaWkZEhsHbkXbZv347vvvsOgwcPxrhx49CzZ09UVFTgxIkTuHv3Lnx9fXHnzh3s3LkTioqKWLhwYaf4oHQONCCgUCgUCuUjMmTIEBw5coTThpEfR44cwZAhQ3iOSyrovby84OjoiIULFyIwMJBnYNeDBw+wceNGFBQUYMuWLSLd0+XLl5GVlcX5b8+ePSCEYMCAARxBPWnSJL72O3fuBCEE9+7dQ2ZmJq5du4ZffvkF4eHhUFJSwtChQxEfHy9wD5IIegDw9PSEp6cnCCHIy8tDdnY2srKykJCQgIiICCgpKeH69euMtv369UN2drbQACorKwv9+vXjOS6poHdxccHKlSsxdOhQODs7M9omJyfj0KFD+PHHHwVeo5309HTY29vzpH5NmzYNYWFhuHTpEsLDwyEnJ4fk5GRGMS8NH5ROglAoFAqFQhELXV1dcvPmTc7vzc3NRFdXl9y+fZvrvJycHMJmsxl9nD9/nujq6pKffvqJNDc386w3NzeTyMhIwmazyYULF3jWHz16RIyMjIibmxvJz8/nWb9//z5xd3cnRkZG5NGjR4x7OHv2LDE3NydsNpuMGjWKuLq6kpkzZxIbGxvCZrOJubk5OXfunMDPQhA1NTUkPT2dzJkzh+jq6vL9LPhRUVFBjh07JpZ9a2sruXv3Ltm9ezfx8fEhw4cPJ2w2mwwdOrRD1z9+/DgJDQ0lkydPJrq6usTa2prv+Tt37iSmpqaM30c7+fn5xMzMjMTExPCspaWlETabTfbv38/XPikpiQwePJgcOXKEcT0gIIDo6uqS6dOnk59++okkJiaS/fv3k8jISOLo6EjYbDYJCAgQcNfcmJiYkEuXLjGuXbx4kZiYmBBC2v6eDQwMOs0HpXOgbwgoFAqFQpGAgoICzpPmlpYWzrH3z+HHyJEjsXjxYmzfvh3JyckYPnw4tLW1AQAvXrzA5cuXUVFRgcWLF2PEiBE89p9//jm2bt2KFStWYNq0aejVqxe0tLTAYrHw4sULlJaWonv37ti2bRvfSbA2NjY4fvw4EhMTkZmZidLSUgBtxcGzZs2Cs7Nzh7oCAW31FLdv30ZmZiays7Nx7do1vH37FsbGxkL79L98+RLZ2dnIzMxEVlYWCgoK8Omnn8LMzAyhoaEwNzcXeR8sFguampro1asXNDQ00LNnT1RWVqJr164C7Y4cOcJ5w1FQUABtbW2YmZlh3rx5MDc3F5jj7+bmhuPHj8PV1RUzZ87EqFGjON9JcXExzp8/j3379mHAgAFwc3PjsZ8yZQouX76MoKAg7N27F6NGjYK2tjaX/d27d+Hg4MD3TcumTZs47VbfLzzu168fQkJC4OLiIvwD/D/k5ORw+/Ztxrcet2/fhpzc/5eUSkpKneaD0jnQtqMUCoVCoYgJm83myQFv/9/qu8fJ/+WK37t3j6+vixcvIj4+HtevX0dDQwMAQFFREWZmZvD09BRaEFtZWckj6DU1NTFs2DCxBL0opKamwtbWlqd4eP78+bhx4wZaW1thZGQEMzMzmJmZYejQoSIVsbLZbHTp0gUTJkzg1AL06dOnQ3vjJ+jbawqEFe2278HZ2Rlubm4dvn5NTQ1CQkJw7NgxnroSFouFCRMmYP369QILwhMTE7Fr1y48fvyY63i/fv0wf/58kQV9aWkp19/EuwXvorJhwwbs27cP3t7esLe3h5qaGiorK5GRkYGdO3fiq6++QmBgIHbu3Ilz584xtkyVhg9K50ADAgqFQqFQxCQzM7ND54sywbalpQWvXr0CAKiqqgrMcy8uLkavXr24nqx2BH6CXhRaWlpgYGCA5ORkno46bDYbioqKmDZtGkaMGAFzc3N88sknIvt2dXXFnTt30LVrV5iYmMDCwgKWlpYdKgyWVNCHh4cjKysLt2/fhpKSEkxNTTkF0gYGBiLvo6SkhCdIs7Cw4DtEjglpCHpREPSdNjU1YcuWLdi3bx/XpGkFBQXMmjULy5cvh5ycHLKystC1a1fGLkvS8EHpHGhAQKFQKBTKR0ASMQ4IFm8fyl5fXx8HDhzgsS8sLERWVhYnXai0tBQ6Ojqcgl5zc3OhLUzfvn2LGzducHzk5uZCQUGBI8znz58v0F5agr6+vh7Xr1/nFBXn5uZCXl4epqamPEPeJKW1tRXu7u4IDQ0Va3JvZ36n7VRXV+P+/fsoKyuDhoYGvvjiC6iqqnboOtLwQZEutIaAQqFQKJQPTEtLC1avXo3k5GSxAwKg4y1OpW3Pj/bBZO0pLU+fPkVWVhYOHjyIvXv3gsVi4e7duwJ9KCkpwcrKClZWVmhsbMTVq1cRFxeHc+fO4fz580IDgvZhb+8K+jNnzmDr1q0dEvRdunSBmZkZ5OTkICMjg6amJuTk5OD8+fMifhqiQwhBZmYm12wLcXx0JioqKh2q4egsHxTpQgMCCoVCoVA+Av+FF/RPnz7lPOHPzMzE8+fPIScnBwMDA4F29fX1nLcDWVlZuHXrFhobG9GrVy9MmjRJpNSrdsQV9JcuXeLUINy6dQtNTU3Q1NSEmZkZHB0d/5OC9s2bN7hy5QpKSkq4Un6AtroId3f3D+KDIn1oQEChUCgUCkWqLFu2DNnZ2Xj58iXk5eUxZMgQTJ06Febm5hg6dKjQDjJmZmZoaWmBtrY2zM3NMX36dFhYWKBv374i70FSQT9//nz06dMH5ubmmDFjBszNzTt0/X8b2dnZWLx4MaqrqxnXRRHz0vBB6RxoQEChUCgUCkWqVFRUwMXFBRYWFjAyMoKCgkKH7Dds2AALCwtoaWmJvQdJBf3Zs2c7VPj7b2fDhg3o168fQkNDMXDgQL5D8DrbB6VzoAEBhUKhUCgUqdHY2AhLS0uMHj0aenp6YvkwMDAQGAycOnUK9vb2An1IKuhzcnLw5Zdf8l3fvHkzVqxYIbb/fyr8iq0LCwsRFRXFOBlZVKThg9I5yHzsDVAoFAqFQvnfQ0ZGBtOnT+dpJ6qgoICYmBi8fv1abN+enp54/vw549qxY8fw7bffCvWRk5MjcH3z5s0C11esWIGLFy8yrn333Xf4448/hO7hYyBq9yR+8Ktt+fzzzzntcMVFGj4onQMNCCgUCoVC+R+ExWJBW1u7w+k47TAJ+gkTJmDXrl2orKwU6fqbNm3iTFV+l8GDByM/P1+sfQHAkCFD4O7ujrKyMq7jqampWLFiBby8vIT6kFTQf/vtt/Dx8UF2djbX8XXr1iEpKQnR0dFC9/AxeF/Qx8bGory8XCRbWVlZ5OXlMbYcDQwMRFxcHB4+fCj23qThg9I50DkEFAqFQqFISGNjI+Lj40VOkyGEIDAwED4+PlyCet26dXBxcRHahYcfEyZMgLOzMxwcHMSaTBwUFISjR4+ioaEBtra2cHJywqhRozr81PnOnTvw8/PD0qVLYWtrK7SI+H2amprg5eWFly9f4s8//4SKigqSkpKwfv16+Pr6wtvbW6iPX375Bdu3b0dcXBzMzMw4x9etW4dDhw4hOjoaI0eOFOjjp59+wp9//onffvsNgwcPRkBAAE6ePImff/4Zw4cPF+lecnJyYGxsLNK5QNuwOwMDA3Tt2hVAm6B3dHSEurq6yD7exdzcHG/fvsXIkSPh4uICGxsbyMh0/HnwlClTUFZWhpqaGmhoaPBMWGaxWEhLS+t0H5TOgQYEFAqFQqFIASMjI/zyyy8StaMcP348njx5gkGDBsHZ2RlTpkzp0JwCaQj6t2/f4ujRozhw4ACuX78OTU1NODo6wtHRUeSi3KFDh6KpqQktLS0A2lp/vrsHFouFa9euCd2Hh4cHGhsbMWHCBERERGDFihXw9PQU+V6kIehDQ0Nx9OhRGBsbIzMzE7GxsVwBhjDYbDZ0dHTg5OSEadOmdWhiMyC5oG9oaMCxY8dw4MABZGVlQV1dHY6OjpgxYwb69esnsp+AgAChf0ebNm3qdB+UzoEGBBQKhUKhSIGvvvoKEydOxJw5cyTyk52djaSkJJw8eRItLS0YM2YMnJ2dRRaw0hD07Tx69AgHDhzAoUOHUFVVBXNzc7i6umLcuHGQk+PflyQqKkqo8FuyZInQ69fW1mLevHnIy8vDmjVrxPpsJRX0QJuQPXXqFOLi4jr0tB8Arl+/juTkZBw/fhxNTU2ws7ODs7MzRowYIZK9tAQ9ABQVFSE5ORmpqamoqKiAmZkZnJyc8OWXX0JRUbFDvij/LmhAQKFQKBSKFJA0TeZ9Xr9+jcOHD+PAgQO4c+cOtLW1MWPGDMyYMQOampoi+RBX0LdTVVWF1NRUJCUloaCgADo6OigoKMCnn36KzZs3w9TUVKJ7fBd+aUBVVVUoKirC0KFDOcdYLBZ27Nghsm9RBf3QoUMZAxlCCJqamrjqNUR5y/Eub968wV9//YXk5GTcvHkT2tranECNqQ6DCWkJ+tLSUixfvhxZWVkAgB49emDmzJlYtGiRxH+3lP9NaEBAoVAoFIoUkEaaDBN37tzB999/zxFvcnJyGD9+PFavXi00r1wcQU8IwYULF5CcnIwzZ85AWVkZDg4OcHFxwYABA/Ds2TMEBwfj+fPnOHbsmMDrv337Fnfv3kV1dTVUVFSgr6+PLl26MJ47d+5cET+RNn7//XeeY5IKelHebLyLKG85mHj48CFCQkKQnZ0NFouF4cOHw8PDQ+S3BuIIekIIzp07h+TkZJw9exaqqqpwdHTE2LFjce7cOezevRvm5ubYvn073+uWl5fjyJEjKCoqQkNDA8+6KOk+0vBBkT40IKBQKBQKRQpIK00GAGpqanD48GEkJycjLy8Penp6cHV1xdixY3H+/HlERUVBW1ubURRLIugjIyORmpqKkpISWFhYcK75fiejGzdu4KuvvsK9e/f43sOOHTsQFxeHt2/fcjrfdO3aFV9//bVIRcHi8KEEvbhUV1fj0KFDSE5Oxv3792FsbMwR5FlZWfDy8sLSpUsZbcUV9E+ePMGBAwdw8OBBlJWVwcrKCq6urrCzs+N6S3Tq1Cn4+/vj5s2bjNd/+PAhZs2aBXl5eVRVVUFLSwvV1dWoq6tDz549oaamhsOHDwu8f2n4oHQShEKhUCgUyj+Cy5cvE39/fzJkyBBiYmJCgoKCyO3bt3nOu3jxItHX1+c5/tNPPxEbGxuiq6tL5s6dS44cOUIaGhp4zrt+/Tphs9k8x4cPH05++OEHUlRUJHCfVVVVJCUlhe96QkICYbPZJDg4mGRmZpJHjx6RzMxMEhwcTPT09Mivv/4q0P8/gdraWlJaWsq4VlpaSl6/fi2yr4sXL5KlS5cSQ0NDYm5uTsLCwkh+fj7XOQkJCcTMzIzH9vHjxyQiIoKMHDmSsNls4unpSU6cOEGampq4zsvIyCBDhgzhsdfV1SUjRowgERER5NmzZ3z3WFBQQObMmcN3ff78+eSbb74hjY2NRFdXl/N3mZGRQWxsbMi1a9cEfgbS8kHpHGhAQKFQKBSKFHnz5g3Jzs4mp06dItnZ2eTt27ci2+rq6pIZM2aQ/fv3k7q6Or7nPXv2jAQEBPAcl1TQNzY2irxXQYwdO5Zs2bKFcW3Lli1k7NixAu0jIiJIUFAQ41pQUBCJjIwUugdJBf23335LAgMDGdfWrl1L/P39he6BEEJGjx5N2Gw2mTlzJjl48CCpr69nPO/WrVtEV1eX57ikgj49PZ00NzeLtFdBDBs2jJw9e5a0tLQQXV1dcv36dc7aH3/8QZydnT+ID0rnILyiiEKhUCgUikhImiZz8OBBkeYY9O7dmzHX+ty5c5CXlxdqr6qqiunTp/McF8VWFF68eMG3K9KwYcPw66+/CrQ/cuQIfHx8GNdMTU2xfft2odOK165di27dumHDhg08a1FRUXjz5g3Cw8P52mdnZ2P9+vWMazY2NggJCRF4/XbGjBkDV1dX6OjoCDzPwMAAeXl5PMejo6Nha2sLWVlZgfYDBgxgTCEbM2YM52dCCKqqqvDJJ590eLZEU1MTlJSUICMjA1VVVbx8+ZKz9vnnn+P+/fsfxAelc6ABAYVCoVAoUuDXX3/Ftm3bMHPmTEycOBE9e/ZERUUFjh49im3btkFJSQlubm4CfYgSDAhCUkHPrygXaJts3L17d7DZbLi7u8PS0pKvH01NTWRnZ8PKyopn7fr16+jVq5fAfbx8+RJaWlqMa59++ilKSkoE2gOSC/rq6mrOcLD3UVJSwqtXr4TuAQDWrFkj0nn8kIagv3DhArZv3447d+6gubkZcnJy0NfXx+LFi4UOZ2unf//+KC4uBtA2ifrPP/+EtbU1ZGVlsXfvXpE6X0nDB6VzoAEBhUKhUChSYM+ePViwYAGWLVvGOfb555/D3NwcysrK+PPPP4UGBILeIrQLcj09Pb4DriQV9B4eHjh48CCamppgY2PDCWra3zyMGTMGWVlZ8PDwQHR0NOzs7Biv5eTkhKioKDQ1NWHChAlQV1dHRUUFjh07hl27dvF9+t+Ompoa7t+/z7jH+/fvizSsTVJB37dvX1y5cgXW1tY8a1euXEHv3r2F7qGdyspK/Pbbb7h58ybKysqgoaEBIyMjuLm5iTRRWhJBn5ycjLVr12Lo0KFYtmwZ5zs9fvw4vv76a4SFhcHJyUnoHqZMmYL8/HwAgK+vL+bPnw8LCwuwWCwQQvDDDz98EB+UzoF2GaJQKBQKRQoYGhoiJiaG8an4pUuX4O3tjVu3bgn0MXfuXBQWFqK8vBx9+/bliLenT59CQ0MD6urqKCgoQLdu3bB7926eNJRt27aJJOjv37/PKOh37NiBrKws7Ny5k6uzUGNjI7y8vDB06FD4+Phg0aJFqKioQFJSEuN9tIu7P/74g9OGFQBkZWUxd+5crFq1SuDnEBYWhiNHjiAuLg5DhgzhHM/NzYWXlxcmTJiAdevWCfQxceJE2NnZYfny5TxrW7ZsQUZGBo4fP87XPiEhAeHh4fj2228xY8YMqKmpobKyEikpKYiMjIS/v79IU5NzcnKwYMECtLS0YNiwYVBXV0d5eTmuXr0KGRkZxMfHC5yN8K6gHz9+PJegv3nzplBBb2dnB0tLS8YUs1WrViErKwunT58Weh/v8+LFC5w/fx4NDQ0YNmwYBg0a9FF8UKTExytfoFAoFArl34O9vT3ZunUr49q2bduInZ2dUB/p6elk3Lhx5N69e1zH7969S8aNG0eOHTtGSkpKyKRJk4iXlxeP/c8//0w8PDx4Ogs1NDQQd3d3snXrVtLa2kq8vLyIk5MTj/3IkSPJ2bNnGfd2+vRpYm1tzdmnkZGR0PuprKwkZ8+eJYcOHSJnz54llZWVQm0IIaSmpoY4ODgQNptNJk2aRDw8PMikSZMIm80m06dPJzU1NUJ97Nq1i+jr65PY2FhSUVFBCCGkoqKCxMXFEX19fRIfHy/QvrW1lQQHBxM2m03YbDbR19fn/BwcHCzSfRBCyPTp04mrqyuprq7mOv7q1Svi7OxMHB0dBdrb2toyFpATQsjKlSuJra2tQHsjIyNy8eJFxrULFy6I9D1S/v3QlCEKhUKhUKSApGkyQNscAF9fX7DZbK7jenp6WLJkCSIjI3H8+HEsWLCAsVh27969CAsL45kboKCggHnz5iEoKAi+vr5wcnJifHJeU1PDN5WmvV88ACgrK/OkJunp6SExMRFDhgzB6tWr8c0336Bv376wsbERet/v0717dyQmJiI1NRVXr17Fq1evMGjQILi5uWHatGk898eEu7s7njx5goiICEREREBWVpbztmLmzJlCn+6zWCysX78ebm5unD2oqqpi2LBh6N+/v8j38vDhQ0RGRqJHjx5cx1VUVODl5QU/Pz+B9pWVlZg8eTLj2pQpU3DixAmB9kOHDsWdO3cYU5/u3LkDIyMjIXfATV5eHkpLSxmHio0bN+6D+aBIFxoQUCgUCoUiBby8vPDq1SskJCTgl19+4RxvT5Px8vIS6uPJkyd88967du3KKcjU1tZmFFOSCHoAGD58OLZs2YLevXvDzMyMczwrKwvh4eGczkGFhYXo06cPl628vDyampoAtHVLmjVrFvr27SvslvmioKAAFxcXuLi4iGUvLUHfv3//Dp3/Pv369UNtbS3jWm1tLT777DOB9pIKej8/P/j7+6OxsRFjxozhpD6lp6fj0KFDiIiI4PqbUVVVZfTz4MED+Pr6oqioiNNB611YLJbAQXXS8kHpHGhAQKFQKBSKFGCxWAgICICXlxdu3ryJmpoaqKioYMiQIYwFwEzo6OggLi4OlpaWXIFBXV0d4uLi8MUXXwBo68Kjrq7OYy+JoAeA4OBgLFq0CHPnzkX37t3xySefoKqqCrW1tdDT0+N07ZGVlcWCBQu4bPv374+4uDg8fvwYQFsL1IKCAr736uDgINJnIimSCvrq6mo8fvyYMQAzNzcXar9q1SoEBwdDS0sLFhYWnON///03oqOj+XZCakdSQd8eUEVHR3NNMW4X5K6urlzn8xPk69evR2trK6KioqCjoyNWRytp+KB0DrSomEKhUCiUfwjXrl3DggULICcnB0tLS474u3r1KlpaWhAfHw8TExOEh4ejubmZpzi3tLQUixYtwr179xgF/Y4dO6CpqYn9+/dDUVER06ZNY9zHuXPncOvWLU5HHENDQ6GpP5cuXcKqVatQXl7O6RrDD1GeBO/ZsweJiYkoKipCY2Mjz7qoT5LFFfQNDQ1YtWoVTp48yfdeRNnDlClT8PLlS9TU1PB8Jz169OBqwcpisZCWlsZl/2762Ltvddr39P6bnvf3lJKS0qEWpUzzKYC2NxVbtmyBvb29yL46wwelc6BvCCgUCoVCkRKStpc0NTXFyZMnkZCQgNu3b+PRo0fQ0NCAq6sr3N3doaGhAQBcrU3fRVNT477a/AAAIABJREFUEykpKUIFPVMaTkNDAxYtWoSvv/4aNjY2Hc79t7a2xsWLF1FTUwMLCwvEx8dj8ODBHfLRTlJSEn744QfMmjUL+fn5mDNnDgghOHnyJBQVFTFr1iyhPiQV9JGRkcjNzUVUVBQWL16MTZs2oVu3bkhLS0NeXh7CwsJEuhd9fX0YGBiIdC4TGzdu7PAQsXdxdHQU2/ZdtLS00Nra+tF9UDoH+oaAQqFQKBQpIGl7ycbGRsTHx2P06NFiDSh7V9APGzZMrHswMzNDVFQU3ynDonLw4EGMHj1a5FSp1NRU2NracuYLTJ06FZMnT8b8+fOhr6+PAwcOQF9fHw0NDZg/fz5GjBghdPLzDz/8gBMnTmDNmjV8Bb2g+xw3bhy8vLzg4OAAfX19JCUlwdDQEAAQFBSE5uZmxlae/1SePXuG69evo7q6GioqKjA1Ne3QLIX09HTExMQgNjZWpOC2s3xQOgf6hoBCoVAoFCkQGhoKHR0dxMbGcnWUqa6uxsKFCxEWFoYDBw7wtVdQUMDOnTu5cv87gqKiInJzcwWm6ghj1KhRuHDhgsQBAb+0EyZaWlqwevVqJCcncwKCp0+fwtjYGLKyspCVlcXr168BtN2ju7s7vvvuO6EBwalTp7B48WKMHj0aQFt9hqGhIcaNG4egoCCkpaUJvM/S0lL069cPsrKyUFRURE1NDWftyy+/hL+/v8j3+K7P9uLmjk7lFVfQt7S0YP369UhJSeF6Oi8jI4MZM2YgODgYsrKyjLbvf8ZlZWWwt7eHnp4eT9ckFouFHTt2dIoPSudDAwIKhUKhUKSApO0lgbb0kvz8fJGKVZmQVNA7ODhg3bp1qKurg52dHXr27MmTrqKvry+Wb0G8H8QoKyujvr4eQFsa1MOHDzlTi5uamrjEOT8kFfQaGhocmz59+uDvv//mdPopKCjoUBpPWloatm7dyukSBbR1ilq6dCmmTJki0FYSQQ+0Das7dOgQ/P39MXHiRM6bq6NHj2Lr1q3o2bMnli5dymjb3pWqnXc7Ir2/xg9p+KB0PjQgoFAoFApFCkjaXhIA1qxZAz8/P6ipqcHW1hZKSkod2oOkgv7rr78GACQmJiIxMZGniPVDtYU0NDREfn4+Ro0aBTs7O0RHR6O1tRXy8vKIjY0VmHrVjqSC3tLSEllZWbCzs4OzszN++OEHFBQUQEFBAenp6XwLst8nLS0NK1euxKhRo+Dj48OZNHz06FGsXLkSLBaL75wBQDJB3359X19frq5Q2traWLBgAVpbW7Fnzx6+9r///rtI9ygIafigdD40IKBQKBQKRQpI2l4SAObMmYOmpiZO0XCXLl24hCuLxcK1a9f42ksq6Hfv3i10jx8Cb29vPH/+HADg6+uL58+fY9OmTWhtbYWhoSFCQkKE+pBU0Pv7+3Paebq7uwMAjh8/joaGBsybNw+LFy8W6V7i4uLg7OzMU4Ts4OCAtWvXIiYmRmBAIImgB4Dy8nK+xd36+vqoqKgQ6T4o/25oQEChUCgUipi8n+5RW1sLNzc3xvaSP/74I0aOHCnQn6enp0QdZSQV9O8GMv+PvTuPi6re/wf+GjZBQVa3lEzgm+CwCJaimBsgUdINl8QsEEUwgXTQ+3UJESXFREV0BsVdzFvyRbPcUKlbF0tEQSRxy6WrhSb7pjIwnN8f/JgHw6zMOaNI7+fj4ePCnPN5zzlAj/t+z/l83p8XydXVFa6urgCAnj17Ytu2bRCLxRCLxTA1NdUoBtuE3traGtbW1tLvZ82aJY3TEb///juWLl2q8Njbb7+Nb7/9VuV4tgm9ra0tfvjhB4Ubm/373//WePO45ORkVFZWYvXq1XLH4uLiYG1tjQULFug8BtENKggIIYQQLfH5fFYJfHvR0dGsxnOV0BcUFKCoqAgPHz5EaGgo+vbti6KiIgwYMOC5d4dhGAaVlZWwtLSEkZGRxuO4Suhra2tx8+ZNlJaWonfv3nj99ddhZmam8XhLS0v89ttvChPy27dvq+3ExDahDwkJwcqVK1FZWQl/f3/Y2NigvLwcp06dwsmTJxUm54ocP35c6d/nsGHDIBKJ1CbzXMQgukEFASGEEKKldevW6STus2fPcO/ePZSUlGD48OEdSkAB7RP62tpaCAQCnDt3Dqampqivr8d7772Hvn37Yv/+/bC0tERsbCzb29NITk4ORCIRiouL0dTUBAMDA/D5fERGRqp90tKWtgm9RCJBSkoKDhw4gGfPnkkXPpuYmOCjjz7CwoULVS7mbfXuu+9i8+bNMDY2hr+/P8zNzVFTU4NTp04hJSUFQUFBKsezTeinT58OsViM1NRUnDx5UrppnJWVFWJjYzFt2jS19wC07I7dr18/hcf69u2LR48ePZcYRDeoICCEEEI6kR07dmDnzp2ora0Fj8dDZmYm+Hw+QkNDMXz4cHzyySdKx7JN6BMTE3Hnzh1kZGRgyJAhMhtqjR49Grt27VJ7/R3dT0FPTw+BgYEyn5RnZmYiNjYW7u7uWLRokXQhblZWFsLDw5GQkICpU6eqjMs2oV+/fj0OHjyIOXPmwM/PT+Ya9uzZA7FYjGXLlqm9P4FAgD/++APx8fFYtWoV9PX1IZFIwDAMJk6cqLb7FJuEvrGxEUVFRZg4cSJmzpyJu3fvorq6GhYWFhg0aBD09PTUXn8rKysr3Lp1S9rtqa1bt25JW8bqOgbRDSoICCGEEI5cvnwZWVlZePToERoaGmSOadJjffv27di2bRsiIyMxcuRImWTPx8cHR48eVVkQsE3ov//+e3z22WdwdXWFRCKROfbKK6/ItM1UpqP7KfB4PLkNvlJTUxEYGCj3+qxZs7BkyRKkpqaqLQjYJvRHjx5FdHQ0IiIipK/16dMHQ4YMgYmJCfbt26dRQWBkZIStW7fi5s2buHTpEmpqaqT7CAwePFjlWLYJvb6+PkJCQrBz50706dMHDg4Oaq9XGR8fHwiFQri5uUnXdwBAUVERUlNT4e/v/1xiEN2ggoAQQgjhwMGDB5GQkABLS0sMHDgQhoaGHY5x6NAhfPrpp5gzZ45cQv7qq6/i/v37KsezTegbGhqUzmmvr6/X+BNltvspVFRUKO28ExAQgNOnT6uNwTahb25ulimo2nJxcZHZE0CZhoYGDBs2DJs3b4aPj4/aAqA9tgm9np4ebG1tUVlZ2aFxiixcuBAFBQWYPn067O3t0bt3bzx+/Bh37tyBk5OTRvtscBGD6AYVBIQQQggH9u3bh8mTJ2P16tUwMNDu/15VdZTR19eXbtalDNuE3tHREVlZWQrn6P/4448yn+qqwnY/BXd3dxQXFytcSFtcXAw3Nze1Mdgm9G+//TaOHz+u8BpOnDiBiRMnqr2Gbt26wdLSUqviEOAmoZ8/fz5SU1Ph4eGBvn37ah3HzMwMhw4dwtGjR5Gbm4uqqiq8/vrrCAkJwT/+8Q+NFnxzEYPoBhUEhBBCCAfKysoQEBCgdTEAtGygVVhYqHCn4cuXL8POzk7leLYJ/fz58zFv3jw8e/YM/v7+4PF4KCoqwrFjx3DkyBHs3r1bo/vQZj+F1hahQMu8+5iYGIjFYvj4+MDKygoVFRU4e/Ysvv32W2zatEntNWiT0J85c0b69bBhw5CcnIyPP/4YPj4+0ilH2dnZePDggcre/21NnjwZX3/9NcaOHavR+e2xTehPnDiBqqoq+Pr6YvDgwbCxsZE5rslUtlZGRkb44IMP8MEHH6g8j2EYiEQiTJ8+Hb169eI8BuEeFQSEEEIIB0aMGIHr168rTOY1NX36dGzevBlWVlbw8/MDADQ1NeGHH37A3r178c9//lPleLYJ/ZgxY7BlyxYkJibixIkTAIBVq1ahX79+SE5OVrgYVBFt9lPw9PSU20hNKBRCJBLJvAa0/JwUbbDGNqH/9NNP5V7766+/cPHiRbnXly1bhvfff1/tffXo0QPFxcWYNGkSxowZAxsbG7niSFU7VLYJfX19PQYNGiTzva41NzdDJBJh/PjxWifzXMQgmuMxrf91EUIIIaRD2n6q/ejRIyxevBgffvghRo8ejZ49e8qdb2FhoTZmYmIiDhw4AKAlKWqd5vPRRx9h+fLlasdnZ2cjMTFRutMvAPTr1w/Lly+Hr6+v2vGtfv/9d1RUVMDc3Bz29vYaj9PWkSNHOlREBAYGyr3m6Oio8XhFuza3/Zlpon///mrPUXdN6naP/vjjj9W+R+vfS2chkUjA5/Nx+PBh8Pn8FxaDaI4KAkIIIURLjo6Ocp9qA1Ca2KpK/Np68OABfvnlF1RWVsLc3BwjR47Ea6+91qFre94JvSJPnz7FtWvXUF1dDXNzc/D5fBgbG3P+PkePHsX48eNRV1fXoXGaJPSaYBgGy5cvR3R0NF555RVOYnJFKBRi2rRp6NOnj9yxx48fIyMjA1FRUZy+JxUELx+aMkQIIYRoae3atZzuVNzK1tYW06dPZxXjtdde63ARAQAlJSXIzs7Go0ePIBaL5Y5rujHZtm3bsHPnTjx9+lRaKHXv3h3h4eGYN29eh69LGYlEgmXLlkn3a9AG24S+ubkZR48exUcffSQ3/uLFixgyZAh69OghN+7JkycoLi5W2Y2JbUIvEokwZswYpeNFIhHnBQF5+VBBQAghhGhp8uTJOol748YN/PXXX3J7GQBQ292GTUJ/5swZxMTESDe+at8dh8fjaVQQ7Nu3D1u2bEFQUBDeeecd6fz9kydPYsuWLTAxMUFISIjaOJpiO9lBVULP9hqCg4Nx6NAhhQu67969i+DgYJVPjtgm9Kp+No8fP1Y4tY38/VBBQAghhHQSv/32Gz799FP8/vvvChM5dfPN2Sb0mzdvxujRo7Fu3TqN1jso869//QthYWHSLkMAYGdnhzfffBOmpqY4ePAgpwUBF3Q1g1pV3KdPn6qdQqVNQn/8+HEcP34cQMvv/IsvvoCZmZnMOWKxGL/++iuGDRum8v3J3wMVBIQQQggHAgIClB7T09ODmZkZnJycMGPGDKXtQ1euXInm5mZs3boVDg4OHe5fzzahLykpQWxsLKtiAAAePnyotNuSp6cn9u3bxyp+Z1dYWIjLly9Lvz927Jhcm9WGhgacPXtW4d8C24S+sbFR2k2IYRg8ffpUbg8KIyMjvP/++wgLC9PuJkmXQgUBIYQQwgFnZ2fk5uaivLwcHh4e0mkyBQUFsLa2hq2tLU6dOoWMjAzs3bsXHh4ecjGuX7+ODRs2wNvbW6trYJvQOzs7448//tBqbFt9+vTBpUuXMGrUKLljBQUF6N27N+v36MzOnTsHoVAIoCWhV9QFyMDAAPb29li5cqXcMbYJfWBgoLQL08cff4z4+PjnurBcT08PUVFRrH7PXMQgmqOCgBBCCOGAu7s7bt68iczMTFhbW0tfLysrQ3h4OEaOHImkpCSEhoYiOTlZYZLYr18/tTvoqsI2oY+Pj0dMTAz69OmDUaNGab3D7tSpU7F161Y0NjbC398fNjY2KC8vx6lTp7Bnzx5ER0drfY0vg6ioKOm8fkdHR2RkZGi8yzPAbULPdUtSTda38Hg8lesauIhBuEUFASGEEMKBHTt2YOnSpTLFAADY2Nhg3rx5WLduHWbOnIng4GB89tlnCmMIBAKkpaVh2LBhsLKy6vA1sE3op02bhqamJsybNw96enro1q2bzHFFOwwrEhERgaqqKuzduxe7du2Svq6vr4+PP/4YERERHbqul9mNGzdYjecioeeicxTb9S1cxSC6QQUBIYQQwoHS0lJIJBKFx5qbm1FeXg6gpUBQtlD08OHDKC0thbe3N5ycnOQWjKrblZZtQq/NDsOK8Hg8LF26FBEREbhy5Qpqampgbm4OV1dXWFpaqhwrFouxe/dujBs3Dk5OTmrfS09PD4GBgWrjdkRDQwM++eQThIeHw9PTU+35+vr6SExMxIABA5Se87J3jmK7voWrGEQ3qCAghBBCOODq6oqUlBTw+XyZxPDBgwdISUmBm5sbAOCPP/5Q2EISAOrr6/Hqq6/KfN8RbBN6rqfyWFpaYty4cR0aY2RkhO3bt+ONN97Q6Hwej4fExESZ19gm9N26dUNRUVGHOg8p2jkZ6Dqdo9iub+EqBtENKggIIYQQDsTHx2PWrFnw8/PD66+/DisrK1RUVODWrVuwtraWLjItKytTuukY2+kh2iT0YrEYRkZGGp33559/YtCgQRrFraiowP79+3HlyhWUlpaiV69ecHNzQ0hIiNrpUHw+Hzdv3lS5YZcqXCT0Y8aMQU5OjtJuSZrqKp2j2K5v4SoG0Q39+Pj4+Bd9EYQQQsjLzsrKCjNnzoS1tTWam5vx5MkTDBw4EFOnTkViYiJ69eoFABg2bBjc3d05e1+xWAx9fX2Nzrt//77c1BpnZ2eZja+am5sxbdo0vPHGGzLnXr16FYGBgRot9CwsLMS0adNQWFiIQYMGwd7eHo2NjThx4gS+/PJLjBgxAn379lU63tHREevXr4e1tTUGDBig1dSSGzduoKKiAl5eXh0eCwAmJibYsWMH7t27Bz09PdTV1aG0tFTmnyYdcD7//HOsWrUKPj4+sLCwQM+ePeX+qZKUlITly5fjf/7nf7S6j3PnzqFfv35a7+Lcqnfv3khLS4OPjw9MTExeWAyiG/SEgBBCCOFIt27dMHPmzA6NCQoKwpo1a6RdZBiGQVJSEkJCQmSmFl27dg3h4eE4d+6czHg3NzeZnXCbm5vxwQcfYP369TI97q9fv46goCC56SntP0VnGAZXr17F06dPO3Qfba1evRoODg7YsWOHTMJbXV2NuXPnIiEhAYcPH1Y6/qOPPkJjY6N0YzNjY2OZqVCaLG5+//33ERcXh/r6ekyYMAHW1tZy06lUJcnh4eEAgEOHDuHQoUMyYxmG0XgBbFfpHMV2fQtXMYhuUEFACCGEvECFhYUyawWam5uxd+9evPvuuzIFQWNjo3Rhclu6SOjZun37NjZv3iyX8JmbmyMiIgICgUDleC4WN7NN6NPT01m9f6uu0jmK7foWrmIQ3aCCgBBCCNGSh4cH0tPT4ezsDHd3d5VJrKaJFyCf5L9sBg4ciNraWoXHamtrZZJCRbhY3Mw2oR8+fDjrawC6TucoLtqfcr0nAuEOFQSEEEKIlmbPni1dG8BV4tUVLFmyBPHx8ejXr59MYn3hwgUIhUKFu/Mq8vTpU1y7dg3V1dUwNzcHn8+HsbGxRmO5SugvXryIS5cuSa/hzTff1LgDEtD1OkcBLQVrfX09evToofW1cRGDcIcKAkIIIURLbRfYvsy77x4/flz6KXNzczN4PB6OHTuGvLw86TklJSUqYwQEBMh8X1tbi5CQEJiZmcHS0hKVlZWora1Fz549sX79erz11lsq423btg07d+7E06dPpU9MunfvjvDwcMybN0/je9M2oX/y5AmioqLwyy+/wMDAABYWFqiqqoJEIsGoUaOwdetWdO/eXW2crtQ5Ki8vD0KhEJcvX0ZTUxMMDAzg4eGB6OhojYskLmIQ7lFBQAghhHCspqYGJSUlGDRokNwUD0Xu3r0r7RTUurnZ3bt35c5Rhm1Cr2h6zb59++ReU/VJLp/P5+yT3n379mHLli0ICgrCO++8A2tra5SXl+PkyZPYsmULTExMEBISojIG24Q+KSkJRUVFSE5Ohp+fH/T09NDc3IzTp08jLi4OGzduxIoVKzi53/bYJvRsF5orcu7cOURERMDOzg4RERGwsbFBWVkZTp8+jVmzZiEtLU1tRycuYhAdYQghhBDCiRMnTjATJ05kHB0dGUdHR+bq1asMwzDMwoULma+++krhmMGDB0vPb/03ePBguddbv1c0XtN/isZ3Rr6+vsyGDRsUHtuwYQPj6+urNkZ8fDwzbNgw5uTJk4xEImEYhmEkEglz8uRJ5o033mBWr16tcvyoUaOYf/3rXwqP/etf/2JGjRqldOz06dOZ27dvS79vbm5mvvjiC+bRo0cy5xUXFzNeXl5y4x0dHZkrV65Iv5dIJMyUKVOYO3fuyJxXWFio9G+i7fimpiZm8ODB0r9HdeMVmTJlChMZGck0NzfLHZs/fz4zderU5xKD6AY9ISCEEEI4kJGRgfj4eEybNg0CgQALFy6UHnN1dcWxY8cQFBQkN47t4tcbN26wGq8thmGwfPlyREdH45VXXuE09sOHD5VuCObp6anw6UV7Z86cwaJFi+Dv7y99TU9PD/7+/qiqqoJQKFT5CX9tba3MjtNtDRgwQOmiaaBrdo66desWPv30U4VPgaZPn67R1CYuYhDdoIKAEEII4cDu3bsxd+5cCAQC6bSfVnZ2dkqn/LBZ/Hr06FGMHz8e5ubmHR7LNqFvbm7G0aNH8dFHHykcf/nyZWRlZeHRo0doaGiQOaaus06fPn1w6dIljBo1Su5YQUGBRhuCsUnoAcDBwQHffPONwrUOR48ehYODg9praKt9kv+yMTU1xV9//aXw2F9//aXRegouYhDdoIKAEEII4UBJSQk8PT0VHuvWrRvq6uo4fT+JRIJly5YhMzNTq4JAXUKvCWVJ7sGDB5GQkABLS0sMHDiww73zp06diq1bt6KxsRH+/v6wsbFBeXk5Tp06hT179mj0STLbhH7+/PmIjo5GSUkJ3n77bel896ysLBQVFWHLli0duqeX3fjx47Fx40b07dtX5md67tw5JCcnw9vb+7nEILpBBQEhhBDCgd69e+O3335TONXlxo0bsLW15fw92X7qrKtPrfft24fJkydj9erVMDDoeKoRERGBqqoq7N27F7t27ZK+rq+vj48//hgRERFqY7BN6H18fCAUCiESifDFF19INzNzcnKCUCjEhAkTOnxfzxMXnaPa+t///V/cunULc+fOhampqXShd319PVxcXPC///u/zyUG0Q0qCAghhBAOBAQEQCQSwc7OTloU8Hg83LhxA7t27UJwcPALvsLnp6ysDAEBAVoVA0DLz23p0qWIiIjAlStXUFNTA3Nzc7i6usLS0lKjGFwk9N7e3vD29saTJ09QW1sLMzMzjae1dIXOUW2Zm5vj0KFD+Pe//438/Hzp72TYsGEYN24c9PT0nksMohs85mWf1EYIIYR0Ao2NjRAIBMjOzoa5uTmqq6thZWWFyspKeHt7IyUlRZogckEikYDP5+Pw4cPg8/mdavy8efMwfPhwzJ49u8NxdUGbhL4thmFQWVkJS0tLjRJoR0dHufNa0622r7cWKe3bfjo6Omp8bYrGE9JR9ISAEEII4YChoSGEQiEuXLiAn3/+GZWVlTA3N4eXl5fSjjldSVVVlfTrhQsXYvHixTA2Nsbo0aPRs2dPufMtLCxUxquoqMD+/ftx5coVlJaWolevXnBzc0NISAisrKw6dG0mJiZ49uwZTExMOjQuJycHIpEIxcXF0k20+Hw+IiMjVW6s1lU6R1VVVaFnz57Q09OT+f0qo+h3ykUMonv0hIAQQgh5CXW2JwTtPxVX9Il4W6o+1S4sLERYWBgkEgk8PT2l8/9zc3Ohp6eH3bt3Y+jQoWqvUduEHgAyMzMRGxsLd3d3+Pn5See7Z2Vl4cqVK0hISMDUqVPVXkNHvcjOURKJBM7OzsjMzASfz4eTk5N0gzNFTz3aU/Q75SIG0T16QkAIIYRoyd3dXeM52DweTzonvDNqaGjAJ598gvDwcKXdktrS19dHYmKitLXn2rVrOdupePXq1XBwcMCOHTtkni5UV1dj7ty5SEhIwOHDh1XGaJvQL1q0SCahDw8PV5vQp6amIjAwEImJiTKvz5o1C0uWLEFqairnBUFn6xy1du1a6WJ4bX+/XMQgukcFASGEEKKl2bNnq01w8vPzcf78ebXnicVi7N69G+PGjYOTk5Pa99bT00NgYKB0kS3bhL5bt24oKirqUOehwMBA6deTJ0/WeJw6t2/fxubNm+WmGpmbmyMiIgICgUBtDLYJfUVFBSZNmqTwWEBAAE6fPq3BnXRcZ+ocxcXvV1d/I4RbtJybEEII0VJ0dDSioqIU/vP09MSlS5dw/vx5DBkyBFu3blUZy8jICNu3b9d4vwIej4fExETpJ8HaJvRtP4keM2YMcnJyNB6vKwMHDlS6cVhtbS1effVVtTHUJfQVFRUqx7u7u6O4uFjhseLiYri5uam9hq4kODgYd+7cUXjs3r17GnXR4iIG0Q16QkAIIYRwKC8vDyKRCHl5eXByckJqaqrGPev5fD5u3ryJN998U6v3bk3otV3E/P777yMuLg719fWYMGECrK2t5Z5saLLeICAgQOkxPT09mJmZwcnJCTNmzICdnZ3cOUuWLEF8fDz69esns5PzhQsXIBQKsXLlSrXX0JrQe3l5yR1TltC3XfQqEAgQExMDsVgMHx8fWFlZoaKiAmfPnsW3336LTZs2qb2GriQvLw/19fUKj9XV1eHSpUvPJQbRDSoICCGEEA7k5uZCJBLh4sWL4PP5SE1Nxfjx4zsU47PPPoNAIICVlRXGjx/f4a44bBP68PBwAMChQ4dw6NAhjVpkKuLs7Izc3FyUl5fDw8NDOn+/oKAA1tbWsLW1xalTp5CRkYG9e/fCw8NDroiora1FSEgIzMzMYGlpicrKStTW1qJnz55Yv369wkXBbBN6T09PuXtu3cug7WsAMH36dFoA+//l5+d3uPOTLmIQ7VFBQAghhLBw/vx5CIVC5Ofnw8XFBWlpaRg7dqxWsT766CM0NjZi0aJFAABjY2OZBFXdwmS2CT3bdpmt3N3dcfPmTWRmZsLa2lr6ellZGcLDwzFy5EgkJSUhNDQUycnJOHDgAPh8PusFp2wTelr0KistLQ1paWkAWv72QkJC5H4+YrEYEokEH374oc5iEN2jgoAQQgjR0owZM1BYWAg3Nzfs3LlTbStLdTRZpKwK24S+7fQcNnbs2IGlS5fKFAMAYGNjg3nz5mHdunWYOXMmgoOD8dlnnwEA1q1bx/p92Sb0XW0XEa1+AAAgAElEQVTRK9uF5u7u7pg9ezYYhoFIJMK7776Lvn37yowxNDSEvb290qdhXMQgukcFASGEEKKly5cvAwBu3ryJBQsWqDxXk7aj0dHRrK6Hq4T+4sWLuHTpEqqrq2Fubo4333wTb7zxhsbjS0tLIZFIFB5rbm5GeXk5gJYCgcuuOJ0toX/ZO0cNHz5c+jfF4/Ewbdo09OnTR+NYXMUgukcFASGEEKKlqKgoncR9+vQprl27Jk3I+Xw+jI2NNR6vbUL/5MkTREVF4ZdffoGBgQEsLCxQVVUFiUSCUaNGYevWrejevbvaOK6urkhJSQGfz5cmpwDw4MEDpKSkSBf0/vHHH0qTw8uXLyMrKwuPHj1CQ0ODzDEej4dt27apvQ42xGIx9uzZg9OnTyu8BgAoKChQGaO1c5SmxVRr56hWbBN6gP1C81Zc/K3r6r8Xwh4VBIQQQoiWdJHgbNu2DTt37sTTp0+liWD37t0RHh6OefPmqRzLNqFPSkpCUVERkpOT4efnBz09PTQ3N+P06dOIi4vDxo0bsWLFCrX3EB8fj1mzZsHPzw+vv/66dEHvrVu3YG1tDaFQCKBlTcH06dPlxh88eBAJCQmwtLTEwIEDYWhoqPY922Ob0CcmJiIjIwPjxo3DmDFjtLoGoOt0jgKAY8eOKf158ng8fPfdd88lBuEej+HyWR0hhBBCtLZv3z588cUXCAoKwjvvvCPtznPy5EkcOnQIS5YsQUhIiNLxq1atwrFjx5CQkKAwoX/vvfdUJvReXl6IiorCjBkz5I599dVXEAqF+PnnnzW6l4aGBmRmZuLq1asoLS1Fr1694OLigilTpqBbt24qx/r6+uLNN9/E6tWrYWCg3WeXq1atkib0Dg4OChN6VQWdl5cXQkNDERYWptX7tyouLoZAIMDChQu16hz1n//8B3FxcRg7dqxWCb2jo6PM99p2jtqyZQtSU1Ph6OgIe3t7GBkZyZ3TfhM4XcQgukEFASGEENJJTJw4EX5+ftIuQ21t3LgRp0+fxpkzZ5SOZ5vQu7q6QiQSKVwcnZOTg8jISBQVFWl4N9pzd3dHamoqq2kubBP6ESNGIDk5GaNGjdL6GoCWe2lsbJSuqeho5yi2CX1eXp7aa9Rk7cm4ceMwadIkLF68WO25uoxBdIOmDBFCCCGdxMOHD5UmwZ6enti3b5/K8bW1tTJz9tsaMGCA0t1/Wzk4OOCbb75RWBAcPXoUDg4OKsdzZcSIEbh+/TqrgqCpqQlDhgzRevx7772H7Oxs1gVBV+kcVVNTo3CTt+cdg+gGFQSEEEJIJ9GnTx9cunRJYRJaUFCA3r17qxzPNqGfP38+oqOjUVJSgrfffhs2NjYoKytDVlYWioqKsGXLFqVjPTw8kJ6eDmdnZ7i7u6tMghV9Kt52U7GFCxdi8eLFMDY2xujRo9GzZ0+5GBYWFirvRZuEvu3TFzc3NyQnJ2PhwoXw8vKCubm53PkTJ05UG7OrdI7y9vZGXl4eqyKNixhEN2jKECGEENJJbN++HVu3bsXs2bPh7+8PGxsblJeX49SpU9izZw+io6MRERGhdHx2djaio6Ph5uamNKH38fFReQ3ff/89RCIRrl+/Lp2S4uTkhKioKEyYMEHpOKFQKG0puXXrVrWfirefv+/o6Cg3HQaA0jiKpsm0TejFYjGSk5Ph4uKicULffnqOKprOvW/1sneOOn/+PFauXAlfX1+lRZq6xclcxCC6QQUBIYQQ0kkwDIMvvvgCX375pUwff319fXz88cdYsmSJ2hjaJvTtPXnyBLW1tTAzM9MoYWTryJEjHZpa0769JsA+of/zzz81Hg8A/fv31+i8F9k5iu1C81ZcLE7maoEz4R4VBIQQQkgnU1lZiStXrqCmpgbm5uZwdXWVblalKbYJPcMwqKyshKWlJas58DU1NSgpKcGgQYPUdhdiS1cJPRtdpXMUF4uTuVrgTLhHBQEhhBDSBWmb0Ofk5EAkEqG4uBhNTU0wMDAAn89HZGSkwrUJypw8eRIpKSm4f/8+ACAzMxN8Ph8CgQAjRoxAUFBQh+/peWq7pqE9PT099OjRA/r6+mrjUOco8jKgRcWEEEJIJ1JRUYH9+/fjypUr0v79bm5uCAkJgZWVldrxbBL6zMxMxMbGwt3dHYsWLZJ+mp2VlYXw8HAkJCRg6tSpaq8hIyMD8fHxmDZtmrQHfytXV1ccO3ZMZUEQEBCg9Jienh7MzMzg5OSEGTNmwM7OTuF5bBN6T09PtQujHRwcEBoaqnD6Uquu1jmqoKAARUVFePjwIUJDQ9G3b18UFRVhwIABGv19chWDcIsKAkIIIaSTKCwsRFhYGCQSCTw9PeHh4YGysjKkp6fjyy+/xO7duzF06FCl49km9KmpqQgMDJTbHGrWrFlYsmQJUlNTNSoIdu/ejblz50IgEMishQAAOzs73L17V+V4Z2dn5Obmory8HB4eHtL7KCgogLW1NWxtbXHq1ClkZGRg79698PDwkIvBNqGPj49HWloaLCws4OvrC2tra5SVleHs2bOoqqrCzJkzkZ+fj+XLl0MikSj9ubzMnaPaqq2thUAgwLlz52Bqaor6+nq899576Nu3L/bv3w9LS0vExsbqPAbRDSoICCGEkE5i9erVcHBwwI4dO2Q6sFRXV2Pu3LlISEjA4cOHlY5nm9BXVFRg0qRJCo8FBATg9OnTGt1HSUkJPD09FR7r1q0b6urqVI53d3fHzZs3kZmZCWtra+nrZWVlCA8Px8iRI5GUlITQ0FAkJyfjwIEDcjHYJvR3796Fh4cHNm7cKPN6ZGQkYmJi8PDhQ2zfvh3Lli3D/v37lf5cp06diq1bt6KxsVFp5yhV2Cb0Pj4+EAqFEIlE+OKLL2QWmguFQo0XmicmJuLOnTvIyMjAkCFD4OzsLD02evRo7Nq167nEIDrCEEIIIaRTcHFxYb7//nuFx7KzsxkXFxeV493c3Jhz584pPJaTk8O4ubmpHD9r1iwmLS1N4bHt27czwcHBKse3mjBhArN//36GYRimqamJGTx4MHP16lWGYRhm7969jL+/v8rx3t7ezNmzZxUeO336NDN+/HiGYRjmxIkTzNChQxWet2bNGiYmJkbhMYFAwKxatYphGIZZunQpM2nSJLlzRowYweTk5Cgc/5///IcZPnw4wzAM88MPP6j8vTQ3NzOJiYkMn89nHB0dpf/4fD6zbt06pePays7OZgIDAxlHR0dm8ODBjKOjIxMYGKj0b0WZ+vp65tGjR0x9fX2HxjEMwwwfPpz59ttvGYaR/53m5uYq/T1wHYPoBj0hIIQQQjqJgQMHKp0TXltbi1dffVXleHd3dxQXFyvcDba4uBhubm5yr7eday8QCBATEwOxWAwfHx9YWVmhoqICZ8+exbfffotNmzZpdB8BAQEQiUSws7OTzp/n8Xi4ceMGdu3aheDgYJXjS0tL5aYatWpubkZ5eTkAwMbGRtrGs73vvvsOGzZsUHgsMDAQixcvRlxcHCZOnIgTJ07IndPY2IgHDx4oHH///n00NTUBAIyNjWFoaKj0Xng8HpYuXYqIiAitO0d5e3vD29ubdecoExMTPHv2DCYmJh0e29DQoPR66+vroaen91xiEN2ggoAQQgjpJJYsWYL4+Hj069dPpv3ihQsXIBQKsXLlSrkxbBP69nPtGYaRTjFp+xoATJ8+XaM+8ZGRkbh9+zbCwsKkG4KFhYWhsrIS3t7emDNnjsrxrq6uSElJAZ/Pl1lQ++DBA6SkpEgLmz/++AN9+vRRGINtQu/j44ONGzfCxMQEPj4+MDU1RV1dHbKzs7Fp0yb4+voCAG7evImBAweq+YkAlpaWGDdunNrzVNE2oeeic5SjoyOysrIUnv/jjz/C1dX1ucQgukEFASGEEPICte+oU1tbi5CQEJiZmcHS0hKVlZWora1Fz549sX79erlkim1Cv3btWlb7DChiaGgIoVCICxcu4Oeff0ZlZSXMzc3h5eWltONOW/Hx8Zg1axb8/Pzw+uuvSwubW7duwdraGkKhEEDLmoLp06crjME2oV+xYgXq6+uxdOlS8Hg8GBgYoKmpCQzDwNfXV7r49ZVXXkFMTIzK++kKnaPmz5+PefPm4dmzZ/D39wePx0NRURGOHTuGI0eOYPfu3c8lBtEN2oeAEEIIeYFaE05NtV8wzMUOv51RQ0MDMjMzcfXqVWkS7eLigilTpmi0wVldXR2WLl2K7OxshQl9YmIiTE1NcebMGXTv3h2jR49WGOfOnTv49ddf8fjxY/Tu3RvOzs4datXZvnNU66Lg3Nxc6OnpdahzlJ+fn0xCf+XKFbUJ/YQJEzBixAi5vxug5YnUxYsX8cMPP2h0L9nZ2UhMTJTZAK5fv35Yvny5tMB6HjEI96ggIIQQQghr7u7uGhcmPB4P+fn5Or6iFmwTerYmT54MIyMjpZ2jJBKJys5RbBP6oUOHQiQSKVxXcu7cOURFRaGwsLBD9/T777+joqIC5ubmsLe379BYLmMQ7tCUIUIIIYQAAMRiMfbs2YPTp0/j0aNHaGhokDunoKBA4djZs2erLQjy8/Nx/vx5zqcoqWJvb69xwllcXAx7e3sYGxujuLhY7fl8Pl/tObdv38bmzZtligEAMDc3R0REBAQCgcrxbFvBarPQXBGhUIhp06ahT58+eO211/Daa69Jjz1+/BgZGRmIiorSeQyiG1QQEEIIIZ3I5cuXkZWVpTAh5/F42LZtm9KxbBJ6oGU6UkZGBsaNG4cxY8ao7J7Tnqp++pcuXYJQKERubi6GDBmC+fPny53j4eGB9PR0ODs7q33aoOwJA9uEfsqUKcjIyICrqyumTJmi9BqY/9/LX5MF1l2lc5RIJMKYMWMULuJ+/PgxRCKR2mSeixhEN6ggIIQQQjqJgwcPIiEhAZaWlhg4cGCHEnKAXUIPAGfOnIFAIEBYWFiHximTl5cHkUiEvLw8ODk5ITU1VelGWLNnz0avXr2kX2vzFIFtQp+eni59mpCent7h91ekq3SOUjXD/PHjx3JPQHQVg+gGrSEghBBCOglfX1+8+eabWL16NQwMOv6ZnZeXF0JDQ7VO6EeMGIHk5GSMGjVKq/GtcnNzIRKJcPHiRfD5fERFRWH8+PGsYmoiLy8PfD4fPXr0QF5entrz2yboXGrfOerx48eoqalR2Dmqd+/eOHbsmMz5jo6Ocgk9AKWvtU/ouVpofvz4cRw/fhwA8NNPP8HDwwNmZmYy54jFYvz6668YNmwYtm/frpMYRPfoCQEhhBDSSZSVlSEgIECrYgAAmpqaMGTIEK3f/7333kN2drbWBcH58+chFAqRn58PFxcXpKWlYezYsVpfDwDU1NSgpKQEgwYNUttdqG2Cz1WyX1JSgmvXrqGkpASTJk2ClZUV/vrrL5ibm8PY2FjhGD6fz2qdBNtWsJMnT9Z6bFuNjY2or68H0FKAPH36VG7zMCMjI7z//vtKi1AuYhDdoycEhBBCSCcxb948DB8+HLNnz9Zq/Jo1ayCRSBAXF6fxmDNnzki/FovFSE5OhouLC7y8vKSbirU1ceJEhXFmzJiBwsJCuLm5dWjDK2VOnjyJlJQU3L9/H0BL+00+nw+BQIARI0YgKChIozjaJPRAy89izZo1OHz4MJqamsDj8aTXMH/+fNjb22PRokWs7vFl8vHHHyM+Pp5VRyAuYhDdoCcEhBBCyAvUdr74woULsXjxYhgbG2P06NEK51RbWFjIfN82oXdzc0NycjIWLlyocUL/6aefyp3z559/IisrS+51VQtpL1++DKBlo68FCxYoPKdtHFVtRzMyMhAfH49p06ZBIBBg4cKF0mOurq44duyY2oJAUUI/bNgwWFlZYdWqVWoT+k2bNiErKwvr16+Hp6enzFOTcePG4eDBgy9FQcB2oXmrESNGwNTUVOExTTsEcRGD6AYVBIQQQsgLpGgB6OrVq5VOGWmfkLNN6L///nttLlsOl4nc7t27MXfuXAgEAkgkEpljdnZ2uHv3rtoYbBP648ePIyYmBu+8847cNdja2spsrKXOy9o5qi3qMtS1UUFACCGEvEBs54uzTej79+/PanwrLhO5kpISeHp6KjzWrVs31NXVqY3BNqGvqamBra2twmNisVgupjJdpXMUdRnq2qggIIQQQl4gtgtAuUroAdnpS+3p6emhR48e0NfX5+z9lOnduzd+++03jBw5Uu7YjRs3lCbqbbFN6O3s7JCTk6NwgfWFCxcwePBgtdcAAPv27cPkyZO17hzFNqFns9C8bYcgHo+HL774QmWHIF3FILpHBQEhhBDSRbBN6NtPX2qPx+PBwcEBoaGhSltVciEgIAAikQh2dnbSooDH4+HGjRvYtWsXgoOD1cZgm9CHhoZi+fLlMDQ0hL+/PwDg4cOHKCgowMGDB5GUlKTRvbzMnaOoy9DfB3UZIoQQQjqJ9v3r29LT04OZmRmcnJwwY8YM2NnZyZ3Tvn99e+oS+q+//hppaWmwsLCAr68vrK2tUVZWhrNnz6KqqgozZ85Efn4+fvrpJyQkJGDq1Kna3agajY2NEAgEyM7Ohrm5Oaqrq2FlZYXKykp4e3sjJSVF7ZOKb7/9FsuXL8ecOXPg7++PwMBACIVCPHz4EBs2bEBSUpLSjkmt0tPTkZKSgidPnkinu3Tv3h0LFixASEiIRvfyMneOaou6DHVtVBAQQgghncSyZcuQm5uL8vJyeHh4wNraGuXl5SgoKIC1tTX4fD4KCwtRW1uLvXv3wsPDQ2Y824R+7dq1KC8vx8aNG+WuLSYmBhYWFoiLi8OyZctw9epVuQ21uHbhwgX8/PPPqKyshLm5Oby8vBROI1KGi4S+vr4ehYWFqKiogLm5OTw8PJR2ymnV9knNo0ePsHjxYnz44YdadY7SJqF3dHTU6N4A1Z2jyN8HFQSEEEJIJ5GRkYGvv/4aO3fuhLW1tfT1srIyhIeHY8qUKZg8eTJCQ0NhaGiIAwcOyIxnm9B7enpiw4YNGD16tNz4nJwcLF68GBcuXMC///1vLFiwAEVFRRzdue5ok9CzpclOw221T8jZJvQd6YAEaL4ORSwW4z//+Q/u3bunsFtSZGTkc4lBuEdrCAghhJBOYseOHVi6dKlMMQAANjY2mDdvHtatW4eZM2ciODgYn332mdz47777Dhs2bFAYOzAwEIsXL0ZcXBwmTpyIEydOyJ3T2NiIBw8eKBx///59NDU1AQCMjY21bl+pjLu7u8bdltTtY9BWjx494OXlpdG5xcXFGp3Xis/nK3y9q3SOauvRo0eYMWMG/vrrLzAMAwMDAzQ2NgJoWQNgYGCgNpnnIgbRDSoICCGEkE6itLRUafeb5uZmlJeXA2gpEBQ94Geb0Pv4+GDjxo0wMTGBj48PTE1NUVdXh+zsbGzatAm+vr4AWjYfGzhwoFb3qMzs2bPVJtH5+fk4f/680vPYJvRTpkxRGrv9p/w8Hg/Xrl1TeG5X7By1du1a9O/fH0eOHMHIkSPx9ddfo3///vjuu+9w4MABbN++/bnEILpBBQEhhBDSSbi6uiIlJQV8Ph8DBgyQvv7gwQOkpKTAzc0NAPDHH38o3NyJbUK/YsUK1NfXY+nSpeDxeDAwMEBTUxMYhoGvry9iY2MBAK+88gpiYmI4vffo6Gilxy5dugShUIjc3FwMGTIE8+fPV3ge24Q+PT1d5TXW1dXhwIEDOH/+PLp166byXK50ls5Rly9fRlxcnHQNg0QigYWFBYKDg/Hs2TMkJCRg3759Ku+FixhEN6ggIIQQQjqJ+Ph4zJo1C35+fnj99ddhZWWFiooK3Lp1C9bW1hAKhQBa1hRMnz5dbjzbhN7U1BRCoRB37tzBr7/+isePH6N3795wdnaGg4OD9DxNutJwIS8vDyKRCHl5eXByckJqaiomTJig9Hy2Cf3w4cOVjktPT8f+/fvR0NCAkJAQjVtksu0cxTahj4+P12ih+fLlyyGRSJR2jqqrq4OFhYX0msvKyqTHXFxcVO62zGUMohtUEBBCCCGdhL29PbKzs5GZmYmrV6+itLQUjo6OmDZtGqZMmSJNYsPDwxWO5yqht7e3f6GtIXNzcyESiXDx4kXw+XykpqZi/PjxasdxndDX1tZi//79OHDgAMRiMYKCgjBnzhzY2NhofC/Ozs4qO0fZ2tri1KlTyMjIUNg5im1Cf/fuXXh4eMgtNI+MjERMTAwePnyI7du3Y9myZdi/f7/SgsDW1halpaUAAAcHBxw9elRanJ05c0auU5KuYhDdoC5DhBBCyN9YcXEx7O3tYWxsrNEcfGULablw/vx5CIVC5Ofnw8XFBVFRURg7dqzW8bRN6GtqarBv3z4cOHAATU1NCAoKQlhYmNxib010lc5RycnJqKioQEJCAn766SdERkbC1NQUBgYGKC8vxz//+U+1ey1wEYPoBj0hIIQQQl5ibBP6KVOmICMjA66urmrn4OuyZ/2MGTNQWFgINzc37Ny5E2+99ZbWsbRN6Kurq7F37158+eWXkEgk+PDDDzFnzhxYWVlpfS1dpXOUQCCQfj127Fh89dVXyM7OxrNnzzBq1CiNCjcuYhDdoIKAEEIIeYE8PDyQnp4OZ2dnta03FbXbZJvQp6enS6cHqZuDr0uXL18G0LLgecGCBSrPVdZ2lG1CP2HCBDx58gSenp6YPXs2rKys8PDhQzx8+FDh+Zo8LemqnaNcXFzg4uKi8BjDMFi+fDmio6Pxyiuv6DQG4QYVBIQQQsgLNHv2bPTq1Uv6dUf717NN6NvOu1c2B/95iIqKYh2DbUJfX18PoGXqUm5urtL36cjTkr9j56jm5mYcPXoUH330kdbJPBcxiOZoDQEhhBBCZJSUlODatWsoKSnBpEmTYGVlhb/++gvm5uYwNjZ+0ZenVNsdflUVVsoS+ry8vA69nyYF1J07dzBr1ixUVFQo7By1d+9e2NvbY8eOHTAwMJCbQ19XV4elS5ciOztbYUKfmJgIU1NTnDlzBt27d1e4VqD1OlQtNOeSRCIBn8/H4cOHtV5zwkUMojkqCAghhJBOqKamBiUlJRg0aFCHe95rm9CLxWKsWbMGhw8fRlNTE3g8HjIzM8Hn8zF//nzY29tj0aJFbG9NZ3SR0Gvq6NGjGD9+vLTHflsNDQ0ynaN69eoFFxcXmc5R6jzPhJ4tKghePjRliBBCCOlETp48iZSUFNy/fx8ApAm5QCDAiBEjEBQUpHSsooR+2LBhsLKywqpVq9Qm9Js2bUJWVhbWr18PT09PjBo1Snps3LhxOHjwYKcuCNgk+KoSenUkEgmWLVuGzMxMheO7deuGmTNnan1tQMdawXamzlHk5UAFASGEENJJZGRkID4+HtOmTYNAIMDChQulx1xdXXHs2DGVBQHbhP748eOIiYnBO++8I7cQ1tbWFn/++SeLu+u81CX0muBywkVX6RxFXh5UEBBCCCGdxO7duzF37lwIBAK5hNzOzg53795VOZ5tQl9TUwNbW1uFx8RisdJuOV0Blwk9dY4iLxsqCAghhJBOoqSkBJ6engqPdevWDXV1dSrHs03o7ezskJOTI/NkodWFCxcwePBgleNJC+ocRV42VBAQQgghnUTv3r3x22+/YeTIkXLHbty4oTTZb8U2oQ8NDcXy5cthaGgIf39/AMDDhw9RUFCAgwcPIikpqQN38/fVtoVqdHR0h8frIqFn0zmqoaEBn3zyCcLDw5UWrG3p6+sjMTFRps0qFzGI7lBBQAghhHQSAQEBEIlEsLOzkxYFPB4PN27cwK5duxAcHKxyPNuE/h//+Aeqq6uRkpKCnTt3AmhJbrt3746YmBhMnDiRg7v8++osnaM6stAcaHk6VVRU1KFpVYGBgZzHILpDBQEhhBDSSURGRuL27dsICwuTLm4NCwtDZWUlvL29MWfOHJXjuUjog4ODMWXKFBQWFqKiogLm5ubw8PCAqakp+xv8m+oKnaPGjBmDnJwchU+vNMVFDKIbVBAQQgghnYShoSGEQiEuXLiAn3/+GZWVlTA3N4eXl5fGSRQXCX2PHj3g5eWl7W387ejp6SEwMBCWlpZyx7pK56j3338fcXFxqK+vx4QJE2BtbS23NkJd+1IuYhDdoIKAEEII6WRGjBiBESNGaD2+Iwm9Jm0t2+qKCVtrQq+vr4+qqiqNx1lYWABomdaVmJio8Jyu0jkqPDwcAHDo0CEcOnRIJpHXtH0pFzGIblBBQAghhLxA6tpStqWoRSXbhF5dW8vW923932vXrnXo/Z6njiTzgHxC7+jo2KGOQJokr12lcxQX7UupBWrnRQUBIYQQ8gJp0pYyPz8f58+fV3ge24ReXZJWV1eHAwcO4Pz58x1eCPu8eXp6skro165dKx0vFouxbds2WFhYwNfXFzY2NigtLcXZs2dRVVWFyMhIjd6jq3SO4qLbEbVA7byoICCEEEJeIFVtKS9dugShUIjc3FwMGTIE8+fPlzuHbUKvLEmrq6tDeno69u/fj4aGBoSEhCAsLEzN3bxYbBP6yZMnS7/+/PPPMXToUGzevFnmnKioKCxYsAA3b97U6Jq6Wueoixcv4tKlS6iuroa5uTnefPNNvPHGG889BuEWj+Fyaz5CCCGEsJaXlweRSIS8vDw4OTkhKioKEyZM6FCM9gn99OnTERYWJt0wS5na2lrs378fBw4cgFgsRlBQEObMmQMbGxs2t/Tcff755ygrK5NL6AFgwYIFsLGxwYoVK5SO9/T0RFJSEt566y25Yzk5OVi8eDEuXLig9joaGxshEAiQnZ0Nc3NzVFdXw8rKSto5KiUlBfr6+ipjpKenIyUlBU+ePJE+9enevTsWLFiAkJAQtdcAAPX19awWmj958gRRUVH45ZdfYGBgAAsLC1RVVUEikWDUqFHYunUrunfvrvMYRDfoCQEhhBDSSeTm5kIkEuHixYvg8/lITU3F+PHjOxRD24S+pqYG++9U4IIAACAASURBVPbtw4EDB9DU1ISgoCCEhYXB2tqazS29MMePH1f66fnUqVOxePFilQVBY2OjtE1oe//973/R1NSk0XV0lc5RSUlJKCoqQnJyMvz8/KCnp4fm5macPn0acXFx2Lhxo8qfJ1cxiG5QQUAIIYS8YOfPn4dQKER+fj5cXFyQlpaGsWPHdiiGtgl9dXU19u7diy+//BISiQQffvgh5syZAysrKza39MKxTegnTpyIjRs3olu3bvDz84OZmRlqa2uRlZWFTZs2wc/Pr0PX87J3jjpz5gwWLVoknbYEtHRn8vf3R1VVFYRCodpknosYRDeoICCEEEJeoBkzZqCwsBBubm7YuXOnwikqqrBN6CdMmIAnT57A09MTs2fPhpWVFR4+fIiHDx8qPP9laTvKNqGPjY3Fs2fPsGLFCqxYsQIGBgbSIsLPzw+xsbFKx3bFzlG1tbUYMGCAwmMDBgxAbW3tc4lBdIPWEBBCCCEvkKOjIwDAxMREbRKpKHkcNmyYXEKvSvvksfX9W+Mr87L1ia+vr0dsbCyysrIAQC6hX7NmDXr06KE2zt27d3HlyhWUlpaid+/ecHFxgb29vcoxW7du7VDnqPY/U1XtTzVJ6PPy8lS+d9uF5sbGxigsLFR5PtCy4Pq1117Dpk2b5I4tWrQI9+7dw5EjR3Qeg+gGFQSEEELICyQUCjt0flRUlMz3bBN6dcljey9b60htEnpdUtQ5ysfHR+YcXST0reO0WWgOANnZ2YiOjoabmxvefvtt2NjYoKysDFlZWSgqKsKWLVvk7kMXMYhuUEFACCGEvMReZEJ/9OhRjB8/Hubm5pzF7Ezq6urw5ZdfoqioCI8ePUJSUhLs7e3x9ddfw8XFpUPTp7pC56jvv/8eIpEI169flxaYHb0XLmIQ7lFBQAghhPxNsUnoJRIJnJ2dkZmZ2WnXFbBJ6G/fvo2QkBA0Nzdj6NCh+PHHH6X3unbtWpSXl2Pjxo1qr6F956ioqKiXvnPUkydPUFtbCzMzM63bhHIRg3CHFhUTQgghf0MSiQTLli1DZmam1p/wd+bPFNsn9NevX8ezZ88AtEwjunjxosqEfu3atbCzs0NaWhqMjIzg7OwsPebu7q52Q7Cu3DnKxMQEz549g4mJyQuNQbhDBQEhhBDyN9WZE3q22Cb0BQUF2Lx5M7p37w6JRCJzrHXuuzJdtXNUTk4ORCIRiouL0dTUBAMDA/D5fERGRmp8j1zEINyjgoAQQgghXQ6bhB4AjIyMlO5VUFpaCjMzM6VjL1++DAC4efMmFixYoPJ9FHWOYpvQ19fXA2h5SpGbm6v0vTvSOSozMxOxsbFwd3fHokWLYG1tjfLycmRlZSE8PBwJCQmYOnWqzmMQ3aCCgBBCCCFdDpuEHmhZfL17926MGTMG+vr6AFqSd4ZhcOjQIZW7DLfvBNVRbBP69PR0Vu+vSGpqKgIDA5GYmCjz+qxZs7BkyRKkpqaqTea5iEF0gwoCQgghhHQ5bBJ6oKUvflBQEN555x14e3uDx+Ph4MGDuHXrFh48eIDPP/9c6Vi2BQHbhJ5NJyllC80rKiowadIkhWMCAgJw+vRptbG5iEF0gwoCQgghhHQ5bBJ6ABg0aBCOHDmCrVu34uTJk9DX18ePP/6IUaNGYdOmTbC1tdXZtesiodeEqoXm7u7uKC4uhpeXl9y44uJiuLm5qY3PRQyiG1QQEEIIIaTD9PT0EBgYCEtLyxd9KQpxkdD3798f69atew5Xyw2uO0dVVVVJvxYIBIiJiYFYLIaPjw+srKxQUVGBs2fP4ttvv1W4+zBXMYju0T4EhBBCyN8QwzBYvnw5QkJC0LdvX43HWVhY6PCqOo/g4GCsXLlS4a7G9+7dw8qVK3UyV58NiUQCPp+Pw4cPa7U3RPvxjo6OMrtft6aMyl5TtDiZixhE9+gJASGEEPISa/sJrCZaE3oej4fExES5hE2dlyVhY5vQ5+XlSRf3tldXV4dLly5xdq2d1dq1azv0t6GrGET3qCAghBBCXmKenp6sEvq2CZtYLMa2bdtgYWEBX19f2NjYoLS0FGfPnkVVVRUiIyM5vXZd0mVCn5+fz9kmX53Z5MmTO0UMontUEBBCCCEvMbYJfduE7fPPP8fQoUOxefNmmXOioqKwYMEC3Lx5U7c385woS+jT0tKQlpYGoOUJSkhIiFyxJRaLpZuFEdJVUEFACCGEvMS4TOiPHz+udAffqVOnYvHixVixYgX7i9YRtgm9u7s7Zs+eDYZhIBKJ8O6778qtrzA0NIS9vT3Gjx+vuxvphMRiMfbs2YPTp0/j0aNHaGhokDunoKBA5zGIblBBQAghhHQRbBP6xsZG3L9/X+Gx//73v0o3+uos2Cb0w4cPl7b85PF4mDZtGvr06fNcrr0zUNU5KjExERkZGRg3bhzGjBkDQ0PDDsfnIgbRDSoICCGEkC6CbUI/ceJEbNy4Ed26dYOfnx/MzMxQW1uLrKwsbNq0CX5+frq4bM5wmdCz3VzsRWhN6PX19Tu02Lz9QnNFzpw5A4FAgLCwMK2vj4sYRDeoICCEEEK6CLYJfWxsLJ49e4YVK1ZgxYoVMDAwkBYRfn5+iI2NfR63wQkuEvpjx44pnd7C4/Hw3XffsX4PRTpj56impiYMGTKkQ9elixhEN2gfAkIIIaSLqK+vR2xsLLKysgBALqFfs2YNevTooTbO3bt3ceXKFZSWlqJ3795wcXFR2L6zs2OT0G/ZsgWpqalwdHSEvb09jIyM5M5R9mk6W2wT+iNHjnRoofkHH3yg9j3WrFkDiUSCuLi4jt0MxzGIblBBQAghhHQxXSWhZ4NtQj9u3DhMmjQJixcv1uVlKsRlQv/555+jrKxMbqE5ACxYsAA2NjZK15WcOXNG+rVYLEZycjJcXFzg5eWlcCfkiRMn6iQG0T0qCAghhBAiVVdXhy+//BJFRUV49OgRkpKSYG9vj6+//houLi5a7YD7IrBN6D08PCASiTBy5EiOr6xj2CT0QMs+FUlJSXjrrbfkjuXk5GDx4sW4cOGCwrGOjo4aX6eqnYrZxiC6R2sICCGEkC6ETUJ/+/ZthISEoLm5GUOHDsX169fx7NkzAC1PHS5evIiNGzc+r1thpaamBl5eXlqP9/b2Rl5e3gsvCF5k56jvv/++YxeroxhE96ggIIQQQroItgn92rVrYWdnh7S0NBgZGcHZ2Vl6zN3dXWli2hlpk9AXFxdLv548eTJWrlwJsViM0aNHo2fPnnLnP4+nJS+yc1T//v1ZXTtXMYjuUUFACCGEdBFsE/qCggJs3rwZ3bt3h0QikTlmY2ODsrIynVw3V9gm9FOmTJFZzMswDHbv3o3du3fLvf68prd0ls5Rqjof6enpoUePHtDX19d5DKIbVBAQQgghXQTbhN7IyEjpJ86lpaUwMzPj7Fp1gW1Cn56e/tyuVVNsE/oePXogOTkZ0dHRrBaae3p6qux8xOPx4ODggNDQUAQGBuosBtENKggIIYSQLoJtQj98+HDs3r0bY8aMkX5Sy+PxwDAMDh069MLn06vDNqFv3dSsM+Eqobezs4OdnZ3W1xEfH4+0tDRptyNra2uUlZVJux3NnDkT+fn5WL58OSQSCaZOnaqTGEQ3qMsQIYQQ0kVERUWhvLwc+/fvh76+Pvh8Po4cOQInJyfMmjULvXr1woYNG5SOv3fvHoKCgmBmZgZvb2+kp6dj8uTJuHXrFh48eID/+7//g62t7XO8I8IFLjpHrV27FuXl5QrXoMTExMDCwgJxcXFYtmwZrl69imPHjukkBtENvRd9AYQQQgjhxqJFi3D37l288847WL9+PXg8Hg4ePIgPPvgAN2/exIIFC1SOHzRoEI4cOYI33ngDJ0+ehL6+Pn788Ue89tprf7tiwN3dHR4eHgr/vfHGGxg/fjw++eQTpS07uVRXV4ft27dj/vz5mDx5Mu7cuQMA+Prrr2XWTShy+/Zt+Pn5Yf/+/WAYRm6h+Z49ezS6hu+++07pNJ7AwECcOHECQMuah//+9786i0F0g6YMEUIIIV1Ea0K/detWmYR+1KhR2LRpk0YJff/+/bFu3brncLW65e7urnS+up6eHszMzODo6IhZs2ZhxIgRcueEhobim2++QWNjI8aOHQtra2uUl5fjp59+gqGhIXx8fHDx4kWEhoZCKBRiwoQJOrmPztI5qrGxEQ8ePFB47P79+9KpasbGxjA0NNRZDKIbVBAQQgghXQibhD44OBgrV65UODf93r17WLlyZadceKsI24Te0NAQgwYNwvbt22V2ORaLxYiIiICZmRm++eYbfPLJJ9i2bZvOCoLO0jnKx8cHGzduhImJCXx8fGBqaoq6ujpkZ2dj06ZN8PX1BQDcvHkTAwcO1FkMohtUEBBCCCFdBNuEPi8vD/X19QqP1dXV4dKlS5xdq66xTei/+uorJCQkyIwFWhZuBwcHY8WKFfj000+lm4PpSmfpHLVixQrU19dj6dKl4PF40m5HDMPA19dX2u3olVdeQUxMjM5iEN2ggoAQQgjpInSZ0Ofn58PKykrr8c8b24S+pqZGad/86upq6c/Z1NRUZStNtjpL5yhTU1MIhULcuXMHv/76Kx4/fozevXvD2dkZDg4O0vMmTpyo0xhEN6ggIIQQQv4GlCX0aWlpSEtLA9CSKIaEhMgluGKxGBKJBB9++OFzuVYusE3oR44ciQ0b/l97dx4U1Z2uD/xpEBFxRUVxGwUXDGJDN3RwyajBYK4KBo1LSoeIMokoYtTkXuOVqKNBJ0Zkog4umInXuEAQqRGjiQtFTDSyCC7RiIlmNDQCIgJiWGz4/ZEfHZFF4CzYh+dTZRX26XP6/TpTleflnO/bH6NXr15wc3Mzvl71zH5VkL516xZ69+4twQp+JzTQL1u2DDNnzsSECRPg6elp3GheNTlq3bp1jarHwcGhUeNOpboGiYsNARERkQkTGuhdXV0xd+5cVFZWYtu2bZg4cSJ69OhR7T0WFhZwcHDA2LFjpVuIyIQG+tWrVyMwMBB/+ctf0L59e3Tu3Bn5+fkoKirCkCFDsGrVKgCAubk5AgICJFuH0EAvZKP5Dz/8AAcHB7Rp0+aZ04yAmt/8LNY1SHr8HgIiIiITlpSUhKSkJGOgf/311+sN9FW/Za7N1q1bMW3aNHTv3l3qsiWXnZ2NwMBAXLt2rdZAHxERge7duyM6OhqWlpaYPHlyrddJTEzE5cuXkZubi27dusHZ2RmjR4+WdS2ZmZnYsmULvvvuO+Tn56Njx44YMWIEgoODJR0F6+joiOjoaAwbNgyOjo51PhpV1zc/i3UNkh4bAiIiIoVQUqAXy/MQ6JuTkI3mSUlJcHJygrW1NZKSkp75WbV907MY1yDpsSEgIiIioyNHjuCrr77C3bt3UVpaWu2YSqXCv//972aqTHoPHjxAhw4dYGZmVuf+gyd16tRJ8pqETo568jf0T7t8+TJmzJiBq1evilozmR7uISAiIlIQIYH+k08+wT//+U84OjrCwcGhxoSe553QQD98+HBERUVh2LBh8PDweOb0IDkeb3neJkfp9XpcvXoVer0ekyZNgo2NDbKzs9GxY0e0adNGtmuQuNgQEBERKYTQQB8bG4uAgABJ5+pLSWigDw0NNT6THxoaKuk4UTHIOTmqrKwMH374IQ4dOoTHjx9DpVJBq9XCxsYGa9asgYODA5YtWyb5NUgabAiIiIgUQmigLywsxMiRI0WuSj5CA72vr6/x5ylTpohaW2M8j5OjwsLCcPz4cXz00Ufw8PDAiBEjjMfGjBmDffv2PTPMi3ENkgYbAiIiIoUQGug9PT2RlJTU4C+ret5IEehLSkpw69Yt6PV66HS6Bn+zrxBCA71OpzNuzlWpVKJsNI+Pj8fSpUsxYcKEGt+Y3KdPH2RmZspyDZIGGwIiIiKFaEqgf3I2/JQpU7Bq1SqUlZVh1KhR6NChQ433m9qceCGBfufOndi1axeKioqgUqkQExMDJycn+Pv7Q6fTITAwUJKaxQz0QUFBotRUWFhY54jTqrsVclyDpMGGgIiIyIQJDfRTp06t9jhKZWUldu/ejd27d9d43dTmxAsJ9Nu3b0dERAQWLlyI4cOHY9q0acZj48aNQ1xcnGQNwZPECPRiTI6yt7fHmTNnqj3mU+X8+fMYPHiwLNcgabAhICIiMmFCA319IytNmdBAHxUVheDgYMybN6/Gb6779u2L27dvS1b7056HyVH+/v5YsWIFLCws8F//9V8AgKysLFy4cAH79u3Dxo0bZbkGSYMNARERkQkTGuiV+kVQQgP9vXv38MILL9R6zNzcHCUlJaLVWp/nZXLU5MmTUVBQgH/84x/YtWsXgN/vXlhZWWHp0qXw8vKS5RokDTYEREREJkypgV4ooYG+d+/eSE9Pr3U/RlpaGuzt7UWp81mep8lRfn5+mDp1KtLT03H//n107NgRGo0G7dq1k/UaJD42BERERATg9+k2dY3qNDMzQ/v27eHo6Ig5c+bgxRdflLm6xhEa6GfMmIHw8HDY2Nhg/PjxAIDHjx/j9OnT+Ne//oX33ntPkrqf9jxNjnr06BG+//573L17F2VlZbh37x5+/vlnAL8/ujRnzhxZrkHiY0NARESkEEIDvb+/Pw4fPozy8nKMHj0aXbp0QV5eHhITE2FhYYFx48YhOTkZ/v7+2Lp1K15++WWpl9RkQgP9nDlzkJWVhTVr1mDNmjUAgDfeeAMAMHv2bMyYMUPaBfx/z8vkqJSUFCxcuBAFBQW1Hm9ImBfjGiQNVWVlZWVzF0FERETCffLJJw0K9BkZGbUG+oiICCQnJ2P79u3VnlUvKyvD22+/DVdXVyxatAiBgYHIy8vDF198IfcSG2X9+vXYu3cvAKCiogJmZmYAfg/0K1asaNA17ty5g7NnzyI/Px8dO3bE8OHD0a9fP6lKBlA90BcWFmLVqlV45ZVXGhzoHR0da2wor9LUyVG+vr6wsLDA3/72Nzg4OMDCwqJRaxLrGiQNNgREREQKITTQ//nPf8batWsxevToGtdOSEhASEgIvv32W5w8eRLvvvsu0tPTJV+TUI0J9JMmTYJWq4VGo4FWq0Xv3r3lLfb/Exrok5KSGvV5DdmH4uLigi1btuCll15q1LXFvgZJg48MERERKcSBAwewdu3aGpNoWrduDT8/P4SEhCA4OBivv/56rZtUCwsL8eDBg1qvXVBQgOLiYgBAu3bt6nw0qTnVFuj79OnT4Md77OzscOzYMURFRUGlUsHW1hYajQZubm7QaDQ1grpUnsfJUfb29nX+f0POa5A02BAQEREphNBAP3z4cHz88cfo1asX3NzcjK8nJydj06ZNxufYb9261Wy/Pa+P0EBfNQrzxo0bSE1NRVpaGlJTU3Hs2DGoVCpYW1tDrVZDq9VCq9VKtrH6eZwctWLFCvztb3/DkCFDMGDAgGa7BkmDjwwREREpRGBgIK5cuYLNmzfXCPRLly6Fs7Mz/vnPf+LAgQPYv38/jhw5Uu387OxsBAYG4tq1a2jfvj06d+6M/Px8FBUVYciQIYiIiED37t0RHR0NS0tLTJ48We4lNsjTgf7XX38VFOhzc3Nx4cIF45+qZ/yvXr0q5TJEIdbkKG9vb+Tm5qKwsBDdunWrsZehId94LMY1SBq8Q0BERKQQq1evRmBgIP7yl7/UGuhXrVoF4Pc5/AEBATXO7969O2JjY5GYmIjLly8jNzcX3bp1g7Ozc7V9BdOnT5dtTU0xcOBADBw4EDNnzgRQM9Bv3boVQMMCvcFgwN27d5GVlQW9Xg+9Xo+Kigr07NlT0jVUeV4mRzk5OQl+XEqMa5A0eIeAiIhIYZ4V6FsSg8GAq1evIjU1Fampqbhw4QLy8vLQs2dPnD59usb7Hz58iPT0dON7L126hPLycjg6OsLV1RUajQYajQbdu3eXpX5OjiI5sCEgIiJqwR48eIAOHTrAzMysQRs+O3XqJENVTSck0L/22mu4ceMG2rdvDxcXF7i6usLV1RXDhg1DmzZtmmE1nBxF8uAjQ0RERCZMaKAfPnw4oqKiMGzYMHh4eDzzkY6GzKxvLk8H+hEjRmDhwoUNDvQ//vgjrKysMGrUKGi1Wri6umLw4MHN+phLS58cRfJgQ0BERGTChAb60NBQ9OnTx/izKYdCoYE+ISHBuM8gOjoa69atg5WVFdRqtfHOglqtRtu2bSVeyR9a+uQokgcfGSIiIjJhhw8fxpgxY9C5c2fExsY+M/z6+vrKVJn8srKyqm0ezsjIEBToi4uLkZaWhrS0NFy4cAEXL15EWVkZBg0aBI1Gg5UrV0q8Ik6OInmwISAiIqJqSkpKcOvWLej1euh0OrRv3765S2oSMQP9o0ePkJKSgv379yMxMRGAPI9PiRXoudGc6sOGgIiISGGEBPqdO3di165dKCoqgkqlQkxMDJycnODv7w+dTofAwEAJK5dOYwN9Tk5OtclEGRkZMBgMMDc3x5AhQ6DVarF8+XK5ymegJ0lxDwEREZGCCAn027dvR0REBBYuXIjhw4dj2rRpxmPjxo1DXFycyTQE9QX6oUOHQqvV1jjn4MGDxvfr9XpUVlaiXbt2cHFxwYIFC6DVaqFWq5tl4tDo0aMb3AAobXIUSY8NARERkUIIDfRRUVEIDg7GvHnzYDAYqh3r27cvbt++LVntYhAa6FevXo0ePXpAq9Vi7ty50Gq1zTJliJOjSG5sCIiIiBRCaKC/d+8eXnjhhVqPmZubo6SkRLRapSA00CckJMDOzq5Jnx0XF4exY8eiY8eOTTr/SZwcRXJjQ0BERKQQQgN97969kZ6ebhxF+aS0tDTY29uLUqdUxAj0TWEwGPD+++8jJiZGlIZAaKB/cpLUlClTBNdDyseGgIiISCGEBvoZM2YgPDwcNjY2GD9+PADg8ePHOH36NP71r3/hvffek6RusTS1GRAj0Is5o0WKQK+UyVEkDTYERERECiE00M+ZMwdZWVlYs2YN1qxZAwB44403AACzZ8/GjBkzpF1AM3rehy5ychRJiQ0BERGRQogR6N9//33Mnj0bZ8+eRX5+Pjp27Ijhw4ejX79+UpZO9eDkKJIaGwIiIiIFaWygnzRpErRaLTQaDbRaLXr37o0+ffoo+m6AKWnpk6NIHmwIiIiITJjQQG9nZ4djx44hKioKKpUKtra20Gg0cHNzg0ajgaOjI6fUNKOWPjmK5MGGgIiIyIQJDfS7du0CANy4cQOpqalIS0tDamoqjh07BpVKBWtra6jVami1Wmi1Wrz44otyLY3AyVEkDzYEREREJkysQD9w4EAMHDgQM2fOBADk5ubiwoULxj9bt24FAFy9elWehZkQMzMz+Pr6onPnzqJfu6VPjiJ5sCEgIiJSADEDvcFgwN27d5GVlQW9Xg+9Xo+Kigr07NlT0jU0l6pAb25u3qBvBq5S9Q3BKpUK69evl6Q2To4iOagqn/c5W0RERNQoBoMBV69eRWpqKlJTU3HhwgXk5eWhZ8+eOH36dI33P3z4EOnp6cb3Xrp0CeXl5XB0dISrqys0Gg00Gg26d+/eDKtpuMaEeeCPQF+lsfslnv6GYKmsX78ee/fuBQBUVFTAzMwMwO+BfsWKFQ26xp07dzg5iurEhoCIiMjECQn0r732Gm7cuIH27dvDxcUFrq6ucHV1xbBhw9CmTZtmWE3TCQ30sbGxxvPLysoQERGBTp064ZVXXkHXrl2Rm5uLEydO4MGDB1i4cCGmT58uav31aUygr22jOVF92BAQERGZMKGB3tHREVZWVvD09IRWq4WrqysGDx5skpOFxAz069atw7179xAeHl7j2OLFi9G1a1eEhIRIsg6hgf6vf/0rLl68iMLCQk6OogZhQ0BERGTChAb6rKysansNMjIyYGVlBbVabbyzoFar0bZtW4lXIi6hgd7DwwMbN27ESy+9VOPYmTNn8O677+L8+fOi1lxFrED/9EbzX3/9lZOjqFZsCIiIiEyY2IG+uLgYaWlpSEtLw4ULF3Dx4kWUlZVh0KBB0Gg0WLlypcQrEofQQK/VarF06VLMmjWrxrHPP/8cmzdvRmpqqqg1P03sQP/0RvMffvgBACdHEacMERERmTQ7OztMnDgREydOBFA90KekpGD37t2NCvTW1tYYNWoURo0ahUePHiElJQX79+9HYmIirl27ZjINQXl5eZ1f2vWf//wHjx8/rvd8Ly8vbNq0CZaWlhg/fjzat2+PoqIiHD9+HGFhYcaJP1Li5CiSCxsCIiIiBRES6HNycqpNJsrIyIDBYIC5uTmGDh0KrVYr40qEERroV65ciZKSEoSEhCAkJAStWrUyNhHjx4+XvTFqbKB/1kbzlStXmsTkKJIHHxkiIiJSiPoC/ZAhQ6DVarF8+fJq5xw8eND4fr1ej8rKSrRr1w4uLi7GTa1qtdrkJg4VFxdj5cqVOH78OADUCPQffvghrK2tn3mdmzdv4tKlS8jJyYGtrS2cnZ3h4OAgae0AJ0eRvNgQEBERmTChgd7R0RE9evSoNtXGVKcM1aYpgb60tBQ+Pj5YsWIFRo8eLVOlf+DkKJIbGwIiIiITJjTQZ2Vlwc7OrkmfHRcXh7Fjx6Jjx45NOl8qYgR6Dw8PbNq0CSNHjhS5umfj5CiSGxsCIiIiE9Zcgd5gMGDo0KGIiYmBk5NTkz5fSkID/erVq1FWVobQ0FCRK3s2To4iubEhICIiaoGEBnqDwQAnJyccOnTouWwIhAb6uLg4hIWFYdCgQRg7diy6du1a4zf0Xl5eYpT6TGIG+qc3mgM1v7GZWh5OGSIiImqhlPw7QRcXF4SFhSEgIKBJgb5q83VOTg6+/fbbGsdVKpVsQZqTo0hqbAiIiIhIcYQG+lOnTklWW2M0JdDXt9F8wYIFJjs5iqTDhoCIiIgUR2ig79Wrl0iVNJ7QQL969WrjRvO5c+cqbnIUiY8NAREReFTtIQAAHM9JREFUESmOmIE+Ly8PpaWlNV6X6lt+hQb6hIQExU2OImmxISAiIiJFa0qgNxgMCAsLwxdffIGioqJa3yPVHgIxAn1TGAwGvP/++4iJiWFD0MKwISAiIqJGMzMzg6+vLzp37tzcpdRKaKDfvXs3YmJiEBQUhNDQUCxZsgQWFhaIj49HYWEh3nnnHalKb3IzIEagV/JGc6qbWXMXQERERPKrCvTm5uZ48OBBg/9UUalUWL9+vWSPzQj1ZKCvrKzEO++8g/feew9DhgxBr169sHHjxnrPj4uLQ3BwMGbNmgUAGDlyJObOnYvY2Fg4OjriypUrciyj0RjoqSl4h4CIiMiEPRnSG6JTp04A/gj0jo6Ojdpsaioz66sC/cyZMxEaGoqRI0di6NChmDt3LoKCgnDlyhVMmjSpzvMzMzMxaNAgmJubw8LCotpdhmnTpmHFihXGSUZEpo4NARERkQnz8PAQFOhDQ0ON55eVlSEiIgKdOnXCK6+8gq5duyI3NxcnTpzAgwcPsHDhQlFrl5LQQG9jY4Pi4mIAvz/Cc+XKFQwfPhzA73sSysrKpF0AkYzYEBAREZkwoYF+ypQpxp/XrVsHFxcXhIeHV3tPUFAQFi9ejOvXr0u7GBEJDfQajQaXL1/GmDFjMGnSJGzbtg15eXmwsLBAVFSU8VpESsCGgIiIyISJGejj4+PrfLb+9ddfx7vvvouQkBDhRctAaKAPCgpCbm4uAGD+/PkoLCzE0aNHUVpaihEjRuCDDz6QYxlEsmBDQEREpBBCA315eTlu375d67H//Oc/ePz4sSh1ykFooO/fvz/69+8PAGjdujVWrlyJlStXSl53c3reJ0eRdNgQEBERKYTQQO/l5YVNmzbB0tIS48ePR/v27VFUVITjx48jLCwM48ePl6JsSQgN9KdOnYKbm5tJzeN/enJUQz290ZxaHlUl51MREREpwvvvv4+vvvoKK1asqBHo169fj/Hjx9cb+IqLi7Fy5UocP34cANCqVStjEzF+/Hh8+OGHsLa2lmUtQgkN9EOGDIFKpcKAAQOg0+ng7u4Od3d32NjYiFxpTU2dHFVFqZOjSDpsCIiIiBRCrEB/8+ZNXLp0CTk5ObC1tYWzszMcHBwkrV1sQgN9fn4+kpOTjX8yMjJQWVmJ/v37w93dHTqdDhMnTpSkdqGBPjY2tlEbzadPny5q/WR62BAQEREpTFMCfWlpKXx8fLBixQqMHj1apkqlI3agLyoqwvnz57Fnzx4kJydDpVJJ9pt1MQP9unXrcO/evRobzQFg8eLF6Nq1q8lsFCfpsCEgIiJSADECvYeHBzZt2oSRI0eKXF3za0qgr6iowJUrV5CUlISUlBSkpqbit99+w9ChQ6HT6bB06VLJ6xYa6D08PLBx40a89NJLNY6dOXMG7777Ls6fPy9qzWR6uKmYiIhIASwtLVFQUIBWrZr+n/ZXX30VR48eVUxDUFegd3FxgU6nq/fcefPmIS0tDRUVFVCr1XBzc8Obb74JV1dXtGnTRqYVcHIUyYMNARERkUIIDfQuLi4ICwtDQEAAxo4di65du9Z4lt3Ly0uMUiUnNNB/9913sLS0xOTJkzFq1Ci4u7s3yzhOTo4iOfCRISIiIoWIi4tDWFgYBg0a1KRA7+joWO/1pXxuXmyOjo6CAv2tW7eQnJxsvLuQnZ2NAQMGGPcfuLu7o0uXLhKu4HecHEVyYENARESkEEIDfWZm5jM/o1evXo2uqzmIHejv3LmD5ORkHD58GCkpKVCpVLh69aqEK/gdJ0eRHNgQEBERKYSSAr3Ymhro79y5Y2wqkpKSkJmZiVatWmHo0KE4ePCgDJX/jpOjSErcQ0BERKQQYob9vLw8lJaW1ni9Z8+eon2GHOoL9PVZtmwZUlJSkJOTAwsLCwwbNgw+Pj5wd3eHq6srrKysJK/96UBvb2/fqPPF2GhOLQP/H0JERKRATQn0BoMBYWFh+OKLL1BUVFTre0xlD4HQQJ+Xl4fp06dDp9NBrVajdevWMlX+B06OIrmwISAiIlIIoYF+9+7diImJQVBQEEJDQ7FkyRJYWFggPj4ehYWFeOedd6QqXXRCA31kZGS9QTw/P1+WqUOcHEVy4B4CIiIihdi5cyd2796NhQsX1hnoJ02aVOf5EyZMwKxZszBz5kw4OTkhJibG+GhNUFAQevfujeXLl8u1HEEeP34sKNAvWbIEmzdvrvVYbm4u/P39ER8fL7jOZ+HkKJIDGwIiIiKFEBro1Wo1IiMj4e7uDmdnZ+zcuRPDhw8HACQmJmLFihX47rvvZFmLUEID/ahRozB27FisXbu22uvZ2dnw8/ODtbU1YmNjRa25NpwcRXLgI0NEREQKkZmZiUGDBsHc3BwWFhbVHhuaNm0aVqxYUW9DYGNjg+LiYgCAnZ0drly5YmwI8vLyUFZWJu0CRJScnIyQkJB6A319du/ebXxf1b9ZZmYm/Pz80LlzZ3z66aeS1f6kU6dOCTqfYZ8agg0BERGRQggN9BqNBpcvX8aYMWMwadIkbNu2DXl5ebCwsEBUVJTxWqZAaKAfPHgwdu7cCX9/f1hbW2Py5Mnw8/NDjx49EBkZiXbt2smxDE6OIlmwISAiIlIIoYE+KCgIubm5AID58+ejsLAQR48eRWlpKUaMGIEPPvhAjmWIQoxAr1arsW3bNsyfPx979uzBkCFDsGPHDrRt21aGFdTU0idHkXS4h4CIiEghbt26hdzcXOh0OpSVleGjjz7CV199VS3Q29jYNHeZsjp37hzmz58PCwuLZwb6r7/+utbXExISkJCQgOXLl1c7V47pPEIDvdCN5tQysCEgIiIiAL8/r+7m5oaOHTs2dylNIjTQP2sD75Pkms7DyVEkBzYERERECiE00A8ZMgQqlQoDBgyATqeDu7s73N3dTeaugtBA35CJPE+SY8MuJ0eRHLiHgIiISCGCgoIEBfqzZ88iOTnZ+Gf//v2orKxE//794e7uDp1Oh4kTJ0q8iqZT4kQeTo4iObAhICIiUgihgb5z587w8vIyPkpTVFSE8+fPY8+ePYiKikJ0dPRz3RCIGejPnTsHvV6PqVOn1jgWGxuLnj17wsPDQ7TPqwsnR5Ec2BAQEREphBiBvqKiAleuXEFSUhJSUlKQmpqK3377DS4uLtDpdHIsQxRCA314eDg8PT1rPXb//n1ER0fj4MGDotVbF06OIjmwISAiIlIQIYF+3rx5SEtLQ0VFBdRqNdzc3PDmm2/C1dUVbdq0kWkF4hAa6G/cuIHFixfXeszJyQnbt28Xpc5nERro+/fvj/79+wMAWrdujZUrV2LlypWS102mhQ0BERGRQggN9N999x0sLS0xefJkjBo1Cu7u7ujcubMMlYtPaKBXqVR1jvksKCiAwWAQXGNDCA30pj45iuTBhoCIiEghhAb6Y8eOITk5GUlJSQgNDUV2djYGDBhg3H/g7u6OLl26SLgC8QgN9Gq1Gp9//jm8vLygUqmMr1dWVmLfvn1Qq9Wi1lsXoYFe6EZzahk4dpSIiEghbt26ZQz0KSkpggP9nTt3kJycjMOHDyMlJQUqlQpXr16VcAXimTt3LsrLy/F///d/NQK9n58fzM3N8dlnn9V5flpaGvz8/NCvXz/4+vqiW7duyMnJQVxcHH755Rfs3bsXLi4ukq9D6CjY/Pz8ahvNMzIyTGpyFMmDDQEREZFCNTXQ37lzx9hUJCUlITMzE61atcLQoUNl2UgrBjECfWpqKjZu3IhLly6hoqICZmZmcHFxwbJly6DVamVZh9iB/smN5snJybJ9wRo939gQEBERKUxTA/2yZcuQkpKCnJwcWFhYYNiwYcbfSLu6usLKykrGVQgnVqAvKSlBQUEBOnTo0Oz/Bk0J9HVtNB86dCh0Oh2WLl0qU/X0vGJDQEREpBBCA/2cOXOMv3VWq9Vo3bq1TJVL63kK9E0hJNDXttHczc3NJCdHkXTYEBARESmE0ED/+PFjtGpV97yR/Px8k5061BT37t1DfHw8fvnlF5SWltY4vn79eslrEBroHR0dFTM5iqTDhoCIiEghhAb6JUuWYPPmzbUey83Nhb+/P+Lj4wXXKRchgf6nn37CG2+8AQsLC+Tn58POzg4FBQUoLi5Gly5dYGNjgyNHjkhZPgDhgV7sjeakTGwIiIiIFEJooB81ahTGjh2LtWvXVns9Ozsbfn5+sLa2RmxsrKg1S0VooA8ICIClpSXCw8Ph7OyMQ4cOwcnJCadOncLatWsRFhYGjUYj+To4OYrkwO8hICIiUojk5GSEhITUG+jrs3v3buP7li9fDgDIzMyEn58fOnfujE8//VSy2sW2YcMG6HQ6Y6DfsmVLtUC/Zs2aes//4YcfsGHDBpibmwMAysrKAACenp64e/cuNmzYgOjoaMnXUfXFZNOnTwdQPdAfOHBAlMlRRGwIiIiIFEJooB88eDB27twJf39/WFtbY/LkyfDz80OPHj0QGRmJdu3aybEMUQgN9OXl5bCysoKZmRk6deqEnJwc4zF7e3tkZGRIu4CnNDXQ17bR3MfHx2QnR5E02BAQEREphBiBXq1WY9u2bZg/fz727NmDIUOGYMeOHWjbtq0MKxCP0EDfr18/6PV6AMALL7yAffv2YeTIkTA3N8eBAwfQvXt3SeuvIjTQ5+XlYfr06YqbHEXiYkNARESkII0N9F9//XWtr0+YMAEJCQmYOnUqvv32W+PrXl5ektQtNqGB3tvbG9evXwcABAcHY968edDpdFCpVKisrMTf//53ydcACA/0kZGRnBxFz8RNxURERCasrkCfkJCAhIQELF++vFoz8HSgd3R0bPBnmdK32u7Zswd3797F//zP/yA9PR3z5s3Db7/9Vi3Qe3t7N/h6WVlZ+Oabb1BaWgoPDw8MGjRIwur/wMlRJAc2BERERCZMaKDPzMxs1Of16tWrUe9/XmRlZeHMmTMoKSmRNdALxclRJAc+MkRERGTCTp06Jeh8Uw34jZWRkYHCwkLY2NjAzs6u0ecnJibixo0b6NKlC8aNG4f27dtLUGVNnBxFcuAdAiIiIgIAnDt3Dnq9HlOnTq1xLDY2Fj179oSHh0czVNYw5eXlCA8Px9dff43Hjx/j1VdfxZIlS7Bw4UKcOXPG+D5bW1tERUXVaAyEni+F69evw8/PD76+vnUG+g4dOtR7jYsXL8Lf3x/+/v4mPTmKpGPW3AUQERGROM6dO4dDhw7Veiw2Nhbff/99veeHh4cjLy+v1mP3799HeHi44BqltGPHDuzZswdubm7w9PTEoUOHsGjRIvz444/45JNPcPToUYSFhaGiogJbtmwR/XwpVE2Oio6OxpYtW3D79m3MmjUL3bp1w2efffbMZgD4Y6N5ZGQkpkyZgj59+uDTTz9lM0BGfGSIiIhIIcLDw+Hp6Vnrsfv37yM6OhoHDx6s8/wbN25g8eLFtR5zcnLC9u3bRalTKkeOHEFwcDDeeustAMCYMWMQEBCAdevWGTdTOzg4oKCgAJGRkaKfLxVOjiKpsSEgIiJSCKGBXqVSoaioqNZjBQUFMBgMgmuUkl6vh6urq/HvGo0GADBw4MBq7xs4cCCys7NFP18sQgN9cHBwvdevevQIMK3JUSQdNgREREQKITTQq9VqfP755/Dy8oJKpTK+XllZiX379kGtVotar9jKy8thaWlp/HvVz0+P7bSwsKj130Lo+WIRGuiFbjSnlocNARERkUIIDfSLFi2Cn58ffHx84Ovri27duiEnJwdxcXH45ZdfsHfvXqmXIIkn/y2a4/zG4uQokhunDBERESlEWloa/Pz80K9fvzoDvYuLS73XSE1NxcaNG3Hp0iVUVFTAzMwMLi4uWLZsGbRarUwraRpHR0dYWVlVC/CPHj2q8VplZSVKSkpq/GZd6PnPI1OfHEXy4B0CIiIihXB1dcVnn32GjRs34uOPP64W6D/77LNnNgMAoNVqcfDgQZSUlKCgoAAdOnSAlZWVDNULFxQU1KznS0FooBe60ZxaBt4hICIiUiBTDPSmTK/Xw9bWtsZ+A6FmzJgBT09P4+SjJ0VGRuLkyZP1BnqNRoOtW7dixIgRNY6dO3cOixYtQkpKiqg1k+nhHQIiIiIFatOmDdq0adPo8+7du4f4+Hj88ssvKC0trXF8/fr1YpSnKAaDAZ6enoiJiYGTk5Oo127pk6NIHmwIiIiIFERIoP/pp5/wxhtvwMLCAvn5+bCzs0NBQQGKi4vRpUsX2NjYSFm6SZPqgYuWPjmK5MGGgIiISCGEBvoNGzZAp9MhPDwczs7O2LJlC5ycnHDq1CmsXbsWa9askWklVIWTo0gObAiIiIgUQmig/+GHH7BhwwaYm5sDAMrKygAAnp6euHv3LjZs2IDo6GjJ10F/EBroxdhoTsrHhoCIiEghhAb68vJyWFlZwczMDJ06dUJOTo7xmL29PTIyMqRdANXQ0idHkTzYEBARESmE0EDfr18/6PV6AMALL7yAffv2YeTIkTA3N8eBAwfQvXt3Seun2okV6Ju60ZyUjw0BERGRQggN9N7e3rh+/ToAIDg4GPPmzYNOp4NKpUJlZSX+/ve/S74GqhsnR5FU2BAQEREphNBA/+abbxp/dnFxQXx8PL755huUlpbCw8MDgwYNkrR+U6VSqdCzZ0+0bt1akutzchRJjV9MRkREpFBZWVk4c+YMSkpKGOhNVEMC/ZEjR+o8PyAgAJaWlsaN5ocOHaq20TwsLAwajUbGFdHzyKy5CyAiIiJpZGRkoLCwEO3atYOdnV2jz09MTERkZCQOHz5c5yx8pcnOzsa2bduwatUq7N27t9Z1//zzz/Dz85OlnqrJUYmJiaisrMSWLVuQmpqKbdu2wcLCokGTo6ZPn17rRvO//vWv2LBhg+RroOcfHxkiIiIyYeXl5QgPD8fXX3+Nx48f49VXX8WSJUuwcOFCnDlzxvi+8PBwREVF1WgMGnr+5s2baz1fSW7fvo1p06bh0aNH6NGjB2JiYhAREYH169dj9OjRxvc9fPgQycnJstTEyVEkB94hICIiMmE7duzAnj174ObmBk9PTxw6dAiLFi3Cjz/+iE8++QRHjx5FWFgYKioqsGXLFtHPV5JNmzahV69eSExMxIkTJ3Dy5Em4urpiwYIFOHjwYLPUJMXkqIcPH+K3337j5Cgy4h0CIiIiE3bkyBEEBwfjrbfeAgCMGTMGAQEBWLduHby8vAAADg4OKCgoQGRkpOjnK8mFCxfwwQcfGDfa2tnZYdu2bdixYwfWrFmD7OxsLF68WNaaODmK5MCGgIiIyITp9Xq4uroa/161QXTgwIHV3jdw4EBkZ2eLfr6SFBcXo0OHDjVef/vtt2Fra4uQkBDcu3cPvr6+stXEyVEkBzYEREREJqy8vByWlpbGv1f93KpV9f/EW1hYwGAwiH6+kvTt2xcXL17Eiy++WOOYr68vOnTogKVLlyI9PV22mmoL9EImR9nZ2WHGjBlil0kmjnsIiIiIFEilUjXr+aZoxIgRiImJQUVFRa3HPT09sWvXLmRlZclc2R84OYqkwO8hICIiMmGOjo6wsrKqFuAfPXpU47XKykqUlJTg2rVrop6vJCkpKSguLoZWq0W7du3qfN/Nmzdx8eJFyR4daujkJ1tbW0GTo+o6n1oePjJERERkwoKCgpr1fCWZPXs2/vSnP8HHxwfe3t7o27dvre+zt7eHvb29ZHVUTX7y9vaGtbU1Dh06hJs3bxonPzk4OOD69esIDQ3Fli1bEBoaKur51PLwDgERERE1iV6vh62tbY39BqYqLi4O8fHx+P7772EwGODs7AwfHx9MmDDBOHlIDuPHj8fUqVONk5++/fZb4+Sn119/3fi+AwcOIDIyEqdOnRL1fGp5uIeAiIiIGs1gMMDT09M4AUcJXnvtNURGRuKbb77B//7v/8LMzAzr1q3Dn//8ZwQEBODf//43Hj16JHkdnBxFclNGS09ERESyU+pDBjY2Npg9ezZmz56NX3/9FUeOHMGXX36J//7v/4aVlRVefvll+Pj4VPv2YjFxchTJjXcIiIiIiOrQu3dvBAYG4siRI4iLi4O3tze+/PJLBAYGyl4LJ0eRVHiHgIiIiKgeZWVlSEhIQHx8PBITE1FZWQm1Wi3pZ7755ps1AvysWbNqTH6S6nxqWdgQEBERET2loqICZ8+exdGjR3HixAk8fPgQ9vb2CAwMxKRJk9CnTx/JPpuTo0hunDJEREREjWYwGODk5IRDhw7BycmpucsRTXp6OuLj43H8+HHk5eWha9eumDhxIry9vRW1zroobXIUNQz/1yYiIiLC799ErNfr0bZtW3h5ecHb2xseHh4wM2sZWy6rJkfFxMS0iOaH/sCGgIiIiBpNpVKhZ8+eaN26dXOXIppBgwZh2bJl8PT0rDalpyXhgyMtExsCIiIiajQzMzOcPn26ucsQVURERHOXQNQsWsY9MCIiIqpTdnY2tm3bhlWrVmHv3r0oKiqq8Z6ff/4Zfn5+zVAdEUmNdwiIiIhasNu3b2PatGl49OgRevTogZiYGERERGD9+vXVvnjr4cOHSE5ObsZKiUgqvENARETUgm3atAm9evVCYmIiTpw4gZMnT8LV1RULFizAwYMHm7s8IpIBGwIiIqIW7MKFCwgMDISNjQ0AwM7ODtu2bUNwcDDWrFmDf/zjH81cIRFJjY8MERERtWDFxcXo0KFDjdfffvtt2NraIiQkBPfu3YOvr28zVEdyUuLkKGoYNgREREQtWN++fXHx4kW8+OKLNY75+vqiQ4cOWLp0KdLT05uhOpKTEidHUcPwkSEiIqIWbMSIEYiJiUFFRUWtxz09PbFr1y5kZWXJXBkJwclR1BiqSn4DBRERUYuVkpKC4uJiaLVatGvXrs733bx5ExcvXuSjQybg6clRer0eHTt2rDE56uLFi5g5cyauXbvWjNXS84B3CIiIiFqw2bNnIzQ0FHv27MHt27frfJ+9vT2bARPByVHUWGwIiIiIWrANGzagT58+iIiIwPjx4zF9+nR8/vnnuH//fnOXRk3EyVHUWHxkiIiIiHD//n18+eWXiI+PR3p6Olq1agUPDw/4+Phg3LhxaNu2bXOXSA2k0WgQERFR60bxw4cPIyQkBL6+vvD19cWsWbP4yBCxISAiIqLqfv31Vxw5cgRffvklbty4ASsrK7z88svw8fGp9gw6PZ9ee+01TJgwAW+99Vatx0+dOoWlS5eib9+++Omnn9gQEBsCIiIiqtuPP/6I/fv344svvoBKpcLVq1ebuyR6ho8++ggnT57E8ePHYWZW+9PhSUlJWLBgAYqLi9kQEL+HgIiIiGoqKytDQkIC4uPjkZiYiMrKSqjV6uYuixrg5ZdfxosvvohHjx7VOTlKp9MhOjoaFy9elLk6eh7xDgEREREBACoqKnD27FkcPXoUJ06cwMOHD2Fvbw9vb29MmjQJffr0ae4SqQEcHR3xpz/9CT4+PvD29kbfvn2buyR6zrEhICIiauHS09MRHx+P48ePIy8vD127dsXEiRPh7e0NJyen5i6PGikuLg7x8fH4/vvvYTAY4OzsDB8fH0yYMME4eYjoSWwIiIiIWjBPT0/o9Xq0bdsWXl5e8Pb2hoeHR53PnpPp4OQoaig2BERERC1YYGAgvL294enpCUtLy+YuhyTCyVFUHzYERERERC0IJ0fR0zhliIiIiKgF4OQoqgvvEBAREREpFCdHUUOwISAiIiJSGE6OosbgI0NERERECsLJUdRYbAiIiIiIFGTQoEFYtmwZJ0dRg/GRISIiIiKiFoz3joiIiIiIWjA2BERERERELRgbAiIiIiKiFowNARERERFRC8aGgIiIiIioBft/WTQTEC8030QAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}