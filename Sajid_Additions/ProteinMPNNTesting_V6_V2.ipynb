{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProteinMPNNTesting_V6_V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c66e0f35faf740b1bcbe44960d2dc5b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfd783f81bdd4bdf974abe20acd1dcb6",
              "IPY_MODEL_a6ebf106b77c48f19aeec8f19699ff86",
              "IPY_MODEL_aef1bd91090b478c89912bc0c1df2d5e"
            ],
            "layout": "IPY_MODEL_a9ca5d8460834744adbefc90aa36fb23"
          }
        },
        "dfd783f81bdd4bdf974abe20acd1dcb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cae1ff11e0814f9ea66fc3a915dc01f9",
            "placeholder": "​",
            "style": "IPY_MODEL_d3de63bd76b74449af3599f7f8c5e718",
            "value": ""
          }
        },
        "a6ebf106b77c48f19aeec8f19699ff86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32e836af7d7241309adca8ab64ee859a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_661747dad62d4da5aff9d8376b39beea",
            "value": 1
          }
        },
        "aef1bd91090b478c89912bc0c1df2d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a3048e8f0c646a9b48a57bd95a49776",
            "placeholder": "​",
            "style": "IPY_MODEL_b6a1d85d9ef04db188f7c22f57ce8a38",
            "value": " 2648/? [00:00&lt;00:00, 64822.64it/s]"
          }
        },
        "a9ca5d8460834744adbefc90aa36fb23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cae1ff11e0814f9ea66fc3a915dc01f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3de63bd76b74449af3599f7f8c5e718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32e836af7d7241309adca8ab64ee859a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "661747dad62d4da5aff9d8376b39beea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a3048e8f0c646a9b48a57bd95a49776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6a1d85d9ef04db188f7c22f57ce8a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16b0189b5b424c8bb4f34c7ad65fb003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd177455cc7b41c59d4047adf8e89dad",
              "IPY_MODEL_2111149deee34e7cbb3bddb4b0840466",
              "IPY_MODEL_484d8bac85cc45cd96fee642805ed6a2"
            ],
            "layout": "IPY_MODEL_eff3d544f00940d88a376a6673cbf321"
          }
        },
        "fd177455cc7b41c59d4047adf8e89dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c7c62aa6f4f4563b65db9f975091790",
            "placeholder": "​",
            "style": "IPY_MODEL_d73148d3183c4048a2df03213834e6ef",
            "value": "100%"
          }
        },
        "2111149deee34e7cbb3bddb4b0840466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb15ba218ddb40d88bf3d3aad18243b5",
            "max": 131,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de22d707d56a49f99750afa82661b0da",
            "value": 131
          }
        },
        "484d8bac85cc45cd96fee642805ed6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_665385b594e946efb4e61b5cb405fe05",
            "placeholder": "​",
            "style": "IPY_MODEL_2d57981794044f3aadce5d08b191c4ce",
            "value": " 131/131 [00:04&lt;00:00, 24.57it/s]"
          }
        },
        "eff3d544f00940d88a376a6673cbf321": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c7c62aa6f4f4563b65db9f975091790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d73148d3183c4048a2df03213834e6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb15ba218ddb40d88bf3d3aad18243b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de22d707d56a49f99750afa82661b0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "665385b594e946efb4e61b5cb405fe05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d57981794044f3aadce5d08b191c4ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_wbcvVBv0QJ",
        "outputId": "2a8cdb62-058f-496e-b341-063a3fef4306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import sys \n",
        "installation_path = \"/content/drive/MyDrive/Colab_Installations_V2\"\n",
        "# The path is being modified so that everything installed in the installation path can now be used without re-installing (in this case, I just need biopython)\n",
        "sys.path.insert(0,installation_path)\n",
        "protein_mpnn_path = \"/content/drive/MyDrive/Protein_MPNN_Digging/ProteinMPNN/vanilla_proteinmpnn\"\n",
        "sys.path.insert(0,protein_mpnn_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Protein_MPNN_Digging"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgTOgsabxBaC",
        "outputId": "41de8526-e6e4-45a2-e535-1041a591327e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1KHc6SLCFDWefngMT266PS74JQMzqN06K/Protein_MPNN_Digging\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import warnings\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, Subset\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import os\n",
        "from Bio.PDB import *\n",
        "\n",
        "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")"
      ],
      "metadata": {
        "id": "jX5ScMeGyLcy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from Bio.PDB.Polypeptide import *\n",
        "from string import ascii_uppercase"
      ],
      "metadata": {
        "id": "NBjszWagtiYL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = os.path.join(protein_mpnn_path,\"vanilla_model_weights\")\n",
        "model_name = \"v_48_020\"\n",
        "checkpoint_path = os.path.join(weights_path,model_name+\".pt\")"
      ],
      "metadata": {
        "id": "Z6ZHe2IIyy1G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, load and dig into the checkpoint object\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device) "
      ],
      "metadata": {
        "id": "JPE_pX8tzdUO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint[\"num_edges\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DD1hpMLk2-y",
        "outputId": "8d1c2700-e5a6-4e7e-e7f0-026cc436e9e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import json, time, os, sys, glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, Subset\n",
        "\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "#A number of functions/classes are adopted from: https://github.com/jingraham/neurips19-graph-protein-design\n",
        "\n",
        "def _scores(S, log_probs, mask):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    criterion = torch.nn.NLLLoss(reduction='none')\n",
        "    loss = criterion(\n",
        "        log_probs.contiguous().view(-1,log_probs.size(-1)),\n",
        "        S.contiguous().view(-1)\n",
        "    ).view(S.size())\n",
        "    # The designable positions have mask set to 1.0, so this function seems to be returning the average score for the designable positions\n",
        "    scores = torch.sum(loss * mask, dim=-1) / torch.sum(mask, dim=-1)\n",
        "    return scores\n",
        "\n",
        "def _S_to_seq(S, mask):\n",
        "    # This is the decoding order\n",
        "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    seq = ''.join([alphabet[c] for c, m in zip(S.tolist(), mask.tolist()) if m > 0])\n",
        "    return seq\n",
        "\n",
        "def parse_PDB_biounits(x, atoms=['N','CA','C'], chain=None):\n",
        "  '''\n",
        "  input:  x = PDB filename\n",
        "          atoms = atoms to extract (optional)\n",
        "  output: (length, atoms, coords=(x,y,z)), sequence\n",
        "  '''\n",
        "\n",
        "  alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "  states = len(alpha_1)\n",
        "  alpha_3 = ['ALA','ARG','ASN','ASP','CYS','GLN','GLU','GLY','HIS','ILE',\n",
        "             'LEU','LYS','MET','PHE','PRO','SER','THR','TRP','TYR','VAL','GAP']\n",
        "  \n",
        "  # The following dictionaries are mapping from one-letter to 0-20 index,\n",
        "  # three-letter to 0-20 index,\n",
        "  # 0-20 index to one-letter,\n",
        "  # one-letter to three-letter, and vice-versa \n",
        "  aa_1_N = {a:n for n,a in enumerate(alpha_1)}\n",
        "  aa_3_N = {a:n for n,a in enumerate(alpha_3)}\n",
        "  aa_N_1 = {n:a for n,a in enumerate(alpha_1)}\n",
        "  aa_1_3 = {a:b for a,b in zip(alpha_1,alpha_3)}\n",
        "  aa_3_1 = {b:a for a,b in zip(alpha_1,alpha_3)}\n",
        "  \n",
        "  def AA_to_N(x):\n",
        "    # [\"ARND\"] -> [[0,1,2,3]]\n",
        "    x = np.array(x);\n",
        "    if x.ndim == 0: x = x[None]\n",
        "    return [[aa_1_N.get(a, states-1) for a in y] for y in x]\n",
        "  \n",
        "  def N_to_AA(x):\n",
        "    # [[0,1,2,3]] -> [\"ARND\"]\n",
        "    x = np.array(x);\n",
        "    if x.ndim == 1: x = x[None]\n",
        "    return [\"\".join([aa_N_1.get(a,\"-\") for a in y]) for y in x]\n",
        "\n",
        "  xyz,seq,min_resn,max_resn = {},{},1e6,-1e6\n",
        "  for line in open(x,\"rb\"):\n",
        "    line = line.decode(\"utf-8\",\"ignore\").rstrip()\n",
        "\n",
        "    if line[:6] == \"HETATM\" and line[17:17+3] == \"MSE\":\n",
        "      line = line.replace(\"HETATM\",\"ATOM  \")\n",
        "      line = line.replace(\"MSE\",\"MET\")\n",
        "\n",
        "    if line[:4] == \"ATOM\":\n",
        "      ch = line[21:22]\n",
        "      # If the input chain is not in the PDB file, which can be the case if the target chains are named differently in the runner script,\n",
        "      # this line will cause the output to have literally no information, this is the case for integer named chains\n",
        "      # that does not mean that this line is not doing its job correctly, this is just a constraint that input chain names and \n",
        "      # chain names in the PDB file have to be congruent\n",
        "      if ch == chain or chain is None:\n",
        "        atom = line[12:12+4].strip()\n",
        "        resi = line[17:17+3]\n",
        "        resn = line[22:22+5].strip()\n",
        "        x,y,z = [float(line[i:(i+8)]) for i in [30,38,46]]\n",
        "\n",
        "        if resn[-1].isalpha(): \n",
        "            resa,resn = resn[-1],int(resn[:-1])-1\n",
        "        else: \n",
        "            resa,resn = \"\",int(resn)-1\n",
        "#         resn = int(resn)\n",
        "        if resn < min_resn: \n",
        "            min_resn = resn\n",
        "        if resn > max_resn: \n",
        "            max_resn = resn\n",
        "        if resn not in xyz: \n",
        "            xyz[resn] = {}\n",
        "        if resa not in xyz[resn]: \n",
        "            xyz[resn][resa] = {}\n",
        "        if resn not in seq: \n",
        "            seq[resn] = {}\n",
        "        if resa not in seq[resn]: \n",
        "            seq[resn][resa] = resi\n",
        "\n",
        "        if atom not in xyz[resn][resa]:\n",
        "          xyz[resn][resa][atom] = np.array([x,y,z])\n",
        "\n",
        "  # convert to numpy arrays, fill in missing values\n",
        "  seq_,xyz_ = [],[]\n",
        "  try:\n",
        "      for resn in range(min_resn,max_resn+1):\n",
        "        if resn in seq:\n",
        "          for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k],20))\n",
        "        else: seq_.append(20)\n",
        "        if resn in xyz:\n",
        "          for k in sorted(xyz[resn]):\n",
        "            for atom in atoms:\n",
        "              if atom in xyz[resn][k]: xyz_.append(xyz[resn][k][atom])\n",
        "              else: xyz_.append(np.full(3,np.nan))\n",
        "        else:\n",
        "          for atom in atoms: xyz_.append(np.full(3,np.nan))\n",
        "      return np.array(xyz_).reshape(-1,len(atoms),3), N_to_AA(np.array(seq_))\n",
        "  except TypeError:\n",
        "      return 'no_chain', 'no_chain'\n",
        "\n",
        "### calling signature\n",
        "# pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list)\n",
        "def parse_PDB(path_to_pdb, input_chain_list=None):\n",
        "    c=0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V','W','X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v','w','x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "     \n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list  \n",
        " \n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    # Each of the biounits is a separate PDB file, so for running with a single PDB file like from colab, this loop will be executed only once\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {} \n",
        "        # This loop will be executed only once for single chain DDG type cases\n",
        "        for letter in chain_alphabet:\n",
        "            xyz, seq = parse_PDB_biounits(biounit, atoms=['N','CA','C','O'], chain=letter)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_'+letter]=seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                coords_dict_chain['N_chain_'+letter]=xyz[:,0,:].tolist()\n",
        "                coords_dict_chain['CA_chain_'+letter]=xyz[:,1,:].tolist()\n",
        "                coords_dict_chain['C_chain_'+letter]=xyz[:,2,:].tolist()\n",
        "                coords_dict_chain['O_chain_'+letter]=xyz[:,3,:].tolist()\n",
        "                my_dict['coords_chain_'+letter]=coords_dict_chain\n",
        "                s += 1\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        my_dict['name']=biounit[(fi+1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c+=1\n",
        "    return pdb_dict_list\n",
        "\n",
        "\n",
        "# X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta \n",
        "# = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "# fixed_pos_list = fixed_position_dict[b['name']][letter]\n",
        "# The trick will be to populate this fixed_position_dict from the calling function, and \n",
        "def tied_featurize(batch, device, chain_dict, fixed_position_dict=None, omit_AA_dict=None, tied_positions_dict=None, pssm_dict=None, bias_by_res_dict=None):\n",
        "    \"\"\" Pack and pad batch into torch tensors \"\"\"\n",
        "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    B = len(batch)\n",
        "    lengths = np.array([len(b['seq']) for b in batch], dtype=np.int32) #sum of chain seq lengths\n",
        "    L_max = max([len(b['seq']) for b in batch])\n",
        "    X = np.zeros([B, L_max, 4, 3])\n",
        "    residue_idx = -100*np.ones([B, L_max], dtype=np.int32)\n",
        "    # This \"chain_M\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of the single sequence as a consequence\n",
        "    chain_M = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    pssm_coef_all = np.zeros([B, L_max], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    pssm_bias_all = np.zeros([B, L_max, 21], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    pssm_log_odds_all = 10000.0*np.ones([B, L_max, 21], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    # This \"chain_M_pos\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of single sequence as a consequence\n",
        "    chain_M_pos = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    bias_by_res_all = np.zeros([B, L_max, 21], dtype=np.float32)\n",
        "    # This \"chain_encoding_all\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of single sequence as a consequence\n",
        "    chain_encoding_all = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    S = np.zeros([B, L_max], dtype=np.int32)\n",
        "    omit_AA_mask = np.zeros([B, L_max, len(alphabet)], dtype=np.int32)\n",
        "    # Build the batch\n",
        "    letter_list_list = []\n",
        "    visible_list_list = []\n",
        "    masked_list_list = []\n",
        "    masked_chain_length_list_list = []\n",
        "    tied_pos_list_of_lists_list = []\n",
        "    #shuffle all chains before the main loop\n",
        "    for i, b in enumerate(batch):\n",
        "        # for my current energy function like usecase, the code will reach \"if and not else\" because chain_dict will not be None\n",
        "        if chain_dict != None:\n",
        "            ### Calling function argument assignment START\n",
        "            # chain_id_dict[pdb_dict_list[0]['name']] = (designed_chain_list, fixed_chain_list)\n",
        "            ### Calling function argument assignment END\n",
        "            masked_chains, visible_chains = chain_dict[b['name']] #masked_chains a list of chain letters to predict [A, D, F]\n",
        "        else:\n",
        "            masked_chains = [item[-1:] for item in list(b) if item[:10]=='seq_chain_']\n",
        "            visible_chains = []\n",
        "        num_chains = b['num_of_chains']\n",
        "        all_chains = masked_chains + visible_chains\n",
        "        #random.shuffle(all_chains)\n",
        "    # This for loop can be ignored since it will be executed only once in my single-chain or single-chain-at-a-time implementation\n",
        "    for i, b in enumerate(batch):\n",
        "        mask_dict = {}\n",
        "        a = 0\n",
        "        x_chain_list = []\n",
        "        chain_mask_list = []\n",
        "        # \"chain_seq_list\" will contain string format sequences of all the chains both fixed and designable \n",
        "        chain_seq_list = []\n",
        "        chain_encoding_list = []\n",
        "        c = 1\n",
        "        # \"letter_list\" will contain names of all the chains both fixed and designable\n",
        "        letter_list = []\n",
        "        global_idx_start_list = [0]\n",
        "        # \"visible_list\" will contain names of the fixed chains \n",
        "        visible_list = []\n",
        "        # \"masked_list\" will contain names of the designable chains\n",
        "        masked_list = []\n",
        "        masked_chain_length_list = []\n",
        "        fixed_position_mask_list = []\n",
        "        omit_AA_mask_list = []\n",
        "        pssm_coef_list = []\n",
        "        pssm_bias_list = []\n",
        "        pssm_log_odds_list = []\n",
        "        bias_by_res_list = []\n",
        "        l0 = 0\n",
        "        l1 = 0\n",
        "        # This loop will also be executed once for my single chain case,\n",
        "        # and since the same chain has both designable and fixed positions, the codes insides both of the if \n",
        "        # statements will be executed\n",
        "        for step, letter in enumerate(all_chains):\n",
        "            if letter in visible_chains:\n",
        "                letter_list.append(letter)\n",
        "                visible_list.append(letter)\n",
        "                chain_seq = b[f'seq_chain_{letter}']\n",
        "                chain_seq = ''.join([a if a!='-' else 'X' for a in chain_seq])\n",
        "                chain_length = len(chain_seq)\n",
        "                global_idx_start_list.append(global_idx_start_list[-1]+chain_length)\n",
        "                chain_coords = b[f'coords_chain_{letter}'] #this is a dictionary\n",
        "                # the \"chain_mask\" varies between fixed and designable chains (1.0 for designable chains which are maxed)\n",
        "                chain_mask = np.zeros(chain_length) #0.0 for visible chains\n",
        "                x_chain = np.stack([chain_coords[c] for c in [f'N_chain_{letter}', f'CA_chain_{letter}', f'C_chain_{letter}', f'O_chain_{letter}']], 1) #[chain_lenght,4,3]\n",
        "                x_chain_list.append(x_chain)\n",
        "                chain_mask_list.append(chain_mask)\n",
        "                chain_seq_list.append(chain_seq)\n",
        "                # \"chain_encoding_list\" contains numpy arrays corresponding to chains (each array corresponds to one chain),\n",
        "                # where all elements of the same array is the same value, which is equal to the index of the chain the it corresponds to\n",
        "                # by index, I mean index of the different numpy arrays annotating the chains\n",
        "                chain_encoding_list.append(c*np.ones(np.array(chain_mask).shape[0]))\n",
        "                # l0 points at the starting of the current chain and l1 points after the ending of the current chain\n",
        "                l1 += chain_length\n",
        "                # the only value i will have is 0 since it will be executed only once in my single-chain or single-chain-at-a-time implementation\n",
        "                # seems like the chains are separated by  \n",
        "                residue_idx[i, l0:l1] = 100*(c-1)+np.arange(l0, l1)\n",
        "                l0 += chain_length\n",
        "                c+=1\n",
        "                # The following variables are numpy arrays with entries corresponding to every position in the sequence\n",
        "                # appending these numpy arrays to a list indicates that the chains are added one after one\n",
        "                # same thing goes for the chain_mask and chain_seq variables declared above\n",
        "                # In code-block below in this cell, these lists of numpy arrays are going through np.concatenate(), which is creating\n",
        "                # the final numpy arrays containing co-ordinates, sequence identity, fixed position, masked position, PSSM bias, and everything\n",
        "                # required to pass the sequences through the model\n",
        "                ### START\n",
        "                fixed_position_mask = np.ones(chain_length)\n",
        "                fixed_position_mask_list.append(fixed_position_mask)\n",
        "                # The omit_AA_mask, pssm_coef, pssm_bias, \"bias_by_res_list\", all these numpy arrays are zero for the fixed positions\n",
        "                # since these positions are used as it is, while for the masked_positions, these values can get activated\n",
        "                # which is why the next if statement has several extra lines manipulating these variables according to the amount of information passed \n",
        "                omit_AA_mask_temp = np.zeros([chain_length, len(alphabet)], np.int32)\n",
        "                omit_AA_mask_list.append(omit_AA_mask_temp)\n",
        "                pssm_coef = np.zeros(chain_length)\n",
        "                pssm_bias = np.zeros([chain_length, 21])\n",
        "                pssm_log_odds = 10000.0*np.ones([chain_length, 21])\n",
        "                pssm_coef_list.append(pssm_coef)\n",
        "                pssm_bias_list.append(pssm_bias)\n",
        "                pssm_log_odds_list.append(pssm_log_odds)\n",
        "                bias_by_res_list.append(np.zeros([chain_length, 21]))\n",
        "                ### END\n",
        "            if letter in masked_chains:\n",
        "                masked_list.append(letter)\n",
        "                letter_list.append(letter)\n",
        "                chain_seq = b[f'seq_chain_{letter}']\n",
        "                chain_seq = ''.join([a if a!='-' else 'X' for a in chain_seq])\n",
        "                chain_length = len(chain_seq)\n",
        "                global_idx_start_list.append(global_idx_start_list[-1]+chain_length)\n",
        "                masked_chain_length_list.append(chain_length)\n",
        "                chain_coords = b[f'coords_chain_{letter}'] #this is a dictionary\n",
        "                chain_mask = np.ones(chain_length) #1.0 for masked\n",
        "                x_chain = np.stack([chain_coords[c] for c in [f'N_chain_{letter}', f'CA_chain_{letter}', f'C_chain_{letter}', f'O_chain_{letter}']], 1) #[chain_lenght,4,3]\n",
        "                x_chain_list.append(x_chain)\n",
        "                chain_mask_list.append(chain_mask)\n",
        "                chain_seq_list.append(chain_seq)\n",
        "                chain_encoding_list.append(c*np.ones(np.array(chain_mask).shape[0]))\n",
        "                l1 += chain_length\n",
        "                residue_idx[i, l0:l1] = 100*(c-1)+np.arange(l0, l1)\n",
        "                l0 += chain_length\n",
        "                c+=1\n",
        "                fixed_position_mask = np.ones(chain_length)\n",
        "                if fixed_position_dict!=None:\n",
        "                    fixed_pos_list = fixed_position_dict[b['name']][letter]\n",
        "                    if fixed_pos_list:\n",
        "                        # seems like \"fixed_pos_list\"  can be an 1-indexed integer list corresponding to positions in \"chain_seq\"\n",
        "                        # this thing ultimately controls which positions in the designable chain will be masked, which is why the fixed \n",
        "                        # positions are set to 0.0 since those positions will not be maxed (1 if maxed, 0 if not maxed)\n",
        "                        fixed_position_mask[np.array(fixed_pos_list)-1] = 0.0\n",
        "                fixed_position_mask_list.append(fixed_position_mask)\n",
        "                omit_AA_mask_temp = np.zeros([chain_length, len(alphabet)], np.int32)\n",
        "                # For my current energy function like usecase, \"omit_AA_dict\" will be None, so the following loop can be ignored\n",
        "                if omit_AA_dict!=None:\n",
        "                    for item in omit_AA_dict[b['name']][letter]:\n",
        "                        idx_AA = np.array(item[0])-1\n",
        "                        AA_idx = np.array([np.argwhere(np.array(list(alphabet))== AA)[0][0] for AA in item[1]]).repeat(idx_AA.shape[0])\n",
        "                        idx_ = np.array([[a, b] for a in idx_AA for b in AA_idx])\n",
        "                        omit_AA_mask_temp[idx_[:,0], idx_[:,1]] = 1\n",
        "                omit_AA_mask_list.append(omit_AA_mask_temp)\n",
        "                pssm_coef = np.zeros(chain_length)\n",
        "                pssm_bias = np.zeros([chain_length, 21])\n",
        "                pssm_log_odds = 10000.0*np.ones([chain_length, 21])\n",
        "                if pssm_dict:\n",
        "                    if pssm_dict[b['name']][letter]:\n",
        "                        pssm_coef = pssm_dict[b['name']][letter]['pssm_coef']\n",
        "                        pssm_bias = pssm_dict[b['name']][letter]['pssm_bias']\n",
        "                        pssm_log_odds = pssm_dict[b['name']][letter]['pssm_log_odds']\n",
        "                pssm_coef_list.append(pssm_coef)\n",
        "                pssm_bias_list.append(pssm_bias)\n",
        "                pssm_log_odds_list.append(pssm_log_odds)\n",
        "                if bias_by_res_dict:\n",
        "                    bias_by_res_list.append(bias_by_res_dict[b['name']][letter])\n",
        "                else:\n",
        "                    bias_by_res_list.append(np.zeros([chain_length, 21]))\n",
        "\n",
        "        ### TIED position START\n",
        "        # Since there will technically be no tied positions for my single chain energy-based usecase for now,\n",
        "        # I do not need to dig into this part of the code\n",
        "        letter_list_np = np.array(letter_list)\n",
        "        tied_pos_list_of_lists = []\n",
        "        tied_beta = np.ones(L_max)\n",
        "        if tied_positions_dict!=None:\n",
        "            tied_pos_list = tied_positions_dict[b['name']]\n",
        "            if tied_pos_list:\n",
        "                set_chains_tied = set(list(itertools.chain(*[list(item) for item in tied_pos_list])))\n",
        "                for tied_item in tied_pos_list:\n",
        "                    one_list = []\n",
        "                    for k, v in tied_item.items():\n",
        "                        start_idx = global_idx_start_list[np.argwhere(letter_list_np == k)[0][0]]\n",
        "                        if isinstance(v[0], list):\n",
        "                            for v_count in range(len(v[0])):\n",
        "                                one_list.append(start_idx+v[0][v_count]-1)#make 0 to be the first\n",
        "                                tied_beta[start_idx+v[0][v_count]-1] = v[1][v_count]\n",
        "                        else:\n",
        "                            for v_ in v:\n",
        "                                one_list.append(start_idx+v_-1)#make 0 to be the first\n",
        "                    tied_pos_list_of_lists.append(one_list)\n",
        "        tied_pos_list_of_lists_list.append(tied_pos_list_of_lists)\n",
        "        ### TIED position END\n",
        " \n",
        "        # Interestingly, although the backbone atom coordinates are used for generating edge features,\n",
        "        # the \"x\" in the following line contains the coodinates of the backbone atoms \n",
        "        x = np.concatenate(x_chain_list,0) #[L, 4, 3]\n",
        "        # \"all_sequence\" is a string where all the chain sequences have been put one after another\n",
        "        all_sequence = \"\".join(chain_seq_list)\n",
        "        # This \"chain_mask_list\" and \"m_pos\" below are the variables of interest if these actually contain full information regarding the\n",
        "        # fixed vs. variable positions definitions \n",
        "        # consequently, since these are concatenated numpy arrays of numpy arrays inside the lists \"chain_mask_list\" and \"fixed_position_mask_list\",\n",
        "        # when those lists are populated in the above code-block with binary numpy arrays \"fixed_position_mask\" and \"fixed_position_mask\" corresponding to \n",
        "        # each of the chains,\n",
        "        # that is where all the controlling needs to be done from\n",
        "        m = np.concatenate(chain_mask_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        # \"chain_encoding_list\" contains numpy arrays corresponding to chains (each array corresponds to one chain),\n",
        "        # where all elements of the same array is the same value, which is equal to the index of the chain the it corresponds to\n",
        "        # by index, I mean index of the different numpy arrays annotating the chains\n",
        "        chain_encoding = np.concatenate(chain_encoding_list,0)\n",
        "        m_pos = np.concatenate(fixed_position_mask_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "\n",
        "        pssm_coef_ = np.concatenate(pssm_coef_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        pssm_bias_ = np.concatenate(pssm_bias_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        pssm_log_odds_ = np.concatenate(pssm_log_odds_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "\n",
        "        bias_by_res_ = np.concatenate(bias_by_res_list, 0)  #[L,21], 0.0 for places where AA frequencies don't need to be tweaked\n",
        "\n",
        "        # Interestingly, all the chains are padded to the same length\n",
        "        # this has to be done most probably because the same layers are applied to all chains\n",
        "        # but for single chain or homomer cases, this should not be an issue\n",
        "        # need to be sure later why this is done\n",
        "        # does not significant when it comes to single chain energy-based usecase\n",
        "        # PADDING START\n",
        "        l = len(all_sequence)\n",
        "        x_pad = np.pad(x, [[0,L_max-l], [0,0], [0,0]], 'constant', constant_values=(np.nan, ))\n",
        "        X[i,:,:,:] = x_pad\n",
        "\n",
        "        m_pad = np.pad(m, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        m_pos_pad = np.pad(m_pos, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        omit_AA_mask_pad = np.pad(np.concatenate(omit_AA_mask_list,0), [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        chain_M[i,:] = m_pad\n",
        "        chain_M_pos[i,:] = m_pos_pad\n",
        "        omit_AA_mask[i,] = omit_AA_mask_pad\n",
        "\n",
        "        chain_encoding_pad = np.pad(chain_encoding, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        chain_encoding_all[i,:] = chain_encoding_pad\n",
        "\n",
        "        pssm_coef_pad = np.pad(pssm_coef_, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        pssm_bias_pad = np.pad(pssm_bias_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "        pssm_log_odds_pad = np.pad(pssm_log_odds_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "\n",
        "        pssm_coef_all[i,:] = pssm_coef_pad\n",
        "        pssm_bias_all[i,:] = pssm_bias_pad\n",
        "        pssm_log_odds_all[i,:] = pssm_log_odds_pad\n",
        "\n",
        "        bias_by_res_pad = np.pad(bias_by_res_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "        bias_by_res_all[i,:] = bias_by_res_pad\n",
        "        # PADDING END\n",
        "\n",
        "        # Convert to labels\n",
        "        indices = np.asarray([alphabet.index(a) for a in all_sequence], dtype=np.int32)\n",
        "        S[i, :l] = indices\n",
        "        letter_list_list.append(letter_list)\n",
        "        visible_list_list.append(visible_list)\n",
        "        masked_list_list.append(masked_list)\n",
        "        masked_chain_length_list_list.append(masked_chain_length_list)\n",
        "\n",
        "\n",
        "    isnan = np.isnan(X)\n",
        "    mask = np.isfinite(np.sum(X,(2,3))).astype(np.float32)\n",
        "    X[isnan] = 0.\n",
        "\n",
        "    # Conversion\n",
        "    pssm_coef_all = torch.from_numpy(pssm_coef_all).to(dtype=torch.float32, device=device)\n",
        "    pssm_bias_all = torch.from_numpy(pssm_bias_all).to(dtype=torch.float32, device=device)\n",
        "    pssm_log_odds_all = torch.from_numpy(pssm_log_odds_all).to(dtype=torch.float32, device=device)\n",
        "\n",
        "    tied_beta = torch.from_numpy(tied_beta).to(dtype=torch.float32, device=device)\n",
        "\n",
        "    jumps = ((residue_idx[:,1:]-residue_idx[:,:-1])==1).astype(np.float32)\n",
        "    bias_by_res_all = torch.from_numpy(bias_by_res_all).to(dtype=torch.float32, device=device)\n",
        "    phi_mask = np.pad(jumps, [[0,0],[1,0]])\n",
        "    psi_mask = np.pad(jumps, [[0,0],[0,1]])\n",
        "    omega_mask = np.pad(jumps, [[0,0],[0,1]])\n",
        "    dihedral_mask = np.concatenate([phi_mask[:,:,None], psi_mask[:,:,None], omega_mask[:,:,None]], -1) #[B,L,3]\n",
        "    dihedral_mask = torch.from_numpy(dihedral_mask).to(dtype=torch.float32, device=device)\n",
        "    residue_idx = torch.from_numpy(residue_idx).to(dtype=torch.long,device=device)\n",
        "    S = torch.from_numpy(S).to(dtype=torch.long,device=device)\n",
        "    X = torch.from_numpy(X).to(dtype=torch.float32, device=device)\n",
        "    mask = torch.from_numpy(mask).to(dtype=torch.float32, device=device)\n",
        "    chain_M = torch.from_numpy(chain_M).to(dtype=torch.float32, device=device)\n",
        "    chain_M_pos = torch.from_numpy(chain_M_pos).to(dtype=torch.float32, device=device)\n",
        "    omit_AA_mask = torch.from_numpy(omit_AA_mask).to(dtype=torch.float32, device=device)\n",
        "    chain_encoding_all = torch.from_numpy(chain_encoding_all).to(dtype=torch.long, device=device)\n",
        "    # in general, in this return statement, *_list_list has the list inside list format because the outer list corresponds to \"batch_clones\", \n",
        "    # whereas the inner list corresponds to \"chains\" for each of the elements of \"batch_clones\"\n",
        "    # \"masked_list_list\" contains names of the designable chains (which is my target for single chain energy), whereas \"visible_list_list\" \n",
        "    # contains names of the fixed chains (which should be empty for my single chain energy)\n",
        "    # for my single chain energy case, \"letter_list_list\" should be equal to \"masked_list_list\", and three lists should have one list for now\n",
        "    # \"chain_encoding_all\" should also contain chain-index related to the only single chain which should be 0 (all 0s)\n",
        "    # the last lists starting from \"tied_pos_list_of_lists_list\" to the end should be irrelevant for my single chain energy case\n",
        "    # but still it would be good to check the values of these irrelevant lists, and get an idea if everything makes sense or not\n",
        "    # \"chain_M_pos\" contains values from \"fixed_position_mask\" through \"m_pos\", which should get populated with 0.0 for fixed positions\n",
        "    # and 1.0 for designable positions, which can be controlled through the , which\n",
        "    # is controlled by \"fixed_position_dict\" input to this function from the running script\n",
        "    # \"chain_M\" is formed from \"m_pad\" which comes from \"m\" which comes from chain_mask = np.ones(chain_length) #1.0 for masked\n",
        "    # so, for my single chain energy usecase, \"chain_M\" should be all 1.0s with the same length as chain_M_pos\n",
        "    # I do not think \"X\", \"S\", and \"mask\" need to be manipulated for now \n",
        "    return X, S, mask, lengths, chain_M, chain_encoding_all, letter_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef_all, pssm_bias_all, pssm_log_odds_all, bias_by_res_all, tied_beta\n",
        "\n",
        "\n",
        "# No need to dig into this loss function for now\n",
        "def loss_nll(S, log_probs, mask):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    criterion = torch.nn.NLLLoss(reduction='none')\n",
        "    loss = criterion(\n",
        "        log_probs.contiguous().view(-1, log_probs.size(-1)), S.contiguous().view(-1)\n",
        "    ).view(S.size())\n",
        "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
        "    return loss, loss_av\n",
        "\n",
        "# No need to dig into this label smoothing stuff for now\n",
        "def loss_smoothed(S, log_probs, mask, weight=0.1):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    S_onehot = torch.nn.functional.one_hot(S, 21).float()\n",
        "\n",
        "    # Label smoothing\n",
        "    S_onehot = S_onehot + weight / float(S_onehot.size(-1))\n",
        "    S_onehot = S_onehot / S_onehot.sum(-1, keepdim=True)\n",
        "\n",
        "    loss = -(S_onehot * log_probs).sum(-1)\n",
        "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
        "    return loss, loss_av\n",
        "\n",
        "# Objects of this class can be indexed since dunder methods __len()__ and __getitem()__ have been implemented, which \n",
        "# indexes a list that has been declared as an instance variable in the constructor,\n",
        "# and each element of that underlying list is a dictionary containing information regarding a specific sequence\n",
        "class StructureDataset():\n",
        "    def __init__(self, jsonl_file, verbose=True, truncate=None, max_length=100,\n",
        "        alphabet='ACDEFGHIKLMNPQRSTVWYX-'):\n",
        "        alphabet_set = set([a for a in alphabet])\n",
        "        discard_count = {\n",
        "            'bad_chars': 0,\n",
        "            'too_long': 0,\n",
        "            'bad_seq_length': 0\n",
        "        }\n",
        "\n",
        "        with open(jsonl_file) as f:\n",
        "            self.data = []\n",
        "\n",
        "            lines = f.readlines()\n",
        "            start = time.time()\n",
        "            for i, line in enumerate(lines):\n",
        "                entry = json.loads(line)\n",
        "                seq = entry['seq'] \n",
        "                name = entry['name']\n",
        "\n",
        "                # Convert raw coords to np arrays\n",
        "                #for key, val in entry['coords'].items():\n",
        "                #    entry['coords'][key] = np.asarray(val)\n",
        "\n",
        "                # Check if in alphabet\n",
        "                bad_chars = set([s for s in seq]).difference(alphabet_set)\n",
        "                if len(bad_chars) == 0:\n",
        "                    if len(entry['seq']) <= max_length:\n",
        "                        if True:\n",
        "                            self.data.append(entry)\n",
        "                        else:\n",
        "                            discard_count['bad_seq_length'] += 1\n",
        "                    else:\n",
        "                        discard_count['too_long'] += 1\n",
        "                else:\n",
        "                    print(name, bad_chars, entry['seq'])\n",
        "                    discard_count['bad_chars'] += 1\n",
        "\n",
        "                # Truncate early\n",
        "                if truncate is not None and len(self.data) == truncate:\n",
        "                    return\n",
        "\n",
        "                if verbose and (i + 1) % 1000 == 0:\n",
        "                    elapsed = time.time() - start\n",
        "                    print('{} entries ({} loaded) in {:.1f} s'.format(len(self.data), i+1, elapsed))\n",
        "\n",
        "            print('discarded', discard_count)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "\n",
        "# Objects of this class can be indexed since dunder methods __len()__ and __getitem()__ have been implemented, which \n",
        "# indexes a list that has been declared as an instance variable in the constructor,\n",
        "# and each element of that underlying list is a dictionary containing information regarding a specific structure,\n",
        "# seems like a structure-specific version of the above method which deals with sequences \n",
        "class StructureDatasetPDB():\n",
        "    def __init__(self, pdb_dict_list, verbose=True, truncate=None, max_length=100,\n",
        "        alphabet='ACDEFGHIKLMNPQRSTVWYX-'):\n",
        "        alphabet_set = set([a for a in alphabet])\n",
        "        discard_count = {\n",
        "            'bad_chars': 0,\n",
        "            'too_long': 0,\n",
        "            'bad_seq_length': 0\n",
        "        }\n",
        "\n",
        "        self.data = []\n",
        "\n",
        "        start = time.time()\n",
        "        # elements of pdb_dict_list are dictionaries containing information regarding a specific pdb file\n",
        "        for i, entry in enumerate(pdb_dict_list):\n",
        "            seq = entry['seq']\n",
        "            name = entry['name']\n",
        "\n",
        "            bad_chars = set([s for s in seq]).difference(alphabet_set)\n",
        "            if len(bad_chars) == 0:\n",
        "                if len(entry['seq']) <= max_length:\n",
        "                    self.data.append(entry)\n",
        "                else:\n",
        "                    discard_count['too_long'] += 1\n",
        "            else:\n",
        "                discard_count['bad_chars'] += 1\n",
        "\n",
        "            # Truncate early\n",
        "            if truncate is not None and len(self.data) == truncate:\n",
        "                return\n",
        "\n",
        "            if verbose and (i + 1) % 1000 == 0:\n",
        "                elapsed = time.time() - start\n",
        "\n",
        "            #print('Discarded', discard_count)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "\n",
        "    \n",
        "class StructureLoader():\n",
        "    def __init__(self, dataset, batch_size=100, shuffle=True,\n",
        "        collate_fn=lambda x:x, drop_last=False):\n",
        "        self.dataset = dataset\n",
        "        self.size = len(dataset)\n",
        "        self.lengths = [len(dataset[i]['seq']) for i in range(self.size)]\n",
        "        self.batch_size = batch_size\n",
        "        sorted_ix = np.argsort(self.lengths)\n",
        "\n",
        "        # Cluster into batches of similar sizes\n",
        "        clusters, batch = [], []\n",
        "        batch_max = 0\n",
        "        for ix in sorted_ix:\n",
        "            size = self.lengths[ix]\n",
        "            if size * (len(batch) + 1) <= self.batch_size:\n",
        "                batch.append(ix)\n",
        "                batch_max = size\n",
        "            else:\n",
        "                clusters.append(batch)\n",
        "                batch, batch_max = [], 0\n",
        "        if len(batch) > 0:\n",
        "            clusters.append(batch)\n",
        "        self.clusters = clusters\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.clusters)\n",
        "\n",
        "    def __iter__(self):\n",
        "        np.random.shuffle(self.clusters)\n",
        "        for b_idx in self.clusters:\n",
        "            batch = [self.dataset[i] for i in b_idx]\n",
        "            yield batch\n",
        "            \n",
        "            \n",
        "            \n",
        "# The following gather functions\n",
        "def gather_edges(edges, neighbor_idx):\n",
        "    # Features [B,N,N,C] at Neighbor indices [B,N,K] => Neighbor features [B,N,K,C]\n",
        "    neighbors = neighbor_idx.unsqueeze(-1).expand(-1, -1, -1, edges.size(-1))\n",
        "    edge_features = torch.gather(edges, 2, neighbors)\n",
        "    return edge_features\n",
        "\n",
        "def gather_nodes(nodes, neighbor_idx):\n",
        "    # Features [B,N,C] at Neighbor indices [B,N,K] => [B,N,K,C]\n",
        "    # Flatten and expand indices per batch [B,N,K] => [B,NK] => [B,NK,C]\n",
        "    neighbors_flat = neighbor_idx.view((neighbor_idx.shape[0], -1))\n",
        "    neighbors_flat = neighbors_flat.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
        "    # Gather and re-pack\n",
        "    neighbor_features = torch.gather(nodes, 1, neighbors_flat)\n",
        "    neighbor_features = neighbor_features.view(list(neighbor_idx.shape)[:3] + [-1])\n",
        "    return neighbor_features\n",
        "\n",
        "def gather_nodes_t(nodes, neighbor_idx):\n",
        "    # Features [B,N,C] at Neighbor index [B,K] => Neighbor features[B,K,C]\n",
        "    idx_flat = neighbor_idx.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
        "    neighbor_features = torch.gather(nodes, 1, idx_flat)\n",
        "    return neighbor_features\n",
        "\n",
        "def cat_neighbors_nodes(h_nodes, h_neighbors, E_idx):\n",
        "    h_nodes = gather_nodes(h_nodes, E_idx)\n",
        "    h_nn = torch.cat([h_neighbors, h_nodes], -1)\n",
        "    return h_nn\n",
        "\n",
        "\n",
        "class EncLayer(nn.Module):\n",
        "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
        "        super(EncLayer, self).__init__()\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_in = num_in\n",
        "        self.scale = scale\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(num_hidden)\n",
        "        self.norm2 = nn.LayerNorm(num_hidden)\n",
        "        self.norm3 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W11 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W12 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W13 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
        "\n",
        "    def forward(self, h_V, h_E, E_idx, mask_V=None, mask_attend=None):\n",
        "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
        "\n",
        "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
        "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
        "        if mask_attend is not None:\n",
        "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
        "        dh = torch.sum(h_message, -2) / self.scale\n",
        "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
        "\n",
        "        dh = self.dense(h_V)\n",
        "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
        "        if mask_V is not None:\n",
        "            mask_V = mask_V.unsqueeze(-1)\n",
        "            h_V = mask_V * h_V\n",
        "\n",
        "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
        "        h_message = self.W13(self.act(self.W12(self.act(self.W11(h_EV)))))\n",
        "        h_E = self.norm3(h_E + self.dropout3(h_message))\n",
        "        return h_V, h_E\n",
        "\n",
        "\n",
        "class DecLayer(nn.Module):\n",
        "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
        "        super(DecLayer, self).__init__()\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_in = num_in\n",
        "        self.scale = scale\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(num_hidden)\n",
        "        self.norm2 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
        "\n",
        "    def forward(self, h_V, h_E, mask_V=None, mask_attend=None):\n",
        "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
        "\n",
        "        # Concatenate h_V_i to h_E_ij\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_E.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_E], -1)\n",
        "\n",
        "        # Maybe, length of the message vector can serve as attention\n",
        "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
        "        # the mask attend here is most probably just for zeroing out the padded positions\n",
        "        # I do not think it will matter that much\n",
        "        if mask_attend is not None:\n",
        "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
        "            # why divide by 30 when we are dealing with 48 neighbors in the current version of the model?\n",
        "        # Let me check the messages corresponding to \n",
        "        dh = torch.sum(h_message, -2) / self.scale\n",
        "\n",
        "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
        "\n",
        "        # Position-wise feedforward\n",
        "        dh = self.dense(h_V)\n",
        "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
        "\n",
        "        if mask_V is not None:\n",
        "            mask_V = mask_V.unsqueeze(-1)\n",
        "            h_V = mask_V * h_V\n",
        "\n",
        "        # \"h_message\" can be returned without dividing by \"self.scale\" also\n",
        "        return h_V, (h_message/self.scale) \n",
        "\n",
        "\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, num_hidden, num_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.W_in = nn.Linear(num_hidden, num_ff, bias=True)\n",
        "        self.W_out = nn.Linear(num_ff, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "    def forward(self, h_V):\n",
        "        h = self.act(self.W_in(h_V))\n",
        "        h = self.W_out(h)\n",
        "        return h\n",
        "\n",
        "class PositionalEncodings(nn.Module):\n",
        "    def __init__(self, num_embeddings, max_relative_feature=32):\n",
        "        super(PositionalEncodings, self).__init__()\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.max_relative_feature = max_relative_feature\n",
        "        self.linear = nn.Linear(2*max_relative_feature+1+1, num_embeddings)\n",
        "\n",
        "    def forward(self, offset, mask):\n",
        "        d = torch.clip(offset + self.max_relative_feature, 0, 2*self.max_relative_feature)*mask + (1-mask)*(2*self.max_relative_feature+1)\n",
        "        d_onehot = torch.nn.functional.one_hot(d, 2*self.max_relative_feature+1+1)\n",
        "        E = self.linear(d_onehot.float())\n",
        "        return E\n",
        "\n",
        "# Does not look like this function needs to be modified for now to use the model as sort of an energy function\n",
        "# The only thing that could do something is \"top_k\", which can be changed for considering more or less neighbors\n",
        "# for each of the nodes, but that too I think does not matter if the default value of top_k is updated by parameter passing\n",
        "# This function is called from the model itself with node_features=128, edge_features=128, and top_k=48\n",
        "# ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
        "class ProteinFeatures(nn.Module):\n",
        "    def __init__(self, edge_features, node_features, num_positional_embeddings=16,\n",
        "        num_rbf=16, top_k=30, augment_eps=0., num_chain_embeddings=16):\n",
        "        \"\"\" Extract protein features \"\"\"\n",
        "        super(ProteinFeatures, self).__init__()\n",
        "        self.edge_features = edge_features\n",
        "        self.node_features = node_features\n",
        "        self.top_k = top_k\n",
        "        self.augment_eps = augment_eps \n",
        "        self.num_rbf = num_rbf\n",
        "        self.num_positional_embeddings = num_positional_embeddings\n",
        "\n",
        "        self.embeddings = PositionalEncodings(num_positional_embeddings)\n",
        "        node_in, edge_in = 6, num_positional_embeddings + num_rbf*25\n",
        "        self.edge_embedding = nn.Linear(edge_in, edge_features, bias=False)\n",
        "        self.norm_edges = nn.LayerNorm(edge_features)\n",
        "\n",
        "    # the output of this function MUST be analyzed either directly or via some other function to \n",
        "    # understand how to get \"index/position\" of neighbors\n",
        "    def _dist(self, X, mask, eps=1E-6):\n",
        "        mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
        "        dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
        "        D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
        "        D_max, _ = torch.max(D, -1, keepdim=True)\n",
        "        D_adjust = D + (1. - mask_2D) * D_max\n",
        "        sampled_top_k = self.top_k\n",
        "        D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(self.top_k, X.shape[1]), dim=-1, largest=False)\n",
        "        return D_neighbors, E_idx\n",
        "\n",
        "    def _rbf(self, D):\n",
        "        device = D.device\n",
        "        D_min, D_max, D_count = 2., 22., self.num_rbf\n",
        "        D_mu = torch.linspace(D_min, D_max, D_count, device=device)\n",
        "        D_mu = D_mu.view([1,1,1,-1])\n",
        "        D_sigma = (D_max - D_min) / D_count\n",
        "        D_expand = torch.unsqueeze(D, -1)\n",
        "        RBF = torch.exp(-((D_expand - D_mu) / D_sigma)**2)\n",
        "        return RBF\n",
        "\n",
        "    def _get_rbf(self, A, B, E_idx):\n",
        "        D_A_B = torch.sqrt(torch.sum((A[:,:,None,:] - B[:,None,:,:])**2,-1) + 1e-6) #[B, L, L]\n",
        "        D_A_B_neighbors = gather_edges(D_A_B[:,:,:,None], E_idx)[:,:,:,0] #[B,L,K]\n",
        "        RBF_A_B = self._rbf(D_A_B_neighbors)\n",
        "        return RBF_A_B\n",
        "\n",
        "    # this function will be called with the arguments as forward(), but will return information regarding \n",
        "    # the neighbors which I will figure out a way to parse\n",
        "    def return_neighbor_info(self, X, mask, residue_idx, chain_labels):\n",
        "        b = X[:,:,1,:] - X[:,:,0,:]\n",
        "        c = X[:,:,2,:] - X[:,:,1,:]\n",
        "        a = torch.cross(b, c, dim=-1)\n",
        "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "        Ca = X[:,:,1,:]\n",
        "        N = X[:,:,0,:]\n",
        "        C = X[:,:,2,:]\n",
        "        O = X[:,:,3,:]\n",
        " \n",
        "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
        "\n",
        "\n",
        "    def forward(self, X, mask, residue_idx, chain_labels):\n",
        "        if self.augment_eps > 0:\n",
        "            X = X + self.augment_eps * torch.randn_like(X)\n",
        "        \n",
        "        b = X[:,:,1,:] - X[:,:,0,:]\n",
        "        c = X[:,:,2,:] - X[:,:,1,:]\n",
        "        a = torch.cross(b, c, dim=-1)\n",
        "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "        Ca = X[:,:,1,:]\n",
        "        N = X[:,:,0,:]\n",
        "        C = X[:,:,2,:]\n",
        "        O = X[:,:,3,:]\n",
        " \n",
        "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
        "\n",
        "        RBF_all = []\n",
        "        RBF_all.append(self._rbf(D_neighbors)) #Ca-Ca\n",
        "        RBF_all.append(self._get_rbf(N, N, E_idx)) #N-N\n",
        "        RBF_all.append(self._get_rbf(C, C, E_idx)) #C-C\n",
        "        RBF_all.append(self._get_rbf(O, O, E_idx)) #O-O\n",
        "        RBF_all.append(self._get_rbf(Cb, Cb, E_idx)) #Cb-Cb\n",
        "        RBF_all.append(self._get_rbf(Ca, N, E_idx)) #Ca-N\n",
        "        RBF_all.append(self._get_rbf(Ca, C, E_idx)) #Ca-C\n",
        "        RBF_all.append(self._get_rbf(Ca, O, E_idx)) #Ca-O\n",
        "        RBF_all.append(self._get_rbf(Ca, Cb, E_idx)) #Ca-Cb\n",
        "        RBF_all.append(self._get_rbf(N, C, E_idx)) #N-C\n",
        "        RBF_all.append(self._get_rbf(N, O, E_idx)) #N-O\n",
        "        RBF_all.append(self._get_rbf(N, Cb, E_idx)) #N-Cb\n",
        "        RBF_all.append(self._get_rbf(Cb, C, E_idx)) #Cb-C\n",
        "        RBF_all.append(self._get_rbf(Cb, O, E_idx)) #Cb-O\n",
        "        RBF_all.append(self._get_rbf(O, C, E_idx)) #O-C\n",
        "        RBF_all.append(self._get_rbf(N, Ca, E_idx)) #N-Ca\n",
        "        RBF_all.append(self._get_rbf(C, Ca, E_idx)) #C-Ca\n",
        "        RBF_all.append(self._get_rbf(O, Ca, E_idx)) #O-Ca\n",
        "        RBF_all.append(self._get_rbf(Cb, Ca, E_idx)) #Cb-Ca\n",
        "        RBF_all.append(self._get_rbf(C, N, E_idx)) #C-N\n",
        "        RBF_all.append(self._get_rbf(O, N, E_idx)) #O-N\n",
        "        RBF_all.append(self._get_rbf(Cb, N, E_idx)) #Cb-N\n",
        "        RBF_all.append(self._get_rbf(C, Cb, E_idx)) #C-Cb\n",
        "        RBF_all.append(self._get_rbf(O, Cb, E_idx)) #O-Cb\n",
        "        RBF_all.append(self._get_rbf(C, O, E_idx)) #C-O\n",
        "        RBF_all = torch.cat(tuple(RBF_all), dim=-1)\n",
        "\n",
        "        offset = residue_idx[:,:,None]-residue_idx[:,None,:]\n",
        "        offset = gather_edges(offset[:,:,:,None], E_idx)[:,:,:,0] #[B, L, K]\n",
        "\n",
        "        d_chains = ((chain_labels[:, :, None] - chain_labels[:,None,:])==0).long() #find self vs non-self interaction\n",
        "        E_chains = gather_edges(d_chains[:,:,:,None], E_idx)[:,:,:,0]\n",
        "        E_positional = self.embeddings(offset.long(), E_chains)\n",
        "        E = torch.cat((E_positional, RBF_all), -1)\n",
        "        E = self.edge_embedding(E)\n",
        "        E = self.norm_edges(E)\n",
        "        return E, E_idx \n",
        "\n",
        "\n",
        "\n",
        "class ProteinMPNN(nn.Module):\n",
        "    # \"node_features\" and \"edge_features\" are actually dimensionality of these features (\"hidden_dim\" in the calling script)\n",
        "    # the value is 128 for the version that I am using\n",
        "    def __init__(self, num_letters, node_features, edge_features,\n",
        "        hidden_dim, num_encoder_layers=3, num_decoder_layers=3,\n",
        "        vocab=21, k_neighbors=64, augment_eps=0.05, dropout=0.1):\n",
        "        super(ProteinMPNN, self).__init__()\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.node_features = node_features\n",
        "        self.edge_features = edge_features\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Featurization layers\n",
        "        # The version that I am using considers 48 neighbors for each position\n",
        "        self.features = ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
        "\n",
        "        self.W_e = nn.Linear(edge_features, hidden_dim, bias=True)\n",
        "        # This W_s is for embedding the sequence\n",
        "        self.W_s = nn.Embedding(vocab, hidden_dim)\n",
        "\n",
        "        # Encoder layers\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            EncLayer(hidden_dim, hidden_dim*2, dropout=dropout)\n",
        "            for _ in range(num_encoder_layers)\n",
        "        ])\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            DecLayer(hidden_dim, hidden_dim*3, dropout=dropout)\n",
        "            for _ in range(num_decoder_layers)\n",
        "        ])\n",
        "        self.W_out = nn.Linear(hidden_dim, num_letters, bias=True)\n",
        "\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    # Creating my own versions of forward should be an easy way to get embeddings or attention weights from diffrerent layers of the model\n",
        "    # See here (https://discuss.pytorch.org/t/how-can-i-extract-intermediate-layer-output-from-loaded-cnn-model/77301) in the forums for adding forward\n",
        "    # hooks or manipulating the forward method\n",
        "    # but my easy solution would be to create different versions of the forward method with different namaes, and calling them explicitly\n",
        "    # \"chain_M\" and \"mask\" seem to be the things that I need to understand very well and play-around with \n",
        "    def forward(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn, use_input_decoding_order=False, decoding_order=None):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Concatenate sequence embeddings for autoregressive decoder\n",
        "        # h_S denotes embedding of the sequence itself for use in decoder\n",
        "        h_S = self.W_s(S)\n",
        "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "\n",
        "\n",
        "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
        "        if not use_input_decoding_order:\n",
        "            decoding_order = torch.argsort((chain_M+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for layer in self.decoder_layers:\n",
        "            # Masked positions attend to encoder information, unmasked see. \n",
        "            h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "            h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
        "            # only the last layer decoder-messages will be stored in \"decoder_messages\"\n",
        "            h_V, decoder_messages = layer(h_V, h_ESV, mask)\n",
        "\n",
        "        logits = self.W_out(h_V)\n",
        "        # The probabilities are passed through log() function so that the sequences can be ranked based by summing the respective values \n",
        "        # for each position instead of multiplication \n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        # messages from the last layer decoder will also be returned for extracting neighbor-attention approximation\\\n",
        "        # last layer embeddings can be extracted from the \"h_V\" tensor \n",
        "        return log_probs, decoder_messages, h_V\n",
        "\n",
        "\n",
        "\n",
        "    # Seems like this is the method which is used by the notebook for calculating probabilites and scoring\n",
        "    # Need to dig into it thoroughly\n",
        "    # \"chain_mask\" and \"residue_idx\" seem like the tensors of interest\n",
        "    def sample(self, X, randn, S_true, chain_mask, chain_encoding_all, residue_idx, mask=None, temperature=1.0, omit_AAs_np=None, bias_AAs_np=None, chain_M_pos=None, omit_AA_mask=None, pssm_coef=None, pssm_bias=None, pssm_multi=None, pssm_log_odds_flag=None, pssm_log_odds_mask=None, pssm_bias_flag=None, bias_by_res=None):\n",
        "        device = X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Decoder uses masked self-attention\n",
        "        chain_mask = chain_mask*chain_M_pos*mask #update chain_M to include missing regions\n",
        "        decoding_order = torch.argsort((chain_mask+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        N_batch, N_nodes = X.size(0), X.size(1)\n",
        "        log_probs = torch.zeros((N_batch, N_nodes, 21), device=device)\n",
        "        all_probs = torch.zeros((N_batch, N_nodes, 21), device=device, dtype=torch.float32)\n",
        "        h_S = torch.zeros_like(h_V, device=device)\n",
        "        S = torch.zeros((N_batch, N_nodes), dtype=torch.int64, device=device)\n",
        "        h_V_stack = [h_V] + [torch.zeros_like(h_V, device=device) for _ in range(len(self.decoder_layers))]\n",
        "        constant = torch.tensor(omit_AAs_np, device=device)\n",
        "        constant_bias = torch.tensor(bias_AAs_np, device=device)\n",
        "        #chain_mask_combined = chain_mask*chain_M_pos \n",
        "        omit_AA_mask_flag = omit_AA_mask != None\n",
        "\n",
        "\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for t_ in range(N_nodes):\n",
        "            t = decoding_order[:,t_] #[B]\n",
        "            chain_mask_gathered = torch.gather(chain_mask, 1, t[:,None]) #[B]\n",
        "            bias_by_res_gathered = torch.gather(bias_by_res, 1, t[:,None,None].repeat(1,1,21))[:,0,:] #[B, 21]\n",
        "            if (chain_mask_gathered==0).all():\n",
        "                S_t = torch.gather(S_true, 1, t[:,None])\n",
        "            else:\n",
        "                # Hidden layers\n",
        "                E_idx_t = torch.gather(E_idx, 1, t[:,None,None].repeat(1,1,E_idx.shape[-1]))\n",
        "                h_E_t = torch.gather(h_E, 1, t[:,None,None,None].repeat(1,1,h_E.shape[-2], h_E.shape[-1]))\n",
        "                h_ES_t = cat_neighbors_nodes(h_S, h_E_t, E_idx_t)\n",
        "                h_EXV_encoder_t = torch.gather(h_EXV_encoder_fw, 1, t[:,None,None,None].repeat(1,1,h_EXV_encoder_fw.shape[-2], h_EXV_encoder_fw.shape[-1]))\n",
        "                mask_t = torch.gather(mask, 1, t[:,None])\n",
        "                for l, layer in enumerate(self.decoder_layers):\n",
        "                    # Updated relational features for future states\n",
        "                    h_ESV_decoder_t = cat_neighbors_nodes(h_V_stack[l], h_ES_t, E_idx_t)\n",
        "                    h_V_t = torch.gather(h_V_stack[l], 1, t[:,None,None].repeat(1,1,h_V_stack[l].shape[-1]))\n",
        "                    h_ESV_t = torch.gather(mask_bw, 1, t[:,None,None,None].repeat(1,1,mask_bw.shape[-2], mask_bw.shape[-1])) * h_ESV_decoder_t + h_EXV_encoder_t\n",
        "                    h_V_stack[l+1].scatter_(1, t[:,None,None].repeat(1,1,h_V.shape[-1]), layer(h_V_t, h_ESV_t, mask_V=mask_t))\n",
        "                # Sampling step\n",
        "                h_V_t = torch.gather(h_V_stack[-1], 1, t[:,None,None].repeat(1,1,h_V_stack[-1].shape[-1]))[:,0]\n",
        "                logits = self.W_out(h_V_t) / temperature\n",
        "                probs = F.softmax(logits-constant[None,:]*1e8+constant_bias[None,:]/temperature+bias_by_res_gathered/temperature, dim=-1)\n",
        "                if pssm_bias_flag:\n",
        "                    pssm_coef_gathered = torch.gather(pssm_coef, 1, t[:,None])[:,0]\n",
        "                    pssm_bias_gathered = torch.gather(pssm_bias, 1, t[:,None,None].repeat(1,1,pssm_bias.shape[-1]))[:,0]\n",
        "                    probs = (1-pssm_multi*pssm_coef_gathered[:,None])*probs + pssm_multi*pssm_coef_gathered[:,None]*pssm_bias_gathered\n",
        "                if pssm_log_odds_flag:\n",
        "                    pssm_log_odds_mask_gathered = torch.gather(pssm_log_odds_mask, 1, t[:,None, None].repeat(1,1,pssm_log_odds_mask.shape[-1]))[:,0] #[B, 21]\n",
        "                    probs_masked = probs*pssm_log_odds_mask_gathered\n",
        "                    probs_masked += probs * 0.001\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                if omit_AA_mask_flag:\n",
        "                    omit_AA_mask_gathered = torch.gather(omit_AA_mask, 1, t[:,None, None].repeat(1,1,omit_AA_mask.shape[-1]))[:,0] #[B, 21]\n",
        "                    probs_masked = probs*(1.0-omit_AA_mask_gathered)\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                # Here is where sampling from the multinomial distribution is happening\n",
        "                # this will sample 1 element according to the given distribution, and return the index of that element [from 0 to 20]\n",
        "                S_t = torch.multinomial(probs, 1)\n",
        "                all_probs.scatter_(1, t[:,None,None].repeat(1,1,21), (chain_mask_gathered[:,:,None,]*probs[:,None,:]).float())\n",
        "            S_true_gathered = torch.gather(S_true, 1, t[:,None])\n",
        "            S_t = (S_t*chain_mask_gathered+S_true_gathered*(1.0-chain_mask_gathered)).long()\n",
        "            temp1 = self.W_s(S_t)\n",
        "            h_S.scatter_(1, t[:,None,None].repeat(1,1,temp1.shape[-1]), temp1)\n",
        "            S.scatter_(1, t[:,None], S_t)\n",
        "        output_dict = {\"S\": S, \"probs\": all_probs, \"decoding_order\": decoding_order}\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "    def tied_sample(self, X, randn, S_true, chain_mask, chain_encoding_all, residue_idx, mask=None, temperature=1.0, omit_AAs_np=None, bias_AAs_np=None, chain_M_pos=None, omit_AA_mask=None, pssm_coef=None, pssm_bias=None, pssm_multi=None, pssm_log_odds_flag=None, pssm_log_odds_mask=None, pssm_bias_flag=None, tied_pos=None, tied_beta=None, bias_by_res=None):\n",
        "        device = X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=device)\n",
        "        h_E = self.W_e(E)\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Decoder uses masked self-attention\n",
        "        chain_mask = chain_mask*chain_M_pos*mask #update chain_M to include missing regions\n",
        "        decoding_order = torch.argsort((chain_mask+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "\n",
        "        new_decoding_order = []\n",
        "        for t_dec in list(decoding_order[0,].cpu().data.numpy()):\n",
        "            if t_dec not in list(itertools.chain(*new_decoding_order)):\n",
        "                list_a = [item for item in tied_pos if t_dec in item]\n",
        "                if list_a:\n",
        "                    new_decoding_order.append(list_a[0])\n",
        "                else:\n",
        "                    new_decoding_order.append([t_dec])\n",
        "        decoding_order = torch.tensor(list(itertools.chain(*new_decoding_order)), device=device)[None,].repeat(X.shape[0],1)\n",
        "\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        N_batch, N_nodes = X.size(0), X.size(1)\n",
        "        log_probs = torch.zeros((N_batch, N_nodes, 21), device=device)\n",
        "        all_probs = torch.zeros((N_batch, N_nodes, 21), device=device, dtype=torch.float32)\n",
        "        h_S = torch.zeros_like(h_V, device=device)\n",
        "        S = torch.zeros((N_batch, N_nodes), dtype=torch.int64, device=device)\n",
        "        h_V_stack = [h_V] + [torch.zeros_like(h_V, device=device) for _ in range(len(self.decoder_layers))]\n",
        "        constant = torch.tensor(omit_AAs_np, device=device)\n",
        "        constant_bias = torch.tensor(bias_AAs_np, device=device)\n",
        "        omit_AA_mask_flag = omit_AA_mask != None\n",
        "\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for t_list in new_decoding_order:\n",
        "            logits = 0.0\n",
        "            logit_list = []\n",
        "            done_flag = False\n",
        "            for t in t_list:\n",
        "                if (chain_mask[:,t]==0).all():\n",
        "                    S_t = S_true[:,t]\n",
        "                    for t in t_list:\n",
        "                        h_S[:,t,:] = self.W_s(S_t)\n",
        "                        S[:,t] = S_t\n",
        "                    done_flag = True\n",
        "                    break\n",
        "                else:\n",
        "                    E_idx_t = E_idx[:,t:t+1,:]\n",
        "                    h_E_t = h_E[:,t:t+1,:,:]\n",
        "                    h_ES_t = cat_neighbors_nodes(h_S, h_E_t, E_idx_t)\n",
        "                    h_EXV_encoder_t = h_EXV_encoder_fw[:,t:t+1,:,:]\n",
        "                    mask_t = mask[:,t:t+1]\n",
        "                    for l, layer in enumerate(self.decoder_layers):\n",
        "                        h_ESV_decoder_t = cat_neighbors_nodes(h_V_stack[l], h_ES_t, E_idx_t)\n",
        "                        h_V_t = h_V_stack[l][:,t:t+1,:]\n",
        "                        h_ESV_t = mask_bw[:,t:t+1,:,:] * h_ESV_decoder_t + h_EXV_encoder_t\n",
        "                        h_V_stack[l+1][:,t,:] = layer(h_V_t, h_ESV_t, mask_V=mask_t).squeeze(1)\n",
        "                    h_V_t = h_V_stack[-1][:,t,:]\n",
        "                    logit_list.append((self.W_out(h_V_t) / temperature)/len(t_list))\n",
        "                    logits += tied_beta[t]*(self.W_out(h_V_t) / temperature)/len(t_list)\n",
        "            if done_flag:\n",
        "                pass\n",
        "            else:\n",
        "                bias_by_res_gathered = bias_by_res[:,t,:] #[B, 21]\n",
        "                probs = F.softmax(logits-constant[None,:]*1e8+constant_bias[None,:]/temperature+bias_by_res_gathered/temperature, dim=-1)\n",
        "                if pssm_bias_flag:\n",
        "                    pssm_coef_gathered = pssm_coef[:,t]\n",
        "                    pssm_bias_gathered = pssm_bias[:,t]\n",
        "                    probs = (1-pssm_multi*pssm_coef_gathered[:,None])*probs + pssm_multi*pssm_coef_gathered[:,None]*pssm_bias_gathered\n",
        "                if pssm_log_odds_flag:\n",
        "                    pssm_log_odds_mask_gathered = pssm_log_odds_mask[:,t]\n",
        "                    probs_masked = probs*pssm_log_odds_mask_gathered\n",
        "                    probs_masked += probs * 0.001\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                if omit_AA_mask_flag:\n",
        "                    omit_AA_mask_gathered = omit_AA_mask[:,t]\n",
        "                    probs_masked = probs*(1.0-omit_AA_mask_gathered)\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                S_t_repeat = torch.multinomial(probs, 1).squeeze(-1)\n",
        "                for t in t_list:\n",
        "                    h_S[:,t,:] = self.W_s(S_t_repeat)\n",
        "                    S[:,t] = S_t_repeat\n",
        "                    all_probs[:,t,:] = probs.float()\n",
        "        output_dict = {\"S\": S, \"probs\": all_probs, \"decoding_order\": decoding_order}\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "    # I am not seeing an immediate use of this method when the model is called through notebook\n",
        "    # So, will skip further commenting and digging for now\n",
        "    # But, seems like an interesting way of interacting with the model in a specific way, so\n",
        "    # might get back to this later\n",
        "    def conditional_probs(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn, backbone_only=False):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V_enc = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V_enc, h_E = layer(h_V_enc, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Concatenate sequence embeddings for autoregressive decoder\n",
        "        h_S = self.W_s(S)\n",
        "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V_enc, h_EX_encoder, E_idx)\n",
        "\n",
        "\n",
        "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
        "  \n",
        "        chain_M_np = chain_M.cpu().numpy()\n",
        "        idx_to_loop = np.argwhere(chain_M_np[0,:]==1)[:,0]\n",
        "        log_conditional_probs = torch.zeros([X.shape[0], chain_M.shape[1], 21], device=device).float()\n",
        "\n",
        "        for idx in idx_to_loop:\n",
        "            h_V = torch.clone(h_V_enc)\n",
        "            order_mask = torch.zeros(chain_M.shape[1], device=device).float()\n",
        "            if backbone_only:\n",
        "                order_mask = torch.ones(chain_M.shape[1], device=device).float()\n",
        "                order_mask[idx] = 0.\n",
        "            else:\n",
        "                order_mask = torch.zeros(chain_M.shape[1], device=device).float()\n",
        "                order_mask[idx] = 1.\n",
        "            decoding_order = torch.argsort((order_mask[None,]+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "            mask_size = E_idx.shape[1]\n",
        "            permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "            order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "            mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "            mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "            mask_bw = mask_1D * mask_attend\n",
        "            mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "            h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "            for layer in self.decoder_layers:\n",
        "                # Masked positions attend to encoder information, unmasked see. \n",
        "                h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "                h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
        "                h_V = layer(h_V, h_ESV, mask)\n",
        "\n",
        "            logits = self.W_out(h_V)\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "            log_conditional_probs[:,idx,:] = log_probs[:,idx,:]\n",
        "        return log_conditional_probs\n",
        "\n",
        "\n",
        "    # I am not seeing an immediate use of this method when the model is called through notebook\n",
        "    # So, will skip further commenting and digging for now\n",
        "    # But, seems like an interesting way of interacting with the model in a specific way, so\n",
        "    # might get back to this later\n",
        "    def unconditional_probs(self, X, mask, residue_idx, chain_encoding_all):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_V), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "\n",
        "        order_mask_backward = torch.zeros([X.shape[0], X.shape[1], X.shape[1]], device=device)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for layer in self.decoder_layers:\n",
        "            h_V = layer(h_V, h_EXV_encoder_fw, mask)\n",
        "\n",
        "        logits = self.W_out(h_V)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        return log_probs"
      ],
      "metadata": {
        "id": "HjbVWJkg7zik"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 128\n",
        "num_layers = 3 \n",
        "# Seems like, backbone_noise is set to 0 at inference path which seems logical\n",
        "backbone_noise=0.00\n",
        "mpnn_model = ProteinMPNN(num_letters=21, node_features=hidden_dim, edge_features=hidden_dim, hidden_dim=hidden_dim, num_encoder_layers=num_layers, num_decoder_layers=num_layers, augment_eps=backbone_noise, k_neighbors=checkpoint['num_edges'])\n",
        "mpnn_model.to(device)\n",
        "mpnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "mpnn_model.eval()"
      ],
      "metadata": {
        "id": "QBgBJd3J0N_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint['model_state_dict'].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pYLpMQS-ill",
        "outputId": "1623e9f0-180b-4e20-88ff-18af5f4a8074"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['features.embeddings.linear.weight', 'features.embeddings.linear.bias', 'features.edge_embedding.weight', 'features.norm_edges.weight', 'features.norm_edges.bias', 'W_e.weight', 'W_e.bias', 'W_s.weight', 'encoder_layers.0.norm1.weight', 'encoder_layers.0.norm1.bias', 'encoder_layers.0.norm2.weight', 'encoder_layers.0.norm2.bias', 'encoder_layers.0.norm3.weight', 'encoder_layers.0.norm3.bias', 'encoder_layers.0.W1.weight', 'encoder_layers.0.W1.bias', 'encoder_layers.0.W2.weight', 'encoder_layers.0.W2.bias', 'encoder_layers.0.W3.weight', 'encoder_layers.0.W3.bias', 'encoder_layers.0.W11.weight', 'encoder_layers.0.W11.bias', 'encoder_layers.0.W12.weight', 'encoder_layers.0.W12.bias', 'encoder_layers.0.W13.weight', 'encoder_layers.0.W13.bias', 'encoder_layers.0.dense.W_in.weight', 'encoder_layers.0.dense.W_in.bias', 'encoder_layers.0.dense.W_out.weight', 'encoder_layers.0.dense.W_out.bias', 'encoder_layers.1.norm1.weight', 'encoder_layers.1.norm1.bias', 'encoder_layers.1.norm2.weight', 'encoder_layers.1.norm2.bias', 'encoder_layers.1.norm3.weight', 'encoder_layers.1.norm3.bias', 'encoder_layers.1.W1.weight', 'encoder_layers.1.W1.bias', 'encoder_layers.1.W2.weight', 'encoder_layers.1.W2.bias', 'encoder_layers.1.W3.weight', 'encoder_layers.1.W3.bias', 'encoder_layers.1.W11.weight', 'encoder_layers.1.W11.bias', 'encoder_layers.1.W12.weight', 'encoder_layers.1.W12.bias', 'encoder_layers.1.W13.weight', 'encoder_layers.1.W13.bias', 'encoder_layers.1.dense.W_in.weight', 'encoder_layers.1.dense.W_in.bias', 'encoder_layers.1.dense.W_out.weight', 'encoder_layers.1.dense.W_out.bias', 'encoder_layers.2.norm1.weight', 'encoder_layers.2.norm1.bias', 'encoder_layers.2.norm2.weight', 'encoder_layers.2.norm2.bias', 'encoder_layers.2.norm3.weight', 'encoder_layers.2.norm3.bias', 'encoder_layers.2.W1.weight', 'encoder_layers.2.W1.bias', 'encoder_layers.2.W2.weight', 'encoder_layers.2.W2.bias', 'encoder_layers.2.W3.weight', 'encoder_layers.2.W3.bias', 'encoder_layers.2.W11.weight', 'encoder_layers.2.W11.bias', 'encoder_layers.2.W12.weight', 'encoder_layers.2.W12.bias', 'encoder_layers.2.W13.weight', 'encoder_layers.2.W13.bias', 'encoder_layers.2.dense.W_in.weight', 'encoder_layers.2.dense.W_in.bias', 'encoder_layers.2.dense.W_out.weight', 'encoder_layers.2.dense.W_out.bias', 'decoder_layers.0.norm1.weight', 'decoder_layers.0.norm1.bias', 'decoder_layers.0.norm2.weight', 'decoder_layers.0.norm2.bias', 'decoder_layers.0.W1.weight', 'decoder_layers.0.W1.bias', 'decoder_layers.0.W2.weight', 'decoder_layers.0.W2.bias', 'decoder_layers.0.W3.weight', 'decoder_layers.0.W3.bias', 'decoder_layers.0.dense.W_in.weight', 'decoder_layers.0.dense.W_in.bias', 'decoder_layers.0.dense.W_out.weight', 'decoder_layers.0.dense.W_out.bias', 'decoder_layers.1.norm1.weight', 'decoder_layers.1.norm1.bias', 'decoder_layers.1.norm2.weight', 'decoder_layers.1.norm2.bias', 'decoder_layers.1.W1.weight', 'decoder_layers.1.W1.bias', 'decoder_layers.1.W2.weight', 'decoder_layers.1.W2.bias', 'decoder_layers.1.W3.weight', 'decoder_layers.1.W3.bias', 'decoder_layers.1.dense.W_in.weight', 'decoder_layers.1.dense.W_in.bias', 'decoder_layers.1.dense.W_out.weight', 'decoder_layers.1.dense.W_out.bias', 'decoder_layers.2.norm1.weight', 'decoder_layers.2.norm1.bias', 'decoder_layers.2.norm2.weight', 'decoder_layers.2.norm2.bias', 'decoder_layers.2.W1.weight', 'decoder_layers.2.W1.bias', 'decoder_layers.2.W2.weight', 'decoder_layers.2.W2.bias', 'decoder_layers.2.W3.weight', 'decoder_layers.2.W3.bias', 'decoder_layers.2.dense.W_in.weight', 'decoder_layers.2.dense.W_in.bias', 'decoder_layers.2.dense.W_out.weight', 'decoder_layers.2.dense.W_out.bias', 'W_out.weight', 'W_out.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse and create dictionaries for all the mutations in PremPS 2648\n",
        "# This dictionary will be a dictionary of dictionaries, where outer-dict keys will be pdbid+mutchain and inner-dict keys will be (wild+pos+mut) and ddg\n",
        "# the icodes can be brought to picture later\n",
        "# this \"two_level_dict\" is literally used everywhere throughout this code for storing all the numbers that are compared with each other under feature-specific keys\n",
        "git_url = \"https://raw.githubusercontent.com/SajidAhmeduiu/PremPS/main/Datasets/S2648/S2648.txt\"\n",
        "dataset =  pd.read_csv(git_url,delimiter=\"\\t\")\n",
        "\n",
        "pdbIds = list(dataset[\"PDB Id\"])\n",
        "mutChains = list(dataset[\"Mutated Chain\"])\n",
        "mutations = list(dataset[\"Mutation_PDB\"])\n",
        "ddgs = list(dataset[\"DDGexp\"])\n",
        "\n",
        "two_level_dict = {}\n",
        "\n",
        "for pdbId, mutChain, mutation, ddg in tqdm(zip(pdbIds,mutChains,mutations,ddgs)):\n",
        "    pos = [int(s) for s in re.findall('-?\\d+',mutation)][0]\n",
        "    wild = mutation[0]\n",
        "    mut = mutation[len(mutation)-1]\n",
        "\n",
        "    pdbId = pdbId.lower()\n",
        "\n",
        "    inner_dict = {}\n",
        "    inner_dict[\"mut\"] = f\"{wild}{pos}{mut}\"\n",
        "    inner_dict[\"ddg\"] = float(ddg)\n",
        "    outer_key = f\"{pdbId}{mutChain}\"\n",
        "    if outer_key not in two_level_dict:\n",
        "        two_level_dict[f\"{pdbId}{mutChain}\"] = [inner_dict]\n",
        "    else:\n",
        "        two_level_dict[f\"{pdbId}{mutChain}\"].append(inner_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c66e0f35faf740b1bcbe44960d2dc5b9",
            "dfd783f81bdd4bdf974abe20acd1dcb6",
            "a6ebf106b77c48f19aeec8f19699ff86",
            "aef1bd91090b478c89912bc0c1df2d5e",
            "a9ca5d8460834744adbefc90aa36fb23",
            "cae1ff11e0814f9ea66fc3a915dc01f9",
            "d3de63bd76b74449af3599f7f8c5e718",
            "32e836af7d7241309adca8ab64ee859a",
            "661747dad62d4da5aff9d8376b39beea",
            "4a3048e8f0c646a9b48a57bd95a49776",
            "b6a1d85d9ef04db188f7c22f57ce8a38"
          ]
        },
        "id": "vP_unq7_sXrn",
        "outputId": "bcfd33ce-3ac5-46ab-a580-467827b80356"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c66e0f35faf740b1bcbe44960d2dc5b9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a seqres to position mapping dictionary\n",
        "# This dictionary will be a dictionary of dictionaries, where outer-dict keys will be pdbid+mutchain and inner-dict key will be (wild+pos) and value of 0-indexed position\n",
        "# the icodes can be brought to picture later\n",
        "mapping_dict = {}\n",
        "pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_2648_PDB_Files\"\n",
        "parser = PDBParser(QUIET=True)\n",
        "# some proteins need to be skipped for now due to ICODE related discrapency\n",
        "proteins_to_skip = []\n",
        "\n",
        "for filename in tqdm(os.listdir(pdbDirectory)):\n",
        "    filepath = os.path.join(pdbDirectory,filename)\n",
        "    structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "    model = structure[0]\n",
        "    inner_dict = {}\n",
        "    outer_key = filename.split(\".\")[0]\n",
        "    skip_flag = False\n",
        "    # single chain-assumption in action again\n",
        "    for chain in model:\n",
        "        for i,residue in enumerate(chain):\n",
        "            inner_key = f\"{three_to_one(residue.get_resname())}{residue.get_id()[1]}\"\n",
        "            if inner_key not in inner_dict:\n",
        "                inner_dict[inner_key] = i\n",
        "            else:\n",
        "                # For \"2immA:N31\" and \"1lveA:S27\", I have been fucked\n",
        "                # Need to think whether this will effect other positions or I can just avoid these two-protein related mutations for now?\n",
        "                # Let me just avoid these two proteins for now\n",
        "                print(\"YOU HAVE JUST BEEN FUCKED BY ICODE\")\n",
        "                print(f\"{outer_key}:{inner_key}\")\n",
        "                skip_flag = True\n",
        "    # The ICODE related problematic proteins will not be considered for now\n",
        "    if not skip_flag:\n",
        "        mapping_dict[outer_key] = inner_dict\n",
        "    else:\n",
        "        proteins_to_skip.append(outer_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "16b0189b5b424c8bb4f34c7ad65fb003",
            "fd177455cc7b41c59d4047adf8e89dad",
            "2111149deee34e7cbb3bddb4b0840466",
            "484d8bac85cc45cd96fee642805ed6a2",
            "eff3d544f00940d88a376a6673cbf321",
            "6c7c62aa6f4f4563b65db9f975091790",
            "d73148d3183c4048a2df03213834e6ef",
            "bb15ba218ddb40d88bf3d3aad18243b5",
            "de22d707d56a49f99750afa82661b0da",
            "665385b594e946efb4e61b5cb405fe05",
            "2d57981794044f3aadce5d08b191c4ce"
          ]
        },
        "id": "vxARThyX3VYv",
        "outputId": "6cd92043-53ba-4ae6-81bf-c9acc6bbbaac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/131 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16b0189b5b424c8bb4f34c7ad65fb003"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "1lveA:S27\n",
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "1lveA:S27\n",
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "2immA:N31\n",
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "2immA:N31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing this \"parse_PDB_biounits()\" function locally for addressing the fucked up integer named chain problem  \n",
        "def parse_PDB_biounits(x, atoms=['N', 'CA', 'C'], chain=None):\n",
        "    '''\n",
        "    input:  x = PDB filename\n",
        "            atoms = atoms to extract (optional)\n",
        "    output: (length, atoms, coords=(x,y,z)), sequence\n",
        "    '''\n",
        "    alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "    states = len(alpha_1)\n",
        "    alpha_3 = ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE',\n",
        "               'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL', 'GAP']\n",
        "\n",
        "    # The following dictionaries are mapping from one-letter to 0-20 index,\n",
        "    # three-letter to 0-20 index,\n",
        "    # 0-20 index to one-letter,\n",
        "    # one-letter to three-letter, and vice-versa\n",
        "    aa_1_N = {a: n for n, a in enumerate(alpha_1)}\n",
        "    aa_3_N = {a: n for n, a in enumerate(alpha_3)}\n",
        "    aa_N_1 = {n: a for n, a in enumerate(alpha_1)}\n",
        "    aa_1_3 = {a: b for a, b in zip(alpha_1, alpha_3)}\n",
        "    aa_3_1 = {b: a for a, b in zip(alpha_1, alpha_3)}\n",
        "\n",
        "    def AA_to_N(x):\n",
        "        # [\"ARND\"] -> [[0,1,2,3]]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 0: x = x[None]\n",
        "        return [[aa_1_N.get(a, states - 1) for a in y] for y in x]\n",
        "\n",
        "    def N_to_AA(x):\n",
        "        # [[0,1,2,3]] -> [\"ARND\"]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 1: x = x[None]\n",
        "        return [\"\".join([aa_N_1.get(a, \"-\") for a in y]) for y in x]\n",
        "\n",
        "    xyz, seq, min_resn, max_resn = {}, {}, 1e6, -1e6\n",
        "    for line in open(x, \"rb\"):\n",
        "        line = line.decode(\"utf-8\", \"ignore\").rstrip()\n",
        "\n",
        "        if line[:6] == \"HETATM\" and line[17:17 + 3] == \"MSE\":\n",
        "            line = line.replace(\"HETATM\", \"ATOM  \")\n",
        "            line = line.replace(\"MSE\", \"MET\")\n",
        "\n",
        "        if line[:4] == \"ATOM\":\n",
        "            ch = line[21:22]\n",
        "            # If the input chain is not in the PDB file, which can be the case if the target chains are named differently in the runner script,\n",
        "            # this line will cause the output to have literally no information, this is the case for integer named chains\n",
        "            # that does not mean that this line is not doing its job correctly, this is just a constraint that input chain names and\n",
        "            # chain names in the PDB file have to be congruent\n",
        "            # If \"ch\" is an integer, map it to alphabet, because input \"chain\" has been converted to alphabet\n",
        "            # In rare cases, some PDB files number chains with 1,2,3 instead of A,B,C\n",
        "            # This \"loc_dict\" dictionary contains integer to alphabet mapping for weird as fuck integer chain names\n",
        "            # This conversion will be done only when  chain name is actually an integer\n",
        "            if ord(ch) >= 49 and ord(ch) <= 57:\n",
        "                loc_dict = {(idx+1):ch for idx,ch in enumerate(ascii_uppercase)}\n",
        "                ch =  str(loc_dict[int(ch)])\n",
        "            if ch == chain or chain is None:\n",
        "                atom = line[12:12 + 4].strip()\n",
        "                resi = line[17:17 + 3]\n",
        "                resn = line[22:22 + 5].strip()\n",
        "                x, y, z = [float(line[i:(i + 8)]) for i in [30, 38, 46]]\n",
        "\n",
        "                if resn[-1].isalpha():\n",
        "                    resa, resn = resn[-1], int(resn[:-1]) - 1\n",
        "                else:\n",
        "                    resa, resn = \"\", int(resn) - 1\n",
        "                #         resn = int(resn)\n",
        "                if resn < min_resn:\n",
        "                    min_resn = resn\n",
        "                if resn > max_resn:\n",
        "                    max_resn = resn\n",
        "                if resn not in xyz:\n",
        "                    xyz[resn] = {}\n",
        "                if resa not in xyz[resn]:\n",
        "                    xyz[resn][resa] = {}\n",
        "                if resn not in seq:\n",
        "                    seq[resn] = {}\n",
        "                if resa not in seq[resn]:\n",
        "                    seq[resn][resa] = resi\n",
        "\n",
        "                if atom not in xyz[resn][resa]:\n",
        "                    xyz[resn][resa][atom] = np.array([x, y, z])\n",
        "\n",
        "    # convert to numpy arrays, fill in missing values\n",
        "    seq_, xyz_ = [], []\n",
        "    try:\n",
        "        for resn in range(min_resn, max_resn + 1):\n",
        "            if resn in seq:\n",
        "                for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k], 20))\n",
        "            else:\n",
        "                seq_.append(20)\n",
        "            if resn in xyz:\n",
        "                for k in sorted(xyz[resn]):\n",
        "                    for atom in atoms:\n",
        "                        if atom in xyz[resn][k]:\n",
        "                            xyz_.append(xyz[resn][k][atom])\n",
        "                        else:\n",
        "                            xyz_.append(np.full(3, np.nan))\n",
        "            else:\n",
        "                for atom in atoms: xyz_.append(np.full(3, np.nan))\n",
        "        return np.array(xyz_).reshape(-1, len(atoms), 3), N_to_AA(np.array(seq_))\n",
        "    except TypeError:\n",
        "        return 'no_chain', 'no_chain'\n",
        "\n",
        "# Took this part out of \"utils.py\", and put here so that smalll changes can be made to address pesky issues like\n",
        "# integer named chain, and shit like those\n",
        "def parse_PDB(path_to_pdb, input_chain_list=None):\n",
        "    c=0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V','W','X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v','w','x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "     \n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list  \n",
        " \n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    # Each of the biounits is a separate PDB file, so for running with a single PDB file like from colab, this loop will be executed only once\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {} \n",
        "        # This loop will be executed only once for single chain DDG type cases\n",
        "        for letter in chain_alphabet:\n",
        "            xyz, seq = parse_PDB_biounits(biounit, atoms=['N','CA','C','O'], chain=letter)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_'+letter]=seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                coords_dict_chain['N_chain_'+letter]=xyz[:,0,:].tolist()\n",
        "                coords_dict_chain['CA_chain_'+letter]=xyz[:,1,:].tolist()\n",
        "                coords_dict_chain['C_chain_'+letter]=xyz[:,2,:].tolist()\n",
        "                coords_dict_chain['O_chain_'+letter]=xyz[:,3,:].tolist()\n",
        "                my_dict['coords_chain_'+letter]=coords_dict_chain\n",
        "                s += 1\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        my_dict['name']=biounit[(fi+1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c+=1\n",
        "    return pdb_dict_list"
      ],
      "metadata": {
        "id": "UzBk27pmlfh7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_func_local(X, mask, eps=1E-6):\n",
        "    mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
        "    dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
        "    D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
        "    D_max, _ = torch.max(D, -1, keepdim=True)\n",
        "    D_adjust = D + (1. - mask_2D) * D_max\n",
        "    top_k = checkpoint[\"num_edges\"]\n",
        "    sampled_top_k = top_k\n",
        "    D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(top_k, X.shape[1]), dim=-1, largest=False)\n",
        "    return D_neighbors, E_idx\n",
        "\n",
        "def return_neighbor_info(X, mask):\n",
        "    b = X[:,:,1,:] - X[:,:,0,:]\n",
        "    c = X[:,:,2,:] - X[:,:,1,:]\n",
        "    a = torch.cross(b, c, dim=-1)\n",
        "    Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "    Ca = X[:,:,1,:]\n",
        "    N = X[:,:,0,:]\n",
        "    C = X[:,:,2,:]\n",
        "    O = X[:,:,3,:]\n",
        "\n",
        "    D_neighbors, E_idx = distance_func_local(Ca, mask)\n",
        "    # Got the indices of the neighbors, E_idx should be the 0-based indexing of the topK closest neighbors\n",
        "    # and D_neighbors should be the distances of those neighbors\n",
        "    return D_neighbors, E_idx"
      ],
      "metadata": {
        "id": "l6pA80oESa7Y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "from scipy.special import kl_div"
      ],
      "metadata": {
        "id": "5mFg99eN_UqM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the PDB files from the directory where the S_2648 PDB Files are stored, and set-them up one by one for featuirization, and passing through the model\n",
        "pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_2648_PDB_Files\"\n",
        "parser = PDBParser(QUIET=True)\n",
        "\n",
        "pdbId_info = []\n",
        "pos_info = []\n",
        "neighbor_pos = []\n",
        "neighbor_attention = []\n",
        "neighbor_attention_softmaxed = []\n",
        "neighbor_distances_tracking = []\n",
        "\n",
        "import time\n",
        "\n",
        "np.set_printoptions(suppress=True,precision=2)\n",
        "loc_proteins = []\n",
        "for i,filename in tqdm(enumerate(os.listdir(pdbDirectory))):\n",
        "    #ICODE related problematic proteins will be skipped from analysis for now\n",
        "    if (filename.split(\".\")[0] not in proteins_to_skip):\n",
        "        prot_start = time.time()\n",
        "        print(f\"Prot Processing:{i+1}\")\n",
        "        loc_proteins.append(filename.split(\".\")[0])\n",
        "        filepath = os.path.join(pdbDirectory,filename)\n",
        "        structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "        model = structure[0]\n",
        "        \n",
        "        # Since there is only one chain, and that same chain is both fixed designable for different residues, extracting that name, and putting them in pertinent lists\n",
        "        # taking chainname from filename since one of the files \"1rtpA.pdb\" has chain name with \"1\" instead of \"A\"\n",
        "        # fuck you motherfucking fucked up PDB file submitter. Have you shoved your head into your ass?\n",
        "        chain_name = (filename.split(\".\")[0])[-1]\n",
        "        fixed_chain_list = []\n",
        "        # the trick is to put the single chain as designable chain, and then create the \"fixed_positions_dict\" dictionary  \n",
        "        designed_chain_list = [chain_name]\n",
        "        chain_list = list(set(designed_chain_list + fixed_chain_list))\n",
        "\n",
        "        # Using the programs custome PDB parser for processing the PDB files\n",
        "        pdb_dict_list = parse_PDB(filepath, input_chain_list=chain_list)\n",
        "        # tacking max_length parameter value from the original colab notebook since I need to process all residues at the same time\n",
        "        # all the PDB files can technically be processed together and put inside the dataset_valid list-like object, but right now\n",
        "        # I am trying to keep everything consistent and simple\n",
        "        # Each element of dataset_valid is a dictionary \n",
        "        dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=20000)\n",
        "\n",
        "        # Simplying the sequence generation loop\n",
        "        protein = dataset_valid[0]\n",
        "\n",
        "        wildtype_seq = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        # If there are gaps in the wildtype_seq \"seq\", remove those positions from both the \"seq\", \"\" and ('coords_chain_{designed_chain_list[0]}'), \n",
        "        # and ('seq_chain_{designed_chain_list[0]}') of the \"protein\"\n",
        "        # print(protein.keys())\n",
        "        # protein is a dict with keys(['seq_chain_A', 'coords_chain_A', 'name', 'num_of_chains', 'seq'])\n",
        "        # \"seq_chain\" and \"seq_all\" are both strings of the same length where gapped positions need to be identified and removed\n",
        "        seq_chain = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "        seq_all = protein[f\"seq\"]\n",
        "        # \"coordinates_chain\" is a dict with keys(['N_chain_A', 'CA_chain_A', 'C_chain_A', 'O_chain_A'])\n",
        "        coordinates_chain = protein[f\"coords_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        \n",
        "        # The following four variables are lists of length equal to seq_chain and seq_all length\n",
        "        # Therefore, the gapped positions can be retrived from seq_chain and removed from everything accordingly\n",
        "        N_chain = coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"]\n",
        "        CA_chain = coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"]\n",
        "        C_chain = coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"]\n",
        "        O_chain = coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        # delete everything related to gapped positions now\n",
        "        # at first, find out the positions that are gapped\n",
        "        # these gapped positions are absolutely messed up fucked up artifact of some kind of sophistification \n",
        "        # provided by proteinMPNN, FUCK YOU motherfucking oversmart CODERS\n",
        "        N_chain = [v for i,v in enumerate(N_chain) if seq_chain[i] != \"-\"]\n",
        "        CA_chain = [v for i,v in enumerate(CA_chain) if seq_chain[i] != \"-\"]\n",
        "        C_chain = [v for i,v in enumerate(C_chain) if seq_chain[i] != \"-\"]\n",
        "        O_chain = [v for i,v in enumerate(O_chain) if seq_chain[i] != \"-\"]\n",
        "        seq_all = [v for i,v in enumerate(seq_all) if seq_chain[i] != \"-\"]\n",
        "        seq_chain = [v for i,v in enumerate(seq_chain) if seq_chain[i] != \"-\"]\n",
        "\n",
        "        # Now, finally, pack everything back to the dictionary \"protein\"\n",
        "        protein[f\"seq_chain_{designed_chain_list[0]}\"] = seq_chain\n",
        "        protein[f\"seq\"] = seq_all\n",
        "        coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"] = N_chain\n",
        "        coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"] = CA_chain\n",
        "        coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"] = C_chain\n",
        "        coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"] = O_chain\n",
        "        protein[f\"coords_chain_{designed_chain_list[0]}\"] = coordinates_chain\n",
        "\n",
        "        # At this point, probably need to put None values in a lot of parameters that are not relevant to my usecase, but need to be sent to featurizer before running model forward\n",
        "        # For now, I will not tie positions together\n",
        "        tied_positions_dict = None\n",
        "        pssm_dict = None\n",
        "        omit_AA_dict = None\n",
        "        bias_AA_dict = None\n",
        "        tied_positions_dict = None\n",
        "        bias_by_res_dict = None\n",
        "        alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "        bias_AAs_np = np.zeros(len(alphabet))\n",
        "\n",
        "        chain_id_dict = {}\n",
        "        chain_id_dict[pdb_dict_list[0]['name']]= (designed_chain_list, fixed_chain_list)\n",
        "\n",
        "        BATCH_COPIES = 1\n",
        "\n",
        "        batch_clones = [copy.deepcopy(protein) for i in range(BATCH_COPIES)]\n",
        "\n",
        "        # \"muts_for_prot\" is a list with information about all the mutations in \"protein\", whose sequence only version is \"wildtype_seq\" \n",
        "        muts_for_prot = two_level_dict[filename.split(\".\")[0]]\n",
        "        # \"cur_map_dict\" will give the 0-based sequence index for the mutations, which will be almost directly used for masking and then running the model\n",
        "        # 1-based indexing needed for the fixed position\n",
        "        cur_map_dict = mapping_dict[filename.split(\".\")[0]]\n",
        "\n",
        "        for mut_track,mut in enumerate(muts_for_prot):\n",
        "            print(f\"Processing_Mut:{mut_track+1}, From_Prot:{i+1}\")\n",
        "            wild_aa = mut[\"mut\"][0]\n",
        "            alternate_aa = mut[\"mut\"][-1]\n",
        "            # (+1) because we need to pass 1-based indexing to tied_featurize() method\n",
        "            seq_pos = cur_map_dict[mut[\"mut\"][0:-1]] + 1\n",
        "            # only need to mask the mutated position position in \"wildtype_seq\" for now\n",
        "            fixed_positions_dict = {}\n",
        "            fixed_positions_dict[protein[\"name\"]] = {}\n",
        "            f_list = []\n",
        "            for ind_fixed in range(0,len(seq_chain)):\n",
        "                if (ind_fixed + 1) not in [seq_pos]:\n",
        "                    f_list.append(ind_fixed + 1)\n",
        "            fixed_positions_dict[protein[\"name\"]][filename.split(\".\")[0][-1]] = f_list\n",
        "\n",
        "            # finally, had to take chain-name from filename instead of biopython parsing to get rid of chain-name with \"1\" instead of \"A\" in \"1rtpA.pdb\"\n",
        "            X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "            omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "            = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "            randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "            log_probs, decoder_messages, node_embedding_info = mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "            # Adding the log_probs to the same inner dictionary where DDG values exist for easier comparison\n",
        "            mut[\"log_prob\"] = log_probs.cpu().data.numpy()\n",
        "            \n",
        "            # the top_k attention weights will be stored here for weighted sum later\n",
        "            # \"seq_pos\" is 1-based since \"fixed_positions_dict\" above needs to hold 1-based indices for the mutation,\n",
        "            # but accessing the tensors will require 0-based indexing\n",
        "            seq_index = seq_pos - 1\n",
        "            # \"dim = 1\", because decoder_messages[0,seq_index,:,:] should be (48,128), and we want to take norm of each of the 48 vectors across the last dimension,\n",
        "            # get 48 norm values, and fetch out the k highest values from there\n",
        "            message_norms = (torch.linalg.vector_norm(x=decoder_messages[0,seq_index,:,:],ord=2,dim=1))\n",
        "            local_distances, local_neighbors = return_neighbor_info(X, mask)\n",
        "            # \"top_k_attended_neighbor_indices\" is the indices from [0,47] corresponding to the highest attended neighbors\n",
        "            # top_(k-1) can technically be extracted from top_k, but currently just for simplicity and easier debugging, extracting everything separately\n",
        "            top_15_attention_vals, top_15_attended_neighbor_indices = torch.topk(message_norms,k=15)\n",
        "            top_10_attention_vals, top_10_attended_neighbor_indices = torch.topk(message_norms,k=10)\n",
        "            top_5_attention_vals, top_5_attended_neighbor_indices = torch.topk(message_norms,k=5)\n",
        "            # now, using \"local_neighbors\" to get the original indices of the neighbors corresponding to the top_k attended positions\n",
        "            # taking both top_5 and top_10 for now\n",
        "            top_15_attended_neighbor_indices = local_neighbors[0,seq_index,top_15_attended_neighbor_indices]\n",
        "            top_10_attended_neighbor_indices = local_neighbors[0,seq_index,top_10_attended_neighbor_indices]\n",
        "            top_5_attended_neighbor_indices = local_neighbors[0,seq_index,top_5_attended_neighbor_indices]\n",
        "            top_15_closest_neighbor_indices = local_neighbors[0,seq_index,1:16]\n",
        "            top_10_closest_neighbor_indices = local_neighbors[0,seq_index,1:11]\n",
        "            mut[\"top_15_attention_weights\"] = top_15_attention_vals.cpu().data.numpy()\n",
        "            mut[\"top_10_attention_weights\"] = top_10_attention_vals.cpu().data.numpy()\n",
        "            mut[\"top_5_attention_weights\"] = top_5_attention_vals.cpu().data.numpy()\n",
        "            # the neighbor indices corresponding to the top_k attention weights will be stored here for entropy calculation later\n",
        "            # 0-based indices of the neighbors will be saved so that corresponding log-probability vectors can be extracted readily from \"log_prob\" keyed value\n",
        "            mut[\"top_15_neighbor_indices\"] = top_15_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_10_neighbor_indices\"] = top_10_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_5_neighbor_indices\"] = top_5_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_15_closest_neighbor_indices\"] = top_15_closest_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_10_closest_neighbor_indices\"] = top_10_closest_neighbor_indices.cpu().data.numpy()\n",
        "\n",
        "            # The lines below are mostly for printing purposes to do external analysis with PyMol,and ROSETTA with Cristina\n",
        "            loc_pos_scores = []\n",
        "            for enum_val,(neighbor_p, neighbor_s, neighbor_distance) in enumerate(zip(local_neighbors[0,seq_index,1:15].cpu().data.numpy(),\n",
        "                                                                 (torch.linalg.vector_norm(x=decoder_messages[0,seq_index,1:15,:],ord=2,dim=1)).cpu().data.numpy(),\n",
        "                  \n",
        "                                                               local_distances[0,seq_index,1:15].cpu().data.numpy())):\n",
        "                # skippoing the first neighbor since it is the mutated position itself\n",
        "                if enum_val == 0:\n",
        "                    continue\n",
        "                pdbId_info.append(filename)\n",
        "                pos_info.append(seq_index+1)\n",
        "                neighbor_pos.append(neighbor_p+1)\n",
        "                neighbor_attention.append(neighbor_s)\n",
        "                loc_pos_scores.append(neighbor_s)\n",
        "                neighbor_distances_tracking.append(neighbor_distance)\n",
        "            # since softmax has to be done over all the neighbors, taking the softmax, and later adding it to the data generation list after\n",
        "            # neighbor enumeration loop\n",
        "            loc_pos_scores = softmax(np.array(loc_pos_scores))\n",
        "            for s in loc_pos_scores:\n",
        "                neighbor_attention_softmaxed.append(s)\n",
        "\n",
        "            # take (\"neighbor_attention\"-weighted sum/average) of the entropies of the top 5 attended neighbors\n",
        "            # are the neighbors with highest message passing values always among the closest 10?\n",
        "            # point to be noted that the closest, therefore the first neighbor of every position is the neighbor itself\n",
        "            # check correlation between distance and attention values since a possible manual edge feature would be distance\n",
        "            # let us see if the model attends to distant neighbors more, or attention value is inversely proportional to distance?\n",
        "            # take L2-norms of the message vectors instead of attention\n",
        "            # take the softmax of L2-norms to approximate attention, although technically the positions are not constrained by each other, this can be considered a sigmoid attention\n",
        "            # where having neighbors with large messages will effect differently than having neighbors with small messages\n",
        "            # can this be correlated with position-entropy?\n",
        "            # the L2-norms should be able to approximate how much each of the neighbors are effecting the mutated position\n",
        "            # This information can be stored for checking the effect of center mutation on those positions afterwards\n",
        "            # Identify major interacting partners (neighbors that are important for center prediction, and also which take center into consideration for its own prediction)\n",
        "            # then check how much the major neighbor position deviates from wildtype due to the mutation\n",
        "            # another much more simples thing can be to check the deviation for top 10 neighbors\n",
        "            # this deviation can be calculated using the log(W) for the neighbor before center mutation, and log(W) for the neighbor after center mutation \n",
        "\n",
        "            # Now, take top_k most attended positions, make them designable, mutate center, and take change in -log(p) of the wildtype at each of the neighbor positions\n",
        "            # take weighted sum of these neighbor energy changes, see if there is any correlation\n",
        "            # next, go for \"strong\" neighbor positions (both way strong attention)\n",
        "            # Many of the tensors will take on new values after running the model again with different fixed positions\n",
        "            \n",
        "            # the \"fixed_positions_dict\" has to be repopulated now since neighbor positions will be masked one by one\n",
        "            # here, \"n_ind\" is the 0-based index corresponding to one of the \"top_k\" attended neighbors \n",
        "            # these lists will contain the log_probabilities for the top_k most attended neighbors serially\n",
        "            # before and after making the center mutation currently at hand, these probabilities will be used later for calculating\n",
        "            # attention_weighted change in neighbor_wildtype probability, attention_weighted_change in KL, and all those things \n",
        "            neighbor_w_log_probs = []\n",
        "            neighbor_m_log_probs = []\n",
        "            # the following array will contain the identities of the neighbors serially so that specific wildtype neighbor positions in the probability\n",
        "            # distribution can be extracted later\n",
        "            neighbor_aa_identities = []\n",
        "            # \"top5\" and \"top10\" should be extractable from \"top15\", since the neighbor\n",
        "            neighbor_w_message_vector_coming_from_center = []\n",
        "            neighbor_m_message_vector_coming_from_center = []\n",
        "            # I will pick out the neighbor embeddings, and put them inside the lists below\n",
        "            # But, do I need to access them one by one, or can I just take a slice out of the embedding tensor across the seq_pos dimension?\n",
        "            # what more information will I get if I fetch out the embeddings one by one?\n",
        "            # if I want to do a slicing, I might have to make all the neighbors designable at the same time, which will \n",
        "            # for one, I can take out the embeddings for each of the neighbors while they are designable, before and \n",
        "            # okay, lets say we will fetch the neighbors out, one by one; we can do that right inside the next loop\n",
        "            # what will be the significance of those neighbor embeddings, in that case?\n",
        "            # they will see everything around them, expcept the mutated position, will they change much due to that?\n",
        "            # neighbor embedding difference in that case might actually catch something about the new interactions that have\n",
        "            # been formed, interesting...very, very interesting\n",
        "            neighbor_w_embedding_info = []\n",
        "            neighbor_m_embedding_info = [] \n",
        "            # informations are stored serially in the lists\n",
        "            for n_ind in mut[\"top_15_neighbor_indices\"]:\n",
        "                neighbor_aa_identities.append(seq_chain[n_ind])\n",
        "                # Some sequence-input manipulation is done later in this loop, so the wildtype aa is placed in the position, so that\n",
        "                # previous iteration manipulations do not cause trouble in this iteration\n",
        "                alpha_tok = \"ACDEFGHIKLMNPQRSTVWYX\"\n",
        "                aa_1_N = {a:n for n,a in enumerate(alpha_tok)}\n",
        "                aa_N_1 = {n:a for n,a in enumerate(alpha_tok)}\n",
        "\n",
        "                # adding (+1) to n_ind, since fixed positions are 1-indexed in the original implementation\n",
        "                n_pos = n_ind + 1  \n",
        "                fixed_positions_dict = {}\n",
        "                fixed_positions_dict[protein[\"name\"]] = {}\n",
        "                f_list = []\n",
        "                for ind_fixed in range(0,len(seq_chain)):\n",
        "                    # Fixing everything except the \"n_pos\" neighbor position\n",
        "                    if (ind_fixed + 1) not in [n_pos]:\n",
        "                        f_list.append(ind_fixed + 1)\n",
        "                fixed_positions_dict[protein[\"name\"]][filename.split(\".\")[0][-1]] = f_list\n",
        "\n",
        "                # Extracting \"n_ind\" 21-way log probabilities when the center is wildtype \n",
        "                X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "                omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "                = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "                randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "\n",
        "                # we want to store the 128-length message vector coming from the center to the neighbor at \"n_ind\"\n",
        "                # for this, at first, we need to find which neighbor of \"n_ind\" is our center so that we can pull out the message vector coming from \n",
        "                # the center to the neighbor at \"n_ind\" \n",
        "                loc_local_distances, loc_local_neighbors = return_neighbor_info(X, mask)\n",
        "                # \"neighbor_neighbor_index\" is the index of the center with respect to the neighbor at \"n_ind\"\n",
        "                # if len(neighbor_neighbor_index) is 0, center is not among the spatially close 48 neighbors of the neighbor at \"n_ind\"\n",
        "                # in that case, message vector passed from center to that neighbor can be considered as a 128 length all 0 vector for now\n",
        "                # for now, it is important to note that if len(neighbor_neighbor_index) is not zero, then the index can be retrived by neighbor_neighbor_index[0][0]  \n",
        "                neighbor_neighbor_index = (loc_local_neighbors[0,n_ind,:] == seq_index).nonzero(as_tuple=False)\n",
        "                neighbor_neighbor_index =  neighbor_neighbor_index[0][0] if (len(neighbor_neighbor_index) == 1) else torch.tensor(-1,device=neighbor_neighbor_index.device)\n",
        "\n",
        "                # calling \"mpnn_model\" \"forward\" function three times below for getting the three tensors is definitely not efficient,\n",
        "                # but, doing it this way for now, since I am getting CUDA out-of-memory errors due to some unsolved (for now) reason   \n",
        "                n_log_probs  = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[0][0,n_ind,:].cpu().data.numpy()\n",
        "                decoder_message = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[1][0,n_ind,neighbor_neighbor_index,:].cpu().data.numpy()\n",
        "                node_embedding_info = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[2][0,n_ind,:].cpu().data.numpy()\n",
        "\n",
        "                neighbor_w_log_probs.append(n_log_probs)\n",
        "                neighbor_w_embedding_info.append(node_embedding_info)\n",
        "\n",
        "                if neighbor_neighbor_index >= 0:\n",
        "                    neighbor_w_message_vector_coming_from_center.append(decoder_message)\n",
        "                else:\n",
        "                    # Adding all-0 vector of length 128 if the center is not among the closest 48 neighbors of center\n",
        "                    neighbor_w_message_vector_coming_from_center.append(np.zeros(128)) \n",
        "                 \n",
        "                # Now, make mutation, and process the corresponding probabilities\n",
        "                X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "                omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "                = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "                randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "                # seems like passing mutant sequence through the model will be a bit more difficult that expected since PDB file is read in by the underlying parser\n",
        "                # How, do I only change the amino acids identity in the sequence, but keep the PDB backbone and everything same?\n",
        "                # At first, just try to manipulate the input \"S\"\n",
        "                S[0,seq_index] = aa_1_N[alternate_aa]\n",
        "                n_log_probs  = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[0][0,n_ind,:].cpu().data.numpy()\n",
        "                decoder_message = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[1][0,n_ind,neighbor_neighbor_index,:].cpu().data.numpy()\n",
        "                node_embedding_info = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[2][0,n_ind,:].cpu().data.numpy()\n",
        "\n",
        "                neighbor_m_log_probs.append(n_log_probs)\n",
        "                neighbor_m_embedding_info.append(node_embedding_info)\n",
        "\n",
        "                if neighbor_neighbor_index >= 0:\n",
        "                    neighbor_m_message_vector_coming_from_center.append(decoder_message)\n",
        "                else:\n",
        "                    # Adding all-0 vector of length 128 if the center is not among the closest 48 neighbors of center\n",
        "                    neighbor_m_message_vector_coming_from_center.append(np.zeros(128))           \n",
        "            mut[\"w_n_log_prob\"] = neighbor_w_log_probs\n",
        "            mut[\"m_n_log_prob\"] = neighbor_m_log_probs\n",
        "            mut[\"neighbor_aa_identities\"] = neighbor_aa_identities\n",
        "            mut[\"neighbor_w_message_vector_coming_from_center\"] = neighbor_w_message_vector_coming_from_center\n",
        "            mut[\"neighbor_m_message_vector_coming_from_center\"] = neighbor_m_message_vector_coming_from_center\n",
        "            mut[\"neighbor_w_neighbor_embedding\"] = neighbor_w_embedding_info\n",
        "            mut[\"neighbor_m_neighbor_embedding\"] = neighbor_m_embedding_info\n",
        "        prot_end = time.time()\n",
        "        print(f\"Took {prot_end-prot_start} for {filename} with {mut_track+1} forward-mutations\")\n",
        "        print(\"....................\")"
      ],
      "metadata": {
        "id": "b8cEsTK1EQ9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the incomplete \"two_level_dict\" as pickle file for a quick dirty comparison\n",
        "# import pickle\n",
        "# with open(\"S_2648_pmppn_info_dict_V2.pickle\",\"wb\") as f:\n",
        "#     pickle.dump(two_level_dict,f)"
      ],
      "metadata": {
        "id": "rXvc5PDmIQyF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# with open(\"S_2648_pmppn_info_dict_V2.pickle\",\"rb\") as f:\n",
        "#     two_level_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "T8iPDaqrZg4U"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import entropy\n",
        "from scipy.special import expit\n",
        "alpha_list = list(\"ACDEFGHIKLMNPQRSTVWYX\")\n",
        "# The following dictionary will be used for fetching out the log-probabilities corresponding to the wild-type and mutated residues at the mutation positions\n",
        "aa_to_N = {a:n for n,a in enumerate(alpha_list)}\n",
        "# This list will contain the experimental ddg values for the mutations for which two-level dict contains information regarding log_probabilities\n",
        "true_vals = []\n",
        "# This list will contain (wild_proba,mut_proba) tuples for the mutations for which two-level dict contains information regarding log_probabilities\n",
        "wild_mut_log_probabilities = []\n",
        "# saving max probabilites for debugging\n",
        "max_log_probabilities = []\n",
        "# Want to add entropy of the position with some kind of weight (maybe, just a for loop for checking weight combinations that sum to 1?)\n",
        "position_entropies = []\n",
        "weighted_neighbor_entropies = []\n",
        "# This \"weighted_neighbor_energy_changes\" will be ((-log(m))-(-log(w))) for each of the topk neighbors, weighted summed by corresponding attention weights   \n",
        "weighted_neighbor_energy_changes = []\n",
        "#\n",
        "backward_weighted_neighbor_energy_changes = []\n",
        "V2_backward_weighted_neighbor_energy_changes = []\n",
        "# the neighbor-forward-KL will at this point treat the center-wildtype conditioned neighbor distributions as true, \n",
        "# and center-mutated conditioned neighbor distributions as approximation\n",
        "weighted_neighbor_forward_KL = []\n",
        "# the neighbor-backward-KL will treat the center-mutated conditioned neighbor distributions as true, \n",
        "# and center-wildtype conditioned neighbor distributions as approximation\n",
        "weighted_neighbor_backward_KL = []\n",
        "#\n",
        "backward_weighted_neighbor_backward_KL = []\n",
        "V2_backward_weighted_neighbor_backward_KL = []  \n",
        "# # This \"weighted_neighbor_entropy_changes\" will be ((entropy(p(nieghbor|m))-(entropy(p(nieghbor|w))) for each of the topk neighbors, weighted summed by corresponding attention weights \n",
        "weighted_neighbor_entropy_changes = []\n",
        "## the weights will now be based on change in center->neighbor message vector L2-norm due to mutation, instead of neighbor->center message norm \n",
        "## however, I think a softmaxing across all those weights will now be a must since scales could be crazily different\n",
        "backward_weighted_neighbor_entropy_changes = []\n",
        "V2_backward_weighted_neighbor_entropy_changes = []\n",
        "# the two arrays below are being saved for checking correlations of (m/w) and (w/m) attention weight changes to ddgs\n",
        "# this debugging-type correlation analysis could reveal significant insights into the best weighing mechanism, and even provide a way to differentiate\n",
        "# between neighbors that have established new connections with the center, and neighbors whose connections with the center has been severed (kinda severed,maybe or weakened?..whatever)  \n",
        "center_neighbor_weight_check_m_w = []\n",
        "center_neighbor_weight_check_w_m = []\n",
        "\n",
        "# putting the dictionary here since we are going to need positions corresponding to alternate amino acid 1-letter codes\n",
        "alpha_tok = \"ACDEFGHIKLMNPQRSTVWYX\"\n",
        "aa_1_N = {a:n for n,a in enumerate(alpha_tok)}\n",
        "for i,(prot,muts) in enumerate(two_level_dict.items()):\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for ind_track, mut in enumerate(muts):\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            # where the fuck is \"log_prob\" coming from, but \"top_5_attention_weights\" and \"top_5_neighbor_indices\" are not there?\n",
        "            if (\"log_prob\" in mut) and (\"w_n_log_prob\" in mut):\n",
        "                wild = mut[\"mut\"][0] \n",
        "                alternate = mut[\"mut\"][-1]\n",
        "                true_vals.append(mut[\"ddg\"])\n",
        "                sequence_index_of_mutation = cur_map_dict[mut[\"mut\"][0:-1]]\n",
        "                position_log_probabilities = mut[\"log_prob\"][0,sequence_index_of_mutation,:]\n",
        "                wild_mut_log_probabilities.append((position_log_probabilities[aa_to_N[wild]],position_log_probabilities[aa_to_N[alternate]]))\n",
        "                max_log_probabilities.append(position_log_probabilities.max())\n",
        "                position_entropies.append(entropy(np.exp(position_log_probabilities)))\n",
        "                # These 0-based neighbor indices will be used for extracting the log-probabilities corresponding to the neighbor positions\n",
        "                n_indices= mut[\"top_15_neighbor_indices\"]\n",
        "                # The neighbor weights will be used here for multiplying \n",
        "                n_weights = mut[\"top_15_attention_weights\"].reshape(-1,1)\n",
        "                # Take entropy while taking care of the dimension along which entropy is calculated\n",
        "                # Taking entropy across last axis, because the shape of the input is (k,21), where 21 is the 21-way probability distribution \n",
        "                n_entropies = entropy(np.exp(mut[\"log_prob\"][0,n_indices,:]),axis=-1).reshape(-1,1)\n",
        "                # I think this element-wise product is getting wrong \n",
        "                weighted_neighbor_entropies.append((n_entropies*softmax(n_weights)).sum())\n",
        "                # weighted_neighbor_entropies.append((n_entropies*softmax(n_weights)).sum())\n",
        "                # weighted_neighbor_entropies.append((n_entropies*n_weights).sum())\n",
        "\n",
        "                # Now, calculate neighbor energy changes, and then weighted sum them after extracting specific log_probabilities\n",
        "                # for mutant center, and wildtype center impacted versions for the top neighbor positions\n",
        "                neighbor_w_log_probabilities = mut[\"w_n_log_prob\"]\n",
        "                neighbor_m_log_probabilities = mut[\"m_n_log_prob\"]\n",
        "                neighbor_amino_a_identities = mut[\"neighbor_aa_identities\"]\n",
        "                neighbor_w_message_vector_coming_from_center = mut[\"neighbor_w_message_vector_coming_from_center\"]\n",
        "                neighbor_m_message_vector_coming_from_center = mut[\"neighbor_m_message_vector_coming_from_center\"]\n",
        "                neighbor_w_neighbor_embedding = mut[\"neighbor_w_neighbor_embedding\"]\n",
        "                neighbor_m_neighbor_embedding = mut[\"neighbor_m_neighbor_embedding\"]\n",
        "                # The \"local_neighbor_log_prob_vals\" will be a list of negative log-probability differences(a.k.a. energy differences)\n",
        "                local_neighbor_log_prob_vals = []\n",
        "                local_neighbor_forward_KL_vals = []\n",
        "                local_neighbor_backward_KL_vals = []\n",
        "                local_neighbor_entropy_change_vals = []\n",
        "                local_neighbor_attention_change_vals = []\n",
        "                # the two lists below are for debugging, and insight-revelation purposes, mostly\n",
        "                local_center_neighbor_weight_check_m_w = []\n",
        "                local_center_neighbor_weight_check_w_m = []\n",
        "                # the \"local_neighbor_embedding_changes\" list below will hold (neighbor_m_embedding/neighbor_w_embedding) arrays of length 128\n",
        "                # so, technically, this list can be converted to a (15,128) 2D numpy array\n",
        "                # all those (15,128) numpy arrays will later be concatenated across axis-0 before taking the PCA in the next cell\n",
        "                local_neighbor_embedding_changes = []\n",
        "                local_neighbor_embedding_changes_raw = []\n",
        "                # the vector below is very similar to (w/m), but L2 norm is taken on the difference vector\n",
        "                local_center_neighbor_message_change_diff = []\n",
        "                # For example, selecting the numbers from the first 5 iterations of this loop will give neighbor energy change corresponding to the first 5 neighbors\n",
        "                for neighbor_w, neighbor_m, neighbor_aa, neighbor_w_message, neighbor_m_message, neighbor_w_embedding, neighbor_m_embedding  in \\\n",
        "                zip(neighbor_w_log_probabilities,neighbor_m_log_probabilities,neighbor_amino_a_identities,neighbor_w_message_vector_coming_from_center,neighbor_m_message_vector_coming_from_center,\n",
        "                    neighbor_w_neighbor_embedding,neighbor_m_neighbor_embedding):\n",
        "                    # get the amino acid identity for the neighbor position, run it through the mapping dictionary, get the log probabilities from those positions,\n",
        "                    # \"neighbor_w\" and \"neighbor_m\" arrays will directly give the log probabilities that need to be substracted to get the energy (put (-1) before thoese numbers?...think a bit)\n",
        "                    neighbor_index = aa_1_N[neighbor_aa]\n",
        "                    local_neighbor_log_prob_vals.append((-1*neighbor_m[neighbor_index])-(-1*neighbor_w[neighbor_index]))\n",
        "                    # summing the output of \"kl_div\", because one number comes for every positions in the currently processing neighbor distribution,\n",
        "                    # and I want to take the total deviation in that distribution \n",
        "                    local_neighbor_forward_KL_vals.append(kl_div(np.exp(neighbor_w),np.exp(neighbor_m)).sum())\n",
        "                    local_neighbor_backward_KL_vals.append(kl_div(np.exp(neighbor_m),np.exp(neighbor_w)).sum())\n",
        "                    local_neighbor_entropy_change_vals.append(entropy(np.exp(neighbor_m))-entropy(np.exp(neighbor_w)))\n",
        "                    # lets just put the absolute value of the difference between the L2-norms for now (taking sign into consideration will require\n",
        "                    # taking care of the correct direction of change, which might make things a bit ncomplicated for now, and have unintended effects)\n",
        "                    # But, having a direction can definitely help with stabilization vs. de-stabilization figuring out\n",
        "                    # some kind of \n",
        "                    # usiung only the norm would more like predict the magnitude of DDG\n",
        "                    # local_neighbor_attention_change_vals.append()\n",
        "                    neighbor_w_message = neighbor_w_message.reshape((-1,1))\n",
        "                    neighbor_m_message = neighbor_m_message.reshape((-1,1))\n",
        "                    # Adding the small numbers for numerical stability, which hopefully will not change the information content of these features\n",
        "                    neighbor_w_message_norm = np.linalg.norm(neighbor_w_message,ord=2,axis=0) + 0.00000001\n",
        "                    neighbor_m_message_norm = np.linalg.norm(neighbor_m_message,ord=2,axis=0) + 0.00000001\n",
        "                    # taking average of two ratios for kind of capturing the change in both (mutant->wild) and (wild->mutant) directions with the same measure \n",
        "                    # the ratio should help to avoid any neighbor to neighbor variability related-scale\n",
        "                    # but scale could also be important, right? since, the same transformation is applied for calculating the numbers for every position in the proteins \n",
        "                    # local_neighbor_attention_change_vals.append((0.5*(neighbor_w_message_norm/neighbor_m_message_norm))+(0.5*(neighbor_m_message_norm/neighbor_w_message_norm)))\n",
        "                    local_neighbor_attention_change_vals.append((neighbor_w_message_norm/neighbor_m_message_norm))\n",
        "                    # the two list-appending lines below are mostly for debugging purposes at the moment,\n",
        "                    # might be something more than that in a few minutes?\n",
        "                    local_center_neighbor_weight_check_m_w.append(neighbor_m_message_norm/neighbor_w_message_norm)\n",
        "                    local_center_neighbor_weight_check_w_m.append(neighbor_w_message_norm/neighbor_m_message_norm)\n",
        "                    # can take PCA of the below as well\n",
        "                    # currently, taking the norm of division vector (-1 to discourage (+1) from contributing to the norm)\n",
        "                    # local_neighbor_embedding_changes.append(np.linalg.norm((neighbor_m_embedding/neighbor_w_embedding)))\n",
        "                    # local_neighbor_embedding_changes.append(neighbor_m_embedding/neighbor_w_embedding)\n",
        "                    # local_neighbor_embedding_changes.append(neighbor_w_embedding)\n",
        "                    local_neighbor_embedding_changes.append(np.linalg.norm(neighbor_w_embedding-neighbor_m_embedding))\n",
        "                    local_neighbor_embedding_changes_raw.append(neighbor_w_embedding-neighbor_m_embedding)\n",
        "                    local_center_neighbor_message_change_diff.append(np.linalg.norm(neighbor_w_message-neighbor_m_message))\n",
        "                # The energy change approximation can be constrained to the top few neighbors by just indexing the arrays below\n",
        "                # So, it looks like a better idea to save log_probs for atleast the top_20 neighbors since we can always fetch the first few from there\n",
        "                weighted_neighbor_energy_changes.append((np.array(local_neighbor_log_prob_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_forward_KL.append((np.array(local_neighbor_forward_KL_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_backward_KL.append((np.array(local_neighbor_backward_KL_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_entropy_changes.append((np.array(local_neighbor_entropy_change_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                # versions of neighbor features, just weighted by backward weights (center->neighbor attention change due to mutation) instead of forward weights (neighbor->center attention)\n",
        "                # sum() of these (m/w) weight-change is apparently positively correlated with DDGs\n",
        "                backward_weighted_neighbor_energy_changes.append((np.array(local_neighbor_log_prob_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_m_w))[0:15])).sum())\n",
        "                backward_weighted_neighbor_backward_KL.append((np.array(local_neighbor_backward_KL_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_m_w))[0:15])).sum())\n",
        "                backward_weighted_neighbor_entropy_changes.append(((np.array(local_neighbor_entropy_change_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_m_w)))[0:15]).sum()))\n",
        "                # the two list-appending lines below are mostly for debugging purposes at the moment,\n",
        "                # might be something more than that in a few minutes?\n",
        "                center_neighbor_weight_check_m_w.append(np.array(local_center_neighbor_weight_check_m_w).sum())\n",
        "                center_neighbor_weight_check_w_m.append(np.array(local_center_neighbor_weight_check_w_m).sum())\n",
        "                # now, let us add features weighted by the other version of attention changes\n",
        "                # sum() of these (w/m) weight-change is apparently negatievly correlated with DDGs\n",
        "                V2_backward_weighted_neighbor_energy_changes.append((np.array(local_neighbor_log_prob_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_w_m))[0:15])).sum())\n",
        "                V2_backward_weighted_neighbor_backward_KL.append((np.array(local_neighbor_backward_KL_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_w_m))[0:15])).sum())\n",
        "                V2_backward_weighted_neighbor_entropy_changes.append(((np.array(local_neighbor_entropy_change_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_w_m)))[0:15]).sum()))\n",
        "\n",
        "\n",
        "                # let us also save the features in the \"mut\" dictionary, so that \"two_letter_dict\" containing all the features for every mutation\n",
        "                # can be saved after this cell in pickle format, and later be accessed from any other script\n",
        "                # print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "                # print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "                # energies (negative log probabilities of the most_probable,wild,and mutated residue, respectively, at the center position)\n",
        "                e_max = (-1*(max_log_probabilities[-1]))\n",
        "                e_wild = (-1*((wild_mut_log_probabilities[-1])[0]))\n",
        "                e_mut = (-1*((wild_mut_log_probabilities[-1])[1]))\n",
        "                mut[\"center_mut_wild_energy\"] = e_mut - e_wild \n",
        "                mut[\"center_mut_max_energy\"] = e_mut - e_max\n",
        "                mut[\"center_entropy\"] = (position_entropies[-1] * (-1))\n",
        "                mut[\"weighted_neighbor_entropies\"] = weighted_neighbor_entropies[-1] \n",
        "                mut[\"weighted_neighbor_energy_changes\"] = weighted_neighbor_energy_changes[-1]\n",
        "                mut[\"backward_weighted_neighbor_energy_changes\"] = backward_weighted_neighbor_energy_changes[-1]\n",
        "                mut[\"V2_backward_weighted_neighbor_energy_changes\"] = V2_backward_weighted_neighbor_energy_changes[-1]\n",
        "                mut[\"weighted_neighbor_forward_KL\"] = weighted_neighbor_forward_KL[-1] \n",
        "                mut[\"weighted_neighbor_backward_KL\"] = weighted_neighbor_backward_KL[-1]\n",
        "                mut[\"backward_weighted_neighbor_backward_KL\"] = backward_weighted_neighbor_backward_KL[-1]\n",
        "                mut[\"V2_backward_weighted_neighbor_backward_KL\"] = V2_backward_weighted_neighbor_backward_KL[-1]  \n",
        "                mut[\"weighted_neighbor_entropy_changes\"] = weighted_neighbor_entropy_changes[-1]\n",
        "                mut[\"backward_weighted_neighbor_entropy_changes\"] = backward_weighted_neighbor_entropy_changes[-1]\n",
        "                mut[\"V2_backward_weighted_neighbor_entropy_changes\"] = V2_backward_weighted_neighbor_entropy_changes[-1]  \n",
        "                mut[\"center_neighbor_weight_check_m_w\"] = center_neighbor_weight_check_m_w[-1]\n",
        "                mut[\"center_neighbor_weight_check_w_m\"] = center_neighbor_weight_check_w_m[-1]\n",
        "                # mut[\"neighbor_embedding_change_m_w\"] should be a (15,128) numpy array for every mutation since we are currently \n",
        "                # considering top15 attended neighbors for every mutation, and the decoder last layer embedding before \n",
        "                # output_transformation is of length 128 \n",
        "                # mut[\"neighbor_embedding_change_m_w\"] = np.array(local_neighbor_embedding_changes)\n",
        "                mut[\"neighbor_embedding_change_m_w\"] = np.array(local_neighbor_embedding_changes).sum()\n",
        "                # for each mutation, mut[\"neighbor_embedding_change_m_w_raw\"] should be a (15,128) array since we are considering\n",
        "                # top15 most attended neighbors \n",
        "                mut[\"neighbor_embedding_change_m_w_raw\"] = np.array(local_neighbor_embedding_changes_raw)\n",
        "                mut[\"neighbor_message_change_m_w\"] = np.array(local_center_neighbor_message_change_diff).sum()\n",
        "                mut[\"unweighted_backward_KL\"] = np.array(local_neighbor_backward_KL_vals).sum()\n",
        "                mut[\"unweighted_forward_KL\"] = np.array(local_neighbor_forward_KL_vals).sum()"
      ],
      "metadata": {
        "id": "7m4jsITsJHmE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.decomposition import PCA\n",
        "\n",
        "# # the data is definitely stored in the correct format here, now how to do PCA\n",
        "# # we have to do fit_transform on a (15*2620,128) matrix\n",
        "# # also, save those PCA results\n",
        "# # check the correlation results for two PCAs weighted by top_15_attention_weights right here in this fucking cell\n",
        "# # most probably, normalization will be needed across all the (15*2620) vectors for now, in order to avoid scale-difference-related issues\n",
        "# # this normalizer has to be saved as well along with the PCA objects for testing on other datasets\n",
        "# very_very_loc_ddg = []\n",
        "# # The \"very_very_loc_embedding_changes\" list below will contain the (15,128) that needs to be concatenated across dimension-0,\n",
        "# # I will override this list with the concatenated numpy array  \n",
        "# very_very_loc_embedding_changes = []\n",
        "\n",
        "# for i,(prot,muts) in enumerate(two_level_dict.items()):\n",
        "#     if prot not in proteins_to_skip:\n",
        "#         try:\n",
        "#             cur_map_dict = mapping_dict[prot]\n",
        "#         except:\n",
        "#             continue\n",
        "#         for ind_track, mut in enumerate(muts):\n",
        "#             very_very_loc_ddg.append(mut[\"ddg\"])\n",
        "#             very_very_loc_embedding_changes.append(mut[\"neighbor_embedding_change_m_w\"])\n",
        "\n",
        "# # let us here concatenate all the (15,128) arrays across dimension-0 for PCA fitting\n",
        "# # pass the concatenated matrix through Scikit-learn StandardScaler() before passing it through PCA\n",
        "# # save both the Scaling object and the PCA object that would be fitted on this S_2648 training set\n",
        "# # the concatenated array has to be divided back for each of the mutations, and mapped to the \"two_level_dict\" in some way\n",
        "# # How about concatenating in a separate array, learning the PCA, and applying to each mutation separately,\n",
        "# # that code should be transferrable to the test datasets directly\n",
        "# very_very_loc_embedding_changes = np.concatenate(very_very_loc_embedding_changes,axis=0)\n",
        "# loc_scaler = StandardScaler()\n",
        "# print(very_very_loc_embedding_changes.shape)\n",
        "# loc_scaler.fit(very_very_loc_embedding_changes)\n",
        "# # now since \"loc_scaler\" has been fit on the whole dataset, it can be saved, and used on each of the mutations separately whenever needed\n",
        "# very_very_loc_embedding_changes = loc_scaler.transform(very_very_loc_embedding_changes)\n",
        "# # now, since the data has been concatenated, and scaled, it can be passed through PCA, which can be saved and used later on each \n",
        "# # of the mutations separately\n",
        "# loc_pca = PCA(n_components=20)\n",
        "# loc_pca.fit(very_very_loc_embedding_changes)\n",
        "# print(loc_pca.explained_variance_ratio_)\n",
        "# print(loc_pca.singular_values_)\n",
        "# # check local correlations (for each of the mutants separately)\n",
        "# # then check  "
      ],
      "metadata": {
        "id": "f96PtuuC_U00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "TwMx2ZMs60Pz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(120):\n",
        "#     for j in range(i+1,120):\n",
        "#         abdgf = pearsonr(very_very_loc_embedding_changes[:,i],very_very_loc_embedding_changes[:,j])[0]\n",
        "#         if abs(abdgf) > 0.05:\n",
        "#             print(\"YESSSSSS\",i,j,abdgf)"
      ],
      "metadata": {
        "id": "HswduBjPlCm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experimental_energies = []\n",
        "mut_wild_predictions = []\n",
        "mut_min_predictions = []\n",
        "entropy_predictions = []\n",
        "neighbor_entropy_change_predictions = []\n",
        "neighbor_energy_change_predictions = []\n",
        "center_neighbor_weight_check_w_m = []\n",
        "V2_backward_weighted_neighbor_backward_KL = []\n",
        "sum_neighbor_embedding_change_m_w = []\n",
        "neighbor_message_change_m_w = []\n",
        "\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        for mut in muts:\n",
        "            if \"center_mut_wild_energy\" in mut:\n",
        "                experimental_energies.append(mut[\"ddg\"])\n",
        "                mut_wild_predictions.append(mut[\"center_mut_wild_energy\"])\n",
        "                mut_min_predictions.append(mut[\"center_mut_max_energy\"])\n",
        "                entropy_predictions.append(mut[\"center_entropy\"])\n",
        "                neighbor_entropy_change_predictions.append(mut[\"weighted_neighbor_entropy_changes\"])\n",
        "                neighbor_energy_change_predictions.append(mut[\"weighted_neighbor_energy_changes\"])\n",
        "                center_neighbor_weight_check_w_m.append(mut[\"center_neighbor_weight_check_w_m\"])\n",
        "                V2_backward_weighted_neighbor_backward_KL.append(mut[\"V2_backward_weighted_neighbor_backward_KL\"])\n",
        "                sum_neighbor_embedding_change_m_w.append(mut[\"neighbor_embedding_change_m_w\"])\n",
        "                neighbor_message_change_m_w.append(mut[\"neighbor_message_change_m_w\"])\n",
        "\n",
        "print(len(experimental_energies),len(mut_wild_predictions))\n",
        "\n",
        "print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "print(pearsonr(experimental_energies,entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_entropy_change_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_energy_change_predictions))\n",
        "print(pearsonr(experimental_energies,center_neighbor_weight_check_w_m))\n",
        "print(pearsonr(experimental_energies,V2_backward_weighted_neighbor_backward_KL))\n",
        "print(pearsonr(experimental_energies,sum_neighbor_embedding_change_m_w))\n",
        "print(pearsonr(experimental_energies,neighbor_message_change_m_w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StvbASTsfta0",
        "outputId": "edce1585-b210-4cbd-8f08-2e943a5e3998"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2620 2620\n",
            "(0.5066529736537145, 6.977318145590863e-171)\n",
            "(0.46967434442269873, 6.906889709666406e-144)\n",
            "(0.35114633273820217, 6.8516125902191846e-77)\n",
            "(0.2982518957749898, 5.685761225875779e-55)\n",
            "(0.29272513393777927, 6.270405582888447e-53)\n",
            "(-0.15030436008655998, 1.0440771163770327e-14)\n",
            "(0.2384432079726765, 3.4350706917055645e-35)\n",
            "(0.30870099814242047, 5.870104605840723e-59)\n",
            "(0.0287730064718497, 0.14091956878536888)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let me get PSSM values and do some comparison quickly\n",
        "# getting the PSSM extraction functions from my custom model data processing scripts\n",
        "from string import ascii_uppercase\n",
        "\n",
        "# In rare cases, some PDB files number chains with 1,2,3 instead of A,B,C\n",
        "def convertChainFromAlphabetToNumber(alphabet):\n",
        "    mappingDict = {ch:(idx+1) for idx,ch in enumerate(ascii_uppercase)}\n",
        "    return str(mappingDict[alphabet])\n",
        "\n",
        "# Before executing this function, the PSSM files with naming format \"pdbIdchain.pssm\" needs to be stored\n",
        "# in the pssm_dir\n",
        "def returnPSSMArray(pdbIdPlusChain,pssm_dir=\"train_pssm_dir\",convert_upper = False):\n",
        "#     Currently, assuming that the pssm file names contain pdbId in upper case\n",
        "    if convert_upper:\n",
        "        fileName = pdbIdPlusChain.upper() + \".pssm\"\n",
        "    else:\n",
        "        fileName = pdbIdPlusChain + \".pssm\"\n",
        "    try:\n",
        "        fullPath = os.path.join(pssm_dir,fileName)\n",
        "        f = open(fullPath)\n",
        "    except:\n",
        "        fileName = pdbIdPlusChain[0:4].upper() + str(convertChainFromAlphabetToNumber(pdbIdPlusChain[4])) + \".pssm\" \n",
        "        fullPath = os.path.join(pssm_dir,fileName)\n",
        "        f = open(fullPath)\n",
        "        \n",
        "# #     all the target lines in the PSSM files have (2+20+20+2=44) strings after line.split()\n",
        "    target_lines = [line.split() for line in f.readlines() if (len(line.split()))==44]\n",
        "    number_of_residues = len(target_lines)\n",
        "    \n",
        "    pssm_features = np.zeros((number_of_residues,20))\n",
        "\n",
        "    for idx,line in enumerate(target_lines):\n",
        "        pssm_features[idx,:] = line[2:22]\n",
        "\n",
        "    f.close()\n",
        "    \n",
        "    return pssm_features\n",
        "\n",
        "# This function also seems necessary for extracting the two pssm values\n",
        "# Must review the three pssm feature functions (this one and the two above) later\n",
        "# These functions seem to be taking up a lot of time....must review\n",
        "def returnPSSMMapping(residue):\n",
        "    pssm_letter_to_index_dict = {\"A\" : 0,   \n",
        "    \"R\" : 1,\n",
        "    \"N\" : 2,\n",
        "    \"D\" : 3,\n",
        "    \"C\" : 4,\n",
        "    \"Q\" : 5,\n",
        "    \"E\" : 6,\n",
        "    \"G\" : 7,\n",
        "    \"H\" : 8,\n",
        "    \"I\" : 9,\n",
        "    \"L\" : 10,\n",
        "    \"K\" : 11,\n",
        "    \"M\" : 12,\n",
        "    \"F\" : 13,\n",
        "    \"P\" : 14,\n",
        "    \"S\" : 15,\n",
        "    \"T\" : 16,\n",
        "    \"W\" : 17,\n",
        "    \"Y\" : 18,\n",
        "    \"V\" : 19}\n",
        "\n",
        "    return pssm_letter_to_index_dict[residue]\n",
        "\n",
        "\n",
        "# I will add PSSM values to the two-level dictionary for places where log_prob is available\n",
        "pssmDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_2648_pssm_dir\"\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                wild = mut[\"mut\"][0] \n",
        "                alternate = mut[\"mut\"][-1]\n",
        "                sequence_index_of_mutation = cur_map_dict[mut[\"mut\"][0:-1]]\n",
        "                pdbId = prot[0:-1]\n",
        "                mutChain = prot[-1]\n",
        "                pssm_array = returnPSSMArray(pdbId + mutChain,pssm_dir=pssmDirectory,convert_upper = False)\n",
        "                position_pssm = pssm_array[sequence_index_of_mutation]\n",
        "                wild_pssm = position_pssm[returnPSSMMapping(wild)] \n",
        "                alternate_pssm = position_pssm[returnPSSMMapping(alternate)]\n",
        "                mut[\"wild_pssm\"] = wild_pssm\n",
        "                mut[\"alternate_pssm\"] = alternate_pssm"
      ],
      "metadata": {
        "id": "eBgpxQx4ispc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pssm_predictions = []\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                pssm_predictions.append((mut[\"wild_pssm\"]-mut[\"alternate_pssm\"]))"
      ],
      "metadata": {
        "id": "xOkQhEQzn32m"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experimental_energies = []\n",
        "mut_wild_predictions = []\n",
        "mut_min_predictions = []\n",
        "entropy_predictions = []\n",
        "neighbor_entropy_change_predictions = []\n",
        "neighbor_energy_change_predictions = []\n",
        "center_neighbor_weight_check_w_m = []\n",
        "V2_backward_weighted_neighbor_backward_KL = []\n",
        "sum_neighbor_embedding_change_m_w = []\n",
        "neighbor_message_change_m_w = []\n",
        "\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        for mut in muts:\n",
        "            if \"center_mut_wild_energy\" in mut:\n",
        "                experimental_energies.append(mut[\"ddg\"])\n",
        "                mut_wild_predictions.append(mut[\"center_mut_wild_energy\"])\n",
        "                mut_min_predictions.append(mut[\"center_mut_max_energy\"])\n",
        "                entropy_predictions.append(mut[\"center_entropy\"])\n",
        "                neighbor_entropy_change_predictions.append(mut[\"weighted_neighbor_entropy_changes\"])\n",
        "                neighbor_energy_change_predictions.append(mut[\"weighted_neighbor_energy_changes\"])\n",
        "                center_neighbor_weight_check_w_m.append(mut[\"center_neighbor_weight_check_w_m\"])\n",
        "                V2_backward_weighted_neighbor_backward_KL.append(mut[\"V2_backward_weighted_neighbor_backward_KL\"])\n",
        "                sum_neighbor_embedding_change_m_w.append(mut[\"neighbor_embedding_change_m_w\"])\n",
        "                neighbor_message_change_m_w.append(mut[\"neighbor_message_change_m_w\"])\n",
        "\n",
        "print(len(experimental_energies),len(mut_wild_predictions))\n",
        "\n",
        "print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "print(pearsonr(experimental_energies,entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_entropy_change_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_energy_change_predictions))\n",
        "print(pearsonr(experimental_energies,center_neighbor_weight_check_w_m))\n",
        "print(pearsonr(experimental_energies,V2_backward_weighted_neighbor_backward_KL))\n",
        "print(pearsonr(experimental_energies,sum_neighbor_embedding_change_m_w))\n",
        "print(pearsonr(experimental_energies,neighbor_message_change_m_w))\n",
        "print(pearsonr(experimental_energies,pssm_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tyw_4erpj1C",
        "outputId": "f056281e-73e3-4fc5-a684-a177c034e747"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2620 2620\n",
            "(0.5066529736537145, 6.977318145590863e-171)\n",
            "(0.46967434442269873, 6.906889709666406e-144)\n",
            "(0.35114633273820217, 6.8516125902191846e-77)\n",
            "(0.2982518957749898, 5.685761225875779e-55)\n",
            "(0.29272513393777927, 6.270405582888447e-53)\n",
            "(-0.15030436008655998, 1.0440771163770327e-14)\n",
            "(0.2384432079726765, 3.4350706917055645e-35)\n",
            "(0.30870099814242047, 5.870104605840723e-59)\n",
            "(0.0287730064718497, 0.14091956878536888)\n",
            "(0.2752044285125163, 9.492115203744281e-47)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "df_Ssym = pd.DataFrame(\n",
        "\n",
        "    {'DDG' : experimental_energies,\n",
        "     'P_DP': mut_wild_predictions,\n",
        "     'P_ET': entropy_predictions,\n",
        "     'P_DEC': pssm_predictions,\n",
        "     'Neighbor_Energy_Change' : neighbor_energy_change_predictions,\n",
        "     'Neighbor_backward_KL' : V2_backward_weighted_neighbor_backward_KL,\n",
        "     'Neighbor_Entropy_Change' : neighbor_entropy_change_predictions,\n",
        "     'neighbor_attention_change_w/m' : center_neighbor_weight_check_w_m,\n",
        "     'neighbor_embedding_change' : sum_neighbor_embedding_change_m_w,\n",
        "     'neighbor_message_change' : neighbor_message_change_m_w  \n",
        "    })\n",
        "corr = df_Ssym.corr()\n",
        "\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(corr, \n",
        "        xticklabels=corr.columns,\n",
        "        yticklabels=corr.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "QlQuGW7f7KDy",
        "outputId": "b81b8db4-9cd4-464f-a8fc-b43c74916695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6e11555e90>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}