{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProteinMPNNTesting_V4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d4d20ae18dd4e758aa5294bfcdc7b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb72992182dc4b8d8216d54346dfb779",
              "IPY_MODEL_f803ce7367f24afa81ccd372a8098e87",
              "IPY_MODEL_37aa14460bf54ed587882960dd345db4"
            ],
            "layout": "IPY_MODEL_c76ceaed859f4b38a7d5635da0eff5e9"
          }
        },
        "fb72992182dc4b8d8216d54346dfb779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab1146a756174b82b361a2baf4155d4b",
            "placeholder": "​",
            "style": "IPY_MODEL_1312868b7afe4bb797d219c3931b3f0d",
            "value": ""
          }
        },
        "f803ce7367f24afa81ccd372a8098e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_581b60215ff64fec950f2b9c66a3b34a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b480423f85f8401fbbf1fe82db2fc25c",
            "value": 1
          }
        },
        "37aa14460bf54ed587882960dd345db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69bd9281ef30426396e248f6200e7c91",
            "placeholder": "​",
            "style": "IPY_MODEL_9fc9c61b3bc243bea3cd5551d3cd6fc7",
            "value": " 2648/? [00:00&lt;00:00, 60768.72it/s]"
          }
        },
        "c76ceaed859f4b38a7d5635da0eff5e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab1146a756174b82b361a2baf4155d4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1312868b7afe4bb797d219c3931b3f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "581b60215ff64fec950f2b9c66a3b34a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b480423f85f8401fbbf1fe82db2fc25c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69bd9281ef30426396e248f6200e7c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fc9c61b3bc243bea3cd5551d3cd6fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45ed6c31ef694dc99eaa6176e5f38586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b6172249b5f4dfa88e88b69be7e8aa4",
              "IPY_MODEL_7096db0a4e954590bfdf247639f8c866",
              "IPY_MODEL_7d63eeb763614a25a8a99448bf4252f4"
            ],
            "layout": "IPY_MODEL_be80186a46b74714b38f0545a3d5e49b"
          }
        },
        "1b6172249b5f4dfa88e88b69be7e8aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd2961acf17d4e0b9609eb6fca59b75d",
            "placeholder": "​",
            "style": "IPY_MODEL_541729e2b2574c799c2017b65e279873",
            "value": "100%"
          }
        },
        "7096db0a4e954590bfdf247639f8c866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2557fc79fedb405ebc06a6b6c5ab04ad",
            "max": 131,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a237d3252bad4901bc03a9b09da7b5c6",
            "value": 131
          }
        },
        "7d63eeb763614a25a8a99448bf4252f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d300a8385100478cb9a99064796ea33c",
            "placeholder": "​",
            "style": "IPY_MODEL_bf3b69001f24407a9c79e4d84c4b746b",
            "value": " 131/131 [00:03&lt;00:00, 35.48it/s]"
          }
        },
        "be80186a46b74714b38f0545a3d5e49b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd2961acf17d4e0b9609eb6fca59b75d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "541729e2b2574c799c2017b65e279873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2557fc79fedb405ebc06a6b6c5ab04ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a237d3252bad4901bc03a9b09da7b5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d300a8385100478cb9a99064796ea33c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf3b69001f24407a9c79e4d84c4b746b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "051d89fe530148b4949175a5612c8745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f22d7368cfe4333a1afad26a851fe9e",
              "IPY_MODEL_eaae1fef65f3483196e640f021f2af35",
              "IPY_MODEL_0a6b1a34cd6a446babc9b06d78254d11"
            ],
            "layout": "IPY_MODEL_c79c3b4b30384b3388806efba3156163"
          }
        },
        "2f22d7368cfe4333a1afad26a851fe9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4afc57d17aed424f82bbfff5b3e94d05",
            "placeholder": "​",
            "style": "IPY_MODEL_c87343439b474988a9633b4ff8a589c5",
            "value": ""
          }
        },
        "eaae1fef65f3483196e640f021f2af35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db98d1d18a574ca9803fea925d9a2a6f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d204ef0b6f114952894d924e0597eee5",
            "value": 1
          }
        },
        "0a6b1a34cd6a446babc9b06d78254d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ec1e912197d4fcf8d21b8160402e942",
            "placeholder": "​",
            "style": "IPY_MODEL_2e4708c1367340e683a23f0d37e978fe",
            "value": " 3/? [00:02&lt;00:00,  1.31it/s]"
          }
        },
        "c79c3b4b30384b3388806efba3156163": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4afc57d17aed424f82bbfff5b3e94d05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c87343439b474988a9633b4ff8a589c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db98d1d18a574ca9803fea925d9a2a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d204ef0b6f114952894d924e0597eee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ec1e912197d4fcf8d21b8160402e942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e4708c1367340e683a23f0d37e978fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_wbcvVBv0QJ",
        "outputId": "bddff83d-1d7f-44a4-c2fe-6f1ccaaeaa77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import sys \n",
        "installation_path = \"/content/drive/MyDrive/Colab_Installations_V2\"\n",
        "# The path is being modified so that everything installed in the installation path can now be used without re-installing (in this case, I just need biopython)\n",
        "sys.path.insert(0,installation_path)\n",
        "protein_mpnn_path = \"/content/drive/MyDrive/Protein_MPNN_Digging/ProteinMPNN/vanilla_proteinmpnn\"\n",
        "sys.path.insert(0,protein_mpnn_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Protein_MPNN_Digging"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgTOgsabxBaC",
        "outputId": "3e859826-2a91-4f43-ed91-1ee82fd34d7a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Protein_MPNN_Digging\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import warnings\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, Subset\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import os\n",
        "from Bio.PDB import *\n",
        "\n",
        "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")"
      ],
      "metadata": {
        "id": "jX5ScMeGyLcy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from Bio.PDB.Polypeptide import *\n",
        "from string import ascii_uppercase"
      ],
      "metadata": {
        "id": "NBjszWagtiYL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = os.path.join(protein_mpnn_path,\"vanilla_model_weights\")\n",
        "model_name = \"v_48_020\"\n",
        "checkpoint_path = os.path.join(weights_path,model_name+\".pt\")"
      ],
      "metadata": {
        "id": "Z6ZHe2IIyy1G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, load and dig into the checkpoint object\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device) "
      ],
      "metadata": {
        "id": "JPE_pX8tzdUO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint[\"num_edges\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DD1hpMLk2-y",
        "outputId": "58ed2e0d-2394-49b6-9883-11daa0cf015a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import json, time, os, sys, glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, Subset\n",
        "\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "#A number of functions/classes are adopted from: https://github.com/jingraham/neurips19-graph-protein-design\n",
        "\n",
        "def _scores(S, log_probs, mask):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    criterion = torch.nn.NLLLoss(reduction='none')\n",
        "    loss = criterion(\n",
        "        log_probs.contiguous().view(-1,log_probs.size(-1)),\n",
        "        S.contiguous().view(-1)\n",
        "    ).view(S.size())\n",
        "    # The designable positions have mask set to 1.0, so this function seems to be returning the average score for the designable positions\n",
        "    scores = torch.sum(loss * mask, dim=-1) / torch.sum(mask, dim=-1)\n",
        "    return scores\n",
        "\n",
        "def _S_to_seq(S, mask):\n",
        "    # This is the decoding order\n",
        "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    seq = ''.join([alphabet[c] for c, m in zip(S.tolist(), mask.tolist()) if m > 0])\n",
        "    return seq\n",
        "\n",
        "def parse_PDB_biounits(x, atoms=['N','CA','C'], chain=None):\n",
        "  '''\n",
        "  input:  x = PDB filename\n",
        "          atoms = atoms to extract (optional)\n",
        "  output: (length, atoms, coords=(x,y,z)), sequence\n",
        "  '''\n",
        "\n",
        "  alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "  states = len(alpha_1)\n",
        "  alpha_3 = ['ALA','ARG','ASN','ASP','CYS','GLN','GLU','GLY','HIS','ILE',\n",
        "             'LEU','LYS','MET','PHE','PRO','SER','THR','TRP','TYR','VAL','GAP']\n",
        "  \n",
        "  # The following dictionaries are mapping from one-letter to 0-20 index,\n",
        "  # three-letter to 0-20 index,\n",
        "  # 0-20 index to one-letter,\n",
        "  # one-letter to three-letter, and vice-versa \n",
        "  aa_1_N = {a:n for n,a in enumerate(alpha_1)}\n",
        "  aa_3_N = {a:n for n,a in enumerate(alpha_3)}\n",
        "  aa_N_1 = {n:a for n,a in enumerate(alpha_1)}\n",
        "  aa_1_3 = {a:b for a,b in zip(alpha_1,alpha_3)}\n",
        "  aa_3_1 = {b:a for a,b in zip(alpha_1,alpha_3)}\n",
        "  \n",
        "  def AA_to_N(x):\n",
        "    # [\"ARND\"] -> [[0,1,2,3]]\n",
        "    x = np.array(x);\n",
        "    if x.ndim == 0: x = x[None]\n",
        "    return [[aa_1_N.get(a, states-1) for a in y] for y in x]\n",
        "  \n",
        "  def N_to_AA(x):\n",
        "    # [[0,1,2,3]] -> [\"ARND\"]\n",
        "    x = np.array(x);\n",
        "    if x.ndim == 1: x = x[None]\n",
        "    return [\"\".join([aa_N_1.get(a,\"-\") for a in y]) for y in x]\n",
        "\n",
        "  xyz,seq,min_resn,max_resn = {},{},1e6,-1e6\n",
        "  for line in open(x,\"rb\"):\n",
        "    line = line.decode(\"utf-8\",\"ignore\").rstrip()\n",
        "\n",
        "    if line[:6] == \"HETATM\" and line[17:17+3] == \"MSE\":\n",
        "      line = line.replace(\"HETATM\",\"ATOM  \")\n",
        "      line = line.replace(\"MSE\",\"MET\")\n",
        "\n",
        "    if line[:4] == \"ATOM\":\n",
        "      ch = line[21:22]\n",
        "      # If the input chain is not in the PDB file, which can be the case if the target chains are named differently in the runner script,\n",
        "      # this line will cause the output to have literally no information, this is the case for integer named chains\n",
        "      # that does not mean that this line is not doing its job correctly, this is just a constraint that input chain names and \n",
        "      # chain names in the PDB file have to be congruent\n",
        "      if ch == chain or chain is None:\n",
        "        atom = line[12:12+4].strip()\n",
        "        resi = line[17:17+3]\n",
        "        resn = line[22:22+5].strip()\n",
        "        x,y,z = [float(line[i:(i+8)]) for i in [30,38,46]]\n",
        "\n",
        "        if resn[-1].isalpha(): \n",
        "            resa,resn = resn[-1],int(resn[:-1])-1\n",
        "        else: \n",
        "            resa,resn = \"\",int(resn)-1\n",
        "#         resn = int(resn)\n",
        "        if resn < min_resn: \n",
        "            min_resn = resn\n",
        "        if resn > max_resn: \n",
        "            max_resn = resn\n",
        "        if resn not in xyz: \n",
        "            xyz[resn] = {}\n",
        "        if resa not in xyz[resn]: \n",
        "            xyz[resn][resa] = {}\n",
        "        if resn not in seq: \n",
        "            seq[resn] = {}\n",
        "        if resa not in seq[resn]: \n",
        "            seq[resn][resa] = resi\n",
        "\n",
        "        if atom not in xyz[resn][resa]:\n",
        "          xyz[resn][resa][atom] = np.array([x,y,z])\n",
        "\n",
        "  # convert to numpy arrays, fill in missing values\n",
        "  seq_,xyz_ = [],[]\n",
        "  try:\n",
        "      for resn in range(min_resn,max_resn+1):\n",
        "        if resn in seq:\n",
        "          for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k],20))\n",
        "        else: seq_.append(20)\n",
        "        if resn in xyz:\n",
        "          for k in sorted(xyz[resn]):\n",
        "            for atom in atoms:\n",
        "              if atom in xyz[resn][k]: xyz_.append(xyz[resn][k][atom])\n",
        "              else: xyz_.append(np.full(3,np.nan))\n",
        "        else:\n",
        "          for atom in atoms: xyz_.append(np.full(3,np.nan))\n",
        "      return np.array(xyz_).reshape(-1,len(atoms),3), N_to_AA(np.array(seq_))\n",
        "  except TypeError:\n",
        "      return 'no_chain', 'no_chain'\n",
        "\n",
        "### calling signature\n",
        "# pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list)\n",
        "def parse_PDB(path_to_pdb, input_chain_list=None):\n",
        "    c=0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V','W','X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v','w','x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "     \n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list  \n",
        " \n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    # Each of the biounits is a separate PDB file, so for running with a single PDB file like from colab, this loop will be executed only once\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {} \n",
        "        # This loop will be executed only once for single chain DDG type cases\n",
        "        for letter in chain_alphabet:\n",
        "            xyz, seq = parse_PDB_biounits(biounit, atoms=['N','CA','C','O'], chain=letter)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_'+letter]=seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                coords_dict_chain['N_chain_'+letter]=xyz[:,0,:].tolist()\n",
        "                coords_dict_chain['CA_chain_'+letter]=xyz[:,1,:].tolist()\n",
        "                coords_dict_chain['C_chain_'+letter]=xyz[:,2,:].tolist()\n",
        "                coords_dict_chain['O_chain_'+letter]=xyz[:,3,:].tolist()\n",
        "                my_dict['coords_chain_'+letter]=coords_dict_chain\n",
        "                s += 1\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        my_dict['name']=biounit[(fi+1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c+=1\n",
        "    return pdb_dict_list\n",
        "\n",
        "\n",
        "# X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta \n",
        "# = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "# fixed_pos_list = fixed_position_dict[b['name']][letter]\n",
        "# The trick will be to populate this fixed_position_dict from the calling function, and \n",
        "def tied_featurize(batch, device, chain_dict, fixed_position_dict=None, omit_AA_dict=None, tied_positions_dict=None, pssm_dict=None, bias_by_res_dict=None):\n",
        "    \"\"\" Pack and pad batch into torch tensors \"\"\"\n",
        "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    B = len(batch)\n",
        "    lengths = np.array([len(b['seq']) for b in batch], dtype=np.int32) #sum of chain seq lengths\n",
        "    L_max = max([len(b['seq']) for b in batch])\n",
        "    X = np.zeros([B, L_max, 4, 3])\n",
        "    residue_idx = -100*np.ones([B, L_max], dtype=np.int32)\n",
        "    # This \"chain_M\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of the single sequence as a consequence\n",
        "    chain_M = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    pssm_coef_all = np.zeros([B, L_max], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    pssm_bias_all = np.zeros([B, L_max, 21], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    pssm_log_odds_all = 10000.0*np.ones([B, L_max, 21], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    # This \"chain_M_pos\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of single sequence as a consequence\n",
        "    chain_M_pos = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    bias_by_res_all = np.zeros([B, L_max, 21], dtype=np.float32)\n",
        "    # This \"chain_encoding_all\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of single sequence as a consequence\n",
        "    chain_encoding_all = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    S = np.zeros([B, L_max], dtype=np.int32)\n",
        "    omit_AA_mask = np.zeros([B, L_max, len(alphabet)], dtype=np.int32)\n",
        "    # Build the batch\n",
        "    letter_list_list = []\n",
        "    visible_list_list = []\n",
        "    masked_list_list = []\n",
        "    masked_chain_length_list_list = []\n",
        "    tied_pos_list_of_lists_list = []\n",
        "    #shuffle all chains before the main loop\n",
        "    for i, b in enumerate(batch):\n",
        "        # for my current energy function like usecase, the code will reach \"if and not else\" because chain_dict will not be None\n",
        "        if chain_dict != None:\n",
        "            ### Calling function argument assignment START\n",
        "            # chain_id_dict[pdb_dict_list[0]['name']] = (designed_chain_list, fixed_chain_list)\n",
        "            ### Calling function argument assignment END\n",
        "            masked_chains, visible_chains = chain_dict[b['name']] #masked_chains a list of chain letters to predict [A, D, F]\n",
        "        else:\n",
        "            masked_chains = [item[-1:] for item in list(b) if item[:10]=='seq_chain_']\n",
        "            visible_chains = []\n",
        "        num_chains = b['num_of_chains']\n",
        "        all_chains = masked_chains + visible_chains\n",
        "        #random.shuffle(all_chains)\n",
        "    # This for loop can be ignored since it will be executed only once in my single-chain or single-chain-at-a-time implementation\n",
        "    for i, b in enumerate(batch):\n",
        "        mask_dict = {}\n",
        "        a = 0\n",
        "        x_chain_list = []\n",
        "        chain_mask_list = []\n",
        "        # \"chain_seq_list\" will contain string format sequences of all the chains both fixed and designable \n",
        "        chain_seq_list = []\n",
        "        chain_encoding_list = []\n",
        "        c = 1\n",
        "        # \"letter_list\" will contain names of all the chains both fixed and designable\n",
        "        letter_list = []\n",
        "        global_idx_start_list = [0]\n",
        "        # \"visible_list\" will contain names of the fixed chains \n",
        "        visible_list = []\n",
        "        # \"masked_list\" will contain names of the designable chains\n",
        "        masked_list = []\n",
        "        masked_chain_length_list = []\n",
        "        fixed_position_mask_list = []\n",
        "        omit_AA_mask_list = []\n",
        "        pssm_coef_list = []\n",
        "        pssm_bias_list = []\n",
        "        pssm_log_odds_list = []\n",
        "        bias_by_res_list = []\n",
        "        l0 = 0\n",
        "        l1 = 0\n",
        "        # This loop will also be executed once for my single chain case,\n",
        "        # and since the same chain has both designable and fixed positions, the codes insides both of the if \n",
        "        # statements will be executed\n",
        "        for step, letter in enumerate(all_chains):\n",
        "            if letter in visible_chains:\n",
        "                letter_list.append(letter)\n",
        "                visible_list.append(letter)\n",
        "                chain_seq = b[f'seq_chain_{letter}']\n",
        "                chain_seq = ''.join([a if a!='-' else 'X' for a in chain_seq])\n",
        "                chain_length = len(chain_seq)\n",
        "                global_idx_start_list.append(global_idx_start_list[-1]+chain_length)\n",
        "                chain_coords = b[f'coords_chain_{letter}'] #this is a dictionary\n",
        "                # the \"chain_mask\" varies between fixed and designable chains (1.0 for designable chains which are maxed)\n",
        "                chain_mask = np.zeros(chain_length) #0.0 for visible chains\n",
        "                x_chain = np.stack([chain_coords[c] for c in [f'N_chain_{letter}', f'CA_chain_{letter}', f'C_chain_{letter}', f'O_chain_{letter}']], 1) #[chain_lenght,4,3]\n",
        "                x_chain_list.append(x_chain)\n",
        "                chain_mask_list.append(chain_mask)\n",
        "                chain_seq_list.append(chain_seq)\n",
        "                # \"chain_encoding_list\" contains numpy arrays corresponding to chains (each array corresponds to one chain),\n",
        "                # where all elements of the same array is the same value, which is equal to the index of the chain the it corresponds to\n",
        "                # by index, I mean index of the different numpy arrays annotating the chains\n",
        "                chain_encoding_list.append(c*np.ones(np.array(chain_mask).shape[0]))\n",
        "                # l0 points at the starting of the current chain and l1 points after the ending of the current chain\n",
        "                l1 += chain_length\n",
        "                # the only value i will have is 0 since it will be executed only once in my single-chain or single-chain-at-a-time implementation\n",
        "                # seems like the chains are separated by  \n",
        "                residue_idx[i, l0:l1] = 100*(c-1)+np.arange(l0, l1)\n",
        "                l0 += chain_length\n",
        "                c+=1\n",
        "                # The following variables are numpy arrays with entries corresponding to every position in the sequence\n",
        "                # appending these numpy arrays to a list indicates that the chains are added one after one\n",
        "                # same thing goes for the chain_mask and chain_seq variables declared above\n",
        "                # In code-block below in this cell, these lists of numpy arrays are going through np.concatenate(), which is creating\n",
        "                # the final numpy arrays containing co-ordinates, sequence identity, fixed position, masked position, PSSM bias, and everything\n",
        "                # required to pass the sequences through the model\n",
        "                ### START\n",
        "                fixed_position_mask = np.ones(chain_length)\n",
        "                fixed_position_mask_list.append(fixed_position_mask)\n",
        "                # The omit_AA_mask, pssm_coef, pssm_bias, \"bias_by_res_list\", all these numpy arrays are zero for the fixed positions\n",
        "                # since these positions are used as it is, while for the masked_positions, these values can get activated\n",
        "                # which is why the next if statement has several extra lines manipulating these variables according to the amount of information passed \n",
        "                omit_AA_mask_temp = np.zeros([chain_length, len(alphabet)], np.int32)\n",
        "                omit_AA_mask_list.append(omit_AA_mask_temp)\n",
        "                pssm_coef = np.zeros(chain_length)\n",
        "                pssm_bias = np.zeros([chain_length, 21])\n",
        "                pssm_log_odds = 10000.0*np.ones([chain_length, 21])\n",
        "                pssm_coef_list.append(pssm_coef)\n",
        "                pssm_bias_list.append(pssm_bias)\n",
        "                pssm_log_odds_list.append(pssm_log_odds)\n",
        "                bias_by_res_list.append(np.zeros([chain_length, 21]))\n",
        "                ### END\n",
        "            if letter in masked_chains:\n",
        "                masked_list.append(letter)\n",
        "                letter_list.append(letter)\n",
        "                chain_seq = b[f'seq_chain_{letter}']\n",
        "                chain_seq = ''.join([a if a!='-' else 'X' for a in chain_seq])\n",
        "                chain_length = len(chain_seq)\n",
        "                global_idx_start_list.append(global_idx_start_list[-1]+chain_length)\n",
        "                masked_chain_length_list.append(chain_length)\n",
        "                chain_coords = b[f'coords_chain_{letter}'] #this is a dictionary\n",
        "                chain_mask = np.ones(chain_length) #1.0 for masked\n",
        "                x_chain = np.stack([chain_coords[c] for c in [f'N_chain_{letter}', f'CA_chain_{letter}', f'C_chain_{letter}', f'O_chain_{letter}']], 1) #[chain_lenght,4,3]\n",
        "                x_chain_list.append(x_chain)\n",
        "                chain_mask_list.append(chain_mask)\n",
        "                chain_seq_list.append(chain_seq)\n",
        "                chain_encoding_list.append(c*np.ones(np.array(chain_mask).shape[0]))\n",
        "                l1 += chain_length\n",
        "                residue_idx[i, l0:l1] = 100*(c-1)+np.arange(l0, l1)\n",
        "                l0 += chain_length\n",
        "                c+=1\n",
        "                fixed_position_mask = np.ones(chain_length)\n",
        "                if fixed_position_dict!=None:\n",
        "                    fixed_pos_list = fixed_position_dict[b['name']][letter]\n",
        "                    if fixed_pos_list:\n",
        "                        # seems like \"fixed_pos_list\"  can be an 1-indexed integer list corresponding to positions in \"chain_seq\"\n",
        "                        # this thing ultimately controls which positions in the designable chain will be masked, which is why the fixed \n",
        "                        # positions are set to 0.0 since those positions will not be maxed (1 if maxed, 0 if not maxed)\n",
        "                        fixed_position_mask[np.array(fixed_pos_list)-1] = 0.0\n",
        "                fixed_position_mask_list.append(fixed_position_mask)\n",
        "                omit_AA_mask_temp = np.zeros([chain_length, len(alphabet)], np.int32)\n",
        "                # For my current energy function like usecase, \"omit_AA_dict\" will be None, so the following loop can be ignored\n",
        "                if omit_AA_dict!=None:\n",
        "                    for item in omit_AA_dict[b['name']][letter]:\n",
        "                        idx_AA = np.array(item[0])-1\n",
        "                        AA_idx = np.array([np.argwhere(np.array(list(alphabet))== AA)[0][0] for AA in item[1]]).repeat(idx_AA.shape[0])\n",
        "                        idx_ = np.array([[a, b] for a in idx_AA for b in AA_idx])\n",
        "                        omit_AA_mask_temp[idx_[:,0], idx_[:,1]] = 1\n",
        "                omit_AA_mask_list.append(omit_AA_mask_temp)\n",
        "                pssm_coef = np.zeros(chain_length)\n",
        "                pssm_bias = np.zeros([chain_length, 21])\n",
        "                pssm_log_odds = 10000.0*np.ones([chain_length, 21])\n",
        "                if pssm_dict:\n",
        "                    if pssm_dict[b['name']][letter]:\n",
        "                        pssm_coef = pssm_dict[b['name']][letter]['pssm_coef']\n",
        "                        pssm_bias = pssm_dict[b['name']][letter]['pssm_bias']\n",
        "                        pssm_log_odds = pssm_dict[b['name']][letter]['pssm_log_odds']\n",
        "                pssm_coef_list.append(pssm_coef)\n",
        "                pssm_bias_list.append(pssm_bias)\n",
        "                pssm_log_odds_list.append(pssm_log_odds)\n",
        "                if bias_by_res_dict:\n",
        "                    bias_by_res_list.append(bias_by_res_dict[b['name']][letter])\n",
        "                else:\n",
        "                    bias_by_res_list.append(np.zeros([chain_length, 21]))\n",
        "\n",
        "        ### TIED position START\n",
        "        # Since there will technically be no tied positions for my single chain energy-based usecase for now,\n",
        "        # I do not need to dig into this part of the code\n",
        "        letter_list_np = np.array(letter_list)\n",
        "        tied_pos_list_of_lists = []\n",
        "        tied_beta = np.ones(L_max)\n",
        "        if tied_positions_dict!=None:\n",
        "            tied_pos_list = tied_positions_dict[b['name']]\n",
        "            if tied_pos_list:\n",
        "                set_chains_tied = set(list(itertools.chain(*[list(item) for item in tied_pos_list])))\n",
        "                for tied_item in tied_pos_list:\n",
        "                    one_list = []\n",
        "                    for k, v in tied_item.items():\n",
        "                        start_idx = global_idx_start_list[np.argwhere(letter_list_np == k)[0][0]]\n",
        "                        if isinstance(v[0], list):\n",
        "                            for v_count in range(len(v[0])):\n",
        "                                one_list.append(start_idx+v[0][v_count]-1)#make 0 to be the first\n",
        "                                tied_beta[start_idx+v[0][v_count]-1] = v[1][v_count]\n",
        "                        else:\n",
        "                            for v_ in v:\n",
        "                                one_list.append(start_idx+v_-1)#make 0 to be the first\n",
        "                    tied_pos_list_of_lists.append(one_list)\n",
        "        tied_pos_list_of_lists_list.append(tied_pos_list_of_lists)\n",
        "        ### TIED position END\n",
        " \n",
        "        # Interestingly, although the backbone atom coordinates are used for generating edge features,\n",
        "        # the \"x\" in the following line contains the coodinates of the backbone atoms \n",
        "        x = np.concatenate(x_chain_list,0) #[L, 4, 3]\n",
        "        # \"all_sequence\" is a string where all the chain sequences have been put one after another\n",
        "        all_sequence = \"\".join(chain_seq_list)\n",
        "        # This \"chain_mask_list\" and \"m_pos\" below are the variables of interest if these actually contain full information regarding the\n",
        "        # fixed vs. variable positions definitions \n",
        "        # consequently, since these are concatenated numpy arrays of numpy arrays inside the lists \"chain_mask_list\" and \"fixed_position_mask_list\",\n",
        "        # when those lists are populated in the above code-block with binary numpy arrays \"fixed_position_mask\" and \"fixed_position_mask\" corresponding to \n",
        "        # each of the chains,\n",
        "        # that is where all the controlling needs to be done from\n",
        "        m = np.concatenate(chain_mask_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        # \"chain_encoding_list\" contains numpy arrays corresponding to chains (each array corresponds to one chain),\n",
        "        # where all elements of the same array is the same value, which is equal to the index of the chain the it corresponds to\n",
        "        # by index, I mean index of the different numpy arrays annotating the chains\n",
        "        chain_encoding = np.concatenate(chain_encoding_list,0)\n",
        "        m_pos = np.concatenate(fixed_position_mask_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "\n",
        "        pssm_coef_ = np.concatenate(pssm_coef_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        pssm_bias_ = np.concatenate(pssm_bias_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        pssm_log_odds_ = np.concatenate(pssm_log_odds_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "\n",
        "        bias_by_res_ = np.concatenate(bias_by_res_list, 0)  #[L,21], 0.0 for places where AA frequencies don't need to be tweaked\n",
        "\n",
        "        # Interestingly, all the chains are padded to the same length\n",
        "        # this has to be done most probably because the same layers are applied to all chains\n",
        "        # but for single chain or homomer cases, this should not be an issue\n",
        "        # need to be sure later why this is done\n",
        "        # does not significant when it comes to single chain energy-based usecase\n",
        "        # PADDING START\n",
        "        l = len(all_sequence)\n",
        "        x_pad = np.pad(x, [[0,L_max-l], [0,0], [0,0]], 'constant', constant_values=(np.nan, ))\n",
        "        X[i,:,:,:] = x_pad\n",
        "\n",
        "        m_pad = np.pad(m, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        m_pos_pad = np.pad(m_pos, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        omit_AA_mask_pad = np.pad(np.concatenate(omit_AA_mask_list,0), [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        chain_M[i,:] = m_pad\n",
        "        chain_M_pos[i,:] = m_pos_pad\n",
        "        omit_AA_mask[i,] = omit_AA_mask_pad\n",
        "\n",
        "        chain_encoding_pad = np.pad(chain_encoding, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        chain_encoding_all[i,:] = chain_encoding_pad\n",
        "\n",
        "        pssm_coef_pad = np.pad(pssm_coef_, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        pssm_bias_pad = np.pad(pssm_bias_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "        pssm_log_odds_pad = np.pad(pssm_log_odds_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "\n",
        "        pssm_coef_all[i,:] = pssm_coef_pad\n",
        "        pssm_bias_all[i,:] = pssm_bias_pad\n",
        "        pssm_log_odds_all[i,:] = pssm_log_odds_pad\n",
        "\n",
        "        bias_by_res_pad = np.pad(bias_by_res_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "        bias_by_res_all[i,:] = bias_by_res_pad\n",
        "        # PADDING END\n",
        "\n",
        "        # Convert to labels\n",
        "        indices = np.asarray([alphabet.index(a) for a in all_sequence], dtype=np.int32)\n",
        "        S[i, :l] = indices\n",
        "        letter_list_list.append(letter_list)\n",
        "        visible_list_list.append(visible_list)\n",
        "        masked_list_list.append(masked_list)\n",
        "        masked_chain_length_list_list.append(masked_chain_length_list)\n",
        "\n",
        "\n",
        "    isnan = np.isnan(X)\n",
        "    mask = np.isfinite(np.sum(X,(2,3))).astype(np.float32)\n",
        "    X[isnan] = 0.\n",
        "\n",
        "    # Conversion\n",
        "    pssm_coef_all = torch.from_numpy(pssm_coef_all).to(dtype=torch.float32, device=device)\n",
        "    pssm_bias_all = torch.from_numpy(pssm_bias_all).to(dtype=torch.float32, device=device)\n",
        "    pssm_log_odds_all = torch.from_numpy(pssm_log_odds_all).to(dtype=torch.float32, device=device)\n",
        "\n",
        "    tied_beta = torch.from_numpy(tied_beta).to(dtype=torch.float32, device=device)\n",
        "\n",
        "    jumps = ((residue_idx[:,1:]-residue_idx[:,:-1])==1).astype(np.float32)\n",
        "    bias_by_res_all = torch.from_numpy(bias_by_res_all).to(dtype=torch.float32, device=device)\n",
        "    phi_mask = np.pad(jumps, [[0,0],[1,0]])\n",
        "    psi_mask = np.pad(jumps, [[0,0],[0,1]])\n",
        "    omega_mask = np.pad(jumps, [[0,0],[0,1]])\n",
        "    dihedral_mask = np.concatenate([phi_mask[:,:,None], psi_mask[:,:,None], omega_mask[:,:,None]], -1) #[B,L,3]\n",
        "    dihedral_mask = torch.from_numpy(dihedral_mask).to(dtype=torch.float32, device=device)\n",
        "    residue_idx = torch.from_numpy(residue_idx).to(dtype=torch.long,device=device)\n",
        "    S = torch.from_numpy(S).to(dtype=torch.long,device=device)\n",
        "    X = torch.from_numpy(X).to(dtype=torch.float32, device=device)\n",
        "    mask = torch.from_numpy(mask).to(dtype=torch.float32, device=device)\n",
        "    chain_M = torch.from_numpy(chain_M).to(dtype=torch.float32, device=device)\n",
        "    chain_M_pos = torch.from_numpy(chain_M_pos).to(dtype=torch.float32, device=device)\n",
        "    omit_AA_mask = torch.from_numpy(omit_AA_mask).to(dtype=torch.float32, device=device)\n",
        "    chain_encoding_all = torch.from_numpy(chain_encoding_all).to(dtype=torch.long, device=device)\n",
        "    # in general, in this return statement, *_list_list has the list inside list format because the outer list corresponds to \"batch_clones\", \n",
        "    # whereas the inner list corresponds to \"chains\" for each of the elements of \"batch_clones\"\n",
        "    # \"masked_list_list\" contains names of the designable chains (which is my target for single chain energy), whereas \"visible_list_list\" \n",
        "    # contains names of the fixed chains (which should be empty for my single chain energy)\n",
        "    # for my single chain energy case, \"letter_list_list\" should be equal to \"masked_list_list\", and three lists should have one list for now\n",
        "    # \"chain_encoding_all\" should also contain chain-index related to the only single chain which should be 0 (all 0s)\n",
        "    # the last lists starting from \"tied_pos_list_of_lists_list\" to the end should be irrelevant for my single chain energy case\n",
        "    # but still it would be good to check the values of these irrelevant lists, and get an idea if everything makes sense or not\n",
        "    # \"chain_M_pos\" contains values from \"fixed_position_mask\" through \"m_pos\", which should get populated with 0.0 for fixed positions\n",
        "    # and 1.0 for designable positions, which can be controlled through the , which\n",
        "    # is controlled by \"fixed_position_dict\" input to this function from the running script\n",
        "    # \"chain_M\" is formed from \"m_pad\" which comes from \"m\" which comes from chain_mask = np.ones(chain_length) #1.0 for masked\n",
        "    # so, for my single chain energy usecase, \"chain_M\" should be all 1.0s with the same length as chain_M_pos\n",
        "    # I do not think \"X\", \"S\", and \"mask\" need to be manipulated for now \n",
        "    return X, S, mask, lengths, chain_M, chain_encoding_all, letter_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef_all, pssm_bias_all, pssm_log_odds_all, bias_by_res_all, tied_beta\n",
        "\n",
        "\n",
        "# No need to dig into this loss function for now\n",
        "def loss_nll(S, log_probs, mask):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    criterion = torch.nn.NLLLoss(reduction='none')\n",
        "    loss = criterion(\n",
        "        log_probs.contiguous().view(-1, log_probs.size(-1)), S.contiguous().view(-1)\n",
        "    ).view(S.size())\n",
        "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
        "    return loss, loss_av\n",
        "\n",
        "# No need to dig into this label smoothing stuff for now\n",
        "def loss_smoothed(S, log_probs, mask, weight=0.1):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    S_onehot = torch.nn.functional.one_hot(S, 21).float()\n",
        "\n",
        "    # Label smoothing\n",
        "    S_onehot = S_onehot + weight / float(S_onehot.size(-1))\n",
        "    S_onehot = S_onehot / S_onehot.sum(-1, keepdim=True)\n",
        "\n",
        "    loss = -(S_onehot * log_probs).sum(-1)\n",
        "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
        "    return loss, loss_av\n",
        "\n",
        "# Objects of this class can be indexed since dunder methods __len()__ and __getitem()__ have been implemented, which \n",
        "# indexes a list that has been declared as an instance variable in the constructor,\n",
        "# and each element of that underlying list is a dictionary containing information regarding a specific sequence\n",
        "class StructureDataset():\n",
        "    def __init__(self, jsonl_file, verbose=True, truncate=None, max_length=100,\n",
        "        alphabet='ACDEFGHIKLMNPQRSTVWYX-'):\n",
        "        alphabet_set = set([a for a in alphabet])\n",
        "        discard_count = {\n",
        "            'bad_chars': 0,\n",
        "            'too_long': 0,\n",
        "            'bad_seq_length': 0\n",
        "        }\n",
        "\n",
        "        with open(jsonl_file) as f:\n",
        "            self.data = []\n",
        "\n",
        "            lines = f.readlines()\n",
        "            start = time.time()\n",
        "            for i, line in enumerate(lines):\n",
        "                entry = json.loads(line)\n",
        "                seq = entry['seq'] \n",
        "                name = entry['name']\n",
        "\n",
        "                # Convert raw coords to np arrays\n",
        "                #for key, val in entry['coords'].items():\n",
        "                #    entry['coords'][key] = np.asarray(val)\n",
        "\n",
        "                # Check if in alphabet\n",
        "                bad_chars = set([s for s in seq]).difference(alphabet_set)\n",
        "                if len(bad_chars) == 0:\n",
        "                    if len(entry['seq']) <= max_length:\n",
        "                        if True:\n",
        "                            self.data.append(entry)\n",
        "                        else:\n",
        "                            discard_count['bad_seq_length'] += 1\n",
        "                    else:\n",
        "                        discard_count['too_long'] += 1\n",
        "                else:\n",
        "                    print(name, bad_chars, entry['seq'])\n",
        "                    discard_count['bad_chars'] += 1\n",
        "\n",
        "                # Truncate early\n",
        "                if truncate is not None and len(self.data) == truncate:\n",
        "                    return\n",
        "\n",
        "                if verbose and (i + 1) % 1000 == 0:\n",
        "                    elapsed = time.time() - start\n",
        "                    print('{} entries ({} loaded) in {:.1f} s'.format(len(self.data), i+1, elapsed))\n",
        "\n",
        "            print('discarded', discard_count)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "\n",
        "# Objects of this class can be indexed since dunder methods __len()__ and __getitem()__ have been implemented, which \n",
        "# indexes a list that has been declared as an instance variable in the constructor,\n",
        "# and each element of that underlying list is a dictionary containing information regarding a specific structure,\n",
        "# seems like a structure-specific version of the above method which deals with sequences \n",
        "class StructureDatasetPDB():\n",
        "    def __init__(self, pdb_dict_list, verbose=True, truncate=None, max_length=100,\n",
        "        alphabet='ACDEFGHIKLMNPQRSTVWYX-'):\n",
        "        alphabet_set = set([a for a in alphabet])\n",
        "        discard_count = {\n",
        "            'bad_chars': 0,\n",
        "            'too_long': 0,\n",
        "            'bad_seq_length': 0\n",
        "        }\n",
        "\n",
        "        self.data = []\n",
        "\n",
        "        start = time.time()\n",
        "        # elements of pdb_dict_list are dictionaries containing information regarding a specific pdb file\n",
        "        for i, entry in enumerate(pdb_dict_list):\n",
        "            seq = entry['seq']\n",
        "            name = entry['name']\n",
        "\n",
        "            bad_chars = set([s for s in seq]).difference(alphabet_set)\n",
        "            if len(bad_chars) == 0:\n",
        "                if len(entry['seq']) <= max_length:\n",
        "                    self.data.append(entry)\n",
        "                else:\n",
        "                    discard_count['too_long'] += 1\n",
        "            else:\n",
        "                discard_count['bad_chars'] += 1\n",
        "\n",
        "            # Truncate early\n",
        "            if truncate is not None and len(self.data) == truncate:\n",
        "                return\n",
        "\n",
        "            if verbose and (i + 1) % 1000 == 0:\n",
        "                elapsed = time.time() - start\n",
        "\n",
        "            #print('Discarded', discard_count)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "\n",
        "    \n",
        "class StructureLoader():\n",
        "    def __init__(self, dataset, batch_size=100, shuffle=True,\n",
        "        collate_fn=lambda x:x, drop_last=False):\n",
        "        self.dataset = dataset\n",
        "        self.size = len(dataset)\n",
        "        self.lengths = [len(dataset[i]['seq']) for i in range(self.size)]\n",
        "        self.batch_size = batch_size\n",
        "        sorted_ix = np.argsort(self.lengths)\n",
        "\n",
        "        # Cluster into batches of similar sizes\n",
        "        clusters, batch = [], []\n",
        "        batch_max = 0\n",
        "        for ix in sorted_ix:\n",
        "            size = self.lengths[ix]\n",
        "            if size * (len(batch) + 1) <= self.batch_size:\n",
        "                batch.append(ix)\n",
        "                batch_max = size\n",
        "            else:\n",
        "                clusters.append(batch)\n",
        "                batch, batch_max = [], 0\n",
        "        if len(batch) > 0:\n",
        "            clusters.append(batch)\n",
        "        self.clusters = clusters\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.clusters)\n",
        "\n",
        "    def __iter__(self):\n",
        "        np.random.shuffle(self.clusters)\n",
        "        for b_idx in self.clusters:\n",
        "            batch = [self.dataset[i] for i in b_idx]\n",
        "            yield batch\n",
        "            \n",
        "            \n",
        "            \n",
        "# The following gather functions\n",
        "def gather_edges(edges, neighbor_idx):\n",
        "    # Features [B,N,N,C] at Neighbor indices [B,N,K] => Neighbor features [B,N,K,C]\n",
        "    neighbors = neighbor_idx.unsqueeze(-1).expand(-1, -1, -1, edges.size(-1))\n",
        "    edge_features = torch.gather(edges, 2, neighbors)\n",
        "    return edge_features\n",
        "\n",
        "def gather_nodes(nodes, neighbor_idx):\n",
        "    # Features [B,N,C] at Neighbor indices [B,N,K] => [B,N,K,C]\n",
        "    # Flatten and expand indices per batch [B,N,K] => [B,NK] => [B,NK,C]\n",
        "    neighbors_flat = neighbor_idx.view((neighbor_idx.shape[0], -1))\n",
        "    neighbors_flat = neighbors_flat.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
        "    # Gather and re-pack\n",
        "    neighbor_features = torch.gather(nodes, 1, neighbors_flat)\n",
        "    neighbor_features = neighbor_features.view(list(neighbor_idx.shape)[:3] + [-1])\n",
        "    return neighbor_features\n",
        "\n",
        "def gather_nodes_t(nodes, neighbor_idx):\n",
        "    # Features [B,N,C] at Neighbor index [B,K] => Neighbor features[B,K,C]\n",
        "    idx_flat = neighbor_idx.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
        "    neighbor_features = torch.gather(nodes, 1, idx_flat)\n",
        "    return neighbor_features\n",
        "\n",
        "def cat_neighbors_nodes(h_nodes, h_neighbors, E_idx):\n",
        "    h_nodes = gather_nodes(h_nodes, E_idx)\n",
        "    h_nn = torch.cat([h_neighbors, h_nodes], -1)\n",
        "    return h_nn\n",
        "\n",
        "\n",
        "class EncLayer(nn.Module):\n",
        "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
        "        super(EncLayer, self).__init__()\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_in = num_in\n",
        "        self.scale = scale\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(num_hidden)\n",
        "        self.norm2 = nn.LayerNorm(num_hidden)\n",
        "        self.norm3 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W11 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W12 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W13 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
        "\n",
        "    def forward(self, h_V, h_E, E_idx, mask_V=None, mask_attend=None):\n",
        "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
        "\n",
        "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
        "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
        "        if mask_attend is not None:\n",
        "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
        "        dh = torch.sum(h_message, -2) / self.scale\n",
        "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
        "\n",
        "        dh = self.dense(h_V)\n",
        "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
        "        if mask_V is not None:\n",
        "            mask_V = mask_V.unsqueeze(-1)\n",
        "            h_V = mask_V * h_V\n",
        "\n",
        "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
        "        h_message = self.W13(self.act(self.W12(self.act(self.W11(h_EV)))))\n",
        "        h_E = self.norm3(h_E + self.dropout3(h_message))\n",
        "        return h_V, h_E\n",
        "\n",
        "\n",
        "class DecLayer(nn.Module):\n",
        "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
        "        super(DecLayer, self).__init__()\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_in = num_in\n",
        "        self.scale = scale\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(num_hidden)\n",
        "        self.norm2 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
        "\n",
        "    def forward(self, h_V, h_E, mask_V=None, mask_attend=None):\n",
        "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
        "\n",
        "        # Concatenate h_V_i to h_E_ij\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_E.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_E], -1)\n",
        "\n",
        "        # Maybe, length of the message vector can serve as attention\n",
        "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
        "        # the mask attend here is most probably just for zeroing out the padded positions\n",
        "        # I do not think it will matter that much\n",
        "        if mask_attend is not None:\n",
        "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
        "            # why divide by 30 when we are dealing with 48 neighbors in the current version of the model?\n",
        "        # Let me check the messages corresponding to \n",
        "        dh = torch.sum(h_message, -2) / self.scale\n",
        "\n",
        "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
        "\n",
        "        # Position-wise feedforward\n",
        "        dh = self.dense(h_V)\n",
        "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
        "\n",
        "        if mask_V is not None:\n",
        "            mask_V = mask_V.unsqueeze(-1)\n",
        "            h_V = mask_V * h_V\n",
        "\n",
        "        # \"h_message\" can be returned without dividing by \"self.scale\" also\n",
        "        return h_V, (h_message/self.scale) \n",
        "\n",
        "\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, num_hidden, num_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.W_in = nn.Linear(num_hidden, num_ff, bias=True)\n",
        "        self.W_out = nn.Linear(num_ff, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "    def forward(self, h_V):\n",
        "        h = self.act(self.W_in(h_V))\n",
        "        h = self.W_out(h)\n",
        "        return h\n",
        "\n",
        "class PositionalEncodings(nn.Module):\n",
        "    def __init__(self, num_embeddings, max_relative_feature=32):\n",
        "        super(PositionalEncodings, self).__init__()\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.max_relative_feature = max_relative_feature\n",
        "        self.linear = nn.Linear(2*max_relative_feature+1+1, num_embeddings)\n",
        "\n",
        "    def forward(self, offset, mask):\n",
        "        d = torch.clip(offset + self.max_relative_feature, 0, 2*self.max_relative_feature)*mask + (1-mask)*(2*self.max_relative_feature+1)\n",
        "        d_onehot = torch.nn.functional.one_hot(d, 2*self.max_relative_feature+1+1)\n",
        "        E = self.linear(d_onehot.float())\n",
        "        return E\n",
        "\n",
        "# Does not look like this function needs to be modified for now to use the model as sort of an energy function\n",
        "# The only thing that could do something is \"top_k\", which can be changed for considering more or less neighbors\n",
        "# for each of the nodes, but that too I think does not matter if the default value of top_k is updated by parameter passing\n",
        "# This function is called from the model itself with node_features=128, edge_features=128, and top_k=48\n",
        "# ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
        "class ProteinFeatures(nn.Module):\n",
        "    def __init__(self, edge_features, node_features, num_positional_embeddings=16,\n",
        "        num_rbf=16, top_k=30, augment_eps=0., num_chain_embeddings=16):\n",
        "        \"\"\" Extract protein features \"\"\"\n",
        "        super(ProteinFeatures, self).__init__()\n",
        "        self.edge_features = edge_features\n",
        "        self.node_features = node_features\n",
        "        self.top_k = top_k\n",
        "        self.augment_eps = augment_eps \n",
        "        self.num_rbf = num_rbf\n",
        "        self.num_positional_embeddings = num_positional_embeddings\n",
        "\n",
        "        self.embeddings = PositionalEncodings(num_positional_embeddings)\n",
        "        node_in, edge_in = 6, num_positional_embeddings + num_rbf*25\n",
        "        self.edge_embedding = nn.Linear(edge_in, edge_features, bias=False)\n",
        "        self.norm_edges = nn.LayerNorm(edge_features)\n",
        "\n",
        "    # the output of this function MUST be analyzed either directly or via some other function to \n",
        "    # understand how to get \"index/position\" of neighbors\n",
        "    def _dist(self, X, mask, eps=1E-6):\n",
        "        mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
        "        dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
        "        D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
        "        D_max, _ = torch.max(D, -1, keepdim=True)\n",
        "        D_adjust = D + (1. - mask_2D) * D_max\n",
        "        sampled_top_k = self.top_k\n",
        "        D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(self.top_k, X.shape[1]), dim=-1, largest=False)\n",
        "        return D_neighbors, E_idx\n",
        "\n",
        "    def _rbf(self, D):\n",
        "        device = D.device\n",
        "        D_min, D_max, D_count = 2., 22., self.num_rbf\n",
        "        D_mu = torch.linspace(D_min, D_max, D_count, device=device)\n",
        "        D_mu = D_mu.view([1,1,1,-1])\n",
        "        D_sigma = (D_max - D_min) / D_count\n",
        "        D_expand = torch.unsqueeze(D, -1)\n",
        "        RBF = torch.exp(-((D_expand - D_mu) / D_sigma)**2)\n",
        "        return RBF\n",
        "\n",
        "    def _get_rbf(self, A, B, E_idx):\n",
        "        D_A_B = torch.sqrt(torch.sum((A[:,:,None,:] - B[:,None,:,:])**2,-1) + 1e-6) #[B, L, L]\n",
        "        D_A_B_neighbors = gather_edges(D_A_B[:,:,:,None], E_idx)[:,:,:,0] #[B,L,K]\n",
        "        RBF_A_B = self._rbf(D_A_B_neighbors)\n",
        "        return RBF_A_B\n",
        "\n",
        "    # this function will be called with the arguments as forward(), but will return information regarding \n",
        "    # the neighbors which I will figure out a way to parse\n",
        "    def return_neighbor_info(self, X, mask, residue_idx, chain_labels):\n",
        "        b = X[:,:,1,:] - X[:,:,0,:]\n",
        "        c = X[:,:,2,:] - X[:,:,1,:]\n",
        "        a = torch.cross(b, c, dim=-1)\n",
        "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "        Ca = X[:,:,1,:]\n",
        "        N = X[:,:,0,:]\n",
        "        C = X[:,:,2,:]\n",
        "        O = X[:,:,3,:]\n",
        " \n",
        "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
        "\n",
        "\n",
        "    def forward(self, X, mask, residue_idx, chain_labels):\n",
        "        if self.augment_eps > 0:\n",
        "            X = X + self.augment_eps * torch.randn_like(X)\n",
        "        \n",
        "        b = X[:,:,1,:] - X[:,:,0,:]\n",
        "        c = X[:,:,2,:] - X[:,:,1,:]\n",
        "        a = torch.cross(b, c, dim=-1)\n",
        "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "        Ca = X[:,:,1,:]\n",
        "        N = X[:,:,0,:]\n",
        "        C = X[:,:,2,:]\n",
        "        O = X[:,:,3,:]\n",
        " \n",
        "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
        "\n",
        "        RBF_all = []\n",
        "        RBF_all.append(self._rbf(D_neighbors)) #Ca-Ca\n",
        "        RBF_all.append(self._get_rbf(N, N, E_idx)) #N-N\n",
        "        RBF_all.append(self._get_rbf(C, C, E_idx)) #C-C\n",
        "        RBF_all.append(self._get_rbf(O, O, E_idx)) #O-O\n",
        "        RBF_all.append(self._get_rbf(Cb, Cb, E_idx)) #Cb-Cb\n",
        "        RBF_all.append(self._get_rbf(Ca, N, E_idx)) #Ca-N\n",
        "        RBF_all.append(self._get_rbf(Ca, C, E_idx)) #Ca-C\n",
        "        RBF_all.append(self._get_rbf(Ca, O, E_idx)) #Ca-O\n",
        "        RBF_all.append(self._get_rbf(Ca, Cb, E_idx)) #Ca-Cb\n",
        "        RBF_all.append(self._get_rbf(N, C, E_idx)) #N-C\n",
        "        RBF_all.append(self._get_rbf(N, O, E_idx)) #N-O\n",
        "        RBF_all.append(self._get_rbf(N, Cb, E_idx)) #N-Cb\n",
        "        RBF_all.append(self._get_rbf(Cb, C, E_idx)) #Cb-C\n",
        "        RBF_all.append(self._get_rbf(Cb, O, E_idx)) #Cb-O\n",
        "        RBF_all.append(self._get_rbf(O, C, E_idx)) #O-C\n",
        "        RBF_all.append(self._get_rbf(N, Ca, E_idx)) #N-Ca\n",
        "        RBF_all.append(self._get_rbf(C, Ca, E_idx)) #C-Ca\n",
        "        RBF_all.append(self._get_rbf(O, Ca, E_idx)) #O-Ca\n",
        "        RBF_all.append(self._get_rbf(Cb, Ca, E_idx)) #Cb-Ca\n",
        "        RBF_all.append(self._get_rbf(C, N, E_idx)) #C-N\n",
        "        RBF_all.append(self._get_rbf(O, N, E_idx)) #O-N\n",
        "        RBF_all.append(self._get_rbf(Cb, N, E_idx)) #Cb-N\n",
        "        RBF_all.append(self._get_rbf(C, Cb, E_idx)) #C-Cb\n",
        "        RBF_all.append(self._get_rbf(O, Cb, E_idx)) #O-Cb\n",
        "        RBF_all.append(self._get_rbf(C, O, E_idx)) #C-O\n",
        "        RBF_all = torch.cat(tuple(RBF_all), dim=-1)\n",
        "\n",
        "        offset = residue_idx[:,:,None]-residue_idx[:,None,:]\n",
        "        offset = gather_edges(offset[:,:,:,None], E_idx)[:,:,:,0] #[B, L, K]\n",
        "\n",
        "        d_chains = ((chain_labels[:, :, None] - chain_labels[:,None,:])==0).long() #find self vs non-self interaction\n",
        "        E_chains = gather_edges(d_chains[:,:,:,None], E_idx)[:,:,:,0]\n",
        "        E_positional = self.embeddings(offset.long(), E_chains)\n",
        "        E = torch.cat((E_positional, RBF_all), -1)\n",
        "        E = self.edge_embedding(E)\n",
        "        E = self.norm_edges(E)\n",
        "        return E, E_idx \n",
        "\n",
        "\n",
        "\n",
        "class ProteinMPNN(nn.Module):\n",
        "    # \"node_features\" and \"edge_features\" are actually dimensionality of these features (\"hidden_dim\" in the calling script)\n",
        "    # the value is 128 for the version that I am using\n",
        "    def __init__(self, num_letters, node_features, edge_features,\n",
        "        hidden_dim, num_encoder_layers=3, num_decoder_layers=3,\n",
        "        vocab=21, k_neighbors=64, augment_eps=0.05, dropout=0.1):\n",
        "        super(ProteinMPNN, self).__init__()\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.node_features = node_features\n",
        "        self.edge_features = edge_features\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Featurization layers\n",
        "        # The version that I am using considers 48 neighbors for each position\n",
        "        self.features = ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
        "\n",
        "        self.W_e = nn.Linear(edge_features, hidden_dim, bias=True)\n",
        "        # This W_s is for embedding the sequence\n",
        "        self.W_s = nn.Embedding(vocab, hidden_dim)\n",
        "\n",
        "        # Encoder layers\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            EncLayer(hidden_dim, hidden_dim*2, dropout=dropout)\n",
        "            for _ in range(num_encoder_layers)\n",
        "        ])\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            DecLayer(hidden_dim, hidden_dim*3, dropout=dropout)\n",
        "            for _ in range(num_decoder_layers)\n",
        "        ])\n",
        "        self.W_out = nn.Linear(hidden_dim, num_letters, bias=True)\n",
        "\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    # Creating my own versions of forward should be an easy way to get embeddings or attention weights from diffrerent layers of the model\n",
        "    # See here (https://discuss.pytorch.org/t/how-can-i-extract-intermediate-layer-output-from-loaded-cnn-model/77301) in the forums for adding forward\n",
        "    # hooks or manipulating the forward method\n",
        "    # but my easy solution would be to create different versions of the forward method with different namaes, and calling them explicitly\n",
        "    # \"chain_M\" and \"mask\" seem to be the things that I need to understand very well and play-around with \n",
        "    def forward(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn, use_input_decoding_order=False, decoding_order=None):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Concatenate sequence embeddings for autoregressive decoder\n",
        "        # h_S denotes embedding of the sequence itself for use in decoder\n",
        "        h_S = self.W_s(S)\n",
        "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "\n",
        "\n",
        "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
        "        if not use_input_decoding_order:\n",
        "            decoding_order = torch.argsort((chain_M+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for layer in self.decoder_layers:\n",
        "            # Masked positions attend to encoder information, unmasked see. \n",
        "            h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "            h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
        "            # only the last layer decoder-messages will be stored in \"decoder_messages\"\n",
        "            h_V, decoder_messages = layer(h_V, h_ESV, mask)\n",
        "\n",
        "        logits = self.W_out(h_V)\n",
        "        # The probabilities are passed through log() function so that the sequences can be ranked based by summing the respective values \n",
        "        # for each position instead of multiplication \n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        # messages from the last layer decoder will also be returned for extracting neighbor-attention approximation\n",
        "        return log_probs, decoder_messages\n",
        "\n",
        "\n",
        "\n",
        "    # Seems like this is the method which is used by the notebook for calculating probabilites and scoring\n",
        "    # Need to dig into it thoroughly\n",
        "    # \"chain_mask\" and \"residue_idx\" seem like the tensors of interest\n",
        "    def sample(self, X, randn, S_true, chain_mask, chain_encoding_all, residue_idx, mask=None, temperature=1.0, omit_AAs_np=None, bias_AAs_np=None, chain_M_pos=None, omit_AA_mask=None, pssm_coef=None, pssm_bias=None, pssm_multi=None, pssm_log_odds_flag=None, pssm_log_odds_mask=None, pssm_bias_flag=None, bias_by_res=None):\n",
        "        device = X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Decoder uses masked self-attention\n",
        "        chain_mask = chain_mask*chain_M_pos*mask #update chain_M to include missing regions\n",
        "        decoding_order = torch.argsort((chain_mask+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        N_batch, N_nodes = X.size(0), X.size(1)\n",
        "        log_probs = torch.zeros((N_batch, N_nodes, 21), device=device)\n",
        "        all_probs = torch.zeros((N_batch, N_nodes, 21), device=device, dtype=torch.float32)\n",
        "        h_S = torch.zeros_like(h_V, device=device)\n",
        "        S = torch.zeros((N_batch, N_nodes), dtype=torch.int64, device=device)\n",
        "        h_V_stack = [h_V] + [torch.zeros_like(h_V, device=device) for _ in range(len(self.decoder_layers))]\n",
        "        constant = torch.tensor(omit_AAs_np, device=device)\n",
        "        constant_bias = torch.tensor(bias_AAs_np, device=device)\n",
        "        #chain_mask_combined = chain_mask*chain_M_pos \n",
        "        omit_AA_mask_flag = omit_AA_mask != None\n",
        "\n",
        "\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for t_ in range(N_nodes):\n",
        "            t = decoding_order[:,t_] #[B]\n",
        "            chain_mask_gathered = torch.gather(chain_mask, 1, t[:,None]) #[B]\n",
        "            bias_by_res_gathered = torch.gather(bias_by_res, 1, t[:,None,None].repeat(1,1,21))[:,0,:] #[B, 21]\n",
        "            if (chain_mask_gathered==0).all():\n",
        "                S_t = torch.gather(S_true, 1, t[:,None])\n",
        "            else:\n",
        "                # Hidden layers\n",
        "                E_idx_t = torch.gather(E_idx, 1, t[:,None,None].repeat(1,1,E_idx.shape[-1]))\n",
        "                h_E_t = torch.gather(h_E, 1, t[:,None,None,None].repeat(1,1,h_E.shape[-2], h_E.shape[-1]))\n",
        "                h_ES_t = cat_neighbors_nodes(h_S, h_E_t, E_idx_t)\n",
        "                h_EXV_encoder_t = torch.gather(h_EXV_encoder_fw, 1, t[:,None,None,None].repeat(1,1,h_EXV_encoder_fw.shape[-2], h_EXV_encoder_fw.shape[-1]))\n",
        "                mask_t = torch.gather(mask, 1, t[:,None])\n",
        "                for l, layer in enumerate(self.decoder_layers):\n",
        "                    # Updated relational features for future states\n",
        "                    h_ESV_decoder_t = cat_neighbors_nodes(h_V_stack[l], h_ES_t, E_idx_t)\n",
        "                    h_V_t = torch.gather(h_V_stack[l], 1, t[:,None,None].repeat(1,1,h_V_stack[l].shape[-1]))\n",
        "                    h_ESV_t = torch.gather(mask_bw, 1, t[:,None,None,None].repeat(1,1,mask_bw.shape[-2], mask_bw.shape[-1])) * h_ESV_decoder_t + h_EXV_encoder_t\n",
        "                    h_V_stack[l+1].scatter_(1, t[:,None,None].repeat(1,1,h_V.shape[-1]), layer(h_V_t, h_ESV_t, mask_V=mask_t))\n",
        "                # Sampling step\n",
        "                h_V_t = torch.gather(h_V_stack[-1], 1, t[:,None,None].repeat(1,1,h_V_stack[-1].shape[-1]))[:,0]\n",
        "                logits = self.W_out(h_V_t) / temperature\n",
        "                probs = F.softmax(logits-constant[None,:]*1e8+constant_bias[None,:]/temperature+bias_by_res_gathered/temperature, dim=-1)\n",
        "                if pssm_bias_flag:\n",
        "                    pssm_coef_gathered = torch.gather(pssm_coef, 1, t[:,None])[:,0]\n",
        "                    pssm_bias_gathered = torch.gather(pssm_bias, 1, t[:,None,None].repeat(1,1,pssm_bias.shape[-1]))[:,0]\n",
        "                    probs = (1-pssm_multi*pssm_coef_gathered[:,None])*probs + pssm_multi*pssm_coef_gathered[:,None]*pssm_bias_gathered\n",
        "                if pssm_log_odds_flag:\n",
        "                    pssm_log_odds_mask_gathered = torch.gather(pssm_log_odds_mask, 1, t[:,None, None].repeat(1,1,pssm_log_odds_mask.shape[-1]))[:,0] #[B, 21]\n",
        "                    probs_masked = probs*pssm_log_odds_mask_gathered\n",
        "                    probs_masked += probs * 0.001\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                if omit_AA_mask_flag:\n",
        "                    omit_AA_mask_gathered = torch.gather(omit_AA_mask, 1, t[:,None, None].repeat(1,1,omit_AA_mask.shape[-1]))[:,0] #[B, 21]\n",
        "                    probs_masked = probs*(1.0-omit_AA_mask_gathered)\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                # Here is where sampling from the multinomial distribution is happening\n",
        "                # this will sample 1 element according to the given distribution, and return the index of that element [from 0 to 20]\n",
        "                S_t = torch.multinomial(probs, 1)\n",
        "                all_probs.scatter_(1, t[:,None,None].repeat(1,1,21), (chain_mask_gathered[:,:,None,]*probs[:,None,:]).float())\n",
        "            S_true_gathered = torch.gather(S_true, 1, t[:,None])\n",
        "            S_t = (S_t*chain_mask_gathered+S_true_gathered*(1.0-chain_mask_gathered)).long()\n",
        "            temp1 = self.W_s(S_t)\n",
        "            h_S.scatter_(1, t[:,None,None].repeat(1,1,temp1.shape[-1]), temp1)\n",
        "            S.scatter_(1, t[:,None], S_t)\n",
        "        output_dict = {\"S\": S, \"probs\": all_probs, \"decoding_order\": decoding_order}\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "    def tied_sample(self, X, randn, S_true, chain_mask, chain_encoding_all, residue_idx, mask=None, temperature=1.0, omit_AAs_np=None, bias_AAs_np=None, chain_M_pos=None, omit_AA_mask=None, pssm_coef=None, pssm_bias=None, pssm_multi=None, pssm_log_odds_flag=None, pssm_log_odds_mask=None, pssm_bias_flag=None, tied_pos=None, tied_beta=None, bias_by_res=None):\n",
        "        device = X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=device)\n",
        "        h_E = self.W_e(E)\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Decoder uses masked self-attention\n",
        "        chain_mask = chain_mask*chain_M_pos*mask #update chain_M to include missing regions\n",
        "        decoding_order = torch.argsort((chain_mask+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "\n",
        "        new_decoding_order = []\n",
        "        for t_dec in list(decoding_order[0,].cpu().data.numpy()):\n",
        "            if t_dec not in list(itertools.chain(*new_decoding_order)):\n",
        "                list_a = [item for item in tied_pos if t_dec in item]\n",
        "                if list_a:\n",
        "                    new_decoding_order.append(list_a[0])\n",
        "                else:\n",
        "                    new_decoding_order.append([t_dec])\n",
        "        decoding_order = torch.tensor(list(itertools.chain(*new_decoding_order)), device=device)[None,].repeat(X.shape[0],1)\n",
        "\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        N_batch, N_nodes = X.size(0), X.size(1)\n",
        "        log_probs = torch.zeros((N_batch, N_nodes, 21), device=device)\n",
        "        all_probs = torch.zeros((N_batch, N_nodes, 21), device=device, dtype=torch.float32)\n",
        "        h_S = torch.zeros_like(h_V, device=device)\n",
        "        S = torch.zeros((N_batch, N_nodes), dtype=torch.int64, device=device)\n",
        "        h_V_stack = [h_V] + [torch.zeros_like(h_V, device=device) for _ in range(len(self.decoder_layers))]\n",
        "        constant = torch.tensor(omit_AAs_np, device=device)\n",
        "        constant_bias = torch.tensor(bias_AAs_np, device=device)\n",
        "        omit_AA_mask_flag = omit_AA_mask != None\n",
        "\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for t_list in new_decoding_order:\n",
        "            logits = 0.0\n",
        "            logit_list = []\n",
        "            done_flag = False\n",
        "            for t in t_list:\n",
        "                if (chain_mask[:,t]==0).all():\n",
        "                    S_t = S_true[:,t]\n",
        "                    for t in t_list:\n",
        "                        h_S[:,t,:] = self.W_s(S_t)\n",
        "                        S[:,t] = S_t\n",
        "                    done_flag = True\n",
        "                    break\n",
        "                else:\n",
        "                    E_idx_t = E_idx[:,t:t+1,:]\n",
        "                    h_E_t = h_E[:,t:t+1,:,:]\n",
        "                    h_ES_t = cat_neighbors_nodes(h_S, h_E_t, E_idx_t)\n",
        "                    h_EXV_encoder_t = h_EXV_encoder_fw[:,t:t+1,:,:]\n",
        "                    mask_t = mask[:,t:t+1]\n",
        "                    for l, layer in enumerate(self.decoder_layers):\n",
        "                        h_ESV_decoder_t = cat_neighbors_nodes(h_V_stack[l], h_ES_t, E_idx_t)\n",
        "                        h_V_t = h_V_stack[l][:,t:t+1,:]\n",
        "                        h_ESV_t = mask_bw[:,t:t+1,:,:] * h_ESV_decoder_t + h_EXV_encoder_t\n",
        "                        h_V_stack[l+1][:,t,:] = layer(h_V_t, h_ESV_t, mask_V=mask_t).squeeze(1)\n",
        "                    h_V_t = h_V_stack[-1][:,t,:]\n",
        "                    logit_list.append((self.W_out(h_V_t) / temperature)/len(t_list))\n",
        "                    logits += tied_beta[t]*(self.W_out(h_V_t) / temperature)/len(t_list)\n",
        "            if done_flag:\n",
        "                pass\n",
        "            else:\n",
        "                bias_by_res_gathered = bias_by_res[:,t,:] #[B, 21]\n",
        "                probs = F.softmax(logits-constant[None,:]*1e8+constant_bias[None,:]/temperature+bias_by_res_gathered/temperature, dim=-1)\n",
        "                if pssm_bias_flag:\n",
        "                    pssm_coef_gathered = pssm_coef[:,t]\n",
        "                    pssm_bias_gathered = pssm_bias[:,t]\n",
        "                    probs = (1-pssm_multi*pssm_coef_gathered[:,None])*probs + pssm_multi*pssm_coef_gathered[:,None]*pssm_bias_gathered\n",
        "                if pssm_log_odds_flag:\n",
        "                    pssm_log_odds_mask_gathered = pssm_log_odds_mask[:,t]\n",
        "                    probs_masked = probs*pssm_log_odds_mask_gathered\n",
        "                    probs_masked += probs * 0.001\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                if omit_AA_mask_flag:\n",
        "                    omit_AA_mask_gathered = omit_AA_mask[:,t]\n",
        "                    probs_masked = probs*(1.0-omit_AA_mask_gathered)\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                S_t_repeat = torch.multinomial(probs, 1).squeeze(-1)\n",
        "                for t in t_list:\n",
        "                    h_S[:,t,:] = self.W_s(S_t_repeat)\n",
        "                    S[:,t] = S_t_repeat\n",
        "                    all_probs[:,t,:] = probs.float()\n",
        "        output_dict = {\"S\": S, \"probs\": all_probs, \"decoding_order\": decoding_order}\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "    # I am not seeing an immediate use of this method when the model is called through notebook\n",
        "    # So, will skip further commenting and digging for now\n",
        "    # But, seems like an interesting way of interacting with the model in a specific way, so\n",
        "    # might get back to this later\n",
        "    def conditional_probs(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn, backbone_only=False):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V_enc = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V_enc, h_E = layer(h_V_enc, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Concatenate sequence embeddings for autoregressive decoder\n",
        "        h_S = self.W_s(S)\n",
        "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V_enc, h_EX_encoder, E_idx)\n",
        "\n",
        "\n",
        "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
        "  \n",
        "        chain_M_np = chain_M.cpu().numpy()\n",
        "        idx_to_loop = np.argwhere(chain_M_np[0,:]==1)[:,0]\n",
        "        log_conditional_probs = torch.zeros([X.shape[0], chain_M.shape[1], 21], device=device).float()\n",
        "\n",
        "        for idx in idx_to_loop:\n",
        "            h_V = torch.clone(h_V_enc)\n",
        "            order_mask = torch.zeros(chain_M.shape[1], device=device).float()\n",
        "            if backbone_only:\n",
        "                order_mask = torch.ones(chain_M.shape[1], device=device).float()\n",
        "                order_mask[idx] = 0.\n",
        "            else:\n",
        "                order_mask = torch.zeros(chain_M.shape[1], device=device).float()\n",
        "                order_mask[idx] = 1.\n",
        "            decoding_order = torch.argsort((order_mask[None,]+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "            mask_size = E_idx.shape[1]\n",
        "            permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "            order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "            mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "            mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "            mask_bw = mask_1D * mask_attend\n",
        "            mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "            h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "            for layer in self.decoder_layers:\n",
        "                # Masked positions attend to encoder information, unmasked see. \n",
        "                h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "                h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
        "                h_V = layer(h_V, h_ESV, mask)\n",
        "\n",
        "            logits = self.W_out(h_V)\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "            log_conditional_probs[:,idx,:] = log_probs[:,idx,:]\n",
        "        return log_conditional_probs\n",
        "\n",
        "\n",
        "    # I am not seeing an immediate use of this method when the model is called through notebook\n",
        "    # So, will skip further commenting and digging for now\n",
        "    # But, seems like an interesting way of interacting with the model in a specific way, so\n",
        "    # might get back to this later\n",
        "    def unconditional_probs(self, X, mask, residue_idx, chain_encoding_all):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_V), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "\n",
        "        order_mask_backward = torch.zeros([X.shape[0], X.shape[1], X.shape[1]], device=device)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for layer in self.decoder_layers:\n",
        "            h_V = layer(h_V, h_EXV_encoder_fw, mask)\n",
        "\n",
        "        logits = self.W_out(h_V)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        return log_probs"
      ],
      "metadata": {
        "id": "HjbVWJkg7zik"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 128\n",
        "num_layers = 3 \n",
        "# Seems like, backbone_noise is set to 0 at inference path which seems logical\n",
        "backbone_noise=0.00\n",
        "mpnn_model = ProteinMPNN(num_letters=21, node_features=hidden_dim, edge_features=hidden_dim, hidden_dim=hidden_dim, num_encoder_layers=num_layers, num_decoder_layers=num_layers, augment_eps=backbone_noise, k_neighbors=checkpoint['num_edges'])\n",
        "mpnn_model.to(device)\n",
        "mpnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "mpnn_model.eval()"
      ],
      "metadata": {
        "id": "QBgBJd3J0N_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint['model_state_dict'].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pYLpMQS-ill",
        "outputId": "f84f155d-80fc-42ef-bc96-d0469f89d0f5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['features.embeddings.linear.weight', 'features.embeddings.linear.bias', 'features.edge_embedding.weight', 'features.norm_edges.weight', 'features.norm_edges.bias', 'W_e.weight', 'W_e.bias', 'W_s.weight', 'encoder_layers.0.norm1.weight', 'encoder_layers.0.norm1.bias', 'encoder_layers.0.norm2.weight', 'encoder_layers.0.norm2.bias', 'encoder_layers.0.norm3.weight', 'encoder_layers.0.norm3.bias', 'encoder_layers.0.W1.weight', 'encoder_layers.0.W1.bias', 'encoder_layers.0.W2.weight', 'encoder_layers.0.W2.bias', 'encoder_layers.0.W3.weight', 'encoder_layers.0.W3.bias', 'encoder_layers.0.W11.weight', 'encoder_layers.0.W11.bias', 'encoder_layers.0.W12.weight', 'encoder_layers.0.W12.bias', 'encoder_layers.0.W13.weight', 'encoder_layers.0.W13.bias', 'encoder_layers.0.dense.W_in.weight', 'encoder_layers.0.dense.W_in.bias', 'encoder_layers.0.dense.W_out.weight', 'encoder_layers.0.dense.W_out.bias', 'encoder_layers.1.norm1.weight', 'encoder_layers.1.norm1.bias', 'encoder_layers.1.norm2.weight', 'encoder_layers.1.norm2.bias', 'encoder_layers.1.norm3.weight', 'encoder_layers.1.norm3.bias', 'encoder_layers.1.W1.weight', 'encoder_layers.1.W1.bias', 'encoder_layers.1.W2.weight', 'encoder_layers.1.W2.bias', 'encoder_layers.1.W3.weight', 'encoder_layers.1.W3.bias', 'encoder_layers.1.W11.weight', 'encoder_layers.1.W11.bias', 'encoder_layers.1.W12.weight', 'encoder_layers.1.W12.bias', 'encoder_layers.1.W13.weight', 'encoder_layers.1.W13.bias', 'encoder_layers.1.dense.W_in.weight', 'encoder_layers.1.dense.W_in.bias', 'encoder_layers.1.dense.W_out.weight', 'encoder_layers.1.dense.W_out.bias', 'encoder_layers.2.norm1.weight', 'encoder_layers.2.norm1.bias', 'encoder_layers.2.norm2.weight', 'encoder_layers.2.norm2.bias', 'encoder_layers.2.norm3.weight', 'encoder_layers.2.norm3.bias', 'encoder_layers.2.W1.weight', 'encoder_layers.2.W1.bias', 'encoder_layers.2.W2.weight', 'encoder_layers.2.W2.bias', 'encoder_layers.2.W3.weight', 'encoder_layers.2.W3.bias', 'encoder_layers.2.W11.weight', 'encoder_layers.2.W11.bias', 'encoder_layers.2.W12.weight', 'encoder_layers.2.W12.bias', 'encoder_layers.2.W13.weight', 'encoder_layers.2.W13.bias', 'encoder_layers.2.dense.W_in.weight', 'encoder_layers.2.dense.W_in.bias', 'encoder_layers.2.dense.W_out.weight', 'encoder_layers.2.dense.W_out.bias', 'decoder_layers.0.norm1.weight', 'decoder_layers.0.norm1.bias', 'decoder_layers.0.norm2.weight', 'decoder_layers.0.norm2.bias', 'decoder_layers.0.W1.weight', 'decoder_layers.0.W1.bias', 'decoder_layers.0.W2.weight', 'decoder_layers.0.W2.bias', 'decoder_layers.0.W3.weight', 'decoder_layers.0.W3.bias', 'decoder_layers.0.dense.W_in.weight', 'decoder_layers.0.dense.W_in.bias', 'decoder_layers.0.dense.W_out.weight', 'decoder_layers.0.dense.W_out.bias', 'decoder_layers.1.norm1.weight', 'decoder_layers.1.norm1.bias', 'decoder_layers.1.norm2.weight', 'decoder_layers.1.norm2.bias', 'decoder_layers.1.W1.weight', 'decoder_layers.1.W1.bias', 'decoder_layers.1.W2.weight', 'decoder_layers.1.W2.bias', 'decoder_layers.1.W3.weight', 'decoder_layers.1.W3.bias', 'decoder_layers.1.dense.W_in.weight', 'decoder_layers.1.dense.W_in.bias', 'decoder_layers.1.dense.W_out.weight', 'decoder_layers.1.dense.W_out.bias', 'decoder_layers.2.norm1.weight', 'decoder_layers.2.norm1.bias', 'decoder_layers.2.norm2.weight', 'decoder_layers.2.norm2.bias', 'decoder_layers.2.W1.weight', 'decoder_layers.2.W1.bias', 'decoder_layers.2.W2.weight', 'decoder_layers.2.W2.bias', 'decoder_layers.2.W3.weight', 'decoder_layers.2.W3.bias', 'decoder_layers.2.dense.W_in.weight', 'decoder_layers.2.dense.W_in.bias', 'decoder_layers.2.dense.W_out.weight', 'decoder_layers.2.dense.W_out.bias', 'W_out.weight', 'W_out.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse and create dictionaries for all the mutations in PremPS 2648\n",
        "# This dictionary will be a dictionary of dictionaries, where outer-dict keys will be pdbid+mutchain and inner-dict keys will be (wild+pos+mut) and ddg\n",
        "# the icodes can be brought to picture later\n",
        "# this \"two_level_dict\" is literally used everywhere throughout this code for storing all the numbers that are compared with each other under feature-specific keys\n",
        "git_url = \"https://raw.githubusercontent.com/SajidAhmeduiu/PremPS/main/Datasets/S2648/S2648.txt\"\n",
        "dataset =  pd.read_csv(git_url,delimiter=\"\\t\")\n",
        "\n",
        "pdbIds = list(dataset[\"PDB Id\"])\n",
        "mutChains = list(dataset[\"Mutated Chain\"])\n",
        "mutations = list(dataset[\"Mutation_PDB\"])\n",
        "ddgs = list(dataset[\"DDGexp\"])\n",
        "\n",
        "two_level_dict = {}\n",
        "\n",
        "for pdbId, mutChain, mutation, ddg in tqdm(zip(pdbIds,mutChains,mutations,ddgs)):\n",
        "    pos = [int(s) for s in re.findall('-?\\d+',mutation)][0]\n",
        "    wild = mutation[0]\n",
        "    mut = mutation[len(mutation)-1]\n",
        "\n",
        "    pdbId = pdbId.lower()\n",
        "\n",
        "    inner_dict = {}\n",
        "    inner_dict[\"mut\"] = f\"{wild}{pos}{mut}\"\n",
        "    inner_dict[\"ddg\"] = float(ddg)\n",
        "    outer_key = f\"{pdbId}{mutChain}\"\n",
        "    if outer_key not in two_level_dict:\n",
        "        two_level_dict[f\"{pdbId}{mutChain}\"] = [inner_dict]\n",
        "    else:\n",
        "        two_level_dict[f\"{pdbId}{mutChain}\"].append(inner_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5d4d20ae18dd4e758aa5294bfcdc7b07",
            "fb72992182dc4b8d8216d54346dfb779",
            "f803ce7367f24afa81ccd372a8098e87",
            "37aa14460bf54ed587882960dd345db4",
            "c76ceaed859f4b38a7d5635da0eff5e9",
            "ab1146a756174b82b361a2baf4155d4b",
            "1312868b7afe4bb797d219c3931b3f0d",
            "581b60215ff64fec950f2b9c66a3b34a",
            "b480423f85f8401fbbf1fe82db2fc25c",
            "69bd9281ef30426396e248f6200e7c91",
            "9fc9c61b3bc243bea3cd5551d3cd6fc7"
          ]
        },
        "id": "vP_unq7_sXrn",
        "outputId": "5963c7ac-d1e2-4fbe-a148-6e365b998d4d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d4d20ae18dd4e758aa5294bfcdc7b07"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a seqres to position mapping dictionary\n",
        "# This dictionary will be a dictionary of dictionaries, where outer-dict keys will be pdbid+mutchain and inner-dict key will be (wild+pos) and value of 0-indexed position\n",
        "# the icodes can be brought to picture later\n",
        "mapping_dict = {}\n",
        "pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_2648_PDB_Files\"\n",
        "parser = PDBParser(QUIET=True)\n",
        "# some proteins need to be skipped for now due to ICODE related discrapency\n",
        "proteins_to_skip = []\n",
        "\n",
        "for filename in tqdm(os.listdir(pdbDirectory)):\n",
        "    filepath = os.path.join(pdbDirectory,filename)\n",
        "    structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "    model = structure[0]\n",
        "    inner_dict = {}\n",
        "    outer_key = filename.split(\".\")[0]\n",
        "    skip_flag = False\n",
        "    # single chain-assumption in action again\n",
        "    for chain in model:\n",
        "        for i,residue in enumerate(chain):\n",
        "            inner_key = f\"{three_to_one(residue.get_resname())}{residue.get_id()[1]}\"\n",
        "            if inner_key not in inner_dict:\n",
        "                inner_dict[inner_key] = i\n",
        "            else:\n",
        "                # For \"2immA:N31\" and \"1lveA:S27\", I have been fucked\n",
        "                # Need to think whether this will effect other positions or I can just avoid these two-protein related mutations for now?\n",
        "                # Let me just avoid these two proteins for now\n",
        "                print(\"YOU HAVE JUST BEEN FUCKED BY ICODE\")\n",
        "                print(f\"{outer_key}:{inner_key}\")\n",
        "                skip_flag = True\n",
        "    # The ICODE related problematic proteins will not be considered for now\n",
        "    if not skip_flag:\n",
        "        mapping_dict[outer_key] = inner_dict\n",
        "    else:\n",
        "        proteins_to_skip.append(outer_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "45ed6c31ef694dc99eaa6176e5f38586",
            "1b6172249b5f4dfa88e88b69be7e8aa4",
            "7096db0a4e954590bfdf247639f8c866",
            "7d63eeb763614a25a8a99448bf4252f4",
            "be80186a46b74714b38f0545a3d5e49b",
            "bd2961acf17d4e0b9609eb6fca59b75d",
            "541729e2b2574c799c2017b65e279873",
            "2557fc79fedb405ebc06a6b6c5ab04ad",
            "a237d3252bad4901bc03a9b09da7b5c6",
            "d300a8385100478cb9a99064796ea33c",
            "bf3b69001f24407a9c79e4d84c4b746b"
          ]
        },
        "id": "vxARThyX3VYv",
        "outputId": "41702403-f842-4b48-8faf-2bf25df5a5c8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/131 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45ed6c31ef694dc99eaa6176e5f38586"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "1lveA:S27\n",
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "1lveA:S27\n",
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "2immA:N31\n",
            "YOU HAVE JUST BEEN FUCKED BY ICODE\n",
            "2immA:N31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing this \"parse_PDB_biounits()\" function locally for addressing the fucked up integer named chain problem  \n",
        "def parse_PDB_biounits(x, atoms=['N', 'CA', 'C'], chain=None):\n",
        "    '''\n",
        "    input:  x = PDB filename\n",
        "            atoms = atoms to extract (optional)\n",
        "    output: (length, atoms, coords=(x,y,z)), sequence\n",
        "    '''\n",
        "    alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "    states = len(alpha_1)\n",
        "    alpha_3 = ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE',\n",
        "               'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL', 'GAP']\n",
        "\n",
        "    # The following dictionaries are mapping from one-letter to 0-20 index,\n",
        "    # three-letter to 0-20 index,\n",
        "    # 0-20 index to one-letter,\n",
        "    # one-letter to three-letter, and vice-versa\n",
        "    aa_1_N = {a: n for n, a in enumerate(alpha_1)}\n",
        "    aa_3_N = {a: n for n, a in enumerate(alpha_3)}\n",
        "    aa_N_1 = {n: a for n, a in enumerate(alpha_1)}\n",
        "    aa_1_3 = {a: b for a, b in zip(alpha_1, alpha_3)}\n",
        "    aa_3_1 = {b: a for a, b in zip(alpha_1, alpha_3)}\n",
        "\n",
        "    def AA_to_N(x):\n",
        "        # [\"ARND\"] -> [[0,1,2,3]]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 0: x = x[None]\n",
        "        return [[aa_1_N.get(a, states - 1) for a in y] for y in x]\n",
        "\n",
        "    def N_to_AA(x):\n",
        "        # [[0,1,2,3]] -> [\"ARND\"]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 1: x = x[None]\n",
        "        return [\"\".join([aa_N_1.get(a, \"-\") for a in y]) for y in x]\n",
        "\n",
        "    xyz, seq, min_resn, max_resn = {}, {}, 1e6, -1e6\n",
        "    for line in open(x, \"rb\"):\n",
        "        line = line.decode(\"utf-8\", \"ignore\").rstrip()\n",
        "\n",
        "        if line[:6] == \"HETATM\" and line[17:17 + 3] == \"MSE\":\n",
        "            line = line.replace(\"HETATM\", \"ATOM  \")\n",
        "            line = line.replace(\"MSE\", \"MET\")\n",
        "\n",
        "        if line[:4] == \"ATOM\":\n",
        "            ch = line[21:22]\n",
        "            # If the input chain is not in the PDB file, which can be the case if the target chains are named differently in the runner script,\n",
        "            # this line will cause the output to have literally no information, this is the case for integer named chains\n",
        "            # that does not mean that this line is not doing its job correctly, this is just a constraint that input chain names and\n",
        "            # chain names in the PDB file have to be congruent\n",
        "            # If \"ch\" is an integer, map it to alphabet, because input \"chain\" has been converted to alphabet\n",
        "            # In rare cases, some PDB files number chains with 1,2,3 instead of A,B,C\n",
        "            # This \"loc_dict\" dictionary contains integer to alphabet mapping for weird as fuck integer chain names\n",
        "            # This conversion will be done only when  chain name is actually an integer\n",
        "            if ord(ch) >= 49 and ord(ch) <= 57:\n",
        "                loc_dict = {(idx+1):ch for idx,ch in enumerate(ascii_uppercase)}\n",
        "                ch =  str(loc_dict[int(ch)])\n",
        "            if ch == chain or chain is None:\n",
        "                atom = line[12:12 + 4].strip()\n",
        "                resi = line[17:17 + 3]\n",
        "                resn = line[22:22 + 5].strip()\n",
        "                x, y, z = [float(line[i:(i + 8)]) for i in [30, 38, 46]]\n",
        "\n",
        "                if resn[-1].isalpha():\n",
        "                    resa, resn = resn[-1], int(resn[:-1]) - 1\n",
        "                else:\n",
        "                    resa, resn = \"\", int(resn) - 1\n",
        "                #         resn = int(resn)\n",
        "                if resn < min_resn:\n",
        "                    min_resn = resn\n",
        "                if resn > max_resn:\n",
        "                    max_resn = resn\n",
        "                if resn not in xyz:\n",
        "                    xyz[resn] = {}\n",
        "                if resa not in xyz[resn]:\n",
        "                    xyz[resn][resa] = {}\n",
        "                if resn not in seq:\n",
        "                    seq[resn] = {}\n",
        "                if resa not in seq[resn]:\n",
        "                    seq[resn][resa] = resi\n",
        "\n",
        "                if atom not in xyz[resn][resa]:\n",
        "                    xyz[resn][resa][atom] = np.array([x, y, z])\n",
        "\n",
        "    # convert to numpy arrays, fill in missing values\n",
        "    seq_, xyz_ = [], []\n",
        "    try:\n",
        "        for resn in range(min_resn, max_resn + 1):\n",
        "            if resn in seq:\n",
        "                for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k], 20))\n",
        "            else:\n",
        "                seq_.append(20)\n",
        "            if resn in xyz:\n",
        "                for k in sorted(xyz[resn]):\n",
        "                    for atom in atoms:\n",
        "                        if atom in xyz[resn][k]:\n",
        "                            xyz_.append(xyz[resn][k][atom])\n",
        "                        else:\n",
        "                            xyz_.append(np.full(3, np.nan))\n",
        "            else:\n",
        "                for atom in atoms: xyz_.append(np.full(3, np.nan))\n",
        "        return np.array(xyz_).reshape(-1, len(atoms), 3), N_to_AA(np.array(seq_))\n",
        "    except TypeError:\n",
        "        return 'no_chain', 'no_chain'\n",
        "\n",
        "# Took this part out of \"utils.py\", and put here so that smalll changes can be made to address pesky issues like\n",
        "# integer named chain, and shit like those\n",
        "def parse_PDB(path_to_pdb, input_chain_list=None):\n",
        "    c=0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V','W','X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v','w','x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "     \n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list  \n",
        " \n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    # Each of the biounits is a separate PDB file, so for running with a single PDB file like from colab, this loop will be executed only once\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {} \n",
        "        # This loop will be executed only once for single chain DDG type cases\n",
        "        for letter in chain_alphabet:\n",
        "            xyz, seq = parse_PDB_biounits(biounit, atoms=['N','CA','C','O'], chain=letter)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_'+letter]=seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                coords_dict_chain['N_chain_'+letter]=xyz[:,0,:].tolist()\n",
        "                coords_dict_chain['CA_chain_'+letter]=xyz[:,1,:].tolist()\n",
        "                coords_dict_chain['C_chain_'+letter]=xyz[:,2,:].tolist()\n",
        "                coords_dict_chain['O_chain_'+letter]=xyz[:,3,:].tolist()\n",
        "                my_dict['coords_chain_'+letter]=coords_dict_chain\n",
        "                s += 1\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        my_dict['name']=biounit[(fi+1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c+=1\n",
        "    return pdb_dict_list"
      ],
      "metadata": {
        "id": "UzBk27pmlfh7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_func_local(X, mask, eps=1E-6):\n",
        "    mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
        "    dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
        "    D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
        "    D_max, _ = torch.max(D, -1, keepdim=True)\n",
        "    D_adjust = D + (1. - mask_2D) * D_max\n",
        "    top_k = checkpoint[\"num_edges\"]\n",
        "    sampled_top_k = top_k\n",
        "    D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(top_k, X.shape[1]), dim=-1, largest=False)\n",
        "    return D_neighbors, E_idx\n",
        "\n",
        "def return_neighbor_info(X, mask):\n",
        "    b = X[:,:,1,:] - X[:,:,0,:]\n",
        "    c = X[:,:,2,:] - X[:,:,1,:]\n",
        "    a = torch.cross(b, c, dim=-1)\n",
        "    Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "    Ca = X[:,:,1,:]\n",
        "    N = X[:,:,0,:]\n",
        "    C = X[:,:,2,:]\n",
        "    O = X[:,:,3,:]\n",
        "\n",
        "    D_neighbors, E_idx = distance_func_local(Ca, mask)\n",
        "    # Got the indices of the neighbors, E_idx should be the 0-based indexing of the topK closest neighbors\n",
        "    # and D_neighbors should be the distances of those neighbors\n",
        "    return D_neighbors, E_idx"
      ],
      "metadata": {
        "id": "l6pA80oESa7Y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the PDB files from the directory where the S_2648 PDB Files are stored, and set-them up one by one for featuirization, and passing through the model\n",
        "pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_2648_PDB_Files\"\n",
        "parser = PDBParser(QUIET=True)\n",
        "for i,filename in tqdm(enumerate(os.listdir(pdbDirectory))):\n",
        "    #ICODE related problematic proteins will be skipped from analysis for now\n",
        "    if (filename.split(\".\")[0] not in proteins_to_skip):\n",
        "        if i > 2:\n",
        "            break\n",
        "        filepath = os.path.join(pdbDirectory,filename)\n",
        "        structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "        model = structure[0]\n",
        "        \n",
        "        # Since there is only one chain, and that same chain is both fixed designable for different residues, extracting that name, and putting them in pertinent lists\n",
        "        # taking chainname from filename since one of the files \"1rtpA.pdb\" has chain name with \"1\" instead of \"A\"\n",
        "        # fuck you motherfucking fucked up PDB file submitter. Have you shoved your head into your ass?\n",
        "        chain_name = (filename.split(\".\")[0])[-1]\n",
        "        fixed_chain_list = []\n",
        "        # the trick is to put the single chain as designable chain, and then create the \"fixed_positions_dict\" dictionary  \n",
        "        designed_chain_list = [chain_name]\n",
        "        chain_list = list(set(designed_chain_list + fixed_chain_list))\n",
        "\n",
        "        # Using the programs custome PDB parser for processing the PDB files\n",
        "        pdb_dict_list = parse_PDB(filepath, input_chain_list=chain_list)\n",
        "        # tacking max_length parameter value from the original colab notebook since I need to process all residues at the same time\n",
        "        # all the PDB files can technically be processed together and put inside the dataset_valid list-like object, but right now\n",
        "        # I am trying to keep everything consistent and simple\n",
        "        # Each element of dataset_valid is a dictionary \n",
        "        dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=20000)\n",
        "\n",
        "        # Simplying the sequence generation loop\n",
        "        protein = dataset_valid[0]\n",
        "\n",
        "        wildtype_seq = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        # If there are gaps in the wildtype_seq \"seq\", remove those positions from both the \"seq\", \"\" and ('coords_chain_{designed_chain_list[0]}'), \n",
        "        # and ('seq_chain_{designed_chain_list[0]}') of the \"protein\"\n",
        "        # print(protein.keys())\n",
        "        # protein is a dict with keys(['seq_chain_A', 'coords_chain_A', 'name', 'num_of_chains', 'seq'])\n",
        "        # \"seq_chain\" and \"seq_all\" are both strings of the same length where gapped positions need to be identified and removed\n",
        "        seq_chain = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "        seq_all = protein[f\"seq\"]\n",
        "        # \"coordinates_chain\" is a dict with keys(['N_chain_A', 'CA_chain_A', 'C_chain_A', 'O_chain_A'])\n",
        "        coordinates_chain = protein[f\"coords_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        \n",
        "        # The following four variables are lists of length equal to seq_chain and seq_all length\n",
        "        # Therefore, the gapped positions can be retrived from seq_chain and removed from everything accordingly\n",
        "        N_chain = coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"]\n",
        "        CA_chain = coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"]\n",
        "        C_chain = coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"]\n",
        "        O_chain = coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        # delete everything related to gapped positions now\n",
        "        # at first, find out the positions that are gapped\n",
        "        # these gapped positions are absolutely messed up fucked up artifact of some kind of sophistification \n",
        "        # provided by proteinMPNN, FUCK YOU motherfucking oversmart CODERS\n",
        "        N_chain = [v for i,v in enumerate(N_chain) if seq_chain[i] != \"-\"]\n",
        "        CA_chain = [v for i,v in enumerate(CA_chain) if seq_chain[i] != \"-\"]\n",
        "        C_chain = [v for i,v in enumerate(C_chain) if seq_chain[i] != \"-\"]\n",
        "        O_chain = [v for i,v in enumerate(O_chain) if seq_chain[i] != \"-\"]\n",
        "        seq_all = [v for i,v in enumerate(seq_all) if seq_chain[i] != \"-\"]\n",
        "        seq_chain = [v for i,v in enumerate(seq_chain) if seq_chain[i] != \"-\"]\n",
        "\n",
        "        # Now, finally, pack everything back to the dictionary \"protein\"\n",
        "        protein[f\"seq_chain_{designed_chain_list[0]}\"] = seq_chain\n",
        "        protein[f\"seq\"] = seq_all\n",
        "        coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"] = N_chain\n",
        "        coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"] = CA_chain\n",
        "        coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"] = C_chain\n",
        "        coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"] = O_chain\n",
        "        protein[f\"coords_chain_{designed_chain_list[0]}\"] = coordinates_chain\n",
        "\n",
        "        # At this point, probably need to put None values in a lot of parameters that are not relevant to my usecase, but need to be sent to featurizer before running model forward\n",
        "        # For now, I will not tie positions together\n",
        "        tied_positions_dict = None\n",
        "        pssm_dict = None\n",
        "        omit_AA_dict = None\n",
        "        bias_AA_dict = None\n",
        "        tied_positions_dict = None\n",
        "        bias_by_res_dict = None\n",
        "        alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "        bias_AAs_np = np.zeros(len(alphabet))\n",
        "\n",
        "        chain_id_dict = {}\n",
        "        chain_id_dict[pdb_dict_list[0]['name']]= (designed_chain_list, fixed_chain_list)\n",
        "\n",
        "        BATCH_COPIES = 1\n",
        "\n",
        "        batch_clones = [copy.deepcopy(protein) for i in range(BATCH_COPIES)]\n",
        "\n",
        "        # \"muts_for_prot\" is a list with information about all the mutations in \"protein\", whose sequence only version is \"wildtype_seq\" \n",
        "        muts_for_prot = two_level_dict[filename.split(\".\")[0]]\n",
        "        # \"cur_map_dict\" will give the 0-based sequence index for the mutations, which will be almost directly used for masking and then running the model\n",
        "        # 1-based indexing needed for the fixed position\n",
        "        cur_map_dict = mapping_dict[filename.split(\".\")[0]]\n",
        "\n",
        "        for mut in muts_for_prot:\n",
        "            wild_aa = mut[\"mut\"][0]\n",
        "            # (+1) because we need to pass 1-based indexing to tied_featurize() method\n",
        "            seq_pos = cur_map_dict[mut[\"mut\"][0:-1]] + 1\n",
        "            # only need to mask the mutated position position in \"wildtype_seq\" for now\n",
        "            fixed_positions_dict = {}\n",
        "            fixed_positions_dict[protein[\"name\"]] = {}\n",
        "            f_list = []\n",
        "            for ind_fixed in range(0,len(seq_chain)):\n",
        "                if (ind_fixed + 1) not in [seq_pos]:\n",
        "                    f_list.append(ind_fixed + 1)\n",
        "            fixed_positions_dict[protein[\"name\"]][filename.split(\".\")[0][-1]] = f_list\n",
        "\n",
        "            # finally, had to take chain-name from filename instead of biopython parsing to get rid of chain-name with \"1\" instead of \"A\" in \"1rtpA.pdb\"\n",
        "            X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "            omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "            = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "            randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "            log_probs, decoder_messages = mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "            # Adding the log_probs to the same inner dictionary where DDG values exist for easier comparison\n",
        "            mut[\"log_prob\"] = log_probs.cpu().data.numpy()\n",
        "\n",
        "            # Now, start getting the neighbor ids/positions/indices\n",
        "            local_distances, local_neighbors = return_neighbor_info(X, mask)\n",
        "            # The third dimension of the neighbors and distances have to be indexed for getting each of the 48 neighbors (0 to 47 should be closer to farther)\n",
        "            # and the second dimension has to be indexed for getting neighbors of specific positions\n",
        "            # map from third dimension of local_neighbors to second dimension of log_probs, that will show which positions to check after masking neighbors and mutating center\n",
        "            # add the neighbor indices one-by-one to designable position-list (in other words, remove from fixed position list while putting the mutated position back into the fixed positions list)\n",
        "            torch.set_printoptions(precision=4,sci_mode=False)\n",
        "            print(f\"Log Probs:{log_probs[0,seq_pos-1,:]}\")\n",
        "            print(f\"Neighbor Distances:{local_distances[0,seq_pos-1,:]}\")\n",
        "            print(f\"Neighbor Positions:{local_neighbors[0,seq_pos-1,:]}\")\n",
        "            print(f\"Decoder Message Shape:{decoder_messages.size()}\")\n",
        "            print(\".................................\")\n",
        "            # check correlation between distance and attention values since a possible manual edge feature would be distance\n",
        "            # let us see if the model attends to distant neighbors more, or attention value is inversely proportional to distance?\n",
        "            # take L2-norms of the message vectors instead of attention\n",
        "            # take the softmax of L2-norms to approximate attention, although technically the positions are not constrained by each other, this can be considered a sigmoid attention\n",
        "            # where having neighbors with large messages will effect differently than having neighbors with small messages\n",
        "            # can this be correlated with position-entropy?\n",
        "            # the L2-norms should be able to approximate how much each of the neighbors are effecting the mutated position\n",
        "            # This information can be stored for checking the effect of center mutation on those positions afterwards\n",
        "            # Identify major interacting partners (neighbors that are important for center prediction, and also which take center into consideration for its own prediction)\n",
        "            # then check how much the major neighbor position deviates from wildtype due to the mutation\n",
        "            # another much more simples thing can be to check the deviation for top 10 neighbors\n",
        "            # this deviation can be calculated using the log(W) for the neighbor before center mutation, and log(W) for the neighbor after center mutation "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "051d89fe530148b4949175a5612c8745",
            "2f22d7368cfe4333a1afad26a851fe9e",
            "eaae1fef65f3483196e640f021f2af35",
            "0a6b1a34cd6a446babc9b06d78254d11",
            "c79c3b4b30384b3388806efba3156163",
            "4afc57d17aed424f82bbfff5b3e94d05",
            "c87343439b474988a9633b4ff8a589c5",
            "db98d1d18a574ca9803fea925d9a2a6f",
            "d204ef0b6f114952894d924e0597eee5",
            "6ec1e912197d4fcf8d21b8160402e942",
            "2e4708c1367340e683a23f0d37e978fe"
          ]
        },
        "id": "b8cEsTK1EQ9J",
        "outputId": "5a95f4e7-66c2-4324-d9d2-3581db7512e8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "051d89fe530148b4949175a5612c8745"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Probs:tensor([-5.7822, -6.0567, -5.3997, -5.3082, -0.1676, -5.5443, -6.0955, -4.1448,\n",
            "        -5.5129, -5.3603, -5.6095, -5.1386, -5.6576, -5.3173, -5.6844, -5.4534,\n",
            "        -5.6137, -5.3292, -5.5611, -2.7044, -5.5724], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7978,     3.8013,     4.6584,     5.2927,     5.7687,\n",
            "            5.9677,     6.0772,     6.7257,     6.7348,     6.7428,     6.7637,\n",
            "            7.5899,     7.7715,     7.8979,     9.0825,     9.1490,     9.1658,\n",
            "            9.3960,     9.5460,     9.6721,     9.8270,    10.1131,    10.2128,\n",
            "           10.2593,    10.5412,    10.5755,    10.9452,    11.0102,    11.5571,\n",
            "           11.5813,    11.9792,    12.0029,    12.1277,    12.1707,    12.2069,\n",
            "           12.3203,    12.4496,    12.4806,    12.5204,    12.8784,    12.9109,\n",
            "           12.9751,    13.0584,    13.1932,    13.4275,    13.4441,    13.5964],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([10,  9, 11, 79, 47, 78, 48, 80, 77, 49,  8, 12, 50, 81, 46, 64, 38, 61,\n",
            "        82, 45, 39, 13,  7, 37, 76, 60, 65, 36, 51, 57, 63, 40, 25, 21, 74, 83,\n",
            "        14, 62,  6, 75, 44, 93, 58, 41, 35, 29, 52, 96], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-5.7930, -6.1452, -5.3616, -5.3412, -0.1579, -5.5597, -6.1259, -4.2838,\n",
            "        -5.5108, -5.4894, -5.6901, -5.1690, -5.6901, -5.3387, -5.6979, -5.4934,\n",
            "        -5.6689, -5.4151, -5.4749, -2.7663, -5.5943], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7978,     3.8013,     4.6584,     5.2927,     5.7687,\n",
            "            5.9677,     6.0772,     6.7257,     6.7348,     6.7428,     6.7637,\n",
            "            7.5899,     7.7715,     7.8979,     9.0825,     9.1490,     9.1658,\n",
            "            9.3960,     9.5460,     9.6721,     9.8270,    10.1131,    10.2128,\n",
            "           10.2593,    10.5412,    10.5755,    10.9452,    11.0102,    11.5571,\n",
            "           11.5813,    11.9792,    12.0029,    12.1277,    12.1707,    12.2069,\n",
            "           12.3203,    12.4496,    12.4806,    12.5204,    12.8784,    12.9109,\n",
            "           12.9751,    13.0584,    13.1932,    13.4275,    13.4441,    13.5964],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([10,  9, 11, 79, 47, 78, 48, 80, 77, 49,  8, 12, 50, 81, 46, 64, 38, 61,\n",
            "        82, 45, 39, 13,  7, 37, 76, 60, 65, 36, 51, 57, 63, 40, 25, 21, 74, 83,\n",
            "        14, 62,  6, 75, 44, 93, 58, 41, 35, 29, 52, 96], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.7336, -3.7771, -4.6149, -4.2018, -4.9030, -4.9983, -4.8820, -1.7470,\n",
            "        -5.1896, -3.9907, -4.6033, -3.9880, -5.7400, -4.3887, -5.2082, -2.4321,\n",
            "        -1.6308, -1.1396, -5.4916, -5.1054, -5.6000], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8032,     3.8219,     4.2215,     4.9311,     5.3890,\n",
            "            5.4158,     5.8225,     6.2381,     6.3097,     6.4866,     6.7242,\n",
            "            6.7637,     7.8332,     8.2542,     8.5859,     8.8667,     8.8826,\n",
            "            8.9861,     9.1516,     9.5149,    10.1298,    10.1933,    10.2035,\n",
            "           10.2225,    10.2691,    10.4226,    10.6119,    10.7327,    10.7547,\n",
            "           10.7740,    11.1251,    11.1811,    11.3751,    11.9574,    12.0363,\n",
            "           12.1004,    12.1243,    12.2888,    12.3115,    12.3616,    12.9431,\n",
            "           13.0795,    13.1366,    13.3545,    13.3895,    13.4532,    13.5788],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([12, 11, 13, 77, 46, 76, 45, 14, 47, 75, 78, 74, 10, 44, 19, 64, 15, 21,\n",
            "        79, 65, 48, 17, 39, 73, 40, 38,  9, 20, 43, 41, 67, 80, 18, 16, 25, 49,\n",
            "        66, 22, 63, 61, 72, 42, 50, 37, 96, 68,  8, 69], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.6412, -5.0510, -1.9779, -2.6357, -4.0396, -2.2466, -3.4224, -4.6194,\n",
            "        -2.2679, -3.9677, -4.5622, -1.8612, -4.5940, -3.4632, -2.4225, -2.3520,\n",
            "        -3.3285, -4.5036, -4.9385, -3.9623, -5.3576], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8257,     3.8271,     5.3253,     5.6911,     5.7389,\n",
            "            6.6181,     8.4632,     8.6157,     8.6497,     8.7796,    10.3935,\n",
            "           10.4961,    10.9437,    11.3751,    12.0070,    12.0441,    12.0654,\n",
            "           12.1288,    12.1943,    12.8613,    13.8552,    13.8983,    14.1225,\n",
            "           14.7711,    14.9072,    15.0979,    16.3391,    16.8070,    16.8645,\n",
            "           16.8743,    17.1627,    17.4666,    17.4857,    17.6919,    17.7647,\n",
            "           18.2901,    18.5823,    18.6683,    19.0364,    19.6140,    19.6370,\n",
            "           19.6885,    19.9199,    19.9288,    20.5346,    20.6515,    20.6709],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([16, 15, 17, 43, 14, 44, 18, 45, 19, 42, 13, 41, 75, 46, 12, 74, 20, 40,\n",
            "        72, 73, 76, 11, 21, 47, 77, 71, 39, 22, 96, 38, 78, 69, 10, 70, 48, 67,\n",
            "        97, 64, 65, 68, 25, 95, 24, 23, 79,  9, 37, 66], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.0298, -3.7575, -3.1131, -3.1806, -4.0332, -4.1013, -3.8157, -2.2786,\n",
            "        -4.0241, -3.7152, -4.7121, -2.6658, -3.2977, -3.4314, -4.0635, -2.8052,\n",
            "        -1.9786, -1.4285, -4.6623, -3.7175, -5.4845], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7941,     3.8390,     5.6028,     5.6435,     5.7100,\n",
            "            5.7993,     5.8175,     6.4433,     6.5931,     7.3677,     7.6097,\n",
            "            7.9663,     8.2542,     8.4584,     8.5547,     8.6157,     8.7267,\n",
            "            9.0090,     9.2494,     9.4085,     9.8396,    10.0804,    10.2691,\n",
            "           11.0003,    11.1293,    11.1373,    11.1601,    11.2524,    11.4011,\n",
            "           11.5375,    11.6044,    11.6892,    11.6910,    11.9407,    11.9538,\n",
            "           12.0536,    12.0793,    13.2487,    13.5351,    13.9296,    13.9623,\n",
            "           14.2300,    14.4227,    14.4636,    14.9732,    15.1468,    15.6214],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([19, 20, 18, 17, 21, 74, 72, 14, 73, 44, 75, 46, 71, 12, 22, 45, 16, 13,\n",
            "        15, 69, 70, 40, 43, 76, 67, 41, 24, 77, 47, 68, 11, 25, 38, 23, 42, 39,\n",
            "        64, 96, 65, 95, 48, 10, 66, 26, 78, 97, 37, 63], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.9325, -4.6265, -4.3572, -4.0991, -2.0849, -4.5398, -4.6860, -1.5312,\n",
            "        -4.2930, -1.3679, -3.9307, -4.4289, -4.7083, -4.6621, -4.5662, -4.2705,\n",
            "        -3.5914, -1.8466, -4.3715, -3.3400, -5.3755], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7840,     3.8276,     5.6435,     5.9818,     6.0167,\n",
            "            6.6427,     6.7198,     7.6049,     7.7154,     7.7270,     8.2916,\n",
            "            8.4372,     8.6257,     8.7276,     8.8415,     8.8826,     9.0318,\n",
            "            9.1176,     9.2455,     9.4406,     9.5584,     9.5821,     9.9254,\n",
            "            9.9555,     9.9888,    10.1578,    10.2120,    10.4619,    10.6123,\n",
            "           10.6870,    10.8495,    10.8988,    11.0419,    11.0653,    11.0845,\n",
            "           11.2459,    11.3893,    11.4651,    11.5816,    11.6034,    11.6545,\n",
            "           11.8978,    11.9991,    12.1277,    12.1386,    12.7223,    12.9694],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([21, 20, 22, 19, 24, 25, 74, 23, 70, 46, 69, 72, 38, 73, 71, 26, 12, 64,\n",
            "        18, 68, 67, 95, 96, 40, 75, 14, 44, 47, 39, 17, 45, 77, 27, 94, 37, 28,\n",
            "        11, 13, 48, 29, 76, 65, 93, 66, 10, 63, 41, 97], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.1242, -4.8014, -4.3129, -3.3083, -3.3970, -4.0015, -3.8621, -2.2147,\n",
            "        -2.5056, -1.6287, -3.6115, -3.9730, -5.2010, -3.5877, -2.7807, -3.4197,\n",
            "        -3.0282, -2.1597, -3.6798, -2.6349, -5.6204], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8149,     3.8342,     5.4382,     5.7255,     5.7274,\n",
            "            5.9818,     6.0341,     6.7764,     7.2106,     7.8572,     8.0798,\n",
            "            8.2480,     9.4863,     9.6539,    10.0486,    10.1040,    10.3643,\n",
            "           10.3973,    10.4023,    10.5507,    10.8086,    10.8180,    11.1373,\n",
            "           11.2261,    11.3434,    11.3440,    11.6748,    11.8878,    12.0861,\n",
            "           12.2285,    12.5475,    12.6238,    13.0538,    13.1192,    13.2099,\n",
            "           13.6345,    13.6870,    13.6882,    13.9967,    14.0933,    14.1595,\n",
            "           14.1614,    14.2948,    14.3473,    14.5447,    14.5534,    14.5631],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([24, 25, 23, 22, 26, 27, 21, 28, 70, 69, 68, 29, 20, 64, 67, 30, 71, 94,\n",
            "        74, 93, 95, 31, 63, 19, 72, 66, 38, 73, 32, 60, 37, 96, 65, 46, 34, 92,\n",
            "        12, 36, 35, 33, 50, 75, 77, 18, 61, 48, 39, 47], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.0229, -3.5755, -5.6425, -5.4784, -3.6373, -0.9039, -5.4870, -5.5870,\n",
            "        -5.5376, -2.6541, -3.5282, -5.4630, -5.8408, -5.6533, -5.4253, -3.8322,\n",
            "        -5.2939, -5.3000, -5.0075, -5.3614, -5.5875], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8189,     3.8413,     4.9052,     5.2630,     5.3228,\n",
            "            5.3887,     5.5637,     5.6442,     6.0872,     6.1239,     7.0392,\n",
            "            7.1420,     8.0485,     8.0798,     8.8531,     8.8937,     8.9404,\n",
            "            8.9711,     9.2003,     9.2906,     9.3520,     9.4076,     9.5259,\n",
            "            9.7313,    10.0140,    10.1078,    10.6209,    10.9857,    11.5298,\n",
            "           11.5340,    11.5816,    11.6477,    11.6769,    11.7573,    11.8426,\n",
            "           12.0290,    12.5783,    12.6976,    12.7115,    13.0407,    13.0586,\n",
            "           13.1023,    13.2724,    13.2998,    13.3540,    13.4275,    13.5383],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([29, 30, 28, 32, 34, 31, 26, 27, 25, 93, 33, 60, 35, 92, 24, 50, 56, 94,\n",
            "        36, 63, 57, 59, 52, 23, 64, 37, 51, 61, 22, 49, 38, 21, 58, 95, 62, 91,\n",
            "        53, 66, 55, 90, 68, 48, 88, 67, 65,  8, 10, 54], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.3182, -3.3893, -4.0701, -4.4989, -4.4382, -4.4234, -3.4941, -5.1094,\n",
            "        -3.3472, -5.4815, -5.4646, -3.5770, -5.6845, -3.9572, -4.1105, -0.8280,\n",
            "        -1.8858, -3.0050, -4.7178, -3.9975, -5.6668], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7960,     3.8379,     4.1374,     4.1719,     5.1171,\n",
            "            5.9502,     5.9573,     6.0505,     6.4087,     6.7053,     7.1420,\n",
            "            7.1601,     7.1617,     7.1727,     7.5454,     7.7493,     8.0600,\n",
            "            8.7403,     9.1975,     9.3999,     9.4608,     9.6031,    10.0051,\n",
            "           10.0462,    10.3081,    10.3499,    10.4068,    10.5326,    10.5716,\n",
            "           10.5837,    10.6420,    10.7609,    10.7979,    10.9204,    11.0322,\n",
            "           11.8623,    12.1871,    12.4258,    12.8791,    12.9677,    13.1932,\n",
            "           13.3205,    13.3270,    13.3462,    13.4847,    13.5934,    13.6882],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([35, 34, 36, 93, 92, 51, 52, 50, 90, 88, 91, 29, 33, 30, 37, 94, 89, 49,\n",
            "        26,  7, 32, 53, 57, 87, 56, 25, 31,  6, 60,  5, 38,  8, 27, 28, 48, 95,\n",
            "         9, 54, 86, 85, 59, 10, 55, 58, 61, 96, 23, 24], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-5.1909, -4.8678, -5.2967, -5.0938, -1.5944, -5.3136, -3.8415, -5.0794,\n",
            "        -4.8715, -4.3115, -5.1324, -4.7031, -5.9400, -5.0331, -4.1931, -4.7766,\n",
            "        -5.1699, -4.9490, -2.9689, -0.5049, -5.6363], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8087,     3.8237,     4.8168,     5.1024,     5.2778,\n",
            "            5.4963,     5.8142,     6.7363,     6.7799,     6.8111,     7.1727,\n",
            "            7.2696,     7.8643,     8.1967,     8.2215,     8.5518,     8.8233,\n",
            "            8.9930,     9.0982,     9.7403,     9.9194,     9.9370,     9.9640,\n",
            "           10.0140,    10.1336,    10.2128,    10.7809,    11.0016,    11.0653,\n",
            "           11.1156,    11.2662,    11.4242,    11.7603,    11.8041,    11.9012,\n",
            "           11.9139,    12.2285,    12.7504,    13.0024,    13.1141,    13.1366,\n",
            "           13.3676,    13.4433,    13.5794,    13.6418,    14.0443,    14.0774],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([37, 38, 36, 94, 93, 49, 48, 95, 39, 96, 50, 35, 97, 92, 90, 26, 47, 25,\n",
            "        51, 91,  9, 40, 22, 34, 29, 46, 10, 89,  8, 21,  7, 23, 30, 88, 52, 11,\n",
            "        27, 24, 28, 60, 41, 12, 64, 33, 45, 57,  6, 20], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.5813, -4.3652, -4.0874, -3.7195, -4.9401, -4.7824, -4.4685, -1.4440,\n",
            "        -5.0235, -1.5427, -2.0106, -3.6615, -5.5179, -2.8690, -4.8118, -3.3467,\n",
            "        -2.5294, -2.6233, -4.9473, -4.8143, -5.5582], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8087,     3.8309,     4.5684,     4.6875,     5.5511,\n",
            "            5.9554,     6.1080,     6.4384,     6.6015,     6.7506,     6.7611,\n",
            "            7.4183,     7.9261,     7.9484,     8.4181,     8.4372,     8.8538,\n",
            "            9.0224,     9.1490,     9.6277,     9.7627,     9.8875,    10.1095,\n",
            "           10.2691,    10.4612,    10.5837,    11.0694,    11.1849,    11.2497,\n",
            "           11.3440,    11.5340,    11.6892,    11.9003,    11.9337,    12.2259,\n",
            "           12.3006,    12.5905,    12.7495,    12.7629,    12.7813,    13.1539,\n",
            "           13.1598,    13.2806,    13.3179,    13.3575,    13.5216,    13.6104],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([38, 37, 39, 48, 96, 95, 47, 97, 40, 46, 49, 94, 36, 93, 22, 25, 21, 50,\n",
            "        26, 10, 11, 41,  9, 45, 12, 23, 35, 20, 92, 44, 24, 29, 19, 51, 90,  8,\n",
            "        64, 91, 34, 77, 27, 74, 14, 13, 42,  7, 28, 30], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-4.1297, -5.0295, -1.9073, -3.4744, -4.5774, -3.6181, -3.3144, -4.9225,\n",
            "        -3.3312, -4.0436, -4.8690, -1.9192, -4.8416, -3.7288, -3.4155, -1.6903,\n",
            "        -1.4981, -4.8216, -4.8097, -4.1390, -5.3989], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8034,     3.8143,     5.5968,     5.6157,     5.8397,\n",
            "            6.4202,     6.6217,     7.9136,     8.6306,     9.0077,     9.3010,\n",
            "            9.7023,     9.7627,    10.1854,    10.3935,    10.6573,    10.6820,\n",
            "           10.7547,    10.8235,    11.1293,    11.6550,    12.7223,    12.8347,\n",
            "           12.9552,    13.0584,    13.1141,    13.5544,    13.9314,    14.5407,\n",
            "           14.7836,    14.8625,    14.8868,    15.6063,    15.8411,    15.8472,\n",
            "           16.4873,    16.5630,    16.8860,    17.0365,    17.0578,    17.1194,\n",
            "           17.2642,    17.3107,    17.6691,    17.8718,    17.9354,    17.9744],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([41, 40, 42, 44, 43, 45, 39, 46, 47, 17, 97, 96, 14, 38, 48, 16, 11, 15,\n",
            "        12, 13, 19, 18, 21, 20, 95, 10, 37, 22, 49,  9, 74, 77, 75, 76, 94, 78,\n",
            "        25, 36, 72, 73, 50, 79, 23, 80, 93, 64, 26, 81], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-5.4730, -5.4417, -5.5113, -5.5581, -5.4951, -0.0833, -5.4740, -5.6006,\n",
            "        -5.6090, -5.4898, -5.6686, -5.2470, -5.6612, -5.5307, -5.5010, -5.4077,\n",
            "        -5.5694, -5.5407, -5.5793, -5.5787, -5.6110], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7476,     3.8180,     3.8391,     4.4687,     5.5567,\n",
            "            5.5968,     5.7389,     5.9419,     5.9675,     6.5779,     6.5931,\n",
            "            6.8950,     6.9457,     7.8332,     8.7753,     9.3744,     9.4825,\n",
            "            9.6484,     9.9784,    10.1578,    10.3070,    11.2497,    11.5082,\n",
            "           11.5438,    11.9600,    12.0190,    12.0932,    12.1209,    12.2477,\n",
            "           12.8497,    12.8784,    13.9033,    14.3544,    14.4569,    15.0247,\n",
            "           15.2560,    15.2567,    15.6101,    15.6810,    15.7636,    15.7846,\n",
            "           15.9630,    16.0439,    16.1312,    16.2102,    16.2871,    17.2157],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([44, 17, 43, 45, 14, 46, 41, 16, 15, 42, 40, 19, 18, 13, 12, 47, 39, 20,\n",
            "        11, 75, 21, 74, 38, 96, 76, 77, 73, 72, 48, 22, 97, 10, 78, 71, 95, 37,\n",
            "        25, 64,  9, 69, 49, 70, 67, 23, 24, 79, 65, 94], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.6487, -4.8403, -3.9395, -2.7539, -3.8179, -5.0968, -4.0099, -1.6316,\n",
            "        -3.2615, -1.6881, -2.8190, -4.3480, -5.3463, -2.8778, -3.3083, -3.8673,\n",
            "        -3.5370, -1.9695, -4.1520, -3.2608, -5.5089], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7715,     3.7971,     4.9311,     5.3268,     5.5567,\n",
            "            5.6136,     5.6821,     6.6015,     6.6217,     6.8139,     6.9429,\n",
            "            6.9665,     7.6097,     7.7154,     7.8979,     8.6203,     8.6254,\n",
            "            8.8165,     8.8298,     9.1953,     9.2443,     9.5096,     9.7583,\n",
            "            9.7938,     9.9143,    10.1336,    10.1653,    10.1910,    10.2105,\n",
            "           10.3947,    10.4991,    10.5167,    10.9437,    11.0919,    11.1140,\n",
            "           11.2546,    11.8609,    12.2731,    12.4707,    12.9879,    13.0478,\n",
            "           13.0538,    13.0715,    13.1509,    13.2261,    13.2883,    13.5031],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([46, 47, 45, 12, 40, 44, 11, 39, 38, 41, 14, 13, 48, 19, 21, 10, 17, 43,\n",
            "        77, 96, 74, 20, 42, 22, 15, 75, 37, 76, 18, 97, 49, 78,  9, 16, 95, 25,\n",
            "        64, 79, 73, 50, 94, 72, 24, 65, 36, 80, 23, 26], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.9972, -5.0110, -5.5772, -5.5027, -5.2415, -5.5466, -5.6358, -0.7398,\n",
            "        -5.4415, -1.8681, -3.3775, -5.4584, -5.6879, -5.2865, -5.4834, -5.3171,\n",
            "        -5.1348, -1.4059, -5.6313, -5.5484, -5.5301], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8162,     3.8189,     4.8014,     5.1691,     5.5710,\n",
            "            5.9573,     6.0703,     6.5320,     6.8111,     6.8236,     7.0170,\n",
            "            7.3633,     7.4035,     7.5899,     7.7777,     8.2613,     8.8531,\n",
            "            8.8538,     9.4867,     9.6068,     9.6289,     9.6468,     9.8447,\n",
            "            9.8725,     9.9082,    10.0363,    10.0609,    10.0825,    10.0829,\n",
            "           10.3116,    10.4199,    10.4778,    10.4801,    10.4954,    10.7260,\n",
            "           10.8712,    10.9937,    11.0053,    11.0685,    11.0825,    11.0888,\n",
            "           11.1033,    11.2059,    11.2547,    11.4093,    11.5445,    11.8072],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([50, 51, 49, 36,  8,  7, 35,  9, 52, 37, 34, 48, 93, 57, 10,  6, 60, 29,\n",
            "        38, 61, 88, 82, 92, 47, 90, 79, 56,  5, 94, 53, 25, 83, 89, 81, 33, 58,\n",
            "        26, 80, 11, 54, 84, 64, 30, 32, 39, 59, 85, 91], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.2218, -4.7799, -4.8816, -3.3800, -2.6932, -5.1284, -3.6310, -3.0806,\n",
            "        -3.1243, -1.3402, -2.6570, -4.1602, -5.7049, -3.4188, -3.6467, -3.9494,\n",
            "        -3.2933, -3.4201, -2.0763, -2.3942, -5.3702], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8068,     3.8433,     4.4445,     4.7756,     5.0106,\n",
            "            5.1712,     6.1787,     7.1700,     8.5324,     9.1580,     9.2003,\n",
            "            9.2329,     9.3112,     9.4837,     9.5176,     9.5930,    10.3900,\n",
            "           10.8180,    10.9323,    11.0153,    11.2291,    11.5755,    11.5813,\n",
            "           11.8475,    11.8955,    12.0014,    12.1386,    12.2284,    12.2888,\n",
            "           12.5194,    12.5927,    12.6503,    12.6575,    12.7049,    13.0117,\n",
            "           13.1171,    13.4718,    13.5145,    13.6031,    13.7301,    13.8911,\n",
            "           14.1838,    14.2500,    14.2510,    14.2554,    14.3889,    14.3952],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([63, 62, 64, 66, 60, 61, 65, 59, 67, 58, 68, 29, 28, 57, 77, 32, 25, 56,\n",
            "        24, 79, 74, 78, 76, 10, 31, 50, 34, 21, 69, 12, 55, 26, 33, 27, 30, 75,\n",
            "        11,  8, 73, 52,  9, 93, 54, 23, 22, 51, 35, 49], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.6978, -4.8839, -4.4776, -4.4226, -3.7107, -4.2482, -4.7833, -0.7098,\n",
            "        -4.4840, -2.1427, -3.6711, -4.5416, -3.0850, -4.4820, -4.2207, -4.1905,\n",
            "        -4.2325, -2.2602, -4.0193, -4.3724, -5.4308], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8040,     3.8054,     5.7100,     5.8325,     6.1301,\n",
            "            6.4999,     6.6427,     6.7242,     7.2605,     7.2699,     7.3177,\n",
            "            7.4266,     7.6374,     7.6639,     7.8929,     7.9407,     8.8425,\n",
            "            8.8940,     9.1953,     9.3922,     9.7880,    10.2613,    10.3070,\n",
            "           10.3175,    10.3343,    10.3973,    10.4291,    10.6423,    10.7007,\n",
            "           11.0153,    11.0961,    11.7933,    12.0070,    12.1707,    12.6925,\n",
            "           13.1539,    13.4525,    13.6334,    13.6473,    13.7698,    13.8077,\n",
            "           14.2301,    14.2572,    14.3391,    14.3739,    14.4566,    14.7836],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([74, 75, 73, 19, 67, 76, 72, 21, 12, 20, 14, 77, 69, 68, 64, 65, 13, 18,\n",
            "        66, 46, 71, 70, 17, 44, 11, 45, 24, 22, 15, 25, 63, 78, 47, 16, 10, 23,\n",
            "        38, 40, 61, 79, 43, 62, 60, 39, 48, 26, 28, 41], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.6012, -2.9439, -5.4321, -5.5037, -4.9861, -5.0621, -5.4473, -3.5913,\n",
            "        -5.4361, -5.1589, -5.3108, -5.1083, -4.7197, -5.3404, -5.4168, -3.8953,\n",
            "        -2.4607, -0.6249, -5.5794, -5.4726, -5.5352], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7950,     3.8064,     4.2215,     5.4857,     5.6932,\n",
            "            6.3705,     6.4500,     6.6526,     6.7167,     6.7257,     7.3177,\n",
            "            8.8165,     9.0630,     9.0689,     9.1495,     9.1734,     9.2514,\n",
            "            9.4837,     9.4927,     9.7303,    10.4044,    10.6007,    10.7797,\n",
            "           10.8495,    11.1601,    11.3704,    11.4729,    11.8415,    11.9600,\n",
            "           12.4400,    12.4703,    12.5388,    12.7629,    12.8343,    12.8839,\n",
            "           13.0171,    13.0739,    13.4533,    13.7848,    13.7894,    13.8608,\n",
            "           14.1245,    14.1310,    14.1614,    14.2190,    14.2282,    14.3085],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([77, 76, 78, 12, 11, 65, 64, 13, 79, 75, 10, 74, 46, 47, 67, 14, 61, 66,\n",
            "        63, 45, 80,  9, 62, 73, 21, 19, 60, 48, 15, 44, 68, 25,  8, 38, 50, 49,\n",
            "        81, 20, 39, 72, 69, 17, 59, 40, 24, 58, 22, 57], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-4.3173, -4.7526, -3.3848, -0.4046, -3.8039, -4.8695, -5.0182, -3.6703,\n",
            "        -4.7724, -4.1570, -4.5628, -4.6590, -5.5405, -4.5026, -4.9258, -3.3942,\n",
            "        -3.1872, -3.2250, -5.0490, -3.7758, -5.3746], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8099,     3.8133,     4.4986,     6.0177,     6.2032,\n",
            "            6.6703,     6.8134,     6.8859,     7.9949,     9.3960,     9.6289,\n",
            "            9.7447,     9.9261,    10.1075,    10.5381,    10.5465,    10.8557,\n",
            "           11.4498,    11.4804,    11.6238,    11.6878,    11.7205,    11.7247,\n",
            "           12.2342,    12.5613,    12.8237,    12.8887,    13.1358,    13.2473,\n",
            "           13.5197,    13.6038,    13.6882,    14.1219,    14.1442,    14.2439,\n",
            "           14.4694,    14.7641,    14.7876,    14.8352,    14.9771,    15.0098,\n",
            "           15.2060,    15.3026,    15.7418,    15.8660,    15.8735,    16.1987],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([82, 81, 83,  8, 80,  7,  9, 84,  6, 79, 10, 50, 85, 51, 49,  5, 57,  1,\n",
            "        54, 61, 78, 52,  4, 58, 48, 11,  0, 53, 60, 86,  3, 47, 36, 56,  2, 55,\n",
            "        77, 35, 59, 34, 88, 62, 87, 37, 64, 89, 12, 63], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-4.1604, -4.5128, -4.3334, -3.3961, -4.8861, -3.7353, -4.6426, -1.6953,\n",
            "        -3.6897, -4.0160, -4.3580, -3.8156, -5.7057, -3.8329, -3.9053, -3.2294,\n",
            "        -1.9245, -0.9739, -5.2598, -4.9706, -5.5148], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8047,     3.8411,     4.3576,     5.1347,     5.6341,\n",
            "            5.8422,     6.3312,     6.3576,     6.4273,     6.9795,     7.4106,\n",
            "            7.7667,     8.5787,     8.8580,     9.6044,     9.7447,     9.8183,\n",
            "            9.8347,     9.9298,    10.7499,    11.5445,    12.4220,    12.4891,\n",
            "           12.6874,    12.8486,    12.8791,    13.0441,    13.0748,    13.7165,\n",
            "           14.4232,    14.5078,    15.3334,    15.4071,    15.9715,    16.0834,\n",
            "           16.1918,    16.2921,    16.3751,    16.4053,    16.5379,    16.6968,\n",
            "           16.8313,    17.2837,    17.9458,    18.4598,    18.4716,    18.9850],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([85, 84, 86,  0,  1,  5,  6, 83,  3,  7, 87,  4,  2, 51, 88, 52, 82,  8,\n",
            "        53, 89, 54, 50, 81, 49, 57,  9, 35, 36, 90, 34, 56, 55, 58, 80, 48, 33,\n",
            "        37, 92, 10, 91, 93, 79, 60, 61, 59, 29, 32, 38], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-4.6433, -5.3645, -4.9078, -3.4615, -4.3868, -5.0730, -5.2413, -4.0686,\n",
            "        -3.7901, -0.3172, -3.0021, -4.8351, -4.7722, -3.7881, -4.4319, -4.5489,\n",
            "        -4.0942, -4.6463, -5.5410, -4.5816, -5.6696], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8156,     3.8161,     5.8057,     6.2709,     6.4087,\n",
            "            6.7270,     6.9723,     7.8496,     8.0856,     8.1620,     8.2603,\n",
            "            8.3996,     8.5911,     8.8580,     8.8681,     9.3251,     9.6068,\n",
            "           10.1665,    10.4143,    11.1050,    11.2520,    11.2533,    11.3611,\n",
            "           11.7603,    11.9477,    11.9670,    12.1064,    12.1167,    12.3306,\n",
            "           12.3576,    12.7516,    13.0756,    13.1023,    13.4547,    13.7457,\n",
            "           14.3041,    14.3287,    14.5639,    14.5957,    14.9771,    14.9832,\n",
            "           15.0076,    15.0262,    15.4541,    15.7974,    16.0515,    16.5819],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([88, 89, 87, 90, 51, 35, 52, 86,  5, 36, 91, 34, 92, 53, 85,  7,  6, 50,\n",
            "        93, 33, 49, 84,  3,  4, 37, 54,  0, 57,  8, 56, 30, 94, 83, 29,  1, 32,\n",
            "        55,  9,  2, 48, 82, 26, 60, 31, 38, 58, 95, 59], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.6554, -4.3978, -4.8911, -5.0214, -5.7168, -5.3848, -5.4104, -3.0904,\n",
            "        -4.9306, -5.7781, -5.7081, -4.7119, -5.3669, -4.6577, -4.8701, -2.7670,\n",
            "        -2.2088, -0.4887, -5.2421, -5.3160, -5.3507], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8114,     3.8438,     4.6528,     4.6896,     5.8356,\n",
            "            6.2837,     6.3234,     6.3698,     6.4367,     7.3018,     7.4649,\n",
            "            7.6001,     7.9400,     8.2057,     8.4170,     8.5488,     8.5602,\n",
            "            9.3768,     9.6651,     9.7700,     9.8016,     9.9677,    10.0342,\n",
            "           10.2168,    10.2220,    10.2351,    10.3235,    10.3311,    10.5084,\n",
            "           10.5417,    10.6957,    10.7837,    10.8714,    10.9197,    11.1091,\n",
            "           11.1470,    11.2720,    11.5442,    11.6787,    11.7456,    11.8195,\n",
            "           12.0312,    12.0650,    12.1251,    12.1394,    12.3778,    12.4038],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([  5,   4,   6, 112,  85,  84, 113,  86,   7, 111,   3,  88, 109,  89,\n",
            "         87,  83, 110, 114, 194,  30,   2, 193, 188,   8,  29,  14,  18,  95,\n",
            "         31,  90, 195, 185,  98, 115, 184, 108,  21,  82, 214,  99,  28,  27,\n",
            "        196,  32,  17, 210,  94,  22], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 218, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.8564, -5.5990, -3.1170, -2.1370, -5.1527, -4.4649, -4.9770, -4.9167,\n",
            "        -2.3199, -4.1782, -4.8516, -4.4971, -1.0626, -2.9912, -3.6732, -3.2468,\n",
            "        -3.7040, -4.1335, -5.3483, -5.4580, -5.5399], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7942,     3.8004,     5.2154,     5.2336,     6.3285,\n",
            "            6.6597,     8.1647,     8.3205,     8.5094,     9.1467,     9.8943,\n",
            "           10.8505,    11.1738,    11.4310,    11.9078,    12.2574,    12.7176,\n",
            "           12.9962,    13.6508,    13.7941,    14.2773,    14.5636,    14.8804,\n",
            "           15.0659,    15.8049,    15.8960,    16.0142,    16.1876,    16.2300,\n",
            "           16.7124,    16.8035,    17.2666,    17.5807,    17.7295,    17.8946,\n",
            "           17.9807,    18.5177,    18.5850,    18.7417,    19.0859,    19.6408,\n",
            "           19.7631,    19.8075,    20.0112,    20.0736,    20.6891,    21.4316],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([ 45,  46,  44,  48,  47,  49,  43,  39,  40,  50,  42,  51,  41,  36,\n",
            "         52,  38,  37,  64,  53,  60,  35,  54,  61,  68,  65,  55,  63,  67,\n",
            "         33,  34,  32,  59,  62,  56,  58,  66, 163,  69,  71, 164,  57,  72,\n",
            "         31, 162, 133,  70, 134,  30], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 218, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.3218, -5.1730, -3.7229, -1.8699, -4.6588, -5.1532, -4.5111, -3.3720,\n",
            "        -2.1687, -2.0809, -3.3332, -3.4564, -5.5988, -2.6140, -3.4062, -3.2569,\n",
            "        -1.8576, -3.5720, -5.2792, -4.7360, -5.4325], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8187,     3.8227,     5.0644,     5.4149,     5.9857,\n",
            "            6.1626,     7.9505,     8.0600,     8.4954,     8.9749,     9.2850,\n",
            "           10.1404,    10.1584,    10.1689,    10.6496,    10.7060,    11.6819,\n",
            "           11.9524,    12.2271,    12.2461,    12.2836,    12.5300,    12.5539,\n",
            "           12.5569,    12.6446,    12.7149,    13.5271,    13.9456,    14.3691,\n",
            "           14.4149,    14.4290,    14.4676,    14.5632,    14.6514,    14.8467,\n",
            "           14.8625,    14.9090,    15.6006,    15.6816,    15.7061,    15.7149,\n",
            "           15.8496,    16.0000,    16.6057,    16.6100,    16.7979,    16.8979],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([ 74,  75,  73,  71,  72,  76,  70,  77,  79,  69,  80, 105, 101,  78,\n",
            "         68,  67, 102, 104, 107,  83,  66,  82,  81,  28, 106,  30,  98, 103,\n",
            "        100,  85, 108,  65,  29,   3,  97,  99,  27,  84,  32,  31, 109,  64,\n",
            "         35,  88,  63,   4,  94,  89], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 218, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.5022, -4.6106, -4.7267, -4.3814, -4.7244, -5.3949, -3.8868, -3.0168,\n",
            "        -1.2253, -3.5195, -3.0532, -3.2355, -5.5194, -2.9240, -1.3959, -3.7455,\n",
            "        -2.9195, -3.2043, -4.8111, -4.6848, -5.3049], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8164,     3.8463,     5.2960,     5.5862,     6.5131,\n",
            "            6.7977,     7.9920,     7.9927,     8.9212,     8.9336,     8.9767,\n",
            "            9.4688,     9.8054,    10.3497,    10.4428,    10.5042,    10.5857,\n",
            "           10.6236,    10.7353,    10.7854,    10.9223,    11.5900,    11.9524,\n",
            "           12.2097,    13.0154,    13.2103,    13.2386,    13.5680,    13.6648,\n",
            "           13.9191,    14.0590,    14.1015,    14.1894,    14.3443,    14.3656,\n",
            "           14.4005,    14.4062,    14.7951,    14.8366,    14.8767,    15.0142,\n",
            "           15.1348,    15.2024,    15.3551,    15.6833,    15.9511,    15.9903],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([107, 106, 108, 102, 105, 103, 109, 104,   3, 101,  82, 110,  80,  99,\n",
            "          2,  83, 100,  73,  79,   4,  81,  98,   1,  74, 111,  84,  70,   5,\n",
            "         85,  27,  97,  78, 193,  28,  72,  77, 112,  69,  76,  96,  95, 191,\n",
            "         75,   0,  71,  30, 188, 192], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 218, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-5.4948, -4.7033, -3.0727, -5.4891, -5.2492, -5.5093, -2.2686, -4.2741,\n",
            "        -4.2828, -5.3928, -5.4323, -0.3880, -5.4198, -5.1786, -4.0048, -4.7139,\n",
            "        -3.1982, -4.4914, -5.3633, -4.6132, -5.3676], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7967,     3.8104,     5.5375,     5.5440,     5.7286,\n",
            "            5.9173,     6.6512,     7.5103,     7.5226,     8.4946,     8.5262,\n",
            "            8.9473,     9.0201,     9.4129,     9.5780,     9.8421,     9.9753,\n",
            "           10.1185,    10.1245,    10.2736,    10.7009,    11.0018,    11.6016,\n",
            "           11.6298,    11.7551,    11.8218,    11.9787,    12.1811,    13.2055,\n",
            "           13.3641,    13.9918,    14.0855,    14.1177,    14.1732,    14.4214,\n",
            "           14.4456,    14.4695,    14.5446,    14.5771,    14.9276,    14.9474,\n",
            "           15.1314,    15.6017,    15.6891,    15.8979,    15.9570,    16.1080],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([166, 165, 167, 168, 169, 170, 164, 127, 126, 163, 162, 171,  55, 123,\n",
            "        161,  57,  56, 128, 173, 172, 129, 124, 125,  54,  10, 122, 174,  11,\n",
            "        130, 160,  58, 131,  53,  52, 175, 140,  51, 120, 119, 121, 141,   9,\n",
            "        176, 138,  12, 177, 139,  59], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 218, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-5.8501, -5.7150, -5.7444, -5.5921, -5.8908, -5.7553, -5.7433, -0.1037,\n",
            "        -5.7758, -5.0212, -4.6852, -5.6649, -5.7135, -5.7217, -5.6386, -5.8031,\n",
            "        -5.4640, -3.6152, -5.8994, -5.6966, -5.6542], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8271,     3.8303,     5.0146,     5.0606,     5.2767,\n",
            "            5.4118,     6.1773,     6.2096,     6.6805,     7.6915,     8.1636,\n",
            "            8.6765,     8.7552,     8.8217,     8.9258,     8.9663,     9.1337,\n",
            "            9.1373,     9.1824,     9.4326,     9.5840,     9.6410,     9.8770,\n",
            "           10.0294,    10.4037,    10.5471,    10.6975,    10.7342,    10.7785,\n",
            "           11.4495,    11.7304,    11.7576,    11.7827,    11.7992,    11.8135,\n",
            "           11.8956,    12.1394,    12.3158,    12.4159,    12.4271,    12.7267,\n",
            "           12.8998,    12.9112,    12.9114,    12.9120,    13.0933,    13.1921],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([210, 211, 209, 213, 207, 212, 208, 214, 206, 197, 113, 217, 196, 205,\n",
            "        195, 215,  17,  21, 198, 115, 216, 114, 199, 204,  20,   6, 203,  18,\n",
            "        112, 111,  14, 201,  13, 116,   4,  24, 194,   5,   7,  16, 202,  19,\n",
            "          2, 200,  22,  25,  84,   8], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 218, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.7881, -5.2153, -1.5035, -1.6350, -4.8325, -3.0092, -4.2789, -4.5765,\n",
            "        -3.5065, -3.7495, -3.2847, -2.6696, -3.7661, -2.8847, -3.8589, -2.3620,\n",
            "        -3.0990, -4.0972, -5.2796, -4.7848, -5.3989], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7919,     5.0766,     5.5611,     6.2113,     8.7007,\n",
            "            9.7695,     9.8214,     9.9922,    10.5174,    10.7479,    10.8698,\n",
            "           11.7129,    12.1127,    12.4023,    12.4536,    12.7167,    13.1937,\n",
            "           13.2234,    13.4297,    13.4665,    13.5638,    13.5743,    13.6906,\n",
            "           13.6911,    13.8902,    14.0215,    14.0434,    14.9531,    15.2067,\n",
            "           15.2570,    15.2850,    15.9826,    16.1497,    16.4817,    16.6806,\n",
            "           17.4054,    17.4129,    17.9476,    18.0786,    18.4097,    18.7702,\n",
            "           19.1354,    19.9927,    20.0139,    21.3436,    21.9034,    22.3012],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([ 0,  1,  3,  2,  4,  5, 71,  6, 74,  7, 70, 63, 60, 73,  8, 67, 59, 72,\n",
            "        75, 56, 77, 64, 66, 69, 68, 78, 62,  9, 61, 76, 57, 10, 65, 58, 11, 55,\n",
            "        81, 79, 53, 80, 12, 54, 52, 13, 82, 14, 51, 84], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.8060, -5.1758, -1.4615, -1.7128, -4.7895, -3.0167, -4.2527, -4.6127,\n",
            "        -3.5085, -3.7716, -3.2561, -2.6227, -3.7213, -2.9177, -3.8428, -2.3292,\n",
            "        -3.1108, -4.0986, -5.2756, -4.7973, -5.3978], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7919,     5.0766,     5.5611,     6.2113,     8.7007,\n",
            "            9.7695,     9.8214,     9.9922,    10.5174,    10.7479,    10.8698,\n",
            "           11.7129,    12.1127,    12.4023,    12.4536,    12.7167,    13.1937,\n",
            "           13.2234,    13.4297,    13.4665,    13.5638,    13.5743,    13.6906,\n",
            "           13.6911,    13.8902,    14.0215,    14.0434,    14.9531,    15.2067,\n",
            "           15.2570,    15.2850,    15.9826,    16.1497,    16.4817,    16.6806,\n",
            "           17.4054,    17.4129,    17.9476,    18.0786,    18.4097,    18.7702,\n",
            "           19.1354,    19.9927,    20.0139,    21.3436,    21.9034,    22.3012],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([ 0,  1,  3,  2,  4,  5, 71,  6, 74,  7, 70, 63, 60, 73,  8, 67, 59, 72,\n",
            "        75, 56, 77, 64, 66, 69, 68, 78, 62,  9, 61, 76, 57, 10, 65, 58, 11, 55,\n",
            "        81, 79, 53, 80, 12, 54, 52, 13, 82, 14, 51, 84], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.8145, -5.3555, -4.6323, -3.9667, -0.9362, -5.0714, -4.4516, -3.0676,\n",
            "        -4.7648, -2.8519, -4.3667, -4.8688, -4.5869, -4.8277, -5.0132, -4.7034,\n",
            "        -3.6478, -2.4851, -4.2623, -1.4279, -5.4821], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8031,     3.8051,     5.0443,     5.4145,     5.5611,\n",
            "            6.0488,     7.8330,     7.9004,     8.0792,     8.5452,     8.7564,\n",
            "            9.2675,     9.7745,     9.8487,    10.2056,    10.4452,    10.7492,\n",
            "           11.0382,    11.1578,    11.2484,    11.2705,    11.3989,    11.9329,\n",
            "           12.1486,    12.1695,    12.4450,    12.5609,    12.7184,    12.7816,\n",
            "           12.8295,    12.8807,    13.4772,    13.5720,    13.7808,    13.9740,\n",
            "           13.9758,    14.0173,    14.2948,    14.7479,    14.9766,    14.9795,\n",
            "           15.6446,    16.2087,    16.3743,    16.4099,    18.0253,    18.1518],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([ 2,  1,  3,  5,  4,  0,  6, 60, 59, 56,  7, 63, 74, 71,  8,  9, 57, 62,\n",
            "        78, 55, 58, 75, 61, 64, 77, 10, 70, 73, 66, 67, 53, 72, 54, 68, 52, 11,\n",
            "        76, 81, 65, 79, 12, 69, 80, 82, 13, 51, 49, 50], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.6053, -5.1836, -4.5072, -3.8196, -0.9969, -4.9777, -4.4285, -2.9246,\n",
            "        -4.6600, -2.7091, -4.2226, -4.7403, -4.5289, -4.6860, -4.9218, -4.5245,\n",
            "        -3.4607, -2.2921, -4.1396, -1.5965, -5.4905], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8031,     3.8051,     5.0443,     5.4145,     5.5611,\n",
            "            6.0488,     7.8330,     7.9004,     8.0792,     8.5452,     8.7564,\n",
            "            9.2675,     9.7745,     9.8487,    10.2056,    10.4452,    10.7492,\n",
            "           11.0382,    11.1578,    11.2484,    11.2705,    11.3989,    11.9329,\n",
            "           12.1486,    12.1695,    12.4450,    12.5609,    12.7184,    12.7816,\n",
            "           12.8295,    12.8807,    13.4772,    13.5720,    13.7808,    13.9740,\n",
            "           13.9758,    14.0173,    14.2948,    14.7479,    14.9766,    14.9795,\n",
            "           15.6446,    16.2087,    16.3743,    16.4099,    18.0253,    18.1518],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([ 2,  1,  3,  5,  4,  0,  6, 60, 59, 56,  7, 63, 74, 71,  8,  9, 57, 62,\n",
            "        78, 55, 58, 75, 61, 64, 77, 10, 70, 73, 66, 67, 53, 72, 54, 68, 52, 11,\n",
            "        76, 81, 65, 79, 12, 69, 80, 82, 13, 51, 49, 50], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.6396, -5.1101, -2.9354, -2.2938, -4.6406, -4.3326, -4.1452, -3.4799,\n",
            "        -1.8988, -2.7376, -3.8207, -3.1017, -5.5677, -1.7548, -2.7114, -2.7923,\n",
            "        -2.8345, -3.3392, -5.2480, -4.6317, -5.4979], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8038,     3.8072,     5.0062,     5.0285,     5.3803,\n",
            "            5.4145,     6.2113,     6.2260,     8.4311,     9.8920,    10.4855,\n",
            "           10.4942,    11.0632,    11.6239,    11.7378,    12.2494,    12.3808,\n",
            "           12.7132,    12.7659,    13.2265,    13.5424,    13.6660,    13.7109,\n",
            "           13.7653,    14.0998,    14.2299,    14.3288,    14.6859,    14.7681,\n",
            "           14.9374,    15.0724,    15.3427,    15.3627,    15.5164,    15.5243,\n",
            "           15.9773,    16.0249,    16.0269,    16.3601,    16.4926,    16.6811,\n",
            "           17.0619,    17.4698,    17.6895,    17.9488,    18.0450,    18.1288],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([ 4,  3,  5,  1,  7,  6,  2,  0,  8,  9, 10, 11, 74, 56, 78, 77, 60, 12,\n",
            "        59, 71, 75, 81, 73, 57, 63, 53, 55, 13, 76, 70, 80, 52, 79, 72, 58, 14,\n",
            "        62, 54, 61, 15, 64, 82, 67, 68, 66, 84, 69, 16], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.5801, -5.1707, -3.0091, -2.3043, -4.6535, -4.2448, -4.1561, -3.5424,\n",
            "        -1.8688, -2.7776, -3.8788, -3.0867, -5.5979, -1.7456, -2.7483, -2.7776,\n",
            "        -2.8313, -3.3510, -5.2157, -4.5933, -5.5045], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8038,     3.8072,     5.0062,     5.0285,     5.3803,\n",
            "            5.4145,     6.2113,     6.2260,     8.4311,     9.8920,    10.4855,\n",
            "           10.4942,    11.0632,    11.6239,    11.7378,    12.2494,    12.3808,\n",
            "           12.7132,    12.7659,    13.2265,    13.5424,    13.6660,    13.7109,\n",
            "           13.7653,    14.0998,    14.2299,    14.3288,    14.6859,    14.7681,\n",
            "           14.9374,    15.0724,    15.3427,    15.3627,    15.5164,    15.5243,\n",
            "           15.9773,    16.0249,    16.0269,    16.3601,    16.4926,    16.6811,\n",
            "           17.0619,    17.4698,    17.6895,    17.9488,    18.0450,    18.1288],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([ 4,  3,  5,  1,  7,  6,  2,  0,  8,  9, 10, 11, 74, 56, 78, 77, 60, 12,\n",
            "        59, 71, 75, 81, 73, 57, 63, 53, 55, 13, 76, 70, 80, 52, 79, 72, 58, 14,\n",
            "        62, 54, 61, 15, 64, 82, 67, 68, 66, 84, 69, 16], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.6874, -3.9653, -5.2324, -4.7817, -3.0904, -4.9377, -5.3444, -3.8892,\n",
            "        -4.9627, -0.4634, -2.6707, -5.1570, -5.7003, -4.8722, -5.0779, -4.2224,\n",
            "        -4.4978, -3.1310, -5.2876, -4.2079, -5.6138], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7999,     3.8109,     4.8226,     5.0123,     5.3803,\n",
            "            5.4969,     6.0488,     6.1369,     6.6972,     7.4155,     8.4116,\n",
            "            8.5057,     8.7296,     8.9006,     8.9573,     8.9745,     9.1425,\n",
            "            9.3793,     9.6006,     9.8214,     9.9041,    10.0154,    10.2115,\n",
            "           10.5055,    10.6236,    10.8701,    11.0588,    11.0923,    11.5590,\n",
            "           11.6744,    11.8517,    12.0926,    12.5965,    12.6336,    12.6931,\n",
            "           13.0401,    13.3709,    13.7044,    13.7201,    13.7906,    13.8278,\n",
            "           13.9880,    13.9968,    14.1114,    14.4138,    14.8386,    14.9264],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([ 6,  7,  5,  9,  3,  4,  8,  2, 10, 56, 78, 11,  1, 81, 74, 53, 77, 57,\n",
            "        60, 12,  0, 59, 55, 75, 13, 52, 80, 54, 79, 82, 58, 76, 71, 14, 73, 63,\n",
            "        61, 84, 49, 85, 51, 72, 62, 15, 83, 50, 16, 64], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.2237, -4.7527, -2.6510, -1.6616, -4.7919, -4.5218, -4.8422, -2.6977,\n",
            "        -3.1677, -1.6256, -3.0488, -3.6819, -5.6986, -2.3107, -3.8452, -3.6449,\n",
            "        -3.2594, -2.5713, -5.1771, -4.5699, -5.4350], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7999,     3.8095,     5.0285,     5.1375,     5.2046,\n",
            "            5.3819,     6.1495,     6.1596,     8.5452,     8.6674,     8.8096,\n",
            "            9.0559,     9.3202,     9.7426,     9.8820,    10.0821,    10.3889,\n",
            "           10.5174,    10.8241,    10.8349,    11.5411,    12.0236,    12.1371,\n",
            "           12.3177,    12.5951,    12.6116,    12.7846,    12.8467,    13.1717,\n",
            "           13.2200,    13.3799,    13.5342,    13.6521,    13.9666,    14.0487,\n",
            "           14.2343,    14.3767,    14.5405,    15.3347,    15.3939,    15.4731,\n",
            "           15.6445,    15.7621,    16.3350,    16.4599,    16.5949,    16.6725],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([ 7,  6,  8,  4, 10,  9,  5, 11,  3,  2, 12, 78, 77, 81,  1, 13, 74, 56,\n",
            "         0, 80, 14, 53, 75, 79, 15, 57, 76, 60, 82, 52, 84, 73, 55, 59, 71, 16,\n",
            "        54, 85, 83, 49, 58, 72, 17, 63, 70, 61, 51, 50], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.1395, -4.7659, -2.1509, -1.4882, -4.8647, -4.5376, -4.8138, -2.9771,\n",
            "        -3.4937, -1.8053, -3.2113, -3.6970, -5.6681, -2.3095, -3.9956, -3.5929,\n",
            "        -3.3051, -2.7506, -5.1821, -4.6818, -5.4066], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7999,     3.8095,     5.0285,     5.1375,     5.2046,\n",
            "            5.3819,     6.1495,     6.1596,     8.5452,     8.6674,     8.8096,\n",
            "            9.0559,     9.3202,     9.7426,     9.8820,    10.0821,    10.3889,\n",
            "           10.5174,    10.8241,    10.8349,    11.5411,    12.0236,    12.1371,\n",
            "           12.3177,    12.5951,    12.6116,    12.7846,    12.8467,    13.1717,\n",
            "           13.2200,    13.3799,    13.5342,    13.6521,    13.9666,    14.0487,\n",
            "           14.2343,    14.3767,    14.5405,    15.3347,    15.3939,    15.4731,\n",
            "           15.6445,    15.7621,    16.3350,    16.4599,    16.5949,    16.6725],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([ 7,  6,  8,  4, 10,  9,  5, 11,  3,  2, 12, 78, 77, 81,  1, 13, 74, 56,\n",
            "         0, 80, 14, 53, 75, 79, 15, 57, 76, 60, 82, 52, 84, 73, 55, 59, 71, 16,\n",
            "        54, 85, 83, 49, 58, 72, 17, 63, 70, 61, 51, 50], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.0514, -5.1159, -3.0562, -2.3114, -4.7355, -3.0717, -3.9536, -4.6238,\n",
            "        -2.0187, -3.0315, -4.1405, -2.6189, -5.6265, -2.1455, -2.1861, -2.7751,\n",
            "        -3.3871, -4.1484, -5.0878, -4.5894, -5.5159], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7940,     3.8196,     4.8575,     5.0639,     5.1874,\n",
            "            5.2960,     6.1495,     6.2192,     8.4116,     8.4721,     9.5218,\n",
            "            9.5979,    10.0392,    10.4855,    10.6183,    11.0904,    11.6453,\n",
            "           11.6465,    11.9359,    12.1057,    12.2263,    12.5511,    12.6467,\n",
            "           12.7033,    12.8994,    12.9028,    13.2354,    13.8558,    13.9740,\n",
            "           14.2051,    14.3091,    14.6330,    15.1405,    15.2694,    15.2825,\n",
            "           15.2906,    15.3360,    15.4482,    15.4592,    15.5825,    15.6215,\n",
            "           15.8915,    15.9764,    16.1146,    16.1975,    16.2669,    16.3304],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([11, 10, 12,  8,  9, 14, 13,  7, 15,  6, 16, 81,  5, 17,  4, 18, 84, 80,\n",
            "        53, 78, 85,  3, 19, 77, 52, 49, 82, 56, 83,  2, 79, 88, 20,  1, 54, 74,\n",
            "        55, 50, 57, 21, 87, 86, 48, 46, 45, 51, 76, 75], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.0398, -5.1081, -3.0414, -2.4165, -4.7490, -2.9182, -3.9651, -4.7199,\n",
            "        -1.9976, -3.1178, -4.2224, -2.5409, -5.6557, -2.0195, -2.3698, -2.7423,\n",
            "        -3.3769, -4.2264, -5.0801, -4.6332, -5.4970], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7940,     3.8196,     4.8575,     5.0639,     5.1874,\n",
            "            5.2960,     6.1495,     6.2192,     8.4116,     8.4721,     9.5218,\n",
            "            9.5979,    10.0392,    10.4855,    10.6183,    11.0904,    11.6453,\n",
            "           11.6465,    11.9359,    12.1057,    12.2263,    12.5511,    12.6467,\n",
            "           12.7033,    12.8994,    12.9028,    13.2354,    13.8558,    13.9740,\n",
            "           14.2051,    14.3091,    14.6330,    15.1405,    15.2694,    15.2825,\n",
            "           15.2906,    15.3360,    15.4482,    15.4592,    15.5825,    15.6215,\n",
            "           15.8915,    15.9764,    16.1146,    16.1975,    16.2669,    16.3304],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([11, 10, 12,  8,  9, 14, 13,  7, 15,  6, 16, 81,  5, 17,  4, 18, 84, 80,\n",
            "        53, 78, 85,  3, 19, 77, 52, 49, 82, 56, 83,  2, 79, 88, 20,  1, 54, 74,\n",
            "        55, 50, 57, 21, 87, 86, 48, 46, 45, 51, 76, 75], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.2764, -5.0292, -3.7615, -3.0712, -4.1249, -3.2731, -3.4721, -4.5253,\n",
            "        -1.4540, -2.8455, -4.3745, -3.3645, -5.7250, -2.8903, -1.8319, -2.6851,\n",
            "        -3.5233, -4.1043, -3.7465, -3.6599, -5.5563], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8029,     3.8196,     4.8127,     4.9039,     5.4021,\n",
            "            5.4023,     5.8091,     6.2913,     8.5557,     8.6674,     9.4929,\n",
            "            9.6006,     9.8816,    10.0929,    10.2376,    10.3341,    10.3517,\n",
            "           10.3954,    11.2890,    11.4569,    12.3808,    12.4821,    12.4968,\n",
            "           12.6451,    12.7113,    12.8547,    12.9577,    13.0480,    13.1347,\n",
            "           13.3579,    13.4305,    13.6839,    13.8474,    13.8547,    14.1077,\n",
            "           14.1233,    14.4586,    14.8698,    14.9416,    14.9766,    15.0348,\n",
            "           15.0532,    15.1186,    15.1698,    15.2288,    15.5734,    15.6120],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([12, 13, 11, 15,  9, 10, 14, 16,  8, 17,  7, 18,  6, 49, 53, 52, 19,  5,\n",
            "        81, 85, 84,  4, 20, 48, 45, 56, 50, 46, 82, 88, 80, 78, 51, 55, 54, 21,\n",
            "         3, 83, 22, 42,  2, 77, 86, 47, 57, 87, 79, 89], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.9626, -4.7422, -4.8603, -4.1960, -4.4012, -4.8086, -5.1439, -2.6344,\n",
            "        -5.0226, -0.4089, -2.9014, -4.8223, -5.6858, -4.1637, -4.9580, -4.3982,\n",
            "        -4.3078, -3.0444, -4.7629, -5.1904, -5.5172], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8029,     3.8069,     4.8855,     5.0223,     5.2960,\n",
            "            5.3822,     6.2892,     6.4335,     7.7199,     7.8768,     7.9589,\n",
            "            8.5537,     8.6372,     8.8321,     9.0422,     9.4673,     9.8820,\n",
            "            9.9140,    10.1646,    10.1685,    10.5055,    10.8969,    10.9415,\n",
            "           10.9714,    11.1198,    11.2097,    11.4139,    11.4260,    11.4885,\n",
            "           11.9425,    12.0424,    12.1167,    12.4012,    12.6222,    12.7562,\n",
            "           12.7967,    12.9864,    13.0075,    13.3550,    13.7298,    13.8228,\n",
            "           13.8275,    14.1898,    14.3086,    14.3100,    14.3288,    14.3392],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([13, 12, 14, 16, 10, 11, 15, 17,  9, 85, 84, 81, 18, 49,  8, 53, 88,  7,\n",
            "        19, 52, 82,  6, 80, 20, 46, 83, 50, 86, 87, 45, 48, 78, 89,  5, 21, 56,\n",
            "        54, 42, 51, 79, 47, 77, 55, 91, 22, 92,  4, 57], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.9328, -4.6190, -4.8429, -4.1933, -4.5560, -4.7892, -5.1774, -2.4298,\n",
            "        -5.0364, -0.4589, -2.8480, -4.8151, -5.6749, -4.0680, -5.0076, -4.3655,\n",
            "        -4.2456, -2.8452, -4.7946, -5.1358, -5.5354], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8029,     3.8069,     4.8855,     5.0223,     5.2960,\n",
            "            5.3822,     6.2892,     6.4335,     7.7199,     7.8768,     7.9589,\n",
            "            8.5537,     8.6372,     8.8321,     9.0422,     9.4673,     9.8820,\n",
            "            9.9140,    10.1646,    10.1685,    10.5055,    10.8969,    10.9415,\n",
            "           10.9714,    11.1198,    11.2097,    11.4139,    11.4260,    11.4885,\n",
            "           11.9425,    12.0424,    12.1167,    12.4012,    12.6222,    12.7562,\n",
            "           12.7967,    12.9864,    13.0075,    13.3550,    13.7298,    13.8228,\n",
            "           13.8275,    14.1898,    14.3086,    14.3100,    14.3288,    14.3392],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([13, 12, 14, 16, 10, 11, 15, 17,  9, 85, 84, 81, 18, 49,  8, 53, 88,  7,\n",
            "        19, 52, 82,  6, 80, 20, 46, 83, 50, 86, 87, 45, 48, 78, 89,  5, 21, 56,\n",
            "        54, 42, 51, 79, 47, 77, 55, 91, 22, 92,  4, 57], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.4497, -5.2009, -2.3753, -1.4431, -4.7415, -3.5905, -3.9839, -4.7683,\n",
            "        -2.3760, -3.8972, -4.2340, -3.0562, -5.5978, -2.0128, -2.7264, -2.8293,\n",
            "        -3.2195, -4.2613, -4.9364, -4.2954, -5.5073], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7954,     3.8037,     4.8127,     4.9384,     5.3822,\n",
            "            5.5300,     6.2192,     6.4017,     8.7356,     8.9647,     9.5613,\n",
            "            9.7981,    10.2268,    10.3992,    12.1423,    12.2323,    12.3177,\n",
            "           12.4227,    12.4836,    12.6187,    12.8911,    12.9526,    13.7851,\n",
            "           13.8091,    13.9383,    13.9968,    14.1160,    14.6395,    14.8588,\n",
            "           14.8704,    15.1152,    15.3105,    15.3952,    15.4419,    15.5350,\n",
            "           15.5470,    15.5576,    15.7596,    15.8391,    16.1529,    16.1958,\n",
            "           16.3601,    16.5737,    16.6549,    16.7301,    16.7638,    16.9337],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([15, 16, 14, 12, 18, 13, 17, 11, 19, 10, 20,  9, 21,  8, 22, 84, 49,  7,\n",
            "        85, 88, 23, 45, 81, 42, 46, 53,  6, 52, 48, 87,  5, 24, 80, 82, 41, 50,\n",
            "        38, 89, 83, 86, 91, 92,  4, 44, 47, 43, 78, 25], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.4824, -5.2423, -2.4127, -1.4306, -4.7779, -3.6209, -4.0057, -4.7966,\n",
            "        -2.3613, -3.9340, -4.2329, -3.0661, -5.6068, -2.0066, -2.6686, -2.7979,\n",
            "        -3.2192, -4.3109, -4.9754, -4.3431, -5.4979], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7954,     3.8037,     4.8127,     4.9384,     5.3822,\n",
            "            5.5300,     6.2192,     6.4017,     8.7356,     8.9647,     9.5613,\n",
            "            9.7981,    10.2268,    10.3992,    12.1423,    12.2323,    12.3177,\n",
            "           12.4227,    12.4836,    12.6187,    12.8911,    12.9526,    13.7851,\n",
            "           13.8091,    13.9383,    13.9968,    14.1160,    14.6395,    14.8588,\n",
            "           14.8704,    15.1152,    15.3105,    15.3952,    15.4419,    15.5350,\n",
            "           15.5470,    15.5576,    15.7596,    15.8391,    16.1529,    16.1958,\n",
            "           16.3601,    16.5737,    16.6549,    16.7301,    16.7638,    16.9337],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([15, 16, 14, 12, 18, 13, 17, 11, 19, 10, 20,  9, 21,  8, 22, 84, 49,  7,\n",
            "        85, 88, 23, 45, 81, 42, 46, 53,  6, 52, 48, 87,  5, 24, 80, 82, 41, 50,\n",
            "        38, 89, 83, 86, 91, 92,  4, 44, 47, 43, 78, 25], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.7019, -4.9538, -4.3730, -3.4822, -1.7288, -4.0836, -3.5122, -3.9661,\n",
            "        -3.3032, -1.8985, -3.5988, -4.1959, -5.7575, -3.2460, -2.0297, -3.5448,\n",
            "        -3.2517, -3.4075, -3.6239, -2.2443, -5.6338], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7954,     3.8075,     4.8855,     5.2316,     5.2810,\n",
            "            5.3162,     5.8091,     6.7275,     8.4721,     8.9042,     9.2377,\n",
            "            9.3162,     9.6698,     9.9509,     9.9568,    10.0751,    10.1863,\n",
            "           10.2290,    10.4028,    11.1163,    11.1665,    11.5785,    11.9378,\n",
            "           12.0736,    12.2735,    12.3499,    12.5141,    12.5698,    12.5873,\n",
            "           12.7199,    12.8847,    12.9365,    12.9610,    12.9700,    13.1795,\n",
            "           13.5250,    13.5841,    13.6782,    13.7330,    14.0487,    14.1840,\n",
            "           14.7239,    14.7433,    14.8386,    14.9825,    15.2206,    15.3861],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([16, 15, 17, 13, 19, 18, 14, 12, 20, 11, 21, 45, 49, 10, 22, 88, 42, 46,\n",
            "         9, 85, 23, 84, 48, 41,  8, 52, 53, 38, 89, 81, 50, 44, 43, 92, 87, 47,\n",
            "        91, 39, 24, 86,  7, 82, 51, 83,  6, 40, 90, 80], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.4206, -4.6249, -2.9292, -2.3226, -3.0440, -4.0203, -4.1781, -2.5078,\n",
            "        -3.5751, -2.2375, -3.6918, -3.7546, -4.8552, -3.3208, -3.3245, -3.3213,\n",
            "        -3.6465, -2.6818, -2.0484, -2.7980, -5.5174], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7966,     3.8004,     5.2202,     5.3917,     5.4344,\n",
            "            5.4850,     6.7275,     7.1412,     7.2014,     7.9459,     8.9647,\n",
            "            9.1283,     9.2197,     9.4678,    10.1538,    10.2644,    10.2712,\n",
            "           10.3459,    10.4148,    10.5124,    10.7753,    10.9415,    11.1905,\n",
            "           11.4348,    11.7055,    11.7595,    11.8732,    12.0668,    12.4821,\n",
            "           12.6427,    12.6779,    12.7806,    13.0289,    13.4339,    13.4686,\n",
            "           13.6197,    14.0318,    14.1708,    14.1760,    14.2125,    14.2201,\n",
            "           14.2863,    14.4696,    14.6330,    14.8774,    15.0820,    15.5452],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([20, 19, 21, 17, 18, 22, 23, 16, 38, 24, 42, 15, 39, 41, 35, 14, 45, 25,\n",
            "        88, 92, 34, 37, 13, 91, 40, 43, 46, 36, 95, 12, 44, 89, 31, 26, 49, 85,\n",
            "        87, 33, 93, 32, 96, 90, 84, 94, 11, 48, 47, 30], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.7228, -5.0143, -2.2327, -2.0489, -3.3224, -3.6593, -3.6593, -3.6154,\n",
            "        -2.7042, -2.1722, -3.6344, -2.9543, -4.4325, -2.8179, -2.8643, -2.9356,\n",
            "        -3.1133, -3.3292, -4.0260, -3.3822, -5.5507], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7967,     3.8205,     5.2081,     5.2636,     5.3219,\n",
            "            5.5971,     5.8876,     6.3228,     8.6600,     8.7998,     8.9727,\n",
            "            9.9629,    10.1934,    11.4142,    11.7848,    14.0785,    14.2131,\n",
            "           15.0351,    15.4349,    15.5452,    16.1203,    16.2567,    17.4292,\n",
            "           17.5681,    17.6909,    19.1763,    19.3574,    19.5997,    19.8762,\n",
            "           20.1663,    20.5797,    20.6164,    21.2479,    21.3020,    21.5507,\n",
            "           22.0556,    23.2325,    23.6672,    23.8566,    24.1067,    24.1473,\n",
            "           25.4146,    25.9541,    25.9556,    26.4785,    26.9469,    26.9939],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([30, 31, 29, 33, 32, 28, 27, 34, 26, 35, 25, 24, 36, 37, 23, 38, 22, 39,\n",
            "        21, 40, 20, 41, 95, 96, 19, 42, 97, 92, 18, 94, 43, 17, 91, 44, 93, 45,\n",
            "        16, 88, 46, 15, 90, 89, 14, 47, 87, 13, 48, 49], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.7912, -5.0277, -2.1651, -1.9649, -3.3443, -3.6921, -3.6672, -3.6124,\n",
            "        -2.7030, -2.2082, -3.6011, -2.9151, -4.5647, -2.7948, -2.9740, -2.9660,\n",
            "        -3.1330, -3.4000, -4.0695, -3.3799, -5.5685], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7967,     3.8205,     5.2081,     5.2636,     5.3219,\n",
            "            5.5971,     5.8876,     6.3228,     8.6600,     8.7998,     8.9727,\n",
            "            9.9629,    10.1934,    11.4142,    11.7848,    14.0785,    14.2131,\n",
            "           15.0351,    15.4349,    15.5452,    16.1203,    16.2567,    17.4292,\n",
            "           17.5681,    17.6909,    19.1763,    19.3574,    19.5997,    19.8762,\n",
            "           20.1663,    20.5797,    20.6164,    21.2479,    21.3020,    21.5507,\n",
            "           22.0556,    23.2325,    23.6672,    23.8566,    24.1067,    24.1473,\n",
            "           25.4146,    25.9541,    25.9556,    26.4785,    26.9469,    26.9939],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([30, 31, 29, 33, 32, 28, 27, 34, 26, 35, 25, 24, 36, 37, 23, 38, 22, 39,\n",
            "        21, 40, 20, 41, 95, 96, 19, 42, 97, 92, 18, 94, 43, 17, 91, 44, 93, 45,\n",
            "        16, 88, 46, 15, 90, 89, 14, 47, 87, 13, 48, 49], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.9921, -5.2277, -3.3428, -2.0551, -3.8980, -3.2365, -4.0997, -3.1897,\n",
            "        -2.5745, -2.5163, -3.8398, -3.9665, -2.9020, -2.8895, -2.5130, -2.9587,\n",
            "        -3.1518, -2.8792, -4.2993, -3.9039, -5.5365], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7988,     3.8089,     5.2226,     5.2636,     5.3379,\n",
            "            6.5948,     6.6317,     6.8234,     8.6986,     8.8460,     9.1717,\n",
            "            9.6017,     9.8612,    10.2049,    11.0901,    11.5615,    11.7854,\n",
            "           12.8717,    13.0721,    13.9286,    14.1760,    14.1815,    14.3360,\n",
            "           14.5661,    15.0204,    15.2750,    15.3691,    16.4504,    16.8123,\n",
            "           17.1161,    17.4017,    18.6828,    18.8018,    19.3176,    19.7704,\n",
            "           19.8066,    19.8141,    20.3559,    20.8111,    21.1437,    22.2068,\n",
            "           23.0349,    23.6254,    23.8873,    24.4605,    24.7196,    24.7374],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([32, 31, 33, 34, 30, 35, 36, 29, 28, 37, 24, 27, 26, 38, 25, 39, 95, 23,\n",
            "        96, 40, 21, 20, 97, 22, 41, 94, 42, 92, 91, 93, 19, 43, 18, 17, 44, 45,\n",
            "        90, 88, 89, 16, 46, 87, 15, 47, 14, 85, 13, 86], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.6727, -5.0123, -2.8096, -2.4694, -4.3801, -4.0555, -4.1049, -4.3933,\n",
            "        -2.8780, -1.7725, -3.4898, -2.5898, -5.5593, -2.8423, -2.3256, -3.0082,\n",
            "        -3.7152, -4.3375, -5.0606, -4.2970, -5.5890], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8004,     3.8041,     4.6212,     5.0180,     5.2226,\n",
            "            5.4486,     5.7832,     5.8876,     5.8995,     7.4003,     7.7302,\n",
            "            8.1345,     8.5783,     9.0585,     9.2693,     9.4041,    10.0170,\n",
            "           10.4461,    10.5124,    10.6949,    11.0554,    11.8024,    11.8069,\n",
            "           12.8973,    12.9829,    14.0354,    14.4145,    15.2908,    15.4287,\n",
            "           15.5687,    15.5754,    15.6035,    15.7468,    15.7490,    16.3370,\n",
            "           16.9007,    17.7801,    17.9001,    18.6737,    19.0970,    19.2091,\n",
            "           20.1333,    20.6455,    20.9203,    21.1649,    21.1688,    21.2309],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([34, 35, 33, 31, 37, 32, 36, 24, 30, 38, 23, 26, 25, 39, 28, 29, 27, 40,\n",
            "        41, 20, 22, 21, 95, 42, 96, 19, 92, 43, 18, 97, 94, 44, 17, 45, 91, 93,\n",
            "        16, 46, 88, 89, 90, 15, 47, 14, 87, 49, 48, 13], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.7061, -5.0237, -2.8125, -2.5105, -4.4130, -4.1642, -4.0747, -4.3713,\n",
            "        -2.7838, -1.7938, -3.4046, -2.6091, -5.5215, -2.7929, -2.2829, -3.0179,\n",
            "        -3.6514, -4.3245, -5.0865, -4.3374, -5.5880], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8004,     3.8041,     4.6212,     5.0180,     5.2226,\n",
            "            5.4486,     5.7832,     5.8876,     5.8995,     7.4003,     7.7302,\n",
            "            8.1345,     8.5783,     9.0585,     9.2693,     9.4041,    10.0170,\n",
            "           10.4461,    10.5124,    10.6949,    11.0554,    11.8024,    11.8069,\n",
            "           12.8973,    12.9829,    14.0354,    14.4145,    15.2908,    15.4287,\n",
            "           15.5687,    15.5754,    15.6035,    15.7468,    15.7490,    16.3370,\n",
            "           16.9007,    17.7801,    17.9001,    18.6737,    19.0970,    19.2091,\n",
            "           20.1333,    20.6455,    20.9203,    21.1649,    21.1688,    21.2309],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([34, 35, 33, 31, 37, 32, 36, 24, 30, 38, 23, 26, 25, 39, 28, 29, 27, 40,\n",
            "        41, 20, 22, 21, 95, 42, 96, 19, 92, 43, 18, 97, 94, 44, 17, 45, 91, 93,\n",
            "        16, 46, 88, 89, 90, 15, 47, 14, 87, 49, 48, 13], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.0013, -5.1109, -3.0503, -2.0231, -4.1684, -3.5361, -4.1717, -2.9366,\n",
            "        -2.7737, -2.1470, -3.7483, -3.8479, -5.0529, -2.5498, -2.5832, -3.1193,\n",
            "        -3.1001, -2.7728, -4.5855, -4.1213, -5.5640], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8004,     3.8017,     4.9263,     5.3379,     5.4270,\n",
            "            5.4890,     6.1565,     6.2273,     6.5111,     8.0721,     8.4506,\n",
            "            8.6600,     8.8563,     9.4678,     9.6174,     9.6400,     9.8627,\n",
            "           10.0672,    10.1639,    10.4309,    10.4442,    10.6980,    11.1366,\n",
            "           11.2520,    11.7771,    11.8060,    12.0395,    12.2176,    12.5254,\n",
            "           12.7431,    12.8275,    14.0089,    14.4469,    14.5235,    14.6182,\n",
            "           14.9399,    15.5334,    15.5684,    15.8564,    15.9052,    17.7130,\n",
            "           18.4296,    18.5660,    19.2024,    19.4071,    19.5761,    19.6649],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([35, 34, 36, 38, 32, 37, 33, 31, 39, 24, 95, 23, 30, 40, 20, 96, 25, 41,\n",
            "        42, 21, 26, 28, 92, 22, 29, 27, 94, 97, 91, 43, 19, 93, 17, 18, 44, 45,\n",
            "        88, 89, 90, 16, 46, 87, 15, 47, 14, 85, 49, 13], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.9124, -5.4600, -2.0650, -1.3643, -4.8024, -4.3489, -4.4718, -4.3136,\n",
            "        -3.0856, -2.7622, -3.8941, -3.0005, -5.7388, -2.7352, -2.6619, -3.2063,\n",
            "        -3.4752, -4.3694, -5.1584, -4.7253, -5.5057], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8000,     3.8133,     5.0180,     5.3287,     5.4270,\n",
            "            5.4509,     6.0069,     6.4518,     8.5652,     8.6986,     9.2658,\n",
            "            9.3410,     9.5075,    10.1934,    10.3475,    10.5086,    10.7513,\n",
            "           10.7753,    11.2569,    12.0936,    12.2895,    12.3093,    12.4572,\n",
            "           12.8477,    12.8484,    13.3168,    13.6447,    13.6817,    13.9516,\n",
            "           14.1054,    14.3155,    14.3745,    14.4167,    14.8493,    15.4586,\n",
            "           16.0777,    16.0887,    16.1284,    16.5289,    16.5925,    17.5441,\n",
            "           17.5551,    18.1545,    19.0913,    19.9129,    20.1627,    20.3035],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([37, 38, 36, 34, 40, 35, 39, 33, 41, 42, 32, 23, 24, 31, 30, 43, 96, 95,\n",
            "        20, 44, 92, 45, 26, 25, 22, 21, 19, 29, 97, 28, 93, 27, 46, 94, 91, 17,\n",
            "        16, 18, 47, 89, 88, 90, 48, 49, 15, 87, 13, 50], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.8142, -5.4806, -2.2291, -1.5348, -4.7980, -4.1998, -4.3843, -4.2965,\n",
            "        -2.9309, -2.7858, -3.9805, -2.8787, -5.7556, -2.6784, -2.4520, -3.0935,\n",
            "        -3.3509, -4.2947, -5.2186, -4.6944, -5.5347], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8000,     3.8133,     5.0180,     5.3287,     5.4270,\n",
            "            5.4509,     6.0069,     6.4518,     8.5652,     8.6986,     9.2658,\n",
            "            9.3410,     9.5075,    10.1934,    10.3475,    10.5086,    10.7513,\n",
            "           10.7753,    11.2569,    12.0936,    12.2895,    12.3093,    12.4572,\n",
            "           12.8477,    12.8484,    13.3168,    13.6447,    13.6817,    13.9516,\n",
            "           14.1054,    14.3155,    14.3745,    14.4167,    14.8493,    15.4586,\n",
            "           16.0777,    16.0887,    16.1284,    16.5289,    16.5925,    17.5441,\n",
            "           17.5551,    18.1545,    19.0913,    19.9129,    20.1627,    20.3035],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([37, 38, 36, 34, 40, 35, 39, 33, 41, 42, 32, 23, 24, 31, 30, 43, 96, 95,\n",
            "        20, 44, 92, 45, 26, 25, 22, 21, 19, 29, 97, 28, 93, 27, 46, 94, 91, 17,\n",
            "        16, 18, 47, 89, 88, 90, 48, 49, 15, 87, 13, 50], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.8633, -4.4243, -3.7137, -2.6928, -3.5609, -3.6867, -3.5746, -3.4273,\n",
            "        -3.9349, -2.6781, -4.4433, -3.1248, -5.3555, -2.2700, -3.6362, -2.9077,\n",
            "        -2.0295, -2.3856, -4.2852, -2.9432, -5.5253], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7990,     3.8113,     4.7415,     5.2283,     5.3933,\n",
            "            5.4509,     6.2273,     6.3570,     6.4530,     6.5990,     6.7347,\n",
            "            8.5783,     8.8215,     8.8937,     9.1283,     9.4695,     9.7953,\n",
            "            9.8603,     9.9415,    10.1231,    10.2962,    10.5910,    10.7152,\n",
            "           11.0901,    11.1652,    11.6469,    11.7404,    12.2069,    12.2604,\n",
            "           12.3659,    12.5262,    12.6292,    13.1936,    13.5841,    14.2131,\n",
            "           14.3359,    14.4539,    14.4913,    14.5876,    14.8540,    15.4874,\n",
            "           15.5896,    16.0832,    16.1327,    16.6473,    16.7835,    16.9912],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([39, 38, 40, 42, 36, 41, 37, 35, 43, 96, 95, 92, 34, 44, 93, 20, 45, 94,\n",
            "        91, 33, 97, 46, 23, 24, 32, 89, 88, 21, 90, 31, 19, 17, 47, 22, 16, 30,\n",
            "        18, 25, 49, 48, 87, 85, 26, 86, 50, 28, 13, 15], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.1921, -5.0738, -2.6950, -2.0098, -4.4024, -4.2748, -4.2109, -3.5811,\n",
            "        -2.2541, -2.4714, -3.4736, -3.4699, -5.5987, -2.1570, -2.5045, -3.2846,\n",
            "        -3.1776, -3.4188, -3.6505, -4.0857, -5.4433], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8005,     3.8009,     5.1117,     5.2297,     5.3933,\n",
            "            5.5210,     5.9547,     6.4518,     8.5601,     8.9248,     9.2197,\n",
            "            9.8627,    10.0386,    10.2297,    10.2838,    10.4461,    11.0344,\n",
            "           11.1270,    11.2524,    11.8193,    11.9378,    12.0399,    12.0974,\n",
            "           12.3950,    12.4609,    12.6906,    12.8017,    13.0119,    13.1329,\n",
            "           13.4151,    13.5654,    13.9621,    14.3197,    14.5661,    14.6053,\n",
            "           14.8528,    15.0430,    15.4198,    15.4419,    15.5485,    15.6266,\n",
            "           15.9818,    16.1203,    16.4747,    16.6296,    16.7099,    16.8070],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([41, 42, 40, 38, 44, 39, 43, 45, 37, 46, 36, 20, 35, 47, 23, 92, 34, 19,\n",
            "        48, 96, 95, 16, 49, 24, 33, 17, 21, 93, 22, 89, 88, 91, 18, 50, 32, 94,\n",
            "        31, 97, 90, 15, 13, 25, 85, 30, 26, 51, 52, 12], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.1056, -5.1073, -2.6756, -1.8718, -4.2618, -4.2932, -4.2694, -3.5664,\n",
            "        -2.5069, -2.3773, -3.4037, -3.6022, -5.6619, -2.1227, -2.7965, -3.3259,\n",
            "        -3.1982, -3.3824, -3.6161, -3.9932, -5.4383], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8005,     3.8009,     5.1117,     5.2297,     5.3933,\n",
            "            5.5210,     5.9547,     6.4518,     8.5601,     8.9248,     9.2197,\n",
            "            9.8627,    10.0386,    10.2297,    10.2838,    10.4461,    11.0344,\n",
            "           11.1270,    11.2524,    11.8193,    11.9378,    12.0399,    12.0974,\n",
            "           12.3950,    12.4609,    12.6906,    12.8017,    13.0119,    13.1329,\n",
            "           13.4151,    13.5654,    13.9621,    14.3197,    14.5661,    14.6053,\n",
            "           14.8528,    15.0430,    15.4198,    15.4419,    15.5485,    15.6266,\n",
            "           15.9818,    16.1203,    16.4747,    16.6296,    16.7099,    16.8070],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([41, 42, 40, 38, 44, 39, 43, 45, 37, 46, 36, 20, 35, 47, 23, 92, 34, 19,\n",
            "        48, 96, 95, 16, 49, 24, 33, 17, 21, 93, 22, 89, 88, 91, 18, 50, 32, 94,\n",
            "        31, 97, 90, 15, 13, 25, 85, 30, 26, 51, 52, 12], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.6076, -4.9887, -4.0005, -2.4281, -3.2676, -4.8768, -5.1357, -2.2075,\n",
            "        -4.8545, -0.9805, -1.7889, -4.7890, -5.6434, -3.6227, -4.5755, -4.3728,\n",
            "        -3.8228, -3.1521, -4.5253, -4.9640, -5.5209], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8005,     3.8014,     4.7415,     4.8665,     5.3114,\n",
            "            5.4606,     5.9152,     5.9913,     6.9624,     7.9459,     8.5652,\n",
            "            8.6215,     9.3858,     9.6557,     9.6725,     9.7208,     9.7444,\n",
            "            9.8438,     9.8700,    10.0334,    10.0343,    10.0672,    10.0751,\n",
            "           10.1539,    10.3026,    10.8948,    11.4875,    11.8047,    11.8069,\n",
            "           11.8995,    11.9004,    12.3739,    12.3796,    12.3931,    12.8533,\n",
            "           12.9864,    13.3380,    13.3660,    13.7851,    13.8123,    13.9524,\n",
            "           14.4258,    14.8087,    14.8516,    14.9416,    15.0566,    15.2750],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([42, 41, 43, 39, 45, 40, 44, 38, 46, 92, 20, 37, 47, 89, 96, 88, 95, 36,\n",
            "        93, 49, 17, 48, 35, 16, 91, 19, 23, 21, 90, 34, 94, 50, 18, 85, 24, 22,\n",
            "        13, 87, 97, 15, 86, 33, 14, 51, 52, 12, 84, 32], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.9725, -5.3277, -3.2060, -1.3363, -5.0915, -4.1931, -4.5368, -3.6895,\n",
            "        -2.0348, -3.3171, -4.3866, -4.0210, -5.6020, -2.3799, -3.1842, -3.2269,\n",
            "        -2.7084, -3.2668, -5.2966, -4.9703, -5.4406], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7968,     3.8039,     5.2297,     5.2514,     5.4606,\n",
            "            5.5099,     6.6884,     7.0551,     8.8215,     8.9371,    10.0350,\n",
            "           10.3986,    11.1339,    11.2569,    12.2011,    12.3123,    12.6427,\n",
            "           12.7178,    12.8847,    12.9273,    13.1506,    13.2369,    13.4320,\n",
            "           13.9705,    14.0650,    14.1299,    14.5235,    14.6183,    14.6293,\n",
            "           14.9044,    14.9517,    15.1832,    15.2123,    15.5754,    15.8247,\n",
            "           16.2047,    16.3192,    16.3318,    16.3941,    16.4256,    16.4543,\n",
            "           16.5737,    16.8895,    16.9939,    17.1111,    17.1957,    17.5543],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([44, 45, 43, 41, 47, 42, 46, 40, 48, 39, 49, 38, 50, 92, 37, 89, 51, 20,\n",
            "        96, 16, 93, 36, 52, 88, 19, 95, 17, 35, 91, 85, 23, 53, 13, 90, 34, 94,\n",
            "        86, 97, 54, 21, 12, 18, 15, 87, 24, 22, 33, 14], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.9915, -5.4015, -5.1875, -4.1470, -2.3782, -5.2253, -4.8428, -2.8388,\n",
            "        -4.7237, -0.5823, -2.2216, -5.1952, -5.8220, -3.7427, -4.2700, -4.8531,\n",
            "        -4.8689, -4.8104, -4.3154, -3.5666, -5.5772], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8004,     3.8087,     4.6820,     5.1433,     5.3359,\n",
            "            5.5099,     5.9392,     5.9913,     7.9965,     8.5601,     8.9727,\n",
            "            9.0835,     9.0856,     9.2731,     9.5497,    10.1233,    10.1863,\n",
            "           10.1984,    10.2962,    10.9714,    11.0905,    11.1377,    11.1843,\n",
            "           11.6092,    11.7236,    11.7595,    11.8696,    11.8837,    12.2696,\n",
            "           12.7548,    12.9577,    13.0326,    13.0748,    13.0895,    13.5524,\n",
            "           13.7808,    13.8091,    13.9740,    14.1488,    14.2733,    14.3474,\n",
            "           14.3745,    14.5217,    14.6109,    14.7534,    15.2950,    15.4668],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([46, 47, 45, 49, 43, 48, 44, 50, 42, 89, 41, 51, 92, 88, 85, 52, 40, 16,\n",
            "        53, 39, 13, 86, 93, 17, 90, 91, 20, 54, 38, 87, 84, 12, 19, 82, 96, 95,\n",
            "        14, 15, 55, 81, 94, 18, 37,  9, 83, 10, 21, 36], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.2969, -4.9846, -3.2275, -1.9969, -4.4295, -3.1364, -3.9393, -3.5109,\n",
            "        -1.7875, -2.8908, -4.1244, -3.8325, -5.5632, -2.4438, -2.5900, -3.0278,\n",
            "        -2.7718, -2.9992, -4.7957, -4.3627, -5.4634], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8090,     3.8166,     5.3359,     5.4356,     5.4640,\n",
            "            5.8960,     6.4246,     7.0551,     8.9669,     9.1634,    10.0343,\n",
            "           10.2724,    11.0243,    11.1270,    11.5785,    11.9425,    12.3382,\n",
            "           12.4968,    12.8931,    13.2019,    13.4218,    13.4557,    13.6115,\n",
            "           13.9852,    14.4000,    14.5876,    14.6395,    14.7918,    14.7968,\n",
            "           14.8137,    14.8201,    14.8774,    14.9064,    15.3010,    15.3327,\n",
            "           15.4210,    15.6390,    15.7686,    15.8915,    16.3812,    16.4613,\n",
            "           16.5035,    16.5705,    16.5762,    16.6472,    16.9193,    17.2076],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([48, 47, 49, 46, 45, 50, 51, 52, 44, 53, 43, 42, 54, 55, 41, 16, 13, 85,\n",
            "        12, 89,  9, 56, 40, 88, 17, 92, 39, 15, 10, 57, 86, 82, 20, 19, 14, 81,\n",
            "        38, 84, 58, 11, 93,  6,  8, 87, 18, 90, 91,  5], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.1583, -4.5626, -4.2452, -3.2317, -4.3718, -5.1182, -4.9571, -2.2649,\n",
            "        -5.2777, -0.8717, -2.0105, -4.8466, -5.8119, -3.5172, -4.6064, -4.2194,\n",
            "        -3.2279, -2.8101, -3.7629, -4.2530, -5.5250], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8080,     3.8166,     4.6820,     5.0305,     5.5875,\n",
            "            5.7478,     6.1522,     6.1814,     8.4198,     8.6372,     8.7476,\n",
            "            8.9371,     9.3162,     9.7234,     9.8446,     9.8700,     9.8816,\n",
            "           10.4321,    10.4915,    10.6519,    11.2582,    11.3486,    11.3933,\n",
            "           11.4108,    11.5906,    11.5985,    11.9022,    12.0399,    12.1708,\n",
            "           12.2323,    12.5240,    12.8610,    12.8994,    13.3557,    13.4339,\n",
            "           13.5091,    13.6873,    13.7044,    13.9897,    14.2802,    14.3190,\n",
            "           14.3600,    14.3665,    14.4913,    14.6752,    14.9159,    15.0839],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([49, 50, 48, 46, 52, 47, 51, 53, 45, 54, 13, 85, 44, 16, 43, 55, 42, 12,\n",
            "         9, 89, 88, 82, 56, 17, 10, 86, 81, 84, 41, 14, 15, 57, 92, 11, 87, 20,\n",
            "        19, 83,  6,  8, 90, 58, 40, 18, 39, 91, 78,  5], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-4.4181, -4.7437, -5.4496, -5.2017, -4.6926, -3.9451, -4.4352, -1.1815,\n",
            "        -4.5266, -1.0352, -3.1575, -5.1001, -5.6269, -4.4999, -4.2326, -4.9784,\n",
            "        -3.8377, -2.0431, -5.1821, -4.5301, -5.5301], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8056,     3.8091,     5.3628,     5.5475,     5.5830,\n",
            "            5.6379,     6.1522,     6.5690,     7.7265,     7.8673,     7.9083,\n",
            "            8.5441,     8.7790,     8.9573,     8.9669,     8.9783,     9.0422,\n",
            "            9.5912,    10.0929,    10.1984,    10.2416,    10.7055,    10.7410,\n",
            "           11.0384,    11.0471,    11.2061,    11.3029,    11.3440,    11.4294,\n",
            "           11.5317,    11.5411,    11.6465,    12.3096,    12.3499,    12.7057,\n",
            "           12.7366,    12.8295,    12.8624,    12.9167,    12.9636,    13.1615,\n",
            "           13.3922,    13.9383,    13.9436,    14.0998,    14.1708,    14.3016],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([53, 52, 54, 55, 50, 56, 51, 49, 57,  9, 82, 81, 85, 10,  6, 48, 58, 13,\n",
            "        78, 12, 46, 59, 47, 84,  5, 60, 79, 86, 83,  8, 80,  7, 11, 45, 16, 88,\n",
            "        14,  2, 89, 61, 75, 77,  3, 15, 87,  4, 17, 74], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-4.4264, -4.7482, -5.4253, -5.1773, -4.7273, -3.9659, -4.4113, -1.1791,\n",
            "        -4.6102, -1.0230, -3.3289, -5.1769, -5.6508, -4.5568, -4.2420, -5.0654,\n",
            "        -3.9323, -1.9874, -5.2039, -4.6016, -5.5214], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8056,     3.8091,     5.3628,     5.5475,     5.5830,\n",
            "            5.6379,     6.1522,     6.5690,     7.7265,     7.8673,     7.9083,\n",
            "            8.5441,     8.7790,     8.9573,     8.9669,     8.9783,     9.0422,\n",
            "            9.5912,    10.0929,    10.1984,    10.2416,    10.7055,    10.7410,\n",
            "           11.0384,    11.0471,    11.2061,    11.3029,    11.3440,    11.4294,\n",
            "           11.5317,    11.5411,    11.6465,    12.3096,    12.3499,    12.7057,\n",
            "           12.7366,    12.8295,    12.8624,    12.9167,    12.9636,    13.1615,\n",
            "           13.3922,    13.9383,    13.9436,    14.0998,    14.1708,    14.3016],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([53, 52, 54, 55, 50, 56, 51, 49, 57,  9, 82, 81, 85, 10,  6, 48, 58, 13,\n",
            "        78, 12, 46, 59, 47, 84,  5, 60, 79, 86, 83,  8, 80,  7, 11, 45, 16, 88,\n",
            "        14,  2, 89, 61, 75, 77,  3, 15, 87,  4, 17, 74], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.3821, -5.7956, -3.7367, -3.3047, -5.3492, -4.6085, -4.6997, -5.4038,\n",
            "        -1.7913, -3.9631, -4.4520, -2.7915, -5.9202, -0.6731, -3.5303, -3.4509,\n",
            "        -3.6530, -5.4355, -5.6584, -5.3794, -5.7348], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7934,     3.8091,     4.8261,     4.9847,     5.3994,\n",
            "            5.5039,     6.0667,     6.1296,     8.4198,     8.5454,     9.0961,\n",
            "            9.7062,    10.2045,    10.2724,    10.5513,    10.6623,    10.7961,\n",
            "           11.0392,    11.0588,    11.3973,    11.8696,    11.8984,    12.1796,\n",
            "           12.5547,    12.6133,    12.7800,    12.7967,    12.8282,    12.9990,\n",
            "           13.2053,    13.3114,    13.4772,    13.8547,    14.2343,    14.2727,\n",
            "           14.3530,    14.3960,    14.4490,    14.5135,    14.6446,    14.7322,\n",
            "           15.0372,    15.1524,    15.2694,    15.3934,    15.8662,    15.9717],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([54, 55, 53, 57, 51, 56, 52, 50, 58, 49, 59, 82, 60, 81, 48, 61, 78, 85,\n",
            "         9,  6, 47, 46, 79, 10, 62, 86, 75, 13, 83,  5, 84, 80,  2, 12,  7, 63,\n",
            "        89, 45, 77,  8,  3, 74, 88, 76, 11, 64, 87, 16], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.1375, -5.9109, -3.6975, -3.2093, -5.4245, -4.6805, -4.8391, -5.5633,\n",
            "        -2.0049, -4.1204, -4.5939, -2.9380, -5.9964, -0.5921, -3.5868, -3.5079,\n",
            "        -3.8595, -5.5349, -5.6863, -5.4089, -5.7817], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7934,     3.8091,     4.8261,     4.9847,     5.3994,\n",
            "            5.5039,     6.0667,     6.1296,     8.4198,     8.5454,     9.0961,\n",
            "            9.7062,    10.2045,    10.2724,    10.5513,    10.6623,    10.7961,\n",
            "           11.0392,    11.0588,    11.3973,    11.8696,    11.8984,    12.1796,\n",
            "           12.5547,    12.6133,    12.7800,    12.7967,    12.8282,    12.9990,\n",
            "           13.2053,    13.3114,    13.4772,    13.8547,    14.2343,    14.2727,\n",
            "           14.3530,    14.3960,    14.4490,    14.5135,    14.6446,    14.7322,\n",
            "           15.0372,    15.1524,    15.2694,    15.3934,    15.8662,    15.9717],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([54, 55, 53, 57, 51, 56, 52, 50, 58, 49, 59, 82, 60, 81, 48, 61, 78, 85,\n",
            "         9,  6, 47, 46, 79, 10, 62, 86, 75, 13, 83,  5, 84, 80,  2, 12,  7, 63,\n",
            "        89, 45, 77,  8,  3, 74, 88, 76, 11, 64, 87, 16], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.8470, -4.5292, -4.7544, -4.4022, -2.7942, -4.8623, -2.0337, -1.8144,\n",
            "        -3.4099, -1.9797, -3.2370, -4.4493, -5.4829, -3.8497, -3.2816, -4.0516,\n",
            "        -3.5627, -1.9887, -4.5311, -2.2849, -5.5207], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7917,     3.8055,     4.9927,     5.3994,     5.4315,\n",
            "            5.5830,     6.1565,     6.6972,     7.0766,     8.0792,     8.2330,\n",
            "            8.4514,     8.6576,     8.6973,     8.8588,     9.5602,     9.8530,\n",
            "            9.9543,    10.2763,    10.3423,    10.3889,    10.4641,    10.5029,\n",
            "           10.6235,    11.0354,    11.0632,    11.0721,    11.3486,    11.4246,\n",
            "           11.6457,    11.9495,    12.5013,    12.6213,    12.7113,    12.7562,\n",
            "           12.7637,    13.1925,    13.2173,    13.2354,    13.4218,    13.4297,\n",
            "           14.0438,    14.2587,    14.4073,    14.6076,    14.6384,    15.0315],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([56, 55, 57, 59, 54, 58, 53, 60,  6, 52,  2,  5,  9, 78, 61, 51,  3, 62,\n",
            "        81, 10, 75,  7, 63, 50, 82,  8,  4, 74, 49, 79,  1, 77, 64, 71, 12, 13,\n",
            "        80, 85, 76, 11, 48,  0, 72, 83, 84, 73, 65, 66], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.7502, -5.4578, -1.0354, -1.5796, -4.8829, -4.6413, -4.7120, -3.9557,\n",
            "        -3.3346, -3.4670, -4.3444, -2.8225, -5.7204, -3.2462, -3.7844, -3.3164,\n",
            "        -3.1278, -3.7137, -5.3457, -4.9030, -5.4110], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8064,     3.8074,     5.1069,     5.2967,     5.3779,\n",
            "            5.4315,     6.1296,     6.5327,     8.9049,     8.9783,    10.0355,\n",
            "           10.0466,    10.2899,    11.0421,    11.1854,    11.2484,    11.3032,\n",
            "           11.6744,    12.1010,    12.6126,    12.6712,    12.6978,    12.8359,\n",
            "           13.0423,    13.1030,    13.2057,    13.3661,    13.6813,    13.7074,\n",
            "           13.8412,    14.3190,    14.3196,    14.4627,    14.6034,    14.8526,\n",
            "           15.2827,    15.3939,    15.5164,    15.5575,    15.5856,    15.7686,\n",
            "           15.9379,    16.1497,    16.3596,    16.3955,    16.4136,    17.0830],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([58, 59, 57, 61, 55, 60, 56, 54, 62, 63, 53, 64, 51, 52, 75, 65,  2, 78,\n",
            "         6, 50, 66, 82, 71, 74, 79,  5,  3, 81, 72, 68,  9, 49, 67, 76, 77,  1,\n",
            "        10,  7,  4, 80, 73, 48, 85,  0, 83, 70,  8, 69], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.8196, -5.5202, -0.9046, -1.6100, -4.9376, -4.7898, -4.8563, -4.0346,\n",
            "        -3.4909, -3.5487, -4.3239, -2.9693, -5.7223, -3.3316, -3.8801, -3.5011,\n",
            "        -3.2564, -3.7876, -5.3686, -4.9795, -5.4164], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8064,     3.8074,     5.1069,     5.2967,     5.3779,\n",
            "            5.4315,     6.1296,     6.5327,     8.9049,     8.9783,    10.0355,\n",
            "           10.0466,    10.2899,    11.0421,    11.1854,    11.2484,    11.3032,\n",
            "           11.6744,    12.1010,    12.6126,    12.6712,    12.6978,    12.8359,\n",
            "           13.0423,    13.1030,    13.2057,    13.3661,    13.6813,    13.7074,\n",
            "           13.8412,    14.3190,    14.3196,    14.4627,    14.6034,    14.8526,\n",
            "           15.2827,    15.3939,    15.5164,    15.5575,    15.5856,    15.7686,\n",
            "           15.9379,    16.1497,    16.3596,    16.3955,    16.4136,    17.0830],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([58, 59, 57, 61, 55, 60, 56, 54, 62, 63, 53, 64, 51, 52, 75, 65,  2, 78,\n",
            "         6, 50, 66, 82, 71, 74, 79,  5,  3, 81, 72, 68,  9, 49, 67, 76, 77,  1,\n",
            "        10,  7,  4, 80, 73, 48, 85,  0, 83, 70,  8, 69], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.6624, -5.3277, -4.0031, -3.0097, -5.0442, -4.0205, -4.2137, -3.7164,\n",
            "        -1.3864, -3.0047, -4.1015, -3.8849, -5.6076, -1.5592, -2.0004, -3.5147,\n",
            "        -3.4956, -3.4565, -5.1184, -4.9782, -5.5449], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8019,     3.8049,     5.0913,     5.2115,     5.2321,\n",
            "            5.2411,     6.1501,     6.5327,     8.4910,     8.8664,     8.9460,\n",
            "            9.7215,     9.8530,    10.7492,    10.9712,    11.5302,    11.5744,\n",
            "           12.3931,    12.4927,    12.5547,    12.7164,    13.0434,    13.6247,\n",
            "           13.9274,    13.9880,    14.0215,    14.2514,    14.7166,    14.8347,\n",
            "           15.3250,    15.9762,    15.9773,    16.0764,    16.0891,    16.3394,\n",
            "           17.4879,    17.4888,    17.5822,    17.6061,    18.5762,    18.8866,\n",
            "           19.0730,    19.1016,    20.4972,    20.8294,    21.4872,    21.9405],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([62, 61, 63, 59, 64, 60, 65, 66, 58, 67, 57, 68, 71, 56,  2, 55, 75, 72,\n",
            "        74, 69, 54, 70,  3,  1, 78,  6,  0, 73,  5, 53, 76, 79,  4, 77, 52, 51,\n",
            "        82,  7, 81,  9, 50, 80, 10,  8, 49, 83, 85, 48], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.7503, -5.3424, -4.0157, -3.0252, -5.1169, -4.1801, -4.3374, -3.6807,\n",
            "        -1.3102, -3.1040, -4.1257, -3.9090, -5.6898, -1.4766, -2.1351, -3.5882,\n",
            "        -3.5160, -3.4672, -5.2272, -5.0470, -5.5442], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8019,     3.8049,     5.0913,     5.2115,     5.2321,\n",
            "            5.2411,     6.1501,     6.5327,     8.4910,     8.8664,     8.9460,\n",
            "            9.7215,     9.8530,    10.7492,    10.9712,    11.5302,    11.5744,\n",
            "           12.3931,    12.4927,    12.5547,    12.7164,    13.0434,    13.6247,\n",
            "           13.9274,    13.9880,    14.0215,    14.2514,    14.7166,    14.8347,\n",
            "           15.3250,    15.9762,    15.9773,    16.0764,    16.0891,    16.3394,\n",
            "           17.4879,    17.4888,    17.5822,    17.6061,    18.5762,    18.8866,\n",
            "           19.0730,    19.1016,    20.4972,    20.8294,    21.4872,    21.9405],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([62, 61, 63, 59, 64, 60, 65, 66, 58, 67, 57, 68, 71, 56,  2, 55, 75, 72,\n",
            "        74, 69, 54, 70,  3,  1, 78,  6,  0, 73,  5, 53, 76, 79,  4, 77, 52, 51,\n",
            "        82,  7, 81,  9, 50, 80, 10,  8, 49, 83, 85, 48], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.4373, -4.5787, -4.6626, -3.4395, -4.5652, -4.7636, -4.8192, -2.9365,\n",
            "        -4.2348, -0.3969, -3.3620, -4.7919, -5.5263, -3.8268, -4.2950, -4.6515,\n",
            "        -4.9454, -3.7012, -4.8843, -4.2478, -5.6505], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8012,     3.8049,     4.8232,     4.9517,     5.4924,\n",
            "            5.5474,     5.7310,     6.4072,     6.4996,     6.5364,     8.7564,\n",
            "            8.9049,     9.1702,     9.2735,     9.5271,     9.8571,     9.9437,\n",
            "            9.9867,    10.4641,    10.5372,    10.8698,    11.2595,    11.4907,\n",
            "           12.6650,    12.6931,    12.8660,    13.3679,    13.6342,    13.7653,\n",
            "           14.2280,    14.2727,    15.2748,    15.7621,    15.7717,    16.9678,\n",
            "           17.1250,    17.3551,    17.6962,    17.8205,    17.9687,    18.1813,\n",
            "           18.3255,    20.2666,    20.7359,    21.0555,    21.7271,    21.8301],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([63, 64, 62, 66, 60, 61, 65, 67, 59, 71, 68,  2, 58, 72, 70, 69, 74, 57,\n",
            "        75, 56,  3,  0,  1, 73, 55,  6, 78,  5, 76,  4, 77, 54, 79,  7, 53,  9,\n",
            "        81, 52, 82,  8, 80, 10, 51, 50, 83, 11, 49, 12], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.6826, -4.7789, -3.4345, -2.4844, -3.3886, -4.4273, -3.8964, -2.7398,\n",
            "        -4.1084, -1.0910, -3.2299, -3.7719, -5.2023, -2.8899, -3.9770, -3.9948,\n",
            "        -3.9474, -3.1400, -3.7416, -2.6092, -5.5333], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7993,     3.8039,     5.0091,     5.0526,     5.3042,\n",
            "            5.4431,     6.0436,     7.0014,     7.4532,     8.0565,     8.4210,\n",
            "            8.9006,     9.2675,     9.8571,     9.9922,     9.9993,    10.0052,\n",
            "           10.0821,    10.1254,    10.4590,    10.4671,    10.4942,    10.6374,\n",
            "           10.8586,    11.0721,    11.3996,    11.5452,    11.7077,    11.8450,\n",
            "           12.3647,    12.3931,    12.6076,    12.8359,    13.1873,    13.5960,\n",
            "           13.7645,    13.7668,    14.3016,    14.3158,    14.7175,    14.7322,\n",
            "           15.2825,    15.6252,    16.9735,    16.9793,    17.2369,    17.4185],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([74, 73, 75, 77, 71, 76, 72, 78,  3, 70, 60, 79,  6,  2, 63,  0, 68, 64,\n",
            "         7, 80, 57, 69,  4, 61, 81, 56, 59,  5,  1, 67, 10, 62, 82, 58,  9,  8,\n",
            "        66, 65, 53, 83, 55, 54, 11, 84, 85, 13, 52, 12], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.6473, -4.6813, -3.1449, -2.1955, -3.3975, -4.2694, -3.7427, -2.7536,\n",
            "        -4.0261, -1.2200, -3.2909, -3.6990, -5.1340, -2.7879, -3.9607, -3.9113,\n",
            "        -3.8856, -3.1303, -3.7944, -2.8409, -5.5169], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7993,     3.8039,     5.0091,     5.0526,     5.3042,\n",
            "            5.4431,     6.0436,     7.0014,     7.4532,     8.0565,     8.4210,\n",
            "            8.9006,     9.2675,     9.8571,     9.9922,     9.9993,    10.0052,\n",
            "           10.0821,    10.1254,    10.4590,    10.4671,    10.4942,    10.6374,\n",
            "           10.8586,    11.0721,    11.3996,    11.5452,    11.7077,    11.8450,\n",
            "           12.3647,    12.3931,    12.6076,    12.8359,    13.1873,    13.5960,\n",
            "           13.7645,    13.7668,    14.3016,    14.3158,    14.7175,    14.7322,\n",
            "           15.2825,    15.6252,    16.9735,    16.9793,    17.2369,    17.4185],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([74, 73, 75, 77, 71, 76, 72, 78,  3, 70, 60, 79,  6,  2, 63,  0, 68, 64,\n",
            "         7, 80, 57, 69,  4, 61, 81, 56, 59,  5,  1, 67, 10, 62, 82, 58,  9,  8,\n",
            "        66, 65, 53, 83, 55, 54, 11, 84, 85, 13, 52, 12], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.5599, -5.1650, -3.4453, -2.3004, -5.1375, -3.3828, -4.2631, -3.7760,\n",
            "        -1.1969, -3.4534, -4.3756, -3.5083, -5.4918, -2.4081, -2.5970, -3.1083,\n",
            "        -2.8832, -3.0695, -5.3232, -4.9604, -5.4753], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8093,     3.8109,     4.9037,     5.3042,     5.3043,\n",
            "            5.3994,     6.7486,     7.1224,     8.9626,     9.3432,    10.1810,\n",
            "           10.8088,    10.8311,    10.9137,    11.4787,    11.6646,    11.8517,\n",
            "           12.4642,    12.5711,    12.6116,    12.6433,    13.0132,    13.0387,\n",
            "           13.0493,    13.2173,    13.6342,    13.9758,    14.3702,    14.4627,\n",
            "           14.6859,    14.7466,    14.8473,    14.9687,    15.1524,    15.2067,\n",
            "           15.2807,    15.3250,    15.3536,    15.4488,    16.1129,    16.2669,\n",
            "           16.3428,    16.4126,    16.7140,    16.8250,    17.1793,    17.3794],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([76, 77, 75, 79, 74, 73, 78, 72, 80, 71, 81, 82, 70, 83, 60, 57,  3,  6,\n",
            "        61, 68,  7, 64, 10, 84, 69, 56, 63,  2, 59, 58,  4, 53, 85,  9, 54,  0,\n",
            "         5, 62, 86, 67,  8, 11, 65, 55,  1, 13, 87, 66], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.6126, -5.2144, -3.4557, -2.3167, -5.1675, -3.3746, -4.3281, -3.8214,\n",
            "        -1.1318, -3.5551, -4.4134, -3.4819, -5.4702, -2.4580, -2.5897, -3.1331,\n",
            "        -2.9213, -3.1211, -5.3512, -4.9872, -5.4776], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8093,     3.8109,     4.9037,     5.3042,     5.3043,\n",
            "            5.3994,     6.7486,     7.1224,     8.9626,     9.3432,    10.1810,\n",
            "           10.8088,    10.8311,    10.9137,    11.4787,    11.6646,    11.8517,\n",
            "           12.4642,    12.5711,    12.6116,    12.6433,    13.0132,    13.0387,\n",
            "           13.0493,    13.2173,    13.6342,    13.9758,    14.3702,    14.4627,\n",
            "           14.6859,    14.7466,    14.8473,    14.9687,    15.1524,    15.2067,\n",
            "           15.2807,    15.3250,    15.3536,    15.4488,    16.1129,    16.2669,\n",
            "           16.3428,    16.4126,    16.7140,    16.8250,    17.1793,    17.3794],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([76, 77, 75, 79, 74, 73, 78, 72, 80, 71, 81, 82, 70, 83, 60, 57,  3,  6,\n",
            "        61, 68,  7, 64, 10, 84, 69, 56, 63,  2, 59, 58,  4, 53, 85,  9, 54,  0,\n",
            "         5, 62, 86, 67,  8, 11, 65, 55,  1, 13, 87, 66], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.5976, -4.0108, -4.7284, -3.3094, -2.9289, -3.9977, -4.2036, -2.4383,\n",
            "        -4.0283, -1.3896, -2.1237, -3.8116, -5.6373, -2.7336, -3.6675, -3.7613,\n",
            "        -3.4909, -3.4959, -4.0827, -2.5226, -5.5095], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8011,     3.8055,     4.8499,     4.9858,     5.1639,\n",
            "            5.3994,     6.0436,     6.6702,     7.4155,     7.7248,     8.3280,\n",
            "            8.6576,     8.6969,     8.7794,     8.8064,     8.8096,     9.2278,\n",
            "            9.5912,     9.8020,     9.8582,     9.9072,    10.3031,    10.6623,\n",
            "           10.9398,    11.0382,    11.1502,    11.2233,    11.2796,    11.3032,\n",
            "           11.6239,    11.7309,    11.8310,    11.9359,    12.0424,    12.5066,\n",
            "           12.8660,    13.0746,    13.1417,    13.2862,    13.4305,    13.8902,\n",
            "           13.9048,    13.9274,    14.1819,    14.2996,    14.4218,    14.5797],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([78, 77, 79, 75, 81, 80, 76, 74, 82,  6, 57, 10, 56, 83, 60, 73,  7,  3,\n",
            "        53, 72, 84,  9, 71, 54, 85,  2,  5, 61, 59, 58,  4,  8, 55, 11, 13, 86,\n",
            "        63, 52, 64, 70, 12,  0, 14, 62,  1, 50, 68, 87], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.3077, -5.1466, -2.8332, -2.4699, -5.2141, -2.8424, -4.6034, -5.1963,\n",
            "        -2.0489, -3.7828, -4.2004, -3.1710, -5.6700, -1.1307, -3.0820, -3.0280,\n",
            "        -3.9051, -4.7643, -5.3259, -5.1958, -5.5744], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8055,     3.8087,     4.9037,     5.2024,     5.3386,\n",
            "            5.4033,     6.0042,     6.2522,     8.4210,     8.7006,     9.5035,\n",
            "            9.9149,    10.0962,    10.5161,    10.6284,    10.6560,    11.0923,\n",
            "           11.2061,    11.2186,    11.4246,    11.8984,    12.1371,    12.3433,\n",
            "           12.6242,    12.6964,    12.8372,    12.9277,    13.0423,    13.3550,\n",
            "           13.8919,    13.9991,    14.2051,    14.4240,    14.7037,    14.7479,\n",
            "           14.8480,    14.8714,    14.9523,    14.9583,    14.9774,    14.9971,\n",
            "           15.2748,    15.3427,    15.3634,    15.5734,    15.7591,    15.9113],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([79, 78, 80, 76, 77, 82, 81, 75, 83, 74, 84, 57, 73, 85, 86, 10, 72,  6,\n",
            "        53, 60, 56, 54,  7, 71, 87, 61,  9,  3, 58, 13, 59, 55, 11, 88, 64,  2,\n",
            "        50,  5,  8, 14, 52, 70, 63,  4, 89, 12, 68, 49], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.3832, -4.8264, -5.3642, -5.2045, -4.1189, -4.9168, -4.3851, -2.6360,\n",
            "        -4.3596, -1.2207, -1.2532, -4.8648, -5.6980, -4.4348, -4.3142, -4.1757,\n",
            "        -3.7207, -1.9758, -4.8443, -3.8774, -5.6067], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7896,     3.8099,     4.9858,     5.1707,     5.4033,\n",
            "            5.4239,     5.9784,     6.3169,     7.2437,     7.9083,     7.9589,\n",
            "            8.5228,     8.5404,     8.7296,     9.3202,     9.3432,     9.5218,\n",
            "            9.5840,     9.6813,     9.8737,     9.9543,    10.1420,    10.2045,\n",
            "           10.3954,    10.7191,    10.8586,    11.1337,    11.3786,    11.5985,\n",
            "           11.6083,    12.1693,    12.3512,    12.3683,    12.3739,    12.5355,\n",
            "           12.5873,    12.6286,    12.9526,    13.2893,    13.3661,    13.5057,\n",
            "           13.5424,    14.0173,    14.0309,    14.1488,    14.4338,    14.7001],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([81, 82, 80, 78, 84, 79, 83, 10, 85, 77, 53, 13,  9, 86,  6,  7, 76, 11,\n",
            "        57, 75, 14, 56, 87, 54, 12, 88, 74,  8, 52, 49, 50, 55,  5,  3, 89, 60,\n",
            "        16, 17, 15, 51, 58, 73,  4,  2, 59, 46, 90, 72], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.7634, -4.7112, -5.0140, -4.9685, -4.0846, -4.6078, -4.3337, -2.8257,\n",
            "        -4.1392, -1.2728, -1.4477, -4.6571, -5.5926, -4.3272, -4.1255, -3.8335,\n",
            "        -3.4897, -1.8601, -4.8490, -3.8172, -5.5650], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7896,     3.8099,     4.9858,     5.1707,     5.4033,\n",
            "            5.4239,     5.9784,     6.3169,     7.2437,     7.9083,     7.9589,\n",
            "            8.5228,     8.5404,     8.7296,     9.3202,     9.3432,     9.5218,\n",
            "            9.5840,     9.6813,     9.8737,     9.9543,    10.1420,    10.2045,\n",
            "           10.3954,    10.7191,    10.8586,    11.1337,    11.3786,    11.5985,\n",
            "           11.6083,    12.1693,    12.3512,    12.3683,    12.3739,    12.5355,\n",
            "           12.5873,    12.6286,    12.9526,    13.2893,    13.3661,    13.5057,\n",
            "           13.5424,    14.0173,    14.0309,    14.1488,    14.4338,    14.7001],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([81, 82, 80, 78, 84, 79, 83, 10, 85, 77, 53, 13,  9, 86,  6,  7, 76, 11,\n",
            "        57, 75, 14, 56, 87, 54, 12, 88, 74,  8, 52, 49, 50, 55,  5,  3, 89, 60,\n",
            "        16, 17, 15, 51, 58, 73,  4,  2, 59, 46, 90, 72], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.3851, -5.2416, -2.3716, -1.8714, -5.0465, -3.6975, -4.1903, -4.9887,\n",
            "        -2.7870, -3.4758, -4.5932, -3.2436, -5.5260, -2.2273, -3.3718, -2.4949,\n",
            "        -3.0767, -4.4257, -5.3758, -5.0314, -5.4166], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7994,     3.8018,     4.9141,     4.9307,     5.4239,\n",
            "            5.4799,     6.2522,     6.4026,     8.6969,     8.7104,     9.8449,\n",
            "           10.1941,    10.6787,    10.8311,    10.8540,    11.1198,    11.3440,\n",
            "           12.1871,    12.3637,    12.5200,    12.7736,    12.8282,    13.0242,\n",
            "           13.5079,    13.6542,    13.6873,    13.8558,    14.1114,    14.2587,\n",
            "           14.3158,    14.3408,    14.4586,    14.5405,    14.6109,    14.7433,\n",
            "           14.8322,    15.4134,    15.6819,    15.7596,    15.7893,    15.9700,\n",
            "           16.1510,    16.3324,    16.3596,    16.7561,    16.7916,    16.8947],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([83, 84, 82, 86, 80, 81, 85, 79, 87, 78, 88, 89, 77, 90, 76, 10, 13, 53,\n",
            "        75, 14, 91, 57, 54, 50, 17,  9, 49, 11,  6, 56, 74, 92, 12,  7, 46, 16,\n",
            "        52, 93, 51, 15, 55, 73, 60,  8, 58, 18, 94, 72], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.4132, -5.2981, -2.3108, -1.8288, -5.0772, -3.7746, -4.2166, -4.9621,\n",
            "        -2.6267, -3.4801, -4.6752, -3.1707, -5.5335, -2.2849, -3.3445, -2.5934,\n",
            "        -3.1418, -4.4176, -5.4022, -5.0319, -5.4249], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7994,     3.8018,     4.9141,     4.9307,     5.4239,\n",
            "            5.4799,     6.2522,     6.4026,     8.6969,     8.7104,     9.8449,\n",
            "           10.1941,    10.6787,    10.8311,    10.8540,    11.1198,    11.3440,\n",
            "           12.1871,    12.3637,    12.5200,    12.7736,    12.8282,    13.0242,\n",
            "           13.5079,    13.6542,    13.6873,    13.8558,    14.1114,    14.2587,\n",
            "           14.3158,    14.3408,    14.4586,    14.5405,    14.6109,    14.7433,\n",
            "           14.8322,    15.4134,    15.6819,    15.7596,    15.7893,    15.9700,\n",
            "           16.1510,    16.3324,    16.3596,    16.7561,    16.7916,    16.8947],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([83, 84, 82, 86, 80, 81, 85, 79, 87, 78, 88, 89, 77, 90, 76, 10, 13, 53,\n",
            "        75, 14, 91, 57, 54, 50, 17,  9, 49, 11,  6, 56, 74, 92, 12,  7, 46, 16,\n",
            "        52, 93, 51, 15, 55, 73, 60,  8, 58, 18, 94, 72], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.7089, -4.9850, -4.4390, -3.4690, -2.2816, -4.8312, -2.1725, -3.6799,\n",
            "        -4.8027, -3.0815, -2.6793, -4.6037, -5.7115, -3.6931, -4.0282, -3.7455,\n",
            "        -3.0930, -2.9986, -3.3994, -1.0748, -5.4833], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7868,     3.7982,     4.9052,     5.1081,     5.4247,\n",
            "            5.4799,     6.1081,     6.3169,     7.7199,     8.5441,     8.6118,\n",
            "            8.6283,     8.7476,     8.8023,     9.2731,     9.6399,     9.6613,\n",
            "            9.7781,     9.8611,    10.0962,    10.4028,    10.4039,    10.7961,\n",
            "           10.9398,    11.1812,    11.2890,    11.6155,    12.0040,    12.0496,\n",
            "           12.1057,    12.1166,    12.2441,    12.3382,    12.3796,    12.4227,\n",
            "           12.6641,    12.9595,    13.1925,    13.3327,    13.3811,    13.4686,\n",
            "           13.7201,    13.7260,    14.2616,    14.3767,    14.5731,    14.6293],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([85, 84, 86, 88, 82, 87, 83, 89, 81, 13, 53, 80, 90, 49, 50, 46, 10, 17,\n",
            "        91, 14, 79, 16, 92, 54, 78, 52, 12,  9, 51, 45, 11, 47, 93, 48, 42, 15,\n",
            "        57, 43, 56, 18, 77, 20,  6, 55, 94,  7, 19, 44], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.8549, -5.0556, -2.7363, -2.1042, -5.0657, -3.0731, -3.8037, -4.6759,\n",
            "        -2.4839, -3.4880, -4.6533, -2.1940, -5.6330, -2.2561, -2.5020, -2.8856,\n",
            "        -2.9295, -4.1098, -5.4290, -5.0131, -5.4505], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7982,     3.8074,     4.9141,     5.1360,     5.3212,\n",
            "            5.4021,     5.9790,     6.3168,     8.5404,     8.7079,     9.5869,\n",
            "            9.9498,    10.5161,    10.6833,    10.7298,    11.0905,    11.3029,\n",
            "           11.4139,    11.5906,    12.3418,    12.5066,    12.5349,    12.6133,\n",
            "           13.0177,    13.0897,    13.7227,    13.7330,    13.8123,    13.8432,\n",
            "           14.1059,    14.1370,    14.2504,    14.3089,    14.3943,    14.7183,\n",
            "           14.8137,    15.0532,    15.1932,    15.3536,    15.5331,    15.5839,\n",
            "           15.6215,    15.6271,    15.8391,    16.0249,    16.0272,    16.0645],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([86, 85, 87, 83, 89, 84, 88, 82, 90, 81, 91, 80, 92, 79, 93, 50, 46, 53,\n",
            "        13, 49, 17, 78, 94, 54, 10, 14, 47, 16, 42, 43, 52, 51, 57, 45, 95, 77,\n",
            "        48, 12,  9, 76, 96, 20, 11, 56, 15, 55, 18, 75], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.9492, -5.1882, -2.6680, -2.1036, -5.1369, -3.2530, -4.0137, -4.7692,\n",
            "        -2.2243, -3.6459, -4.7430, -2.0050, -5.6696, -2.2632, -2.6836, -2.9716,\n",
            "        -2.8953, -4.2119, -5.4749, -5.0500, -5.4710], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7982,     3.8074,     4.9141,     5.1360,     5.3212,\n",
            "            5.4021,     5.9790,     6.3168,     8.5404,     8.7079,     9.5869,\n",
            "            9.9498,    10.5161,    10.6833,    10.7298,    11.0905,    11.3029,\n",
            "           11.4139,    11.5906,    12.3418,    12.5066,    12.5349,    12.6133,\n",
            "           13.0177,    13.0897,    13.7227,    13.7330,    13.8123,    13.8432,\n",
            "           14.1059,    14.1370,    14.2504,    14.3089,    14.3943,    14.7183,\n",
            "           14.8137,    15.0532,    15.1932,    15.3536,    15.5331,    15.5839,\n",
            "           15.6215,    15.6271,    15.8391,    16.0249,    16.0272,    16.0645],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([86, 85, 87, 83, 89, 84, 88, 82, 90, 81, 91, 80, 92, 79, 93, 50, 46, 53,\n",
            "        13, 49, 17, 78, 94, 54, 10, 14, 47, 16, 42, 43, 52, 51, 57, 45, 95, 77,\n",
            "        48, 12,  9, 76, 96, 20, 11, 56, 15, 55, 18, 75], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-4.1296, -5.0259, -4.6740, -3.5437, -1.7406, -4.6284, -4.0522, -2.0643,\n",
            "        -5.0390, -1.5145, -2.4923, -4.9218, -5.7662, -3.4992, -3.9863, -4.8646,\n",
            "        -4.5174, -3.3157, -2.8511, -2.0808, -5.5835], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7994,     3.8039,     4.9052,     5.1292,     5.4021,\n",
            "            5.4814,     6.1899,     6.3557,     7.8613,     8.6440,     8.7104,\n",
            "            9.0856,     9.4673,     9.6725,     9.7683,     9.9568,     9.9814,\n",
            "           10.3459,    10.4068,    10.6125,    10.6519,    10.7191,    10.9099,\n",
            "           11.2770,    11.4305,    11.5121,    11.6469,    12.0456,    12.3599,\n",
            "           12.4285,    12.4836,    12.5399,    12.6408,    12.7057,    12.9145,\n",
            "           13.1347,    13.1999,    13.4151,    13.4320,    13.6115,    14.1741,\n",
            "           14.3091,    14.4240,    14.4650,    14.5080,    14.9399,    15.0110],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([88, 87, 89, 85, 91, 86, 90, 92, 84, 17, 93, 83, 46, 13, 42, 82, 16, 94,\n",
            "        20, 14, 95, 49, 81, 43, 45, 50, 18, 39, 21, 80, 96, 15, 19, 47, 53, 10,\n",
            "        12, 38, 41, 44, 48, 40, 11, 79, 97, 52, 35,  9], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.4545, -5.3020, -2.4823, -1.4775, -5.2319, -4.2301, -4.6304, -4.5956,\n",
            "        -2.3838, -3.4560, -4.6096, -3.6365, -5.6564, -2.4907, -3.1784, -3.1435,\n",
            "        -3.1161, -3.9681, -5.3278, -5.0996, -5.3757], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8031,     3.8106,     5.0915,     5.1181,     5.4802,\n",
            "            5.4814,     6.2717,     6.3168,     8.6283,     8.6969,     9.9971,\n",
            "           10.0793,    10.6787,    10.7901,    11.6092,    11.8047,    11.8225,\n",
            "           12.2069,    12.2709,    12.9645,    13.9048,    14.2201,    14.2802,\n",
            "           14.3131,    14.4338,    14.5161,    14.7927,    14.8490,    14.8822,\n",
            "           15.2123,    15.2206,    15.3530,    15.4198,    15.5684,    15.7074,\n",
            "           15.8016,    15.9967,    16.2573,    16.3762,    16.6472,    16.6941,\n",
            "           17.1327,    17.5441,    17.6029,    17.7250,    17.8705,    17.9043],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([90, 89, 91, 87, 93, 92, 88, 94, 86, 85, 95, 96, 84, 83, 97, 46, 42, 43,\n",
            "        39, 82, 17, 50, 20, 49, 45, 81, 47, 40, 13, 38, 44, 16, 80, 41, 35, 21,\n",
            "        14, 36, 53, 18, 48, 79, 19, 37, 54, 51, 10, 15], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.4763, -5.2575, -2.4829, -1.5351, -5.2483, -4.2936, -4.6439, -4.5909,\n",
            "        -2.2442, -3.4849, -4.6876, -3.6185, -5.6619, -2.4968, -3.1376, -3.1065,\n",
            "        -3.0467, -3.9533, -5.3512, -5.1277, -5.3689], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8031,     3.8106,     5.0915,     5.1181,     5.4802,\n",
            "            5.4814,     6.2717,     6.3168,     8.6283,     8.6969,     9.9971,\n",
            "           10.0793,    10.6787,    10.7901,    11.6092,    11.8047,    11.8225,\n",
            "           12.2069,    12.2709,    12.9645,    13.9048,    14.2201,    14.2802,\n",
            "           14.3131,    14.4338,    14.5161,    14.7927,    14.8490,    14.8822,\n",
            "           15.2123,    15.2206,    15.3530,    15.4198,    15.5684,    15.7074,\n",
            "           15.8016,    15.9967,    16.2573,    16.3762,    16.6472,    16.6941,\n",
            "           17.1327,    17.5441,    17.6029,    17.7250,    17.8705,    17.9043],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([90, 89, 91, 87, 93, 92, 88, 94, 86, 85, 95, 96, 84, 83, 97, 46, 42, 43,\n",
            "        39, 82, 17, 50, 20, 49, 45, 81, 47, 40, 13, 38, 44, 16, 80, 41, 35, 21,\n",
            "        14, 36, 53, 18, 48, 79, 19, 37, 54, 51, 10, 15], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-1.8370, -4.0658, -4.3194, -3.2865, -4.6861, -4.3883, -3.7669, -2.1009,\n",
            "        -3.8032, -2.1846, -3.7040, -3.8920, -5.4641, -2.8409, -2.9850, -2.8013,\n",
            "        -2.8039, -1.8084, -4.4668, -4.5043, -5.3030], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.8057,     3.8075,     5.0911,     5.0985,     5.4627,\n",
            "            5.4802,     6.1899,     6.2704,     6.7347,     6.9624,     7.5926,\n",
            "            8.6269,     8.7796,     9.0835,     9.5110,     9.5259,     9.9498,\n",
            "           10.2838,    10.4039,    10.4148,    10.6439,    10.6980,    10.8536,\n",
            "           11.0221,    11.1339,    12.0936,    12.1860,    12.5079,    12.5380,\n",
            "           12.8610,    12.9610,    13.5234,    13.7262,    14.0354,    14.0573,\n",
            "           14.1964,    14.3100,    14.3398,    14.3408,    14.4000,    15.1496,\n",
            "           15.2250,    15.3691,    15.4395,    15.5481,    16.1958,    16.5305],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([92, 93, 91, 95, 89, 94, 90, 88, 96, 39, 42, 43, 87, 97, 46, 40, 38, 86,\n",
            "        41, 85, 20, 45, 35, 36, 17, 44, 37, 47, 84, 21, 49, 16, 50, 19, 34, 18,\n",
            "        24, 13, 23, 83, 48, 82, 14, 32, 22, 33, 15, 31], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-2.2314, -4.9200, -3.0527, -1.7651, -3.9775, -4.0666, -4.1843, -3.1321,\n",
            "        -2.4044, -2.3267, -3.5532, -3.7491, -5.5748, -2.3177, -2.9325, -2.8362,\n",
            "        -3.0658, -3.2535, -4.6286, -3.9897, -5.4357], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7978,     3.8039,     5.1581,     5.1735,     5.4282,\n",
            "            5.4627,     6.2717,     8.6728,     9.7953,     9.9814,    10.6636,\n",
            "           11.7898,    11.8060,    11.8995,    12.0632,    12.5349,    12.7336,\n",
            "           12.7356,    14.2616,    14.2733,    14.4167,    14.4696,    14.6053,\n",
            "           15.0204,    15.3649,    15.5687,    15.6038,    15.6669,    15.8247,\n",
            "           15.9360,    16.0957,    16.3387,    16.7916,    16.9914,    16.9960,\n",
            "           17.6177,    17.9175,    18.0336,    18.0914,    18.0943,    18.2266,\n",
            "           18.4166,    18.7368,    19.0561,    19.4763,    19.5842,    19.5991],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([94, 93, 95, 91, 97, 96, 92, 90, 89, 39, 88, 87, 36, 35, 42, 43, 86, 38,\n",
            "        40, 85, 46, 37, 20, 41, 32, 17, 34, 21, 84, 44, 45, 33, 24, 83, 47, 31,\n",
            "        23, 16, 18, 49, 19, 50, 82, 22, 13, 14, 25, 48], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n",
            "Log Probs:tensor([-3.7078, -5.2479, -4.7936, -4.0398, -3.8573, -3.8703, -5.3001, -1.9881,\n",
            "        -4.6905, -0.8181, -2.5627, -4.8380, -5.6892, -3.9756, -4.2874, -4.5611,\n",
            "        -4.3295, -3.0766, -2.3406, -3.9398, -5.6353], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n",
            "Neighbor Distances:tensor([    0.0010,     3.7964,     3.8039,     5.0911,     5.4190,     5.4506,\n",
            "            6.2365,     6.5990,     8.0667,     8.0721,     8.6969,     9.2650,\n",
            "            9.7208,     9.8564,     9.8926,    10.5406,    10.6125,    10.7513,\n",
            "           11.5615,    11.8024,    11.8193,    12.0668,    12.3793,    12.3845,\n",
            "           13.0737,    13.3175,    13.5114,    13.5524,    14.0650,    14.1524,\n",
            "           14.3181,    14.3943,    14.4258,    15.2274,    15.8223,    16.0218,\n",
            "           16.2567,    16.3284,    16.3531,    16.4138,    16.5359,    16.7963,\n",
            "           17.0175,    17.6310,    18.0775,    18.1030,    18.4343,    18.6129],\n",
            "       device='cuda:0')\n",
            "Neighbor Positions:tensor([95, 96, 94, 92, 93, 97, 91, 39, 36, 35, 90, 38, 42, 40, 89, 43, 88, 37,\n",
            "        32, 34, 41, 20, 33, 87, 24, 21, 31, 46, 44, 17, 45, 86, 23, 85, 19, 22,\n",
            "        30, 47, 18, 25, 16, 84, 28, 49, 29, 26, 50, 83], device='cuda:0')\n",
            "Decoder Message Shape:torch.Size([1, 98, 48, 128])\n",
            ".................................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # read in the PDB files from the directory where the S_2648 PDB Files are stored, and set-them up one by one for featuirization, and passing through the model\n",
        "# pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_2648_PDB_Files\"\n",
        "# parser = PDBParser(QUIET=True)\n",
        "# for i,filename in tqdm(enumerate(os.listdir(pdbDirectory))):\n",
        "#     #ICODE related problematic proteins will be skipped from analysis for now\n",
        "#     if (filename.split(\".\")[0] not in proteins_to_skip):\n",
        "#         if i > 7:\n",
        "#             break\n",
        "#         filepath = os.path.join(pdbDirectory,filename)\n",
        "#         structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "#         model = structure[0]\n",
        "        \n",
        "#         # Since there is only one chain, and that same chain is both fixed designable for different residues, extracting that name, and putting them in pertinent lists\n",
        "#         # taking chainname from filename since one of the files \"1rtpA.pdb\" has chain name with \"1\" instead of \"A\"\n",
        "#         # fuck you motherfucking fucked up PDB file submitter. Have you shoved your head into your ass?\n",
        "#         chain_name = (filename.split(\".\")[0])[-1]\n",
        "#         fixed_chain_list = []\n",
        "#         # the trick is to put the single chain as designable chain, and then create the \"fixed_positions_dict\" dictionary  \n",
        "#         designed_chain_list = [chain_name]\n",
        "#         chain_list = list(set(designed_chain_list + fixed_chain_list))\n",
        "\n",
        "#         # Using the programs custome PDB parser for processing the PDB files\n",
        "#         pdb_dict_list = parse_PDB(filepath, input_chain_list=chain_list)\n",
        "#         # tacking max_length parameter value from the original colab notebook since I need to process all residues at the same time\n",
        "#         # all the PDB files can technically be processed together and put inside the dataset_valid list-like object, but right now\n",
        "#         # I am trying to keep everything consistent and simple\n",
        "#         # Each element of dataset_valid is a dictionary \n",
        "#         dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=20000)\n",
        "\n",
        "#         # Simplying the sequence generation loop\n",
        "#         protein = dataset_valid[0]\n",
        "\n",
        "#         wildtype_seq = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "#         # If there are gaps in the wildtype_seq \"seq\", remove those positions from both the \"seq\", \"\" and ('coords_chain_{designed_chain_list[0]}'), \n",
        "#         # and ('seq_chain_{designed_chain_list[0]}') of the \"protein\"\n",
        "#         # print(protein.keys())\n",
        "#         # protein is a dict with keys(['seq_chain_A', 'coords_chain_A', 'name', 'num_of_chains', 'seq'])\n",
        "#         # \"seq_chain\" and \"seq_all\" are both strings of the same length where gapped positions need to be identified and removed\n",
        "#         seq_chain = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "#         seq_all = protein[f\"seq\"]\n",
        "#         # \"coordinates_chain\" is a dict with keys(['N_chain_A', 'CA_chain_A', 'C_chain_A', 'O_chain_A'])\n",
        "#         coordinates_chain = protein[f\"coords_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        \n",
        "#         # The following four variables are lists of length equal to seq_chain and seq_all length\n",
        "#         # Therefore, the gapped positions can be retrived from seq_chain and removed from everything accordingly\n",
        "#         N_chain = coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"]\n",
        "#         CA_chain = coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"]\n",
        "#         C_chain = coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"]\n",
        "#         O_chain = coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "#         # delete everything related to gapped positions now\n",
        "#         # at first, find out the positions that are gapped\n",
        "#         # these gapped positions are absolutely messed up fucked up artifact of some kind of sophistification \n",
        "#         # provided by proteinMPNN, FUCK YOU motherfucking oversmart CODERS\n",
        "#         N_chain = [v for i,v in enumerate(N_chain) if seq_chain[i] != \"-\"]\n",
        "#         CA_chain = [v for i,v in enumerate(CA_chain) if seq_chain[i] != \"-\"]\n",
        "#         C_chain = [v for i,v in enumerate(C_chain) if seq_chain[i] != \"-\"]\n",
        "#         O_chain = [v for i,v in enumerate(O_chain) if seq_chain[i] != \"-\"]\n",
        "#         seq_all = [v for i,v in enumerate(seq_all) if seq_chain[i] != \"-\"]\n",
        "#         seq_chain = [v for i,v in enumerate(seq_chain) if seq_chain[i] != \"-\"]\n",
        "\n",
        "#         # Now, finally, pack everything back to the dictionary \"protein\"\n",
        "#         protein[f\"seq_chain_{designed_chain_list[0]}\"] = seq_chain\n",
        "#         protein[f\"seq\"] = seq_all\n",
        "#         coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"] = N_chain\n",
        "#         coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"] = CA_chain\n",
        "#         coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"] = C_chain\n",
        "#         coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"] = O_chain\n",
        "#         protein[f\"coords_chain_{designed_chain_list[0]}\"] = coordinates_chain\n",
        "\n",
        "#         # At this point, probably need to put None values in a lot of parameters that are not relevant to my usecase, but need to be sent to featurizer before running model forward\n",
        "#         # For now, I will not tie positions together\n",
        "#         tied_positions_dict = None\n",
        "#         pssm_dict = None\n",
        "#         omit_AA_dict = None\n",
        "#         bias_AA_dict = None\n",
        "#         tied_positions_dict = None\n",
        "#         bias_by_res_dict = None\n",
        "#         alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "#         bias_AAs_np = np.zeros(len(alphabet))\n",
        "\n",
        "#         chain_id_dict = {}\n",
        "#         chain_id_dict[pdb_dict_list[0]['name']]= (designed_chain_list, fixed_chain_list)\n",
        "\n",
        "#         BATCH_COPIES = 1\n",
        "\n",
        "#         batch_clones = [copy.deepcopy(protein) for i in range(BATCH_COPIES)]\n",
        "\n",
        "#         # \"muts_for_prot\" is a list with information about all the mutations in \"protein\", whose sequence only version is \"wildtype_seq\" \n",
        "#         muts_for_prot = two_level_dict[filename.split(\".\")[0]]\n",
        "#         # \"cur_map_dict\" will give the 0-based sequence index for the mutations, which will be almost directly used for masking and then running the model\n",
        "#         # 1-based indexing needed for the fixed position\n",
        "#         cur_map_dict = mapping_dict[filename.split(\".\")[0]]\n",
        "\n",
        "#         for mut in muts_for_prot:\n",
        "#             wild_aa = mut[\"mut\"][0]\n",
        "#             # (+1) because we need to pass 1-based indexing to tied_featurize() method\n",
        "#             seq_pos = cur_map_dict[mut[\"mut\"][0:-1]] + 1\n",
        "#             # only need to mask the mutated position position in \"wildtype_seq\" for now\n",
        "#             fixed_positions_dict = {}\n",
        "#             fixed_positions_dict[protein[\"name\"]] = {}\n",
        "#             f_list = []\n",
        "#             for ind_fixed in range(0,len(seq_chain)):\n",
        "#                 if (ind_fixed + 1) not in [seq_pos]:\n",
        "#                     f_list.append(ind_fixed + 1)\n",
        "#             # What the fuck have I done here?\n",
        "#             # f_list.append(seq_pos)\n",
        "#             fixed_positions_dict[protein[\"name\"]][filename.split(\".\")[0][-1]] = f_list\n",
        "#             # finally, had to take chain-name from filename instead of biopython parsing to get rid of chain-name with \"1\" instead of \"A\" in \"1rtpA.pdb\"\n",
        "#             X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "#             omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "#             = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "#             randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "#             log_probs = mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "#             # Adding the log_probs to the same inner dictionary where DDG values exist for easier comparison\n",
        "#             mut[\"log_prob\"] = log_probs.cpu().data.numpy()"
      ],
      "metadata": {
        "id": "yo2j-BtC1-Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the incomplete \"two_level_dict\" as pickle file for a quick dirty comparison\n",
        "# import pickle\n",
        "# with open(\"res_dict.pickle\",\"wb\") as f:\n",
        "#     pickle.dump(two_level_dict,f)"
      ],
      "metadata": {
        "id": "rXvc5PDmIQyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# with open(\"res_dict.pickle\",\"rb\") as f:\n",
        "#     two_level_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "QVXEWT9ye7NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import entropy\n",
        "alpha_list = list(\"ACDEFGHIKLMNPQRSTVWYX\")\n",
        "# The following dictionary will be used for fetching out the log-probabilities corresponding to the wild-type and mutated residues at the mutation positions\n",
        "aa_to_N = {a:n for n,a in enumerate(alpha_list)}\n",
        "# This list will contain the experimental ddg values for the mutations for which two-level dict contains information regarding log_probabilities\n",
        "true_vals = []\n",
        "# This list will contain (wild_proba,mut_proba) tuples for the mutations for which two-level dict contains information regarding log_probabilities\n",
        "wild_mut_log_probabilities = []\n",
        "# saving max probabilites for debugging\n",
        "max_log_probabilities = []\n",
        "# Want to add entropy of the position with some kind of weight (maybe, just a for loop for checking weight combinations that sum to 1?)\n",
        "position_entropies = []\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                wild = mut[\"mut\"][0] \n",
        "                alternate = mut[\"mut\"][-1]\n",
        "                true_vals.append(mut[\"ddg\"])\n",
        "                sequence_index_of_mutation = cur_map_dict[mut[\"mut\"][0:-1]]\n",
        "                position_log_probabilities = mut[\"log_prob\"][0,sequence_index_of_mutation,:]\n",
        "                wild_mut_log_probabilities.append((position_log_probabilities[aa_to_N[wild]],position_log_probabilities[aa_to_N[alternate]]))\n",
        "                max_log_probabilities.append(position_log_probabilities.max())\n",
        "                position_entropies.append(entropy(np.exp(position_log_probabilities)))\n",
        "    # Take only those mutations where \"log_prob\" is available and make a quick comparison for correlation plot\n",
        "    # Next, read in PSSM, and do same\n",
        "    # Then tree-way plot\n",
        "    # Then linear regression with PSSM + log_prob for the specific positions\n",
        "    # Then log-prob to probability distribution, and entropy calculation"
      ],
      "metadata": {
        "id": "7m4jsITsJHmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let us also look at the energy of the most probable amino acid in those mutation positions\n",
        "wild_energies = []\n",
        "mut_energies = []\n",
        "min_energies = []\n",
        "experimental_energies = []\n",
        "entropy_conservations = []\n",
        "# Now, add entropy of the position\n",
        "for true, estimate, max_prob, entropy_conservation in zip(true_vals,wild_mut_log_probabilities,max_log_probabilities,position_entropies):\n",
        "    experimental_energies.append(true)\n",
        "    wild_energies.append(estimate[0]*-1)\n",
        "    mut_energies.append(estimate[1]*-1)\n",
        "    min_energies.append(max_prob*-1)\n",
        "    entropy_conservations.append(entropy_conservation*-1)"
      ],
      "metadata": {
        "id": "vn-AjUmcoYDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "TwMx2ZMs60Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wild_energies = np.array(wild_energies)\n",
        "mut_energies = np.array(mut_energies)\n",
        "min_energies = np.array(min_energies)\n",
        "experimental_energies = np.array(experimental_energies)\n",
        "mut_wild_predictions = mut_energies - wild_energies\n",
        "mut_min_predictions = mut_energies - min_energies\n",
        "entropy_predictions = np.array(entropy_conservations)\n",
        "print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "print(pearsonr(experimental_energies,entropy_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jrRRaEi7fJY",
        "outputId": "340cf984-0f0e-4465-9154-45342a488430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.641572639246113, 5.910109285977553e-108)\n",
            "(0.6084704994299707, 2.2762974328708658e-94)\n",
            "(0.25682284663543997, 2.440394179939062e-15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now combine \"mut_wild_predictions\" and \"entropy_predictions\" using weight combinations from 0 to 1 in 0.05 increments so that they some to one\n",
        "# so, when one weight is x, the other weight is automatically (1-x)\n",
        "# The keys of this dictionary will be (term1_coeff,term2_coeff) tuples, and values will be the observed correlations \n",
        "coefficient_result_dictionary = {}\n",
        "for i in np.arange(0.0,1.000001,0.005):\n",
        "    term1_coeff = round(i,2)\n",
        "    term2_coeff = round((1.000001 - i),2)\n",
        "    local_preds = (term1_coeff*mut_wild_predictions) + (term2_coeff*entropy_predictions)\n",
        "    coefficient_result_dictionary[(term1_coeff,term2_coeff)] = round(pearsonr(experimental_energies,local_preds)[0],2) "
      ],
      "metadata": {
        "id": "xI2DgnlzMh6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefficient_result_dictionary"
      ],
      "metadata": {
        "id": "pUMxNOmfUwX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let me get PSSM values and do some comparison quickly\n",
        "# getting the PSSM extraction functions from my custom model data processing scripts\n",
        "from string import ascii_uppercase\n",
        "\n",
        "# In rare cases, some PDB files number chains with 1,2,3 instead of A,B,C\n",
        "def convertChainFromAlphabetToNumber(alphabet):\n",
        "    mappingDict = {ch:(idx+1) for idx,ch in enumerate(ascii_uppercase)}\n",
        "    return str(mappingDict[alphabet])\n",
        "\n",
        "# Before executing this function, the PSSM files with naming format \"pdbIdchain.pssm\" needs to be stored\n",
        "# in the pssm_dir\n",
        "def returnPSSMArray(pdbIdPlusChain,pssm_dir=\"train_pssm_dir\",convert_upper = False):\n",
        "#     Currently, assuming that the pssm file names contain pdbId in upper case\n",
        "    if convert_upper:\n",
        "        fileName = pdbIdPlusChain.upper() + \".pssm\"\n",
        "    else:\n",
        "        fileName = pdbIdPlusChain + \".pssm\"\n",
        "    try:\n",
        "        fullPath = os.path.join(pssm_dir,fileName)\n",
        "        f = open(fullPath)\n",
        "    except:\n",
        "        fileName = pdbIdPlusChain[0:4].upper() + str(convertChainFromAlphabetToNumber(pdbIdPlusChain[4])) + \".pssm\" \n",
        "        fullPath = os.path.join(pssm_dir,fileName)\n",
        "        f = open(fullPath)\n",
        "        \n",
        "# #     all the target lines in the PSSM files have (2+20+20+2=44) strings after line.split()\n",
        "    target_lines = [line.split() for line in f.readlines() if (len(line.split()))==44]\n",
        "    number_of_residues = len(target_lines)\n",
        "    \n",
        "    pssm_features = np.zeros((number_of_residues,20))\n",
        "\n",
        "    for idx,line in enumerate(target_lines):\n",
        "        pssm_features[idx,:] = line[2:22]\n",
        "\n",
        "    f.close()\n",
        "    \n",
        "    return pssm_features\n",
        "\n",
        "# This function also seems necessary for extracting the two pssm values\n",
        "# Must review the three pssm feature functions (this one and the two above) later\n",
        "# These functions seem to be taking up a lot of time....must review\n",
        "def returnPSSMMapping(residue):\n",
        "    pssm_letter_to_index_dict = {\"A\" : 0,   \n",
        "    \"R\" : 1,\n",
        "    \"N\" : 2,\n",
        "    \"D\" : 3,\n",
        "    \"C\" : 4,\n",
        "    \"Q\" : 5,\n",
        "    \"E\" : 6,\n",
        "    \"G\" : 7,\n",
        "    \"H\" : 8,\n",
        "    \"I\" : 9,\n",
        "    \"L\" : 10,\n",
        "    \"K\" : 11,\n",
        "    \"M\" : 12,\n",
        "    \"F\" : 13,\n",
        "    \"P\" : 14,\n",
        "    \"S\" : 15,\n",
        "    \"T\" : 16,\n",
        "    \"W\" : 17,\n",
        "    \"Y\" : 18,\n",
        "    \"V\" : 19}\n",
        "\n",
        "    return pssm_letter_to_index_dict[residue]\n",
        "\n",
        "\n",
        "# I will add PSSM values to the two-level dictionary for places where log_prob is available\n",
        "pssmDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_921_pssm_dir\"\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                wild = mut[\"mut\"][0] \n",
        "                alternate = mut[\"mut\"][-1]\n",
        "                sequence_index_of_mutation = cur_map_dict[mut[\"mut\"][0:-1]]\n",
        "                pdbId = prot[0:-1]\n",
        "                mutChain = prot[-1]\n",
        "                pssm_array = returnPSSMArray(pdbId + mutChain,pssm_dir=pssmDirectory,convert_upper = False)\n",
        "                position_pssm = pssm_array[sequence_index_of_mutation]\n",
        "                wild_pssm = position_pssm[returnPSSMMapping(wild)] \n",
        "                alternate_pssm = position_pssm[returnPSSMMapping(alternate)]\n",
        "                mut[\"wild_pssm\"] = wild_pssm\n",
        "                mut[\"alternate_pssm\"] = alternate_pssm"
      ],
      "metadata": {
        "id": "eBgpxQx4ispc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pssm_predictions = []\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                pssm_predictions.append((mut[\"wild_pssm\"]-mut[\"alternate_pssm\"]))"
      ],
      "metadata": {
        "id": "xOkQhEQzn32m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wild_energies = np.array(wild_energies)\n",
        "mut_energies = np.array(mut_energies)\n",
        "min_energies = np.array(min_energies)\n",
        "experimental_energies = np.array(experimental_energies)\n",
        "mut_wild_predictions = mut_energies - wild_energies\n",
        "mut_min_predictions = mut_energies - min_energies\n",
        "entropy_predictions = np.array(entropy_conservations)\n",
        "pssm_predictions = np.array(pssm_predictions)\n",
        "print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "print(pearsonr(experimental_energies,entropy_predictions))\n",
        "print(pearsonr(experimental_energies,pssm_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tyw_4erpj1C",
        "outputId": "9f55a730-3be8-4d2a-9c03-bf42415dfc17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.641572639246113, 5.910109285977553e-108)\n",
            "(0.25682284663543997, 2.440394179939062e-15)\n",
            "(0.5145587134119901, 2.1316560964554222e-63)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now combine \"mut_wild_predictions\" and \"pssm_predictions\" using weight combinations from 0 to 1 in 0.05 increments so that they some to one\n",
        "# so, when one weight is x, the other weight is automatically (1-x)\n",
        "# The keys of this dictionary will be (term1_coeff,term2_coeff) tuples, and values will be the observed correlations \n",
        "coefficient_result_dictionary = {}\n",
        "for i in np.arange(0.0,1.000001,0.005):\n",
        "    term1_coeff = round(i,2)\n",
        "    term2_coeff = round((1.000001 - i),2)\n",
        "    local_preds = (term1_coeff*mut_wild_predictions) + (term2_coeff*pssm_predictions)\n",
        "    coefficient_result_dictionary[(term1_coeff,term2_coeff)] = round(pearsonr(experimental_energies,local_preds)[0],2) "
      ],
      "metadata": {
        "id": "nP6x7ym_10QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefficient_result_dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ6lfx3VunPq",
        "outputId": "6e55932c-2801-41a1-ba23-aa17bf607086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(0.0, 1.0): 0.51,\n",
              " (0.01, 0.99): 0.52,\n",
              " (0.02, 0.98): 0.52,\n",
              " (0.02, 0.99): 0.52,\n",
              " (0.03, 0.97): 0.52,\n",
              " (0.04, 0.96): 0.52,\n",
              " (0.04, 0.97): 0.52,\n",
              " (0.05, 0.95): 0.52,\n",
              " (0.06, 0.94): 0.52,\n",
              " (0.06, 0.95): 0.52,\n",
              " (0.07, 0.93): 0.53,\n",
              " (0.08, 0.92): 0.53,\n",
              " (0.08, 0.93): 0.53,\n",
              " (0.09, 0.91): 0.53,\n",
              " (0.1, 0.9): 0.53,\n",
              " (0.1, 0.91): 0.53,\n",
              " (0.11, 0.89): 0.53,\n",
              " (0.12, 0.88): 0.54,\n",
              " (0.12, 0.89): 0.54,\n",
              " (0.13, 0.87): 0.54,\n",
              " (0.14, 0.86): 0.54,\n",
              " (0.14, 0.87): 0.54,\n",
              " (0.15, 0.85): 0.54,\n",
              " (0.16, 0.84): 0.54,\n",
              " (0.16, 0.85): 0.54,\n",
              " (0.17, 0.83): 0.54,\n",
              " (0.18, 0.82): 0.55,\n",
              " (0.18, 0.83): 0.55,\n",
              " (0.19, 0.81): 0.55,\n",
              " (0.2, 0.8): 0.55,\n",
              " (0.2, 0.81): 0.55,\n",
              " (0.21, 0.79): 0.55,\n",
              " (0.22, 0.78): 0.55,\n",
              " (0.22, 0.79): 0.55,\n",
              " (0.23, 0.77): 0.56,\n",
              " (0.24, 0.76): 0.56,\n",
              " (0.24, 0.77): 0.56,\n",
              " (0.25, 0.75): 0.56,\n",
              " (0.26, 0.74): 0.56,\n",
              " (0.26, 0.75): 0.56,\n",
              " (0.27, 0.73): 0.57,\n",
              " (0.28, 0.72): 0.57,\n",
              " (0.28, 0.73): 0.57,\n",
              " (0.29, 0.71): 0.57,\n",
              " (0.29, 0.72): 0.57,\n",
              " (0.3, 0.7): 0.57,\n",
              " (0.3, 0.71): 0.57,\n",
              " (0.31, 0.69): 0.57,\n",
              " (0.32, 0.68): 0.58,\n",
              " (0.32, 0.69): 0.58,\n",
              " (0.33, 0.67): 0.58,\n",
              " (0.34, 0.66): 0.58,\n",
              " (0.34, 0.67): 0.58,\n",
              " (0.35, 0.65): 0.58,\n",
              " (0.36, 0.64): 0.59,\n",
              " (0.36, 0.65): 0.58,\n",
              " (0.37, 0.63): 0.59,\n",
              " (0.38, 0.62): 0.59,\n",
              " (0.38, 0.63): 0.59,\n",
              " (0.39, 0.61): 0.59,\n",
              " (0.4, 0.6): 0.59,\n",
              " (0.4, 0.61): 0.59,\n",
              " (0.41, 0.59): 0.6,\n",
              " (0.42, 0.58): 0.6,\n",
              " (0.42, 0.59): 0.6,\n",
              " (0.43, 0.57): 0.6,\n",
              " (0.44, 0.56): 0.6,\n",
              " (0.44, 0.57): 0.6,\n",
              " (0.45, 0.55): 0.61,\n",
              " (0.46, 0.54): 0.61,\n",
              " (0.46, 0.55): 0.61,\n",
              " (0.47, 0.53): 0.61,\n",
              " (0.48, 0.52): 0.61,\n",
              " (0.48, 0.53): 0.61,\n",
              " (0.49, 0.51): 0.62,\n",
              " (0.5, 0.5): 0.62,\n",
              " (0.5, 0.51): 0.62,\n",
              " (0.51, 0.49): 0.62,\n",
              " (0.52, 0.48): 0.62,\n",
              " (0.52, 0.49): 0.62,\n",
              " (0.53, 0.47): 0.63,\n",
              " (0.54, 0.46): 0.63,\n",
              " (0.54, 0.47): 0.63,\n",
              " (0.55, 0.45): 0.63,\n",
              " (0.55, 0.46): 0.63,\n",
              " (0.56, 0.44): 0.63,\n",
              " (0.56, 0.45): 0.63,\n",
              " (0.57, 0.43): 0.64,\n",
              " (0.57, 0.44): 0.63,\n",
              " (0.58, 0.42): 0.64,\n",
              " (0.58, 0.43): 0.64,\n",
              " (0.59, 0.41): 0.64,\n",
              " (0.6, 0.4): 0.64,\n",
              " (0.6, 0.41): 0.64,\n",
              " (0.61, 0.39): 0.64,\n",
              " (0.62, 0.38): 0.65,\n",
              " (0.62, 0.39): 0.65,\n",
              " (0.63, 0.37): 0.65,\n",
              " (0.64, 0.36): 0.65,\n",
              " (0.64, 0.37): 0.65,\n",
              " (0.65, 0.35): 0.65,\n",
              " (0.66, 0.34): 0.65,\n",
              " (0.66, 0.35): 0.65,\n",
              " (0.67, 0.33): 0.66,\n",
              " (0.68, 0.32): 0.66,\n",
              " (0.68, 0.33): 0.66,\n",
              " (0.69, 0.31): 0.66,\n",
              " (0.7, 0.3): 0.66,\n",
              " (0.7, 0.31): 0.66,\n",
              " (0.71, 0.29): 0.66,\n",
              " (0.72, 0.28): 0.67,\n",
              " (0.72, 0.29): 0.66,\n",
              " (0.73, 0.27): 0.67,\n",
              " (0.74, 0.26): 0.67,\n",
              " (0.74, 0.27): 0.67,\n",
              " (0.75, 0.25): 0.67,\n",
              " (0.76, 0.24): 0.67,\n",
              " (0.76, 0.25): 0.67,\n",
              " (0.77, 0.23): 0.67,\n",
              " (0.78, 0.22): 0.67,\n",
              " (0.78, 0.23): 0.67,\n",
              " (0.79, 0.21): 0.67,\n",
              " (0.8, 0.2): 0.67,\n",
              " (0.8, 0.21): 0.67,\n",
              " (0.81, 0.19): 0.67,\n",
              " (0.82, 0.18): 0.67,\n",
              " (0.82, 0.19): 0.67,\n",
              " (0.83, 0.17): 0.67,\n",
              " (0.84, 0.16): 0.67,\n",
              " (0.84, 0.17): 0.67,\n",
              " (0.85, 0.15): 0.67,\n",
              " (0.86, 0.14): 0.67,\n",
              " (0.86, 0.15): 0.67,\n",
              " (0.87, 0.13): 0.67,\n",
              " (0.88, 0.12): 0.67,\n",
              " (0.88, 0.13): 0.67,\n",
              " (0.89, 0.11): 0.67,\n",
              " (0.9, 0.1): 0.67,\n",
              " (0.9, 0.11): 0.67,\n",
              " (0.91, 0.09): 0.67,\n",
              " (0.92, 0.08): 0.67,\n",
              " (0.92, 0.09): 0.67,\n",
              " (0.93, 0.07): 0.66,\n",
              " (0.94, 0.06): 0.66,\n",
              " (0.94, 0.07): 0.66,\n",
              " (0.95, 0.05): 0.66,\n",
              " (0.96, 0.04): 0.66,\n",
              " (0.96, 0.05): 0.66,\n",
              " (0.97, 0.03): 0.65,\n",
              " (0.98, 0.02): 0.65,\n",
              " (0.98, 0.03): 0.65,\n",
              " (0.99, 0.01): 0.65,\n",
              " (1.0, 0.0): 0.64,\n",
              " (1.0, 0.01): 0.65}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# coefficient_result_dictionary\n",
        "# (0.82, 0.18): 0.52,\n",
        "#  (0.82, 0.19): 0.51,\n",
        "#  (0.83, 0.17): 0.52,\n",
        "#  (0.84, 0.16): 0.52,\n",
        "#  (0.84, 0.17): 0.52,\n",
        "#  (0.85, 0.15): 0.52,\n",
        "#  (0.86, 0.14): 0.52,\n",
        "#  (0.86, 0.15): 0.52,\n",
        "#  (0.87, 0.13): 0.52,\n",
        "#  (0.88, 0.12): 0.52,\n",
        "#  (0.88, 0.13): 0.52,\n",
        "#  (0.89, 0.11): 0.52,\n",
        "#  (0.9, 0.1): 0.52,\n",
        "#  (0.9, 0.11): 0.52,\n",
        "#  (0.91, 0.09): 0.52,\n",
        "#  (0.92, 0.08): 0.52,\n",
        "#  (0.92, 0.09): 0.52,\n",
        "#  (0.93, 0.07): 0.52,\n",
        "#  (0.94, 0.06): 0.52,\n",
        "#  (0.94, 0.07): 0.52,\n",
        "#  (0.95, 0.05): 0.52,\n",
        "#  (0.96, 0.04): 0.52,\n",
        "# great thing since the decorrelation is actually interesting, and using both definitely seems to help"
      ],
      "metadata": {
        "id": "GZYSS4zz2CSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "methods = ['PMPNN_DEP','PMPNN_ET','PMPNN_DEP_ET','PSSM_DEC','PMPNN_DEP_PSSM_DEC']\n",
        "vals = [0.64,0.26,0.64,0.51,0.67]\n",
        "plt.ylabel(\"Pearson Correlation\",fontsize=18)\n",
        "plt.xlabel(\"Informative Features\",fontsize=18)\n",
        "plt.xticks(fontsize=18, rotation=90)\n",
        "plt.yticks(fontsize=18)\n",
        "plt.ylim(0.20,0.70)\n",
        "ax.bar(methods,vals,color=\"maroon\",width=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "sirQvLLnyerw",
        "outputId": "102b2f5e-e58b-4571-8cc9-f6adfbdb08eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "mut_wild_predictions = np.array(mut_energies - wild_energies)\n",
        "entropy_predictions = np.array(entropy_conservations)\n",
        "first_second_combined = 0.5*mut_wild_predictions + 0.5*entropy_predictions\n",
        "pssm_predictions = np.array(pssm_predictions)\n",
        "first_pssm_combined = 0.89*mut_wild_predictions + 0.11*pssm_predictions\n",
        "\n",
        "df_Ssym = pd.DataFrame(\n",
        "    {'P_DP': mut_wild_predictions,\n",
        "     'P_ET': entropy_predictions,\n",
        "     'P_DP_ET':first_second_combined,\n",
        "     'P_DEC': pssm_predictions,\n",
        "     'PMPNN_DP_PSSM_DEC' : first_pssm_combined\n",
        "\n",
        "    })\n",
        "corr = df_Ssym.corr()\n",
        "\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(corr, \n",
        "        xticklabels=corr.columns,\n",
        "        yticklabels=corr.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "QlQuGW7f7KDy",
        "outputId": "7ab6c7b3-92bb-4a0f-e5d9-7389498e1312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff0840fc590>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}