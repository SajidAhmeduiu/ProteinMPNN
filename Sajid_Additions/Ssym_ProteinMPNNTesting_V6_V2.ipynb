{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ssym_ProteinMPNNTesting_V6_V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "332971040f5744458c087c14286b34ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_837ebdb482384a25806f956a96f36f2b",
              "IPY_MODEL_b35a3767e7cc4d1c956595e81614df14",
              "IPY_MODEL_f3a67765216345dbb0c4884563619ccb"
            ],
            "layout": "IPY_MODEL_a6cb95a73bd3450184f0dcbcd0626585"
          }
        },
        "837ebdb482384a25806f956a96f36f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_088a2146c3b04eb28f86a6f2a654b80d",
            "placeholder": "​",
            "style": "IPY_MODEL_351a28972c1c4e1bb4af837af3e01e98",
            "value": ""
          }
        },
        "b35a3767e7cc4d1c956595e81614df14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13b6090fbf6a4b098ef059b6ace049f1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69423e46b3874c81a9cd0c36efc7755e",
            "value": 1
          }
        },
        "f3a67765216345dbb0c4884563619ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a0e46bcbfd34d1daf558937a9fe7c16",
            "placeholder": "​",
            "style": "IPY_MODEL_63cc47990fa54997b8e41329c3000de5",
            "value": " 684/? [00:00&lt;00:00, 15265.41it/s]"
          }
        },
        "a6cb95a73bd3450184f0dcbcd0626585": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088a2146c3b04eb28f86a6f2a654b80d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "351a28972c1c4e1bb4af837af3e01e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13b6090fbf6a4b098ef059b6ace049f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "69423e46b3874c81a9cd0c36efc7755e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a0e46bcbfd34d1daf558937a9fe7c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63cc47990fa54997b8e41329c3000de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32aa3ea6c4c549c492cc4f8c7e719de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50598242e3d4428a9a17564a8fe38071",
              "IPY_MODEL_ac1b41ae62b14c89bcdf538ab7723621",
              "IPY_MODEL_c50a30ae7f514065a8797ce71f605164"
            ],
            "layout": "IPY_MODEL_98c8d4c4a1c54b8eb2141cfaeb8f6f27"
          }
        },
        "50598242e3d4428a9a17564a8fe38071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a747e06d4c47437e926c724ff77d66b9",
            "placeholder": "​",
            "style": "IPY_MODEL_0aace9f11ba34a5da8e1e74a0a555f00",
            "value": "100%"
          }
        },
        "ac1b41ae62b14c89bcdf538ab7723621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6e942fb66546dd8181e2e5434962ba",
            "max": 357,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2c9880c0d024faba037892fc0351d8f",
            "value": 357
          }
        },
        "c50a30ae7f514065a8797ce71f605164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_837803589c264aa6a2c6bd1312224ccf",
            "placeholder": "​",
            "style": "IPY_MODEL_a02b54c3cc2c4395b6b2ce18dd7c6192",
            "value": " 357/357 [00:12&lt;00:00, 37.22it/s]"
          }
        },
        "98c8d4c4a1c54b8eb2141cfaeb8f6f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a747e06d4c47437e926c724ff77d66b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aace9f11ba34a5da8e1e74a0a555f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b6e942fb66546dd8181e2e5434962ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c9880c0d024faba037892fc0351d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "837803589c264aa6a2c6bd1312224ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a02b54c3cc2c4395b6b2ce18dd7c6192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_wbcvVBv0QJ",
        "outputId": "21665419-36cd-4054-dfcb-7c23428e2975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import sys \n",
        "installation_path = \"/content/drive/MyDrive/Colab_Installations_V2\"\n",
        "# The path is being modified so that everything installed in the installation path can now be used without re-installing (in this case, I just need biopython)\n",
        "sys.path.insert(0,installation_path)\n",
        "protein_mpnn_path = \"/content/drive/MyDrive/Protein_MPNN_Digging/ProteinMPNN/vanilla_proteinmpnn\"\n",
        "sys.path.insert(0,protein_mpnn_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Protein_MPNN_Digging"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgTOgsabxBaC",
        "outputId": "3d6397a9-b42f-4a8a-fcb9-51e22af76744"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1KHc6SLCFDWefngMT266PS74JQMzqN06K/Protein_MPNN_Digging\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import warnings\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, Subset\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import os\n",
        "from Bio.PDB import *\n",
        "\n",
        "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")"
      ],
      "metadata": {
        "id": "jX5ScMeGyLcy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from Bio.PDB.Polypeptide import *\n",
        "from string import ascii_uppercase"
      ],
      "metadata": {
        "id": "NBjszWagtiYL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = os.path.join(protein_mpnn_path,\"vanilla_model_weights\")\n",
        "model_name = \"v_48_020\"\n",
        "checkpoint_path = os.path.join(weights_path,model_name+\".pt\")"
      ],
      "metadata": {
        "id": "Z6ZHe2IIyy1G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, load and dig into the checkpoint object\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device) "
      ],
      "metadata": {
        "id": "JPE_pX8tzdUO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint[\"num_edges\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DD1hpMLk2-y",
        "outputId": "b8f5d98c-99ad-4b3b-ed19-2c539101086b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import json, time, os, sys, glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, Subset\n",
        "\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "#A number of functions/classes are adopted from: https://github.com/jingraham/neurips19-graph-protein-design\n",
        "\n",
        "def _scores(S, log_probs, mask):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    criterion = torch.nn.NLLLoss(reduction='none')\n",
        "    loss = criterion(\n",
        "        log_probs.contiguous().view(-1,log_probs.size(-1)),\n",
        "        S.contiguous().view(-1)\n",
        "    ).view(S.size())\n",
        "    # The designable positions have mask set to 1.0, so this function seems to be returning the average score for the designable positions\n",
        "    scores = torch.sum(loss * mask, dim=-1) / torch.sum(mask, dim=-1)\n",
        "    return scores\n",
        "\n",
        "def _S_to_seq(S, mask):\n",
        "    # This is the decoding order\n",
        "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    seq = ''.join([alphabet[c] for c, m in zip(S.tolist(), mask.tolist()) if m > 0])\n",
        "    return seq\n",
        "\n",
        "def parse_PDB_biounits(x, atoms=['N','CA','C'], chain=None):\n",
        "  '''\n",
        "  input:  x = PDB filename\n",
        "          atoms = atoms to extract (optional)\n",
        "  output: (length, atoms, coords=(x,y,z)), sequence\n",
        "  '''\n",
        "\n",
        "  alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "  states = len(alpha_1)\n",
        "  alpha_3 = ['ALA','ARG','ASN','ASP','CYS','GLN','GLU','GLY','HIS','ILE',\n",
        "             'LEU','LYS','MET','PHE','PRO','SER','THR','TRP','TYR','VAL','GAP']\n",
        "  \n",
        "  # The following dictionaries are mapping from one-letter to 0-20 index,\n",
        "  # three-letter to 0-20 index,\n",
        "  # 0-20 index to one-letter,\n",
        "  # one-letter to three-letter, and vice-versa \n",
        "  aa_1_N = {a:n for n,a in enumerate(alpha_1)}\n",
        "  aa_3_N = {a:n for n,a in enumerate(alpha_3)}\n",
        "  aa_N_1 = {n:a for n,a in enumerate(alpha_1)}\n",
        "  aa_1_3 = {a:b for a,b in zip(alpha_1,alpha_3)}\n",
        "  aa_3_1 = {b:a for a,b in zip(alpha_1,alpha_3)}\n",
        "  \n",
        "  def AA_to_N(x):\n",
        "    # [\"ARND\"] -> [[0,1,2,3]]\n",
        "    x = np.array(x);\n",
        "    if x.ndim == 0: x = x[None]\n",
        "    return [[aa_1_N.get(a, states-1) for a in y] for y in x]\n",
        "  \n",
        "  def N_to_AA(x):\n",
        "    # [[0,1,2,3]] -> [\"ARND\"]\n",
        "    x = np.array(x);\n",
        "    if x.ndim == 1: x = x[None]\n",
        "    return [\"\".join([aa_N_1.get(a,\"-\") for a in y]) for y in x]\n",
        "\n",
        "  xyz,seq,min_resn,max_resn = {},{},1e6,-1e6\n",
        "  for line in open(x,\"rb\"):\n",
        "    line = line.decode(\"utf-8\",\"ignore\").rstrip()\n",
        "\n",
        "    if line[:6] == \"HETATM\" and line[17:17+3] == \"MSE\":\n",
        "      line = line.replace(\"HETATM\",\"ATOM  \")\n",
        "      line = line.replace(\"MSE\",\"MET\")\n",
        "\n",
        "    if line[:4] == \"ATOM\":\n",
        "      ch = line[21:22]\n",
        "      # If the input chain is not in the PDB file, which can be the case if the target chains are named differently in the runner script,\n",
        "      # this line will cause the output to have literally no information, this is the case for integer named chains\n",
        "      # that does not mean that this line is not doing its job correctly, this is just a constraint that input chain names and \n",
        "      # chain names in the PDB file have to be congruent\n",
        "      if ch == chain or chain is None:\n",
        "        atom = line[12:12+4].strip()\n",
        "        resi = line[17:17+3]\n",
        "        resn = line[22:22+5].strip()\n",
        "        x,y,z = [float(line[i:(i+8)]) for i in [30,38,46]]\n",
        "\n",
        "        if resn[-1].isalpha(): \n",
        "            resa,resn = resn[-1],int(resn[:-1])-1\n",
        "        else: \n",
        "            resa,resn = \"\",int(resn)-1\n",
        "#         resn = int(resn)\n",
        "        if resn < min_resn: \n",
        "            min_resn = resn\n",
        "        if resn > max_resn: \n",
        "            max_resn = resn\n",
        "        if resn not in xyz: \n",
        "            xyz[resn] = {}\n",
        "        if resa not in xyz[resn]: \n",
        "            xyz[resn][resa] = {}\n",
        "        if resn not in seq: \n",
        "            seq[resn] = {}\n",
        "        if resa not in seq[resn]: \n",
        "            seq[resn][resa] = resi\n",
        "\n",
        "        if atom not in xyz[resn][resa]:\n",
        "          xyz[resn][resa][atom] = np.array([x,y,z])\n",
        "\n",
        "  # convert to numpy arrays, fill in missing values\n",
        "  seq_,xyz_ = [],[]\n",
        "  try:\n",
        "      for resn in range(min_resn,max_resn+1):\n",
        "        if resn in seq:\n",
        "          for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k],20))\n",
        "        else: seq_.append(20)\n",
        "        if resn in xyz:\n",
        "          for k in sorted(xyz[resn]):\n",
        "            for atom in atoms:\n",
        "              if atom in xyz[resn][k]: xyz_.append(xyz[resn][k][atom])\n",
        "              else: xyz_.append(np.full(3,np.nan))\n",
        "        else:\n",
        "          for atom in atoms: xyz_.append(np.full(3,np.nan))\n",
        "      return np.array(xyz_).reshape(-1,len(atoms),3), N_to_AA(np.array(seq_))\n",
        "  except TypeError:\n",
        "      return 'no_chain', 'no_chain'\n",
        "\n",
        "### calling signature\n",
        "# pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list)\n",
        "def parse_PDB(path_to_pdb, input_chain_list=None):\n",
        "    c=0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V','W','X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v','w','x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "     \n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list  \n",
        " \n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    # Each of the biounits is a separate PDB file, so for running with a single PDB file like from colab, this loop will be executed only once\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {} \n",
        "        # This loop will be executed only once for single chain DDG type cases\n",
        "        for letter in chain_alphabet:\n",
        "            xyz, seq = parse_PDB_biounits(biounit, atoms=['N','CA','C','O'], chain=letter)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_'+letter]=seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                coords_dict_chain['N_chain_'+letter]=xyz[:,0,:].tolist()\n",
        "                coords_dict_chain['CA_chain_'+letter]=xyz[:,1,:].tolist()\n",
        "                coords_dict_chain['C_chain_'+letter]=xyz[:,2,:].tolist()\n",
        "                coords_dict_chain['O_chain_'+letter]=xyz[:,3,:].tolist()\n",
        "                my_dict['coords_chain_'+letter]=coords_dict_chain\n",
        "                s += 1\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        my_dict['name']=biounit[(fi+1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c+=1\n",
        "    return pdb_dict_list\n",
        "\n",
        "\n",
        "# X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta \n",
        "# = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "# fixed_pos_list = fixed_position_dict[b['name']][letter]\n",
        "# The trick will be to populate this fixed_position_dict from the calling function, and \n",
        "def tied_featurize(batch, device, chain_dict, fixed_position_dict=None, omit_AA_dict=None, tied_positions_dict=None, pssm_dict=None, bias_by_res_dict=None):\n",
        "    \"\"\" Pack and pad batch into torch tensors \"\"\"\n",
        "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    B = len(batch)\n",
        "    lengths = np.array([len(b['seq']) for b in batch], dtype=np.int32) #sum of chain seq lengths\n",
        "    L_max = max([len(b['seq']) for b in batch])\n",
        "    X = np.zeros([B, L_max, 4, 3])\n",
        "    residue_idx = -100*np.ones([B, L_max], dtype=np.int32)\n",
        "    # This \"chain_M\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of the single sequence as a consequence\n",
        "    chain_M = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    pssm_coef_all = np.zeros([B, L_max], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    pssm_bias_all = np.zeros([B, L_max, 21], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    pssm_log_odds_all = 10000.0*np.ones([B, L_max, 21], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    # This \"chain_M_pos\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of single sequence as a consequence\n",
        "    chain_M_pos = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    bias_by_res_all = np.zeros([B, L_max, 21], dtype=np.float32)\n",
        "    # This \"chain_encoding_all\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of single sequence as a consequence\n",
        "    chain_encoding_all = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    S = np.zeros([B, L_max], dtype=np.int32)\n",
        "    omit_AA_mask = np.zeros([B, L_max, len(alphabet)], dtype=np.int32)\n",
        "    # Build the batch\n",
        "    letter_list_list = []\n",
        "    visible_list_list = []\n",
        "    masked_list_list = []\n",
        "    masked_chain_length_list_list = []\n",
        "    tied_pos_list_of_lists_list = []\n",
        "    #shuffle all chains before the main loop\n",
        "    for i, b in enumerate(batch):\n",
        "        # for my current energy function like usecase, the code will reach \"if and not else\" because chain_dict will not be None\n",
        "        if chain_dict != None:\n",
        "            ### Calling function argument assignment START\n",
        "            # chain_id_dict[pdb_dict_list[0]['name']] = (designed_chain_list, fixed_chain_list)\n",
        "            ### Calling function argument assignment END\n",
        "            masked_chains, visible_chains = chain_dict[b['name']] #masked_chains a list of chain letters to predict [A, D, F]\n",
        "        else:\n",
        "            masked_chains = [item[-1:] for item in list(b) if item[:10]=='seq_chain_']\n",
        "            visible_chains = []\n",
        "        num_chains = b['num_of_chains']\n",
        "        all_chains = masked_chains + visible_chains\n",
        "        #random.shuffle(all_chains)\n",
        "    # This for loop can be ignored since it will be executed only once in my single-chain or single-chain-at-a-time implementation\n",
        "    for i, b in enumerate(batch):\n",
        "        mask_dict = {}\n",
        "        a = 0\n",
        "        x_chain_list = []\n",
        "        chain_mask_list = []\n",
        "        # \"chain_seq_list\" will contain string format sequences of all the chains both fixed and designable \n",
        "        chain_seq_list = []\n",
        "        chain_encoding_list = []\n",
        "        c = 1\n",
        "        # \"letter_list\" will contain names of all the chains both fixed and designable\n",
        "        letter_list = []\n",
        "        global_idx_start_list = [0]\n",
        "        # \"visible_list\" will contain names of the fixed chains \n",
        "        visible_list = []\n",
        "        # \"masked_list\" will contain names of the designable chains\n",
        "        masked_list = []\n",
        "        masked_chain_length_list = []\n",
        "        fixed_position_mask_list = []\n",
        "        omit_AA_mask_list = []\n",
        "        pssm_coef_list = []\n",
        "        pssm_bias_list = []\n",
        "        pssm_log_odds_list = []\n",
        "        bias_by_res_list = []\n",
        "        l0 = 0\n",
        "        l1 = 0\n",
        "        # This loop will also be executed once for my single chain case,\n",
        "        # and since the same chain has both designable and fixed positions, the codes insides both of the if \n",
        "        # statements will be executed\n",
        "        for step, letter in enumerate(all_chains):\n",
        "            if letter in visible_chains:\n",
        "                letter_list.append(letter)\n",
        "                visible_list.append(letter)\n",
        "                chain_seq = b[f'seq_chain_{letter}']\n",
        "                chain_seq = ''.join([a if a!='-' else 'X' for a in chain_seq])\n",
        "                chain_length = len(chain_seq)\n",
        "                global_idx_start_list.append(global_idx_start_list[-1]+chain_length)\n",
        "                chain_coords = b[f'coords_chain_{letter}'] #this is a dictionary\n",
        "                # the \"chain_mask\" varies between fixed and designable chains (1.0 for designable chains which are maxed)\n",
        "                chain_mask = np.zeros(chain_length) #0.0 for visible chains\n",
        "                x_chain = np.stack([chain_coords[c] for c in [f'N_chain_{letter}', f'CA_chain_{letter}', f'C_chain_{letter}', f'O_chain_{letter}']], 1) #[chain_lenght,4,3]\n",
        "                x_chain_list.append(x_chain)\n",
        "                chain_mask_list.append(chain_mask)\n",
        "                chain_seq_list.append(chain_seq)\n",
        "                # \"chain_encoding_list\" contains numpy arrays corresponding to chains (each array corresponds to one chain),\n",
        "                # where all elements of the same array is the same value, which is equal to the index of the chain the it corresponds to\n",
        "                # by index, I mean index of the different numpy arrays annotating the chains\n",
        "                chain_encoding_list.append(c*np.ones(np.array(chain_mask).shape[0]))\n",
        "                # l0 points at the starting of the current chain and l1 points after the ending of the current chain\n",
        "                l1 += chain_length\n",
        "                # the only value i will have is 0 since it will be executed only once in my single-chain or single-chain-at-a-time implementation\n",
        "                # seems like the chains are separated by  \n",
        "                residue_idx[i, l0:l1] = 100*(c-1)+np.arange(l0, l1)\n",
        "                l0 += chain_length\n",
        "                c+=1\n",
        "                # The following variables are numpy arrays with entries corresponding to every position in the sequence\n",
        "                # appending these numpy arrays to a list indicates that the chains are added one after one\n",
        "                # same thing goes for the chain_mask and chain_seq variables declared above\n",
        "                # In code-block below in this cell, these lists of numpy arrays are going through np.concatenate(), which is creating\n",
        "                # the final numpy arrays containing co-ordinates, sequence identity, fixed position, masked position, PSSM bias, and everything\n",
        "                # required to pass the sequences through the model\n",
        "                ### START\n",
        "                fixed_position_mask = np.ones(chain_length)\n",
        "                fixed_position_mask_list.append(fixed_position_mask)\n",
        "                # The omit_AA_mask, pssm_coef, pssm_bias, \"bias_by_res_list\", all these numpy arrays are zero for the fixed positions\n",
        "                # since these positions are used as it is, while for the masked_positions, these values can get activated\n",
        "                # which is why the next if statement has several extra lines manipulating these variables according to the amount of information passed \n",
        "                omit_AA_mask_temp = np.zeros([chain_length, len(alphabet)], np.int32)\n",
        "                omit_AA_mask_list.append(omit_AA_mask_temp)\n",
        "                pssm_coef = np.zeros(chain_length)\n",
        "                pssm_bias = np.zeros([chain_length, 21])\n",
        "                pssm_log_odds = 10000.0*np.ones([chain_length, 21])\n",
        "                pssm_coef_list.append(pssm_coef)\n",
        "                pssm_bias_list.append(pssm_bias)\n",
        "                pssm_log_odds_list.append(pssm_log_odds)\n",
        "                bias_by_res_list.append(np.zeros([chain_length, 21]))\n",
        "                ### END\n",
        "            if letter in masked_chains:\n",
        "                masked_list.append(letter)\n",
        "                letter_list.append(letter)\n",
        "                chain_seq = b[f'seq_chain_{letter}']\n",
        "                chain_seq = ''.join([a if a!='-' else 'X' for a in chain_seq])\n",
        "                chain_length = len(chain_seq)\n",
        "                global_idx_start_list.append(global_idx_start_list[-1]+chain_length)\n",
        "                masked_chain_length_list.append(chain_length)\n",
        "                chain_coords = b[f'coords_chain_{letter}'] #this is a dictionary\n",
        "                chain_mask = np.ones(chain_length) #1.0 for masked\n",
        "                x_chain = np.stack([chain_coords[c] for c in [f'N_chain_{letter}', f'CA_chain_{letter}', f'C_chain_{letter}', f'O_chain_{letter}']], 1) #[chain_lenght,4,3]\n",
        "                x_chain_list.append(x_chain)\n",
        "                chain_mask_list.append(chain_mask)\n",
        "                chain_seq_list.append(chain_seq)\n",
        "                chain_encoding_list.append(c*np.ones(np.array(chain_mask).shape[0]))\n",
        "                l1 += chain_length\n",
        "                residue_idx[i, l0:l1] = 100*(c-1)+np.arange(l0, l1)\n",
        "                l0 += chain_length\n",
        "                c+=1\n",
        "                fixed_position_mask = np.ones(chain_length)\n",
        "                if fixed_position_dict!=None:\n",
        "                    fixed_pos_list = fixed_position_dict[b['name']][letter]\n",
        "                    if fixed_pos_list:\n",
        "                        # seems like \"fixed_pos_list\"  can be an 1-indexed integer list corresponding to positions in \"chain_seq\"\n",
        "                        # this thing ultimately controls which positions in the designable chain will be masked, which is why the fixed \n",
        "                        # positions are set to 0.0 since those positions will not be maxed (1 if maxed, 0 if not maxed)\n",
        "                        fixed_position_mask[np.array(fixed_pos_list)-1] = 0.0\n",
        "                fixed_position_mask_list.append(fixed_position_mask)\n",
        "                omit_AA_mask_temp = np.zeros([chain_length, len(alphabet)], np.int32)\n",
        "                # For my current energy function like usecase, \"omit_AA_dict\" will be None, so the following loop can be ignored\n",
        "                if omit_AA_dict!=None:\n",
        "                    for item in omit_AA_dict[b['name']][letter]:\n",
        "                        idx_AA = np.array(item[0])-1\n",
        "                        AA_idx = np.array([np.argwhere(np.array(list(alphabet))== AA)[0][0] for AA in item[1]]).repeat(idx_AA.shape[0])\n",
        "                        idx_ = np.array([[a, b] for a in idx_AA for b in AA_idx])\n",
        "                        omit_AA_mask_temp[idx_[:,0], idx_[:,1]] = 1\n",
        "                omit_AA_mask_list.append(omit_AA_mask_temp)\n",
        "                pssm_coef = np.zeros(chain_length)\n",
        "                pssm_bias = np.zeros([chain_length, 21])\n",
        "                pssm_log_odds = 10000.0*np.ones([chain_length, 21])\n",
        "                if pssm_dict:\n",
        "                    if pssm_dict[b['name']][letter]:\n",
        "                        pssm_coef = pssm_dict[b['name']][letter]['pssm_coef']\n",
        "                        pssm_bias = pssm_dict[b['name']][letter]['pssm_bias']\n",
        "                        pssm_log_odds = pssm_dict[b['name']][letter]['pssm_log_odds']\n",
        "                pssm_coef_list.append(pssm_coef)\n",
        "                pssm_bias_list.append(pssm_bias)\n",
        "                pssm_log_odds_list.append(pssm_log_odds)\n",
        "                if bias_by_res_dict:\n",
        "                    bias_by_res_list.append(bias_by_res_dict[b['name']][letter])\n",
        "                else:\n",
        "                    bias_by_res_list.append(np.zeros([chain_length, 21]))\n",
        "\n",
        "        ### TIED position START\n",
        "        # Since there will technically be no tied positions for my single chain energy-based usecase for now,\n",
        "        # I do not need to dig into this part of the code\n",
        "        letter_list_np = np.array(letter_list)\n",
        "        tied_pos_list_of_lists = []\n",
        "        tied_beta = np.ones(L_max)\n",
        "        if tied_positions_dict!=None:\n",
        "            tied_pos_list = tied_positions_dict[b['name']]\n",
        "            if tied_pos_list:\n",
        "                set_chains_tied = set(list(itertools.chain(*[list(item) for item in tied_pos_list])))\n",
        "                for tied_item in tied_pos_list:\n",
        "                    one_list = []\n",
        "                    for k, v in tied_item.items():\n",
        "                        start_idx = global_idx_start_list[np.argwhere(letter_list_np == k)[0][0]]\n",
        "                        if isinstance(v[0], list):\n",
        "                            for v_count in range(len(v[0])):\n",
        "                                one_list.append(start_idx+v[0][v_count]-1)#make 0 to be the first\n",
        "                                tied_beta[start_idx+v[0][v_count]-1] = v[1][v_count]\n",
        "                        else:\n",
        "                            for v_ in v:\n",
        "                                one_list.append(start_idx+v_-1)#make 0 to be the first\n",
        "                    tied_pos_list_of_lists.append(one_list)\n",
        "        tied_pos_list_of_lists_list.append(tied_pos_list_of_lists)\n",
        "        ### TIED position END\n",
        " \n",
        "        # Interestingly, although the backbone atom coordinates are used for generating edge features,\n",
        "        # the \"x\" in the following line contains the coodinates of the backbone atoms \n",
        "        x = np.concatenate(x_chain_list,0) #[L, 4, 3]\n",
        "        # \"all_sequence\" is a string where all the chain sequences have been put one after another\n",
        "        all_sequence = \"\".join(chain_seq_list)\n",
        "        # This \"chain_mask_list\" and \"m_pos\" below are the variables of interest if these actually contain full information regarding the\n",
        "        # fixed vs. variable positions definitions \n",
        "        # consequently, since these are concatenated numpy arrays of numpy arrays inside the lists \"chain_mask_list\" and \"fixed_position_mask_list\",\n",
        "        # when those lists are populated in the above code-block with binary numpy arrays \"fixed_position_mask\" and \"fixed_position_mask\" corresponding to \n",
        "        # each of the chains,\n",
        "        # that is where all the controlling needs to be done from\n",
        "        m = np.concatenate(chain_mask_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        # \"chain_encoding_list\" contains numpy arrays corresponding to chains (each array corresponds to one chain),\n",
        "        # where all elements of the same array is the same value, which is equal to the index of the chain the it corresponds to\n",
        "        # by index, I mean index of the different numpy arrays annotating the chains\n",
        "        chain_encoding = np.concatenate(chain_encoding_list,0)\n",
        "        m_pos = np.concatenate(fixed_position_mask_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "\n",
        "        pssm_coef_ = np.concatenate(pssm_coef_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        pssm_bias_ = np.concatenate(pssm_bias_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        pssm_log_odds_ = np.concatenate(pssm_log_odds_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "\n",
        "        bias_by_res_ = np.concatenate(bias_by_res_list, 0)  #[L,21], 0.0 for places where AA frequencies don't need to be tweaked\n",
        "\n",
        "        # Interestingly, all the chains are padded to the same length\n",
        "        # this has to be done most probably because the same layers are applied to all chains\n",
        "        # but for single chain or homomer cases, this should not be an issue\n",
        "        # need to be sure later why this is done\n",
        "        # does not significant when it comes to single chain energy-based usecase\n",
        "        # PADDING START\n",
        "        l = len(all_sequence)\n",
        "        x_pad = np.pad(x, [[0,L_max-l], [0,0], [0,0]], 'constant', constant_values=(np.nan, ))\n",
        "        X[i,:,:,:] = x_pad\n",
        "\n",
        "        m_pad = np.pad(m, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        m_pos_pad = np.pad(m_pos, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        omit_AA_mask_pad = np.pad(np.concatenate(omit_AA_mask_list,0), [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        chain_M[i,:] = m_pad\n",
        "        chain_M_pos[i,:] = m_pos_pad\n",
        "        omit_AA_mask[i,] = omit_AA_mask_pad\n",
        "\n",
        "        chain_encoding_pad = np.pad(chain_encoding, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        chain_encoding_all[i,:] = chain_encoding_pad\n",
        "\n",
        "        pssm_coef_pad = np.pad(pssm_coef_, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        pssm_bias_pad = np.pad(pssm_bias_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "        pssm_log_odds_pad = np.pad(pssm_log_odds_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "\n",
        "        pssm_coef_all[i,:] = pssm_coef_pad\n",
        "        pssm_bias_all[i,:] = pssm_bias_pad\n",
        "        pssm_log_odds_all[i,:] = pssm_log_odds_pad\n",
        "\n",
        "        bias_by_res_pad = np.pad(bias_by_res_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "        bias_by_res_all[i,:] = bias_by_res_pad\n",
        "        # PADDING END\n",
        "\n",
        "        # Convert to labels\n",
        "        indices = np.asarray([alphabet.index(a) for a in all_sequence], dtype=np.int32)\n",
        "        S[i, :l] = indices\n",
        "        letter_list_list.append(letter_list)\n",
        "        visible_list_list.append(visible_list)\n",
        "        masked_list_list.append(masked_list)\n",
        "        masked_chain_length_list_list.append(masked_chain_length_list)\n",
        "\n",
        "\n",
        "    isnan = np.isnan(X)\n",
        "    mask = np.isfinite(np.sum(X,(2,3))).astype(np.float32)\n",
        "    X[isnan] = 0.\n",
        "\n",
        "    # Conversion\n",
        "    pssm_coef_all = torch.from_numpy(pssm_coef_all).to(dtype=torch.float32, device=device)\n",
        "    pssm_bias_all = torch.from_numpy(pssm_bias_all).to(dtype=torch.float32, device=device)\n",
        "    pssm_log_odds_all = torch.from_numpy(pssm_log_odds_all).to(dtype=torch.float32, device=device)\n",
        "\n",
        "    tied_beta = torch.from_numpy(tied_beta).to(dtype=torch.float32, device=device)\n",
        "\n",
        "    jumps = ((residue_idx[:,1:]-residue_idx[:,:-1])==1).astype(np.float32)\n",
        "    bias_by_res_all = torch.from_numpy(bias_by_res_all).to(dtype=torch.float32, device=device)\n",
        "    phi_mask = np.pad(jumps, [[0,0],[1,0]])\n",
        "    psi_mask = np.pad(jumps, [[0,0],[0,1]])\n",
        "    omega_mask = np.pad(jumps, [[0,0],[0,1]])\n",
        "    dihedral_mask = np.concatenate([phi_mask[:,:,None], psi_mask[:,:,None], omega_mask[:,:,None]], -1) #[B,L,3]\n",
        "    dihedral_mask = torch.from_numpy(dihedral_mask).to(dtype=torch.float32, device=device)\n",
        "    residue_idx = torch.from_numpy(residue_idx).to(dtype=torch.long,device=device)\n",
        "    S = torch.from_numpy(S).to(dtype=torch.long,device=device)\n",
        "    X = torch.from_numpy(X).to(dtype=torch.float32, device=device)\n",
        "    mask = torch.from_numpy(mask).to(dtype=torch.float32, device=device)\n",
        "    chain_M = torch.from_numpy(chain_M).to(dtype=torch.float32, device=device)\n",
        "    chain_M_pos = torch.from_numpy(chain_M_pos).to(dtype=torch.float32, device=device)\n",
        "    omit_AA_mask = torch.from_numpy(omit_AA_mask).to(dtype=torch.float32, device=device)\n",
        "    chain_encoding_all = torch.from_numpy(chain_encoding_all).to(dtype=torch.long, device=device)\n",
        "    # in general, in this return statement, *_list_list has the list inside list format because the outer list corresponds to \"batch_clones\", \n",
        "    # whereas the inner list corresponds to \"chains\" for each of the elements of \"batch_clones\"\n",
        "    # \"masked_list_list\" contains names of the designable chains (which is my target for single chain energy), whereas \"visible_list_list\" \n",
        "    # contains names of the fixed chains (which should be empty for my single chain energy)\n",
        "    # for my single chain energy case, \"letter_list_list\" should be equal to \"masked_list_list\", and three lists should have one list for now\n",
        "    # \"chain_encoding_all\" should also contain chain-index related to the only single chain which should be 0 (all 0s)\n",
        "    # the last lists starting from \"tied_pos_list_of_lists_list\" to the end should be irrelevant for my single chain energy case\n",
        "    # but still it would be good to check the values of these irrelevant lists, and get an idea if everything makes sense or not\n",
        "    # \"chain_M_pos\" contains values from \"fixed_position_mask\" through \"m_pos\", which should get populated with 0.0 for fixed positions\n",
        "    # and 1.0 for designable positions, which can be controlled through the , which\n",
        "    # is controlled by \"fixed_position_dict\" input to this function from the running script\n",
        "    # \"chain_M\" is formed from \"m_pad\" which comes from \"m\" which comes from chain_mask = np.ones(chain_length) #1.0 for masked\n",
        "    # so, for my single chain energy usecase, \"chain_M\" should be all 1.0s with the same length as chain_M_pos\n",
        "    # I do not think \"X\", \"S\", and \"mask\" need to be manipulated for now \n",
        "    return X, S, mask, lengths, chain_M, chain_encoding_all, letter_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef_all, pssm_bias_all, pssm_log_odds_all, bias_by_res_all, tied_beta\n",
        "\n",
        "\n",
        "# No need to dig into this loss function for now\n",
        "def loss_nll(S, log_probs, mask):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    criterion = torch.nn.NLLLoss(reduction='none')\n",
        "    loss = criterion(\n",
        "        log_probs.contiguous().view(-1, log_probs.size(-1)), S.contiguous().view(-1)\n",
        "    ).view(S.size())\n",
        "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
        "    return loss, loss_av\n",
        "\n",
        "# No need to dig into this label smoothing stuff for now\n",
        "def loss_smoothed(S, log_probs, mask, weight=0.1):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    S_onehot = torch.nn.functional.one_hot(S, 21).float()\n",
        "\n",
        "    # Label smoothing\n",
        "    S_onehot = S_onehot + weight / float(S_onehot.size(-1))\n",
        "    S_onehot = S_onehot / S_onehot.sum(-1, keepdim=True)\n",
        "\n",
        "    loss = -(S_onehot * log_probs).sum(-1)\n",
        "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
        "    return loss, loss_av\n",
        "\n",
        "# Objects of this class can be indexed since dunder methods __len()__ and __getitem()__ have been implemented, which \n",
        "# indexes a list that has been declared as an instance variable in the constructor,\n",
        "# and each element of that underlying list is a dictionary containing information regarding a specific sequence\n",
        "class StructureDataset():\n",
        "    def __init__(self, jsonl_file, verbose=True, truncate=None, max_length=100,\n",
        "        alphabet='ACDEFGHIKLMNPQRSTVWYX-'):\n",
        "        alphabet_set = set([a for a in alphabet])\n",
        "        discard_count = {\n",
        "            'bad_chars': 0,\n",
        "            'too_long': 0,\n",
        "            'bad_seq_length': 0\n",
        "        }\n",
        "\n",
        "        with open(jsonl_file) as f:\n",
        "            self.data = []\n",
        "\n",
        "            lines = f.readlines()\n",
        "            start = time.time()\n",
        "            for i, line in enumerate(lines):\n",
        "                entry = json.loads(line)\n",
        "                seq = entry['seq'] \n",
        "                name = entry['name']\n",
        "\n",
        "                # Convert raw coords to np arrays\n",
        "                #for key, val in entry['coords'].items():\n",
        "                #    entry['coords'][key] = np.asarray(val)\n",
        "\n",
        "                # Check if in alphabet\n",
        "                bad_chars = set([s for s in seq]).difference(alphabet_set)\n",
        "                if len(bad_chars) == 0:\n",
        "                    if len(entry['seq']) <= max_length:\n",
        "                        if True:\n",
        "                            self.data.append(entry)\n",
        "                        else:\n",
        "                            discard_count['bad_seq_length'] += 1\n",
        "                    else:\n",
        "                        discard_count['too_long'] += 1\n",
        "                else:\n",
        "                    print(name, bad_chars, entry['seq'])\n",
        "                    discard_count['bad_chars'] += 1\n",
        "\n",
        "                # Truncate early\n",
        "                if truncate is not None and len(self.data) == truncate:\n",
        "                    return\n",
        "\n",
        "                if verbose and (i + 1) % 1000 == 0:\n",
        "                    elapsed = time.time() - start\n",
        "                    print('{} entries ({} loaded) in {:.1f} s'.format(len(self.data), i+1, elapsed))\n",
        "\n",
        "            print('discarded', discard_count)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "\n",
        "# Objects of this class can be indexed since dunder methods __len()__ and __getitem()__ have been implemented, which \n",
        "# indexes a list that has been declared as an instance variable in the constructor,\n",
        "# and each element of that underlying list is a dictionary containing information regarding a specific structure,\n",
        "# seems like a structure-specific version of the above method which deals with sequences \n",
        "class StructureDatasetPDB():\n",
        "    def __init__(self, pdb_dict_list, verbose=True, truncate=None, max_length=100,\n",
        "        alphabet='ACDEFGHIKLMNPQRSTVWYX-'):\n",
        "        alphabet_set = set([a for a in alphabet])\n",
        "        discard_count = {\n",
        "            'bad_chars': 0,\n",
        "            'too_long': 0,\n",
        "            'bad_seq_length': 0\n",
        "        }\n",
        "\n",
        "        self.data = []\n",
        "\n",
        "        start = time.time()\n",
        "        # elements of pdb_dict_list are dictionaries containing information regarding a specific pdb file\n",
        "        for i, entry in enumerate(pdb_dict_list):\n",
        "            seq = entry['seq']\n",
        "            name = entry['name']\n",
        "\n",
        "            bad_chars = set([s for s in seq]).difference(alphabet_set)\n",
        "            if len(bad_chars) == 0:\n",
        "                if len(entry['seq']) <= max_length:\n",
        "                    self.data.append(entry)\n",
        "                else:\n",
        "                    discard_count['too_long'] += 1\n",
        "            else:\n",
        "                discard_count['bad_chars'] += 1\n",
        "\n",
        "            # Truncate early\n",
        "            if truncate is not None and len(self.data) == truncate:\n",
        "                return\n",
        "\n",
        "            if verbose and (i + 1) % 1000 == 0:\n",
        "                elapsed = time.time() - start\n",
        "\n",
        "            #print('Discarded', discard_count)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "\n",
        "    \n",
        "class StructureLoader():\n",
        "    def __init__(self, dataset, batch_size=100, shuffle=True,\n",
        "        collate_fn=lambda x:x, drop_last=False):\n",
        "        self.dataset = dataset\n",
        "        self.size = len(dataset)\n",
        "        self.lengths = [len(dataset[i]['seq']) for i in range(self.size)]\n",
        "        self.batch_size = batch_size\n",
        "        sorted_ix = np.argsort(self.lengths)\n",
        "\n",
        "        # Cluster into batches of similar sizes\n",
        "        clusters, batch = [], []\n",
        "        batch_max = 0\n",
        "        for ix in sorted_ix:\n",
        "            size = self.lengths[ix]\n",
        "            if size * (len(batch) + 1) <= self.batch_size:\n",
        "                batch.append(ix)\n",
        "                batch_max = size\n",
        "            else:\n",
        "                clusters.append(batch)\n",
        "                batch, batch_max = [], 0\n",
        "        if len(batch) > 0:\n",
        "            clusters.append(batch)\n",
        "        self.clusters = clusters\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.clusters)\n",
        "\n",
        "    def __iter__(self):\n",
        "        np.random.shuffle(self.clusters)\n",
        "        for b_idx in self.clusters:\n",
        "            batch = [self.dataset[i] for i in b_idx]\n",
        "            yield batch\n",
        "            \n",
        "            \n",
        "            \n",
        "# The following gather functions\n",
        "def gather_edges(edges, neighbor_idx):\n",
        "    # Features [B,N,N,C] at Neighbor indices [B,N,K] => Neighbor features [B,N,K,C]\n",
        "    neighbors = neighbor_idx.unsqueeze(-1).expand(-1, -1, -1, edges.size(-1))\n",
        "    edge_features = torch.gather(edges, 2, neighbors)\n",
        "    return edge_features\n",
        "\n",
        "def gather_nodes(nodes, neighbor_idx):\n",
        "    # Features [B,N,C] at Neighbor indices [B,N,K] => [B,N,K,C]\n",
        "    # Flatten and expand indices per batch [B,N,K] => [B,NK] => [B,NK,C]\n",
        "    neighbors_flat = neighbor_idx.view((neighbor_idx.shape[0], -1))\n",
        "    neighbors_flat = neighbors_flat.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
        "    # Gather and re-pack\n",
        "    neighbor_features = torch.gather(nodes, 1, neighbors_flat)\n",
        "    neighbor_features = neighbor_features.view(list(neighbor_idx.shape)[:3] + [-1])\n",
        "    return neighbor_features\n",
        "\n",
        "def gather_nodes_t(nodes, neighbor_idx):\n",
        "    # Features [B,N,C] at Neighbor index [B,K] => Neighbor features[B,K,C]\n",
        "    idx_flat = neighbor_idx.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
        "    neighbor_features = torch.gather(nodes, 1, idx_flat)\n",
        "    return neighbor_features\n",
        "\n",
        "def cat_neighbors_nodes(h_nodes, h_neighbors, E_idx):\n",
        "    h_nodes = gather_nodes(h_nodes, E_idx)\n",
        "    h_nn = torch.cat([h_neighbors, h_nodes], -1)\n",
        "    return h_nn\n",
        "\n",
        "\n",
        "class EncLayer(nn.Module):\n",
        "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
        "        super(EncLayer, self).__init__()\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_in = num_in\n",
        "        self.scale = scale\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(num_hidden)\n",
        "        self.norm2 = nn.LayerNorm(num_hidden)\n",
        "        self.norm3 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W11 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W12 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W13 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
        "\n",
        "    def forward(self, h_V, h_E, E_idx, mask_V=None, mask_attend=None):\n",
        "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
        "\n",
        "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
        "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
        "        if mask_attend is not None:\n",
        "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
        "        dh = torch.sum(h_message, -2) / self.scale\n",
        "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
        "\n",
        "        dh = self.dense(h_V)\n",
        "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
        "        if mask_V is not None:\n",
        "            mask_V = mask_V.unsqueeze(-1)\n",
        "            h_V = mask_V * h_V\n",
        "\n",
        "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
        "        h_message = self.W13(self.act(self.W12(self.act(self.W11(h_EV)))))\n",
        "        h_E = self.norm3(h_E + self.dropout3(h_message))\n",
        "        return h_V, h_E\n",
        "\n",
        "\n",
        "class DecLayer(nn.Module):\n",
        "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
        "        super(DecLayer, self).__init__()\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_in = num_in\n",
        "        self.scale = scale\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(num_hidden)\n",
        "        self.norm2 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
        "\n",
        "    def forward(self, h_V, h_E, mask_V=None, mask_attend=None):\n",
        "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
        "\n",
        "        # Concatenate h_V_i to h_E_ij\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_E.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_E], -1)\n",
        "\n",
        "        # Maybe, length of the message vector can serve as attention\n",
        "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
        "        # the mask attend here is most probably just for zeroing out the padded positions\n",
        "        # I do not think it will matter that much\n",
        "        if mask_attend is not None:\n",
        "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
        "            # why divide by 30 when we are dealing with 48 neighbors in the current version of the model?\n",
        "        # Let me check the messages corresponding to \n",
        "        dh = torch.sum(h_message, -2) / self.scale\n",
        "\n",
        "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
        "\n",
        "        # Position-wise feedforward\n",
        "        dh = self.dense(h_V)\n",
        "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
        "\n",
        "        if mask_V is not None:\n",
        "            mask_V = mask_V.unsqueeze(-1)\n",
        "            h_V = mask_V * h_V\n",
        "\n",
        "        # \"h_message\" can be returned without dividing by \"self.scale\" also\n",
        "        return h_V, (h_message/self.scale) \n",
        "\n",
        "\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, num_hidden, num_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.W_in = nn.Linear(num_hidden, num_ff, bias=True)\n",
        "        self.W_out = nn.Linear(num_ff, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "    def forward(self, h_V):\n",
        "        h = self.act(self.W_in(h_V))\n",
        "        h = self.W_out(h)\n",
        "        return h\n",
        "\n",
        "class PositionalEncodings(nn.Module):\n",
        "    def __init__(self, num_embeddings, max_relative_feature=32):\n",
        "        super(PositionalEncodings, self).__init__()\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.max_relative_feature = max_relative_feature\n",
        "        self.linear = nn.Linear(2*max_relative_feature+1+1, num_embeddings)\n",
        "\n",
        "    def forward(self, offset, mask):\n",
        "        d = torch.clip(offset + self.max_relative_feature, 0, 2*self.max_relative_feature)*mask + (1-mask)*(2*self.max_relative_feature+1)\n",
        "        d_onehot = torch.nn.functional.one_hot(d, 2*self.max_relative_feature+1+1)\n",
        "        E = self.linear(d_onehot.float())\n",
        "        return E\n",
        "\n",
        "# Does not look like this function needs to be modified for now to use the model as sort of an energy function\n",
        "# The only thing that could do something is \"top_k\", which can be changed for considering more or less neighbors\n",
        "# for each of the nodes, but that too I think does not matter if the default value of top_k is updated by parameter passing\n",
        "# This function is called from the model itself with node_features=128, edge_features=128, and top_k=48\n",
        "# ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
        "class ProteinFeatures(nn.Module):\n",
        "    def __init__(self, edge_features, node_features, num_positional_embeddings=16,\n",
        "        num_rbf=16, top_k=30, augment_eps=0., num_chain_embeddings=16):\n",
        "        \"\"\" Extract protein features \"\"\"\n",
        "        super(ProteinFeatures, self).__init__()\n",
        "        self.edge_features = edge_features\n",
        "        self.node_features = node_features\n",
        "        self.top_k = top_k\n",
        "        self.augment_eps = augment_eps \n",
        "        self.num_rbf = num_rbf\n",
        "        self.num_positional_embeddings = num_positional_embeddings\n",
        "\n",
        "        self.embeddings = PositionalEncodings(num_positional_embeddings)\n",
        "        node_in, edge_in = 6, num_positional_embeddings + num_rbf*25\n",
        "        self.edge_embedding = nn.Linear(edge_in, edge_features, bias=False)\n",
        "        self.norm_edges = nn.LayerNorm(edge_features)\n",
        "\n",
        "    # the output of this function MUST be analyzed either directly or via some other function to \n",
        "    # understand how to get \"index/position\" of neighbors\n",
        "    def _dist(self, X, mask, eps=1E-6):\n",
        "        mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
        "        dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
        "        D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
        "        D_max, _ = torch.max(D, -1, keepdim=True)\n",
        "        D_adjust = D + (1. - mask_2D) * D_max\n",
        "        sampled_top_k = self.top_k\n",
        "        D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(self.top_k, X.shape[1]), dim=-1, largest=False)\n",
        "        return D_neighbors, E_idx\n",
        "\n",
        "    def _rbf(self, D):\n",
        "        device = D.device\n",
        "        D_min, D_max, D_count = 2., 22., self.num_rbf\n",
        "        D_mu = torch.linspace(D_min, D_max, D_count, device=device)\n",
        "        D_mu = D_mu.view([1,1,1,-1])\n",
        "        D_sigma = (D_max - D_min) / D_count\n",
        "        D_expand = torch.unsqueeze(D, -1)\n",
        "        RBF = torch.exp(-((D_expand - D_mu) / D_sigma)**2)\n",
        "        return RBF\n",
        "\n",
        "    def _get_rbf(self, A, B, E_idx):\n",
        "        D_A_B = torch.sqrt(torch.sum((A[:,:,None,:] - B[:,None,:,:])**2,-1) + 1e-6) #[B, L, L]\n",
        "        D_A_B_neighbors = gather_edges(D_A_B[:,:,:,None], E_idx)[:,:,:,0] #[B,L,K]\n",
        "        RBF_A_B = self._rbf(D_A_B_neighbors)\n",
        "        return RBF_A_B\n",
        "\n",
        "    # this function will be called with the arguments as forward(), but will return information regarding \n",
        "    # the neighbors which I will figure out a way to parse\n",
        "    def return_neighbor_info(self, X, mask, residue_idx, chain_labels):\n",
        "        b = X[:,:,1,:] - X[:,:,0,:]\n",
        "        c = X[:,:,2,:] - X[:,:,1,:]\n",
        "        a = torch.cross(b, c, dim=-1)\n",
        "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "        Ca = X[:,:,1,:]\n",
        "        N = X[:,:,0,:]\n",
        "        C = X[:,:,2,:]\n",
        "        O = X[:,:,3,:]\n",
        " \n",
        "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
        "\n",
        "\n",
        "    def forward(self, X, mask, residue_idx, chain_labels):\n",
        "        if self.augment_eps > 0:\n",
        "            X = X + self.augment_eps * torch.randn_like(X)\n",
        "        \n",
        "        b = X[:,:,1,:] - X[:,:,0,:]\n",
        "        c = X[:,:,2,:] - X[:,:,1,:]\n",
        "        a = torch.cross(b, c, dim=-1)\n",
        "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "        Ca = X[:,:,1,:]\n",
        "        N = X[:,:,0,:]\n",
        "        C = X[:,:,2,:]\n",
        "        O = X[:,:,3,:]\n",
        " \n",
        "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
        "\n",
        "        RBF_all = []\n",
        "        RBF_all.append(self._rbf(D_neighbors)) #Ca-Ca\n",
        "        RBF_all.append(self._get_rbf(N, N, E_idx)) #N-N\n",
        "        RBF_all.append(self._get_rbf(C, C, E_idx)) #C-C\n",
        "        RBF_all.append(self._get_rbf(O, O, E_idx)) #O-O\n",
        "        RBF_all.append(self._get_rbf(Cb, Cb, E_idx)) #Cb-Cb\n",
        "        RBF_all.append(self._get_rbf(Ca, N, E_idx)) #Ca-N\n",
        "        RBF_all.append(self._get_rbf(Ca, C, E_idx)) #Ca-C\n",
        "        RBF_all.append(self._get_rbf(Ca, O, E_idx)) #Ca-O\n",
        "        RBF_all.append(self._get_rbf(Ca, Cb, E_idx)) #Ca-Cb\n",
        "        RBF_all.append(self._get_rbf(N, C, E_idx)) #N-C\n",
        "        RBF_all.append(self._get_rbf(N, O, E_idx)) #N-O\n",
        "        RBF_all.append(self._get_rbf(N, Cb, E_idx)) #N-Cb\n",
        "        RBF_all.append(self._get_rbf(Cb, C, E_idx)) #Cb-C\n",
        "        RBF_all.append(self._get_rbf(Cb, O, E_idx)) #Cb-O\n",
        "        RBF_all.append(self._get_rbf(O, C, E_idx)) #O-C\n",
        "        RBF_all.append(self._get_rbf(N, Ca, E_idx)) #N-Ca\n",
        "        RBF_all.append(self._get_rbf(C, Ca, E_idx)) #C-Ca\n",
        "        RBF_all.append(self._get_rbf(O, Ca, E_idx)) #O-Ca\n",
        "        RBF_all.append(self._get_rbf(Cb, Ca, E_idx)) #Cb-Ca\n",
        "        RBF_all.append(self._get_rbf(C, N, E_idx)) #C-N\n",
        "        RBF_all.append(self._get_rbf(O, N, E_idx)) #O-N\n",
        "        RBF_all.append(self._get_rbf(Cb, N, E_idx)) #Cb-N\n",
        "        RBF_all.append(self._get_rbf(C, Cb, E_idx)) #C-Cb\n",
        "        RBF_all.append(self._get_rbf(O, Cb, E_idx)) #O-Cb\n",
        "        RBF_all.append(self._get_rbf(C, O, E_idx)) #C-O\n",
        "        RBF_all = torch.cat(tuple(RBF_all), dim=-1)\n",
        "\n",
        "        offset = residue_idx[:,:,None]-residue_idx[:,None,:]\n",
        "        offset = gather_edges(offset[:,:,:,None], E_idx)[:,:,:,0] #[B, L, K]\n",
        "\n",
        "        d_chains = ((chain_labels[:, :, None] - chain_labels[:,None,:])==0).long() #find self vs non-self interaction\n",
        "        E_chains = gather_edges(d_chains[:,:,:,None], E_idx)[:,:,:,0]\n",
        "        E_positional = self.embeddings(offset.long(), E_chains)\n",
        "        E = torch.cat((E_positional, RBF_all), -1)\n",
        "        E = self.edge_embedding(E)\n",
        "        E = self.norm_edges(E)\n",
        "        return E, E_idx \n",
        "\n",
        "\n",
        "\n",
        "class ProteinMPNN(nn.Module):\n",
        "    # \"node_features\" and \"edge_features\" are actually dimensionality of these features (\"hidden_dim\" in the calling script)\n",
        "    # the value is 128 for the version that I am using\n",
        "    def __init__(self, num_letters, node_features, edge_features,\n",
        "        hidden_dim, num_encoder_layers=3, num_decoder_layers=3,\n",
        "        vocab=21, k_neighbors=64, augment_eps=0.05, dropout=0.1):\n",
        "        super(ProteinMPNN, self).__init__()\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.node_features = node_features\n",
        "        self.edge_features = edge_features\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Featurization layers\n",
        "        # The version that I am using considers 48 neighbors for each position\n",
        "        self.features = ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
        "\n",
        "        self.W_e = nn.Linear(edge_features, hidden_dim, bias=True)\n",
        "        # This W_s is for embedding the sequence\n",
        "        self.W_s = nn.Embedding(vocab, hidden_dim)\n",
        "\n",
        "        # Encoder layers\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            EncLayer(hidden_dim, hidden_dim*2, dropout=dropout)\n",
        "            for _ in range(num_encoder_layers)\n",
        "        ])\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            DecLayer(hidden_dim, hidden_dim*3, dropout=dropout)\n",
        "            for _ in range(num_decoder_layers)\n",
        "        ])\n",
        "        self.W_out = nn.Linear(hidden_dim, num_letters, bias=True)\n",
        "\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    # Creating my own versions of forward should be an easy way to get embeddings or attention weights from diffrerent layers of the model\n",
        "    # See here (https://discuss.pytorch.org/t/how-can-i-extract-intermediate-layer-output-from-loaded-cnn-model/77301) in the forums for adding forward\n",
        "    # hooks or manipulating the forward method\n",
        "    # but my easy solution would be to create different versions of the forward method with different namaes, and calling them explicitly\n",
        "    # \"chain_M\" and \"mask\" seem to be the things that I need to understand very well and play-around with \n",
        "    def forward(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn, use_input_decoding_order=False, decoding_order=None):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Concatenate sequence embeddings for autoregressive decoder\n",
        "        # h_S denotes embedding of the sequence itself for use in decoder\n",
        "        h_S = self.W_s(S)\n",
        "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "\n",
        "\n",
        "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
        "        if not use_input_decoding_order:\n",
        "            decoding_order = torch.argsort((chain_M+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for layer in self.decoder_layers:\n",
        "            # Masked positions attend to encoder information, unmasked see. \n",
        "            h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "            h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
        "            # only the last layer decoder-messages will be stored in \"decoder_messages\"\n",
        "            h_V, decoder_messages = layer(h_V, h_ESV, mask)\n",
        "\n",
        "        logits = self.W_out(h_V)\n",
        "        # The probabilities are passed through log() function so that the sequences can be ranked based by summing the respective values \n",
        "        # for each position instead of multiplication \n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        # messages from the last layer decoder will also be returned for extracting neighbor-attention approximation\\\n",
        "        # last layer embeddings can be extracted from the \"h_V\" tensor \n",
        "        return log_probs, decoder_messages, h_V\n",
        "\n",
        "\n",
        "\n",
        "    # Seems like this is the method which is used by the notebook for calculating probabilites and scoring\n",
        "    # Need to dig into it thoroughly\n",
        "    # \"chain_mask\" and \"residue_idx\" seem like the tensors of interest\n",
        "    def sample(self, X, randn, S_true, chain_mask, chain_encoding_all, residue_idx, mask=None, temperature=1.0, omit_AAs_np=None, bias_AAs_np=None, chain_M_pos=None, omit_AA_mask=None, pssm_coef=None, pssm_bias=None, pssm_multi=None, pssm_log_odds_flag=None, pssm_log_odds_mask=None, pssm_bias_flag=None, bias_by_res=None):\n",
        "        device = X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Decoder uses masked self-attention\n",
        "        chain_mask = chain_mask*chain_M_pos*mask #update chain_M to include missing regions\n",
        "        decoding_order = torch.argsort((chain_mask+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        N_batch, N_nodes = X.size(0), X.size(1)\n",
        "        log_probs = torch.zeros((N_batch, N_nodes, 21), device=device)\n",
        "        all_probs = torch.zeros((N_batch, N_nodes, 21), device=device, dtype=torch.float32)\n",
        "        h_S = torch.zeros_like(h_V, device=device)\n",
        "        S = torch.zeros((N_batch, N_nodes), dtype=torch.int64, device=device)\n",
        "        h_V_stack = [h_V] + [torch.zeros_like(h_V, device=device) for _ in range(len(self.decoder_layers))]\n",
        "        constant = torch.tensor(omit_AAs_np, device=device)\n",
        "        constant_bias = torch.tensor(bias_AAs_np, device=device)\n",
        "        #chain_mask_combined = chain_mask*chain_M_pos \n",
        "        omit_AA_mask_flag = omit_AA_mask != None\n",
        "\n",
        "\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for t_ in range(N_nodes):\n",
        "            t = decoding_order[:,t_] #[B]\n",
        "            chain_mask_gathered = torch.gather(chain_mask, 1, t[:,None]) #[B]\n",
        "            bias_by_res_gathered = torch.gather(bias_by_res, 1, t[:,None,None].repeat(1,1,21))[:,0,:] #[B, 21]\n",
        "            if (chain_mask_gathered==0).all():\n",
        "                S_t = torch.gather(S_true, 1, t[:,None])\n",
        "            else:\n",
        "                # Hidden layers\n",
        "                E_idx_t = torch.gather(E_idx, 1, t[:,None,None].repeat(1,1,E_idx.shape[-1]))\n",
        "                h_E_t = torch.gather(h_E, 1, t[:,None,None,None].repeat(1,1,h_E.shape[-2], h_E.shape[-1]))\n",
        "                h_ES_t = cat_neighbors_nodes(h_S, h_E_t, E_idx_t)\n",
        "                h_EXV_encoder_t = torch.gather(h_EXV_encoder_fw, 1, t[:,None,None,None].repeat(1,1,h_EXV_encoder_fw.shape[-2], h_EXV_encoder_fw.shape[-1]))\n",
        "                mask_t = torch.gather(mask, 1, t[:,None])\n",
        "                for l, layer in enumerate(self.decoder_layers):\n",
        "                    # Updated relational features for future states\n",
        "                    h_ESV_decoder_t = cat_neighbors_nodes(h_V_stack[l], h_ES_t, E_idx_t)\n",
        "                    h_V_t = torch.gather(h_V_stack[l], 1, t[:,None,None].repeat(1,1,h_V_stack[l].shape[-1]))\n",
        "                    h_ESV_t = torch.gather(mask_bw, 1, t[:,None,None,None].repeat(1,1,mask_bw.shape[-2], mask_bw.shape[-1])) * h_ESV_decoder_t + h_EXV_encoder_t\n",
        "                    h_V_stack[l+1].scatter_(1, t[:,None,None].repeat(1,1,h_V.shape[-1]), layer(h_V_t, h_ESV_t, mask_V=mask_t))\n",
        "                # Sampling step\n",
        "                h_V_t = torch.gather(h_V_stack[-1], 1, t[:,None,None].repeat(1,1,h_V_stack[-1].shape[-1]))[:,0]\n",
        "                logits = self.W_out(h_V_t) / temperature\n",
        "                probs = F.softmax(logits-constant[None,:]*1e8+constant_bias[None,:]/temperature+bias_by_res_gathered/temperature, dim=-1)\n",
        "                if pssm_bias_flag:\n",
        "                    pssm_coef_gathered = torch.gather(pssm_coef, 1, t[:,None])[:,0]\n",
        "                    pssm_bias_gathered = torch.gather(pssm_bias, 1, t[:,None,None].repeat(1,1,pssm_bias.shape[-1]))[:,0]\n",
        "                    probs = (1-pssm_multi*pssm_coef_gathered[:,None])*probs + pssm_multi*pssm_coef_gathered[:,None]*pssm_bias_gathered\n",
        "                if pssm_log_odds_flag:\n",
        "                    pssm_log_odds_mask_gathered = torch.gather(pssm_log_odds_mask, 1, t[:,None, None].repeat(1,1,pssm_log_odds_mask.shape[-1]))[:,0] #[B, 21]\n",
        "                    probs_masked = probs*pssm_log_odds_mask_gathered\n",
        "                    probs_masked += probs * 0.001\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                if omit_AA_mask_flag:\n",
        "                    omit_AA_mask_gathered = torch.gather(omit_AA_mask, 1, t[:,None, None].repeat(1,1,omit_AA_mask.shape[-1]))[:,0] #[B, 21]\n",
        "                    probs_masked = probs*(1.0-omit_AA_mask_gathered)\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                # Here is where sampling from the multinomial distribution is happening\n",
        "                # this will sample 1 element according to the given distribution, and return the index of that element [from 0 to 20]\n",
        "                S_t = torch.multinomial(probs, 1)\n",
        "                all_probs.scatter_(1, t[:,None,None].repeat(1,1,21), (chain_mask_gathered[:,:,None,]*probs[:,None,:]).float())\n",
        "            S_true_gathered = torch.gather(S_true, 1, t[:,None])\n",
        "            S_t = (S_t*chain_mask_gathered+S_true_gathered*(1.0-chain_mask_gathered)).long()\n",
        "            temp1 = self.W_s(S_t)\n",
        "            h_S.scatter_(1, t[:,None,None].repeat(1,1,temp1.shape[-1]), temp1)\n",
        "            S.scatter_(1, t[:,None], S_t)\n",
        "        output_dict = {\"S\": S, \"probs\": all_probs, \"decoding_order\": decoding_order}\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "    def tied_sample(self, X, randn, S_true, chain_mask, chain_encoding_all, residue_idx, mask=None, temperature=1.0, omit_AAs_np=None, bias_AAs_np=None, chain_M_pos=None, omit_AA_mask=None, pssm_coef=None, pssm_bias=None, pssm_multi=None, pssm_log_odds_flag=None, pssm_log_odds_mask=None, pssm_bias_flag=None, tied_pos=None, tied_beta=None, bias_by_res=None):\n",
        "        device = X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=device)\n",
        "        h_E = self.W_e(E)\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Decoder uses masked self-attention\n",
        "        chain_mask = chain_mask*chain_M_pos*mask #update chain_M to include missing regions\n",
        "        decoding_order = torch.argsort((chain_mask+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "\n",
        "        new_decoding_order = []\n",
        "        for t_dec in list(decoding_order[0,].cpu().data.numpy()):\n",
        "            if t_dec not in list(itertools.chain(*new_decoding_order)):\n",
        "                list_a = [item for item in tied_pos if t_dec in item]\n",
        "                if list_a:\n",
        "                    new_decoding_order.append(list_a[0])\n",
        "                else:\n",
        "                    new_decoding_order.append([t_dec])\n",
        "        decoding_order = torch.tensor(list(itertools.chain(*new_decoding_order)), device=device)[None,].repeat(X.shape[0],1)\n",
        "\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        N_batch, N_nodes = X.size(0), X.size(1)\n",
        "        log_probs = torch.zeros((N_batch, N_nodes, 21), device=device)\n",
        "        all_probs = torch.zeros((N_batch, N_nodes, 21), device=device, dtype=torch.float32)\n",
        "        h_S = torch.zeros_like(h_V, device=device)\n",
        "        S = torch.zeros((N_batch, N_nodes), dtype=torch.int64, device=device)\n",
        "        h_V_stack = [h_V] + [torch.zeros_like(h_V, device=device) for _ in range(len(self.decoder_layers))]\n",
        "        constant = torch.tensor(omit_AAs_np, device=device)\n",
        "        constant_bias = torch.tensor(bias_AAs_np, device=device)\n",
        "        omit_AA_mask_flag = omit_AA_mask != None\n",
        "\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for t_list in new_decoding_order:\n",
        "            logits = 0.0\n",
        "            logit_list = []\n",
        "            done_flag = False\n",
        "            for t in t_list:\n",
        "                if (chain_mask[:,t]==0).all():\n",
        "                    S_t = S_true[:,t]\n",
        "                    for t in t_list:\n",
        "                        h_S[:,t,:] = self.W_s(S_t)\n",
        "                        S[:,t] = S_t\n",
        "                    done_flag = True\n",
        "                    break\n",
        "                else:\n",
        "                    E_idx_t = E_idx[:,t:t+1,:]\n",
        "                    h_E_t = h_E[:,t:t+1,:,:]\n",
        "                    h_ES_t = cat_neighbors_nodes(h_S, h_E_t, E_idx_t)\n",
        "                    h_EXV_encoder_t = h_EXV_encoder_fw[:,t:t+1,:,:]\n",
        "                    mask_t = mask[:,t:t+1]\n",
        "                    for l, layer in enumerate(self.decoder_layers):\n",
        "                        h_ESV_decoder_t = cat_neighbors_nodes(h_V_stack[l], h_ES_t, E_idx_t)\n",
        "                        h_V_t = h_V_stack[l][:,t:t+1,:]\n",
        "                        h_ESV_t = mask_bw[:,t:t+1,:,:] * h_ESV_decoder_t + h_EXV_encoder_t\n",
        "                        h_V_stack[l+1][:,t,:] = layer(h_V_t, h_ESV_t, mask_V=mask_t).squeeze(1)\n",
        "                    h_V_t = h_V_stack[-1][:,t,:]\n",
        "                    logit_list.append((self.W_out(h_V_t) / temperature)/len(t_list))\n",
        "                    logits += tied_beta[t]*(self.W_out(h_V_t) / temperature)/len(t_list)\n",
        "            if done_flag:\n",
        "                pass\n",
        "            else:\n",
        "                bias_by_res_gathered = bias_by_res[:,t,:] #[B, 21]\n",
        "                probs = F.softmax(logits-constant[None,:]*1e8+constant_bias[None,:]/temperature+bias_by_res_gathered/temperature, dim=-1)\n",
        "                if pssm_bias_flag:\n",
        "                    pssm_coef_gathered = pssm_coef[:,t]\n",
        "                    pssm_bias_gathered = pssm_bias[:,t]\n",
        "                    probs = (1-pssm_multi*pssm_coef_gathered[:,None])*probs + pssm_multi*pssm_coef_gathered[:,None]*pssm_bias_gathered\n",
        "                if pssm_log_odds_flag:\n",
        "                    pssm_log_odds_mask_gathered = pssm_log_odds_mask[:,t]\n",
        "                    probs_masked = probs*pssm_log_odds_mask_gathered\n",
        "                    probs_masked += probs * 0.001\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                if omit_AA_mask_flag:\n",
        "                    omit_AA_mask_gathered = omit_AA_mask[:,t]\n",
        "                    probs_masked = probs*(1.0-omit_AA_mask_gathered)\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                S_t_repeat = torch.multinomial(probs, 1).squeeze(-1)\n",
        "                for t in t_list:\n",
        "                    h_S[:,t,:] = self.W_s(S_t_repeat)\n",
        "                    S[:,t] = S_t_repeat\n",
        "                    all_probs[:,t,:] = probs.float()\n",
        "        output_dict = {\"S\": S, \"probs\": all_probs, \"decoding_order\": decoding_order}\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "    # I am not seeing an immediate use of this method when the model is called through notebook\n",
        "    # So, will skip further commenting and digging for now\n",
        "    # But, seems like an interesting way of interacting with the model in a specific way, so\n",
        "    # might get back to this later\n",
        "    def conditional_probs(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn, backbone_only=False):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V_enc = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V_enc, h_E = layer(h_V_enc, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Concatenate sequence embeddings for autoregressive decoder\n",
        "        h_S = self.W_s(S)\n",
        "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V_enc, h_EX_encoder, E_idx)\n",
        "\n",
        "\n",
        "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
        "  \n",
        "        chain_M_np = chain_M.cpu().numpy()\n",
        "        idx_to_loop = np.argwhere(chain_M_np[0,:]==1)[:,0]\n",
        "        log_conditional_probs = torch.zeros([X.shape[0], chain_M.shape[1], 21], device=device).float()\n",
        "\n",
        "        for idx in idx_to_loop:\n",
        "            h_V = torch.clone(h_V_enc)\n",
        "            order_mask = torch.zeros(chain_M.shape[1], device=device).float()\n",
        "            if backbone_only:\n",
        "                order_mask = torch.ones(chain_M.shape[1], device=device).float()\n",
        "                order_mask[idx] = 0.\n",
        "            else:\n",
        "                order_mask = torch.zeros(chain_M.shape[1], device=device).float()\n",
        "                order_mask[idx] = 1.\n",
        "            decoding_order = torch.argsort((order_mask[None,]+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "            mask_size = E_idx.shape[1]\n",
        "            permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "            order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "            mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "            mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "            mask_bw = mask_1D * mask_attend\n",
        "            mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "            h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "            for layer in self.decoder_layers:\n",
        "                # Masked positions attend to encoder information, unmasked see. \n",
        "                h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "                h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
        "                h_V = layer(h_V, h_ESV, mask)\n",
        "\n",
        "            logits = self.W_out(h_V)\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "            log_conditional_probs[:,idx,:] = log_probs[:,idx,:]\n",
        "        return log_conditional_probs\n",
        "\n",
        "\n",
        "    # I am not seeing an immediate use of this method when the model is called through notebook\n",
        "    # So, will skip further commenting and digging for now\n",
        "    # But, seems like an interesting way of interacting with the model in a specific way, so\n",
        "    # might get back to this later\n",
        "    def unconditional_probs(self, X, mask, residue_idx, chain_encoding_all):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_V), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "\n",
        "        order_mask_backward = torch.zeros([X.shape[0], X.shape[1], X.shape[1]], device=device)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for layer in self.decoder_layers:\n",
        "            h_V = layer(h_V, h_EXV_encoder_fw, mask)\n",
        "\n",
        "        logits = self.W_out(h_V)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        return log_probs"
      ],
      "metadata": {
        "id": "HjbVWJkg7zik"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 128\n",
        "num_layers = 3 \n",
        "# Seems like, backbone_noise is set to 0 at inference path which seems logical\n",
        "backbone_noise=0.00\n",
        "mpnn_model = ProteinMPNN(num_letters=21, node_features=hidden_dim, edge_features=hidden_dim, hidden_dim=hidden_dim, num_encoder_layers=num_layers, num_decoder_layers=num_layers, augment_eps=backbone_noise, k_neighbors=checkpoint['num_edges'])\n",
        "mpnn_model.to(device)\n",
        "mpnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "mpnn_model.eval()"
      ],
      "metadata": {
        "id": "QBgBJd3J0N_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint['model_state_dict'].keys()) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pYLpMQS-ill",
        "outputId": "c454bccb-d0e4-4fb3-baa7-a892ebcf55a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['features.embeddings.linear.weight', 'features.embeddings.linear.bias', 'features.edge_embedding.weight', 'features.norm_edges.weight', 'features.norm_edges.bias', 'W_e.weight', 'W_e.bias', 'W_s.weight', 'encoder_layers.0.norm1.weight', 'encoder_layers.0.norm1.bias', 'encoder_layers.0.norm2.weight', 'encoder_layers.0.norm2.bias', 'encoder_layers.0.norm3.weight', 'encoder_layers.0.norm3.bias', 'encoder_layers.0.W1.weight', 'encoder_layers.0.W1.bias', 'encoder_layers.0.W2.weight', 'encoder_layers.0.W2.bias', 'encoder_layers.0.W3.weight', 'encoder_layers.0.W3.bias', 'encoder_layers.0.W11.weight', 'encoder_layers.0.W11.bias', 'encoder_layers.0.W12.weight', 'encoder_layers.0.W12.bias', 'encoder_layers.0.W13.weight', 'encoder_layers.0.W13.bias', 'encoder_layers.0.dense.W_in.weight', 'encoder_layers.0.dense.W_in.bias', 'encoder_layers.0.dense.W_out.weight', 'encoder_layers.0.dense.W_out.bias', 'encoder_layers.1.norm1.weight', 'encoder_layers.1.norm1.bias', 'encoder_layers.1.norm2.weight', 'encoder_layers.1.norm2.bias', 'encoder_layers.1.norm3.weight', 'encoder_layers.1.norm3.bias', 'encoder_layers.1.W1.weight', 'encoder_layers.1.W1.bias', 'encoder_layers.1.W2.weight', 'encoder_layers.1.W2.bias', 'encoder_layers.1.W3.weight', 'encoder_layers.1.W3.bias', 'encoder_layers.1.W11.weight', 'encoder_layers.1.W11.bias', 'encoder_layers.1.W12.weight', 'encoder_layers.1.W12.bias', 'encoder_layers.1.W13.weight', 'encoder_layers.1.W13.bias', 'encoder_layers.1.dense.W_in.weight', 'encoder_layers.1.dense.W_in.bias', 'encoder_layers.1.dense.W_out.weight', 'encoder_layers.1.dense.W_out.bias', 'encoder_layers.2.norm1.weight', 'encoder_layers.2.norm1.bias', 'encoder_layers.2.norm2.weight', 'encoder_layers.2.norm2.bias', 'encoder_layers.2.norm3.weight', 'encoder_layers.2.norm3.bias', 'encoder_layers.2.W1.weight', 'encoder_layers.2.W1.bias', 'encoder_layers.2.W2.weight', 'encoder_layers.2.W2.bias', 'encoder_layers.2.W3.weight', 'encoder_layers.2.W3.bias', 'encoder_layers.2.W11.weight', 'encoder_layers.2.W11.bias', 'encoder_layers.2.W12.weight', 'encoder_layers.2.W12.bias', 'encoder_layers.2.W13.weight', 'encoder_layers.2.W13.bias', 'encoder_layers.2.dense.W_in.weight', 'encoder_layers.2.dense.W_in.bias', 'encoder_layers.2.dense.W_out.weight', 'encoder_layers.2.dense.W_out.bias', 'decoder_layers.0.norm1.weight', 'decoder_layers.0.norm1.bias', 'decoder_layers.0.norm2.weight', 'decoder_layers.0.norm2.bias', 'decoder_layers.0.W1.weight', 'decoder_layers.0.W1.bias', 'decoder_layers.0.W2.weight', 'decoder_layers.0.W2.bias', 'decoder_layers.0.W3.weight', 'decoder_layers.0.W3.bias', 'decoder_layers.0.dense.W_in.weight', 'decoder_layers.0.dense.W_in.bias', 'decoder_layers.0.dense.W_out.weight', 'decoder_layers.0.dense.W_out.bias', 'decoder_layers.1.norm1.weight', 'decoder_layers.1.norm1.bias', 'decoder_layers.1.norm2.weight', 'decoder_layers.1.norm2.bias', 'decoder_layers.1.W1.weight', 'decoder_layers.1.W1.bias', 'decoder_layers.1.W2.weight', 'decoder_layers.1.W2.bias', 'decoder_layers.1.W3.weight', 'decoder_layers.1.W3.bias', 'decoder_layers.1.dense.W_in.weight', 'decoder_layers.1.dense.W_in.bias', 'decoder_layers.1.dense.W_out.weight', 'decoder_layers.1.dense.W_out.bias', 'decoder_layers.2.norm1.weight', 'decoder_layers.2.norm1.bias', 'decoder_layers.2.norm2.weight', 'decoder_layers.2.norm2.bias', 'decoder_layers.2.W1.weight', 'decoder_layers.2.W1.bias', 'decoder_layers.2.W2.weight', 'decoder_layers.2.W2.bias', 'decoder_layers.2.W3.weight', 'decoder_layers.2.W3.bias', 'decoder_layers.2.dense.W_in.weight', 'decoder_layers.2.dense.W_in.bias', 'decoder_layers.2.dense.W_out.weight', 'decoder_layers.2.dense.W_out.bias', 'W_out.weight', 'W_out.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse and create dictionaries for all the mutations in PremPS 2648\n",
        "# This dictionary will be a dictionary of dictionaries, where outer-dict keys will be pdbid+mutchain and inner-dict keys will be (wild+pos+mut) and ddg\n",
        "# the icodes can be brought to picture later\n",
        "# this \"two_level_dict\" is literally used everywhere throughout this code for storing all the numbers that are compared with each other under feature-specific keys\n",
        "git_url = \"https://raw.githubusercontent.com/SajidAhmeduiu/PremPS/main/Datasets/Eight%20test%20sets/Ssym.txt\"\n",
        "dataset =  pd.read_csv(git_url,delimiter=\"\\t\")\n",
        "\n",
        "pdbIds = list(dataset[\"PDB Id\"])\n",
        "mutChains = list(dataset[\"Mutated Chain\"])\n",
        "mutations = list(dataset[\"Mutation_PDB\"])\n",
        "ddgs = list(dataset[\"DDGexp\"])\n",
        "labels = list(dataset[\"Label\"])\n",
        "\n",
        "two_level_dict = {}\n",
        "\n",
        "for pdbId, mutChain, mutation, ddg, label in tqdm(zip(pdbIds,mutChains,mutations,ddgs,labels)):\n",
        "    # Taking forward mutations only since taking both forward and reverse inflates correlation\n",
        "    # we do not need to consider reverse mutations for now since our non-machine learning method is symmetric by default since the features can be directly sign flipped for reverse mutations\n",
        "    if \"forward\" in label:\n",
        "        pos = [int(s) for s in re.findall('-?\\d+',mutation)][0]\n",
        "        wild = mutation[0]\n",
        "        mut = mutation[len(mutation)-1]\n",
        "\n",
        "        pdbId = pdbId.lower()\n",
        "\n",
        "        inner_dict = {}\n",
        "        inner_dict[\"mut\"] = f\"{wild}{pos}{mut}\"\n",
        "        inner_dict[\"ddg\"] = float(ddg)\n",
        "        outer_key = f\"{pdbId}{mutChain}\"\n",
        "        if outer_key not in two_level_dict:\n",
        "            two_level_dict[f\"{pdbId}{mutChain}\"] = [inner_dict]\n",
        "        else:\n",
        "            two_level_dict[f\"{pdbId}{mutChain}\"].append(inner_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "332971040f5744458c087c14286b34ac",
            "837ebdb482384a25806f956a96f36f2b",
            "b35a3767e7cc4d1c956595e81614df14",
            "f3a67765216345dbb0c4884563619ccb",
            "a6cb95a73bd3450184f0dcbcd0626585",
            "088a2146c3b04eb28f86a6f2a654b80d",
            "351a28972c1c4e1bb4af837af3e01e98",
            "13b6090fbf6a4b098ef059b6ace049f1",
            "69423e46b3874c81a9cd0c36efc7755e",
            "5a0e46bcbfd34d1daf558937a9fe7c16",
            "63cc47990fa54997b8e41329c3000de5"
          ]
        },
        "id": "vP_unq7_sXrn",
        "outputId": "6f054eaf-b7e3-4f59-aba4-13deb6de25f6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "332971040f5744458c087c14286b34ac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a seqres to position mapping dictionary\n",
        "# This dictionary will be a dictionary of dictionaries, where outer-dict keys will be pdbid+mutchain and inner-dict key will be (wild+pos) and value of 0-indexed position\n",
        "# the icodes can be brought to picture later\n",
        "mapping_dict = {}\n",
        "pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/Ssym_PDB_Files\"\n",
        "parser = PDBParser(QUIET=True)\n",
        "# some proteins need to be skipped for now due to ICODE related discrapency\n",
        "proteins_to_skip = []\n",
        "\n",
        "for filename in tqdm(os.listdir(pdbDirectory)):\n",
        "    filepath = os.path.join(pdbDirectory,filename)\n",
        "    structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "    model = structure[0]\n",
        "    inner_dict = {}\n",
        "    outer_key = filename.split(\".\")[0]\n",
        "    skip_flag = False\n",
        "    # single chain-assumption in action again\n",
        "    for chain in model:\n",
        "        for i,residue in enumerate(chain):\n",
        "            inner_key = f\"{three_to_one(residue.get_resname())}{residue.get_id()[1]}\"\n",
        "            if inner_key not in inner_dict:\n",
        "                inner_dict[inner_key] = i\n",
        "            else:\n",
        "                # For \"2immA:N31\" and \"1lveA:S27\", I have been fucked\n",
        "                # Need to think whether this will effect other positions or I can just avoid these two-protein related mutations for now?\n",
        "                # Let me just avoid these two proteins for now\n",
        "                print(\"YOU HAVE JUST BEEN FUCKED BY ICODE\")\n",
        "                print(f\"{outer_key}:{inner_key}\")\n",
        "                skip_flag = True\n",
        "    # The ICODE related problematic proteins will not be considered for now\n",
        "    if not skip_flag:\n",
        "        mapping_dict[outer_key] = inner_dict\n",
        "    else:\n",
        "        proteins_to_skip.append(outer_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "32aa3ea6c4c549c492cc4f8c7e719de4",
            "50598242e3d4428a9a17564a8fe38071",
            "ac1b41ae62b14c89bcdf538ab7723621",
            "c50a30ae7f514065a8797ce71f605164",
            "98c8d4c4a1c54b8eb2141cfaeb8f6f27",
            "a747e06d4c47437e926c724ff77d66b9",
            "0aace9f11ba34a5da8e1e74a0a555f00",
            "1b6e942fb66546dd8181e2e5434962ba",
            "c2c9880c0d024faba037892fc0351d8f",
            "837803589c264aa6a2c6bd1312224ccf",
            "a02b54c3cc2c4395b6b2ce18dd7c6192"
          ]
        },
        "id": "vxARThyX3VYv",
        "outputId": "bcf34cd3-7002-483f-bb7e-898fb99959aa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/357 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32aa3ea6c4c549c492cc4f8c7e719de4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing this \"parse_PDB_biounits()\" function locally for addressing the fucked up integer named chain problem  \n",
        "def parse_PDB_biounits(x, atoms=['N', 'CA', 'C'], chain=None):\n",
        "    '''\n",
        "    input:  x = PDB filename\n",
        "            atoms = atoms to extract (optional)\n",
        "    output: (length, atoms, coords=(x,y,z)), sequence\n",
        "    '''\n",
        "    alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "    states = len(alpha_1)\n",
        "    alpha_3 = ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE',\n",
        "               'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL', 'GAP']\n",
        "\n",
        "    # The following dictionaries are mapping from one-letter to 0-20 index,\n",
        "    # three-letter to 0-20 index,\n",
        "    # 0-20 index to one-letter,\n",
        "    # one-letter to three-letter, and vice-versa\n",
        "    aa_1_N = {a: n for n, a in enumerate(alpha_1)}\n",
        "    aa_3_N = {a: n for n, a in enumerate(alpha_3)}\n",
        "    aa_N_1 = {n: a for n, a in enumerate(alpha_1)}\n",
        "    aa_1_3 = {a: b for a, b in zip(alpha_1, alpha_3)}\n",
        "    aa_3_1 = {b: a for a, b in zip(alpha_1, alpha_3)}\n",
        "\n",
        "    def AA_to_N(x):\n",
        "        # [\"ARND\"] -> [[0,1,2,3]]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 0: x = x[None]\n",
        "        return [[aa_1_N.get(a, states - 1) for a in y] for y in x]\n",
        "\n",
        "    def N_to_AA(x):\n",
        "        # [[0,1,2,3]] -> [\"ARND\"]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 1: x = x[None]\n",
        "        return [\"\".join([aa_N_1.get(a, \"-\") for a in y]) for y in x]\n",
        "\n",
        "    xyz, seq, min_resn, max_resn = {}, {}, 1e6, -1e6\n",
        "    for line in open(x, \"rb\"):\n",
        "        line = line.decode(\"utf-8\", \"ignore\").rstrip()\n",
        "\n",
        "        if line[:6] == \"HETATM\" and line[17:17 + 3] == \"MSE\":\n",
        "            line = line.replace(\"HETATM\", \"ATOM  \")\n",
        "            line = line.replace(\"MSE\", \"MET\")\n",
        "\n",
        "        if line[:4] == \"ATOM\":\n",
        "            ch = line[21:22]\n",
        "            # If the input chain is not in the PDB file, which can be the case if the target chains are named differently in the runner script,\n",
        "            # this line will cause the output to have literally no information, this is the case for integer named chains\n",
        "            # that does not mean that this line is not doing its job correctly, this is just a constraint that input chain names and\n",
        "            # chain names in the PDB file have to be congruent\n",
        "            # If \"ch\" is an integer, map it to alphabet, because input \"chain\" has been converted to alphabet\n",
        "            # In rare cases, some PDB files number chains with 1,2,3 instead of A,B,C\n",
        "            # This \"loc_dict\" dictionary contains integer to alphabet mapping for weird as fuck integer chain names\n",
        "            # This conversion will be done only when  chain name is actually an integer\n",
        "            if ord(ch) >= 49 and ord(ch) <= 57:\n",
        "                loc_dict = {(idx+1):ch for idx,ch in enumerate(ascii_uppercase)}\n",
        "                ch =  str(loc_dict[int(ch)])\n",
        "            if ch == chain or chain is None:\n",
        "                atom = line[12:12 + 4].strip()\n",
        "                resi = line[17:17 + 3]\n",
        "                resn = line[22:22 + 5].strip()\n",
        "                x, y, z = [float(line[i:(i + 8)]) for i in [30, 38, 46]]\n",
        "\n",
        "                if resn[-1].isalpha():\n",
        "                    resa, resn = resn[-1], int(resn[:-1]) - 1\n",
        "                else:\n",
        "                    resa, resn = \"\", int(resn) - 1\n",
        "                #         resn = int(resn)\n",
        "                if resn < min_resn:\n",
        "                    min_resn = resn\n",
        "                if resn > max_resn:\n",
        "                    max_resn = resn\n",
        "                if resn not in xyz:\n",
        "                    xyz[resn] = {}\n",
        "                if resa not in xyz[resn]:\n",
        "                    xyz[resn][resa] = {}\n",
        "                if resn not in seq:\n",
        "                    seq[resn] = {}\n",
        "                if resa not in seq[resn]:\n",
        "                    seq[resn][resa] = resi\n",
        "\n",
        "                if atom not in xyz[resn][resa]:\n",
        "                    xyz[resn][resa][atom] = np.array([x, y, z])\n",
        "\n",
        "    # convert to numpy arrays, fill in missing values\n",
        "    seq_, xyz_ = [], []\n",
        "    try:\n",
        "        for resn in range(min_resn, max_resn + 1):\n",
        "            if resn in seq:\n",
        "                for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k], 20))\n",
        "            else:\n",
        "                seq_.append(20)\n",
        "            if resn in xyz:\n",
        "                for k in sorted(xyz[resn]):\n",
        "                    for atom in atoms:\n",
        "                        if atom in xyz[resn][k]:\n",
        "                            xyz_.append(xyz[resn][k][atom])\n",
        "                        else:\n",
        "                            xyz_.append(np.full(3, np.nan))\n",
        "            else:\n",
        "                for atom in atoms: xyz_.append(np.full(3, np.nan))\n",
        "        return np.array(xyz_).reshape(-1, len(atoms), 3), N_to_AA(np.array(seq_))\n",
        "    except TypeError:\n",
        "        return 'no_chain', 'no_chain'\n",
        "\n",
        "# Took this part out of \"utils.py\", and put here so that smalll changes can be made to address pesky issues like\n",
        "# integer named chain, and shit like those\n",
        "def parse_PDB(path_to_pdb, input_chain_list=None):\n",
        "    c=0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V','W','X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v','w','x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "     \n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list  \n",
        " \n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    # Each of the biounits is a separate PDB file, so for running with a single PDB file like from colab, this loop will be executed only once\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {} \n",
        "        # This loop will be executed only once for single chain DDG type cases\n",
        "        for letter in chain_alphabet:\n",
        "            xyz, seq = parse_PDB_biounits(biounit, atoms=['N','CA','C','O'], chain=letter)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_'+letter]=seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                coords_dict_chain['N_chain_'+letter]=xyz[:,0,:].tolist()\n",
        "                coords_dict_chain['CA_chain_'+letter]=xyz[:,1,:].tolist()\n",
        "                coords_dict_chain['C_chain_'+letter]=xyz[:,2,:].tolist()\n",
        "                coords_dict_chain['O_chain_'+letter]=xyz[:,3,:].tolist()\n",
        "                my_dict['coords_chain_'+letter]=coords_dict_chain\n",
        "                s += 1\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        my_dict['name']=biounit[(fi+1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c+=1\n",
        "    return pdb_dict_list"
      ],
      "metadata": {
        "id": "UzBk27pmlfh7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_func_local(X, mask, eps=1E-6):\n",
        "    mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
        "    dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
        "    D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
        "    D_max, _ = torch.max(D, -1, keepdim=True)\n",
        "    D_adjust = D + (1. - mask_2D) * D_max\n",
        "    top_k = checkpoint[\"num_edges\"]\n",
        "    sampled_top_k = top_k\n",
        "    D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(top_k, X.shape[1]), dim=-1, largest=False)\n",
        "    return D_neighbors, E_idx\n",
        "\n",
        "def return_neighbor_info(X, mask):\n",
        "    b = X[:,:,1,:] - X[:,:,0,:]\n",
        "    c = X[:,:,2,:] - X[:,:,1,:]\n",
        "    a = torch.cross(b, c, dim=-1)\n",
        "    Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "    Ca = X[:,:,1,:]\n",
        "    N = X[:,:,0,:]\n",
        "    C = X[:,:,2,:]\n",
        "    O = X[:,:,3,:]\n",
        "\n",
        "    D_neighbors, E_idx = distance_func_local(Ca, mask)\n",
        "    # Got the indices of the neighbors, E_idx should be the 0-based indexing of the topK closest neighbors\n",
        "    # and D_neighbors should be the distances of those neighbors\n",
        "    return D_neighbors, E_idx"
      ],
      "metadata": {
        "id": "l6pA80oESa7Y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "from scipy.special import kl_div"
      ],
      "metadata": {
        "id": "5mFg99eN_UqM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the PDB files from the directory where the S_2648 PDB Files are stored, and set-them up one by one for featuirization, and passing through the model\n",
        "pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/Ssym_PDB_Files\"\n",
        "parser = PDBParser(QUIET=True)\n",
        "\n",
        "pdbId_info = []\n",
        "pos_info = []\n",
        "neighbor_pos = []\n",
        "neighbor_attention = []\n",
        "neighbor_attention_softmaxed = []\n",
        "neighbor_distances_tracking = []\n",
        "\n",
        "import time\n",
        "\n",
        "np.set_printoptions(suppress=True,precision=2)\n",
        "loc_proteins = []\n",
        "for i,filename in tqdm(enumerate(os.listdir(pdbDirectory))):\n",
        "    #ICODE related problematic proteins will be skipped from analysis for now\n",
        "    if (filename.split(\".\")[0] not in proteins_to_skip) and (filename.split(\".\")[0] in two_level_dict):\n",
        "        prot_start = time.time()\n",
        "        print(f\"Prot Processing:{i+1}\")\n",
        "        loc_proteins.append(filename.split(\".\")[0])\n",
        "        filepath = os.path.join(pdbDirectory,filename)\n",
        "        structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "        model = structure[0]\n",
        "        \n",
        "        # Since there is only one chain, and that same chain is both fixed designable for different residues, extracting that name, and putting them in pertinent lists\n",
        "        # taking chainname from filename since one of the files \"1rtpA.pdb\" has chain name with \"1\" instead of \"A\"\n",
        "        # fuck you motherfucking fucked up PDB file submitter. Have you shoved your head into your ass?\n",
        "        chain_name = (filename.split(\".\")[0])[-1]\n",
        "        fixed_chain_list = []\n",
        "        # the trick is to put the single chain as designable chain, and then create the \"fixed_positions_dict\" dictionary  \n",
        "        designed_chain_list = [chain_name]\n",
        "        chain_list = list(set(designed_chain_list + fixed_chain_list))\n",
        "\n",
        "        # Using the programs custome PDB parser for processing the PDB files\n",
        "        pdb_dict_list = parse_PDB(filepath, input_chain_list=chain_list)\n",
        "        # tacking max_length parameter value from the original colab notebook since I need to process all residues at the same time\n",
        "        # all the PDB files can technically be processed together and put inside the dataset_valid list-like object, but right now\n",
        "        # I am trying to keep everything consistent and simple\n",
        "        # Each element of dataset_valid is a dictionary \n",
        "        dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=20000)\n",
        "\n",
        "        # Simplying the sequence generation loop\n",
        "        protein = dataset_valid[0]\n",
        "\n",
        "        wildtype_seq = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        # If there are gaps in the wildtype_seq \"seq\", remove those positions from both the \"seq\", \"\" and ('coords_chain_{designed_chain_list[0]}'), \n",
        "        # and ('seq_chain_{designed_chain_list[0]}') of the \"protein\"\n",
        "        # print(protein.keys())\n",
        "        # protein is a dict with keys(['seq_chain_A', 'coords_chain_A', 'name', 'num_of_chains', 'seq'])\n",
        "        # \"seq_chain\" and \"seq_all\" are both strings of the same length where gapped positions need to be identified and removed\n",
        "        seq_chain = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "        seq_all = protein[f\"seq\"]\n",
        "        # \"coordinates_chain\" is a dict with keys(['N_chain_A', 'CA_chain_A', 'C_chain_A', 'O_chain_A'])\n",
        "        coordinates_chain = protein[f\"coords_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        \n",
        "        # The following four variables are lists of length equal to seq_chain and seq_all length\n",
        "        # Therefore, the gapped positions can be retrived from seq_chain and removed from everything accordingly\n",
        "        N_chain = coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"]\n",
        "        CA_chain = coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"]\n",
        "        C_chain = coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"]\n",
        "        O_chain = coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        # delete everything related to gapped positions now\n",
        "        # at first, find out the positions that are gapped\n",
        "        # these gapped positions are absolutely messed up fucked up artifact of some kind of sophistification \n",
        "        # provided by proteinMPNN, FUCK YOU motherfucking oversmart CODERS\n",
        "        N_chain = [v for i,v in enumerate(N_chain) if seq_chain[i] != \"-\"]\n",
        "        CA_chain = [v for i,v in enumerate(CA_chain) if seq_chain[i] != \"-\"]\n",
        "        C_chain = [v for i,v in enumerate(C_chain) if seq_chain[i] != \"-\"]\n",
        "        O_chain = [v for i,v in enumerate(O_chain) if seq_chain[i] != \"-\"]\n",
        "        seq_all = [v for i,v in enumerate(seq_all) if seq_chain[i] != \"-\"]\n",
        "        seq_chain = [v for i,v in enumerate(seq_chain) if seq_chain[i] != \"-\"]\n",
        "\n",
        "        # Now, finally, pack everything back to the dictionary \"protein\"\n",
        "        protein[f\"seq_chain_{designed_chain_list[0]}\"] = seq_chain\n",
        "        protein[f\"seq\"] = seq_all\n",
        "        coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"] = N_chain\n",
        "        coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"] = CA_chain\n",
        "        coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"] = C_chain\n",
        "        coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"] = O_chain\n",
        "        protein[f\"coords_chain_{designed_chain_list[0]}\"] = coordinates_chain\n",
        "\n",
        "        # At this point, probably need to put None values in a lot of parameters that are not relevant to my usecase, but need to be sent to featurizer before running model forward\n",
        "        # For now, I will not tie positions together\n",
        "        tied_positions_dict = None\n",
        "        pssm_dict = None\n",
        "        omit_AA_dict = None\n",
        "        bias_AA_dict = None\n",
        "        tied_positions_dict = None\n",
        "        bias_by_res_dict = None\n",
        "        alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "        bias_AAs_np = np.zeros(len(alphabet))\n",
        "\n",
        "        chain_id_dict = {}\n",
        "        chain_id_dict[pdb_dict_list[0]['name']]= (designed_chain_list, fixed_chain_list)\n",
        "\n",
        "        BATCH_COPIES = 1\n",
        "\n",
        "        batch_clones = [copy.deepcopy(protein) for i in range(BATCH_COPIES)]\n",
        "\n",
        "        # \"muts_for_prot\" is a list with information about all the mutations in \"protein\", whose sequence only version is \"wildtype_seq\" \n",
        "        muts_for_prot = two_level_dict[filename.split(\".\")[0]]\n",
        "        # \"cur_map_dict\" will give the 0-based sequence index for the mutations, which will be almost directly used for masking and then running the model\n",
        "        # 1-based indexing needed for the fixed position\n",
        "        cur_map_dict = mapping_dict[filename.split(\".\")[0]]\n",
        "\n",
        "        for mut_track,mut in enumerate(muts_for_prot):\n",
        "            print(f\"Processing_Mut:{mut_track+1}, From_Prot:{i+1}\")\n",
        "            wild_aa = mut[\"mut\"][0]\n",
        "            alternate_aa = mut[\"mut\"][-1]\n",
        "            # (+1) because we need to pass 1-based indexing to tied_featurize() method\n",
        "            seq_pos = cur_map_dict[mut[\"mut\"][0:-1]] + 1\n",
        "            # only need to mask the mutated position position in \"wildtype_seq\" for now\n",
        "            fixed_positions_dict = {}\n",
        "            fixed_positions_dict[protein[\"name\"]] = {}\n",
        "            f_list = []\n",
        "            for ind_fixed in range(0,len(seq_chain)):\n",
        "                if (ind_fixed + 1) not in [seq_pos]:\n",
        "                    f_list.append(ind_fixed + 1)\n",
        "            fixed_positions_dict[protein[\"name\"]][filename.split(\".\")[0][-1]] = f_list\n",
        "\n",
        "            # finally, had to take chain-name from filename instead of biopython parsing to get rid of chain-name with \"1\" instead of \"A\" in \"1rtpA.pdb\"\n",
        "            X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "            omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "            = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "            randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "            log_probs, decoder_messages, node_embedding_info = mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "            # Adding the log_probs to the same inner dictionary where DDG values exist for easier comparison\n",
        "            mut[\"log_prob\"] = log_probs.cpu().data.numpy()\n",
        "            \n",
        "            # the top_k attention weights will be stored here for weighted sum later\n",
        "            # \"seq_pos\" is 1-based since \"fixed_positions_dict\" above needs to hold 1-based indices for the mutation,\n",
        "            # but accessing the tensors will require 0-based indexing\n",
        "            seq_index = seq_pos - 1\n",
        "            # \"dim = 1\", because decoder_messages[0,seq_index,:,:] should be (48,128), and we want to take norm of each of the 48 vectors across the last dimension,\n",
        "            # get 48 norm values, and fetch out the k highest values from there\n",
        "            message_norms = (torch.linalg.vector_norm(x=decoder_messages[0,seq_index,:,:],ord=2,dim=1))\n",
        "            local_distances, local_neighbors = return_neighbor_info(X, mask)\n",
        "            # \"top_k_attended_neighbor_indices\" is the indices from [0,47] corresponding to the highest attended neighbors\n",
        "            # top_(k-1) can technically be extracted from top_k, but currently just for simplicity and easier debugging, extracting everything separately\n",
        "            top_15_attention_vals, top_15_attended_neighbor_indices = torch.topk(message_norms,k=15)\n",
        "            top_10_attention_vals, top_10_attended_neighbor_indices = torch.topk(message_norms,k=10)\n",
        "            top_5_attention_vals, top_5_attended_neighbor_indices = torch.topk(message_norms,k=5)\n",
        "            # now, using \"local_neighbors\" to get the original indices of the neighbors corresponding to the top_k attended positions\n",
        "            # taking both top_5 and top_10 for now\n",
        "            top_15_attended_neighbor_indices = local_neighbors[0,seq_index,top_15_attended_neighbor_indices]\n",
        "            top_10_attended_neighbor_indices = local_neighbors[0,seq_index,top_10_attended_neighbor_indices]\n",
        "            top_5_attended_neighbor_indices = local_neighbors[0,seq_index,top_5_attended_neighbor_indices]\n",
        "            top_15_closest_neighbor_indices = local_neighbors[0,seq_index,1:16]\n",
        "            top_10_closest_neighbor_indices = local_neighbors[0,seq_index,1:11]\n",
        "            mut[\"top_15_attention_weights\"] = top_15_attention_vals.cpu().data.numpy()\n",
        "            mut[\"top_10_attention_weights\"] = top_10_attention_vals.cpu().data.numpy()\n",
        "            mut[\"top_5_attention_weights\"] = top_5_attention_vals.cpu().data.numpy()\n",
        "            # the neighbor indices corresponding to the top_k attention weights will be stored here for entropy calculation later\n",
        "            # 0-based indices of the neighbors will be saved so that corresponding log-probability vectors can be extracted readily from \"log_prob\" keyed value\n",
        "            mut[\"top_15_neighbor_indices\"] = top_15_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_10_neighbor_indices\"] = top_10_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_5_neighbor_indices\"] = top_5_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_15_closest_neighbor_indices\"] = top_15_closest_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_10_closest_neighbor_indices\"] = top_10_closest_neighbor_indices.cpu().data.numpy()\n",
        "\n",
        "            # The lines below are mostly for printing purposes to do external analysis with PyMol,and ROSETTA with Cristina\n",
        "            loc_pos_scores = []\n",
        "            for enum_val,(neighbor_p, neighbor_s, neighbor_distance) in enumerate(zip(local_neighbors[0,seq_index,1:15].cpu().data.numpy(),\n",
        "                                                                 (torch.linalg.vector_norm(x=decoder_messages[0,seq_index,1:15,:],ord=2,dim=1)).cpu().data.numpy(),\n",
        "                  \n",
        "                                                               local_distances[0,seq_index,1:15].cpu().data.numpy())):\n",
        "                # skippoing the first neighbor since it is the mutated position itself\n",
        "                if enum_val == 0:\n",
        "                    continue\n",
        "                pdbId_info.append(filename)\n",
        "                pos_info.append(seq_index+1)\n",
        "                neighbor_pos.append(neighbor_p+1)\n",
        "                neighbor_attention.append(neighbor_s)\n",
        "                loc_pos_scores.append(neighbor_s)\n",
        "                neighbor_distances_tracking.append(neighbor_distance)\n",
        "            # since softmax has to be done over all the neighbors, taking the softmax, and later adding it to the data generation list after\n",
        "            # neighbor enumeration loop\n",
        "            loc_pos_scores = softmax(np.array(loc_pos_scores))\n",
        "            for s in loc_pos_scores:\n",
        "                neighbor_attention_softmaxed.append(s)\n",
        "\n",
        "            # take (\"neighbor_attention\"-weighted sum/average) of the entropies of the top 5 attended neighbors\n",
        "            # are the neighbors with highest message passing values always among the closest 10?\n",
        "            # point to be noted that the closest, therefore the first neighbor of every position is the neighbor itself\n",
        "            # check correlation between distance and attention values since a possible manual edge feature would be distance\n",
        "            # let us see if the model attends to distant neighbors more, or attention value is inversely proportional to distance?\n",
        "            # take L2-norms of the message vectors instead of attention\n",
        "            # take the softmax of L2-norms to approximate attention, although technically the positions are not constrained by each other, this can be considered a sigmoid attention\n",
        "            # where having neighbors with large messages will effect differently than having neighbors with small messages\n",
        "            # can this be correlated with position-entropy?\n",
        "            # the L2-norms should be able to approximate how much each of the neighbors are effecting the mutated position\n",
        "            # This information can be stored for checking the effect of center mutation on those positions afterwards\n",
        "            # Identify major interacting partners (neighbors that are important for center prediction, and also which take center into consideration for its own prediction)\n",
        "            # then check how much the major neighbor position deviates from wildtype due to the mutation\n",
        "            # another much more simples thing can be to check the deviation for top 10 neighbors\n",
        "            # this deviation can be calculated using the log(W) for the neighbor before center mutation, and log(W) for the neighbor after center mutation \n",
        "\n",
        "            # Now, take top_k most attended positions, make them designable, mutate center, and take change in -log(p) of the wildtype at each of the neighbor positions\n",
        "            # take weighted sum of these neighbor energy changes, see if there is any correlation\n",
        "            # next, go for \"strong\" neighbor positions (both way strong attention)\n",
        "            # Many of the tensors will take on new values after running the model again with different fixed positions\n",
        "            \n",
        "            # the \"fixed_positions_dict\" has to be repopulated now since neighbor positions will be masked one by one\n",
        "            # here, \"n_ind\" is the 0-based index corresponding to one of the \"top_k\" attended neighbors \n",
        "            # these lists will contain the log_probabilities for the top_k most attended neighbors serially\n",
        "            # before and after making the center mutation currently at hand, these probabilities will be used later for calculating\n",
        "            # attention_weighted change in neighbor_wildtype probability, attention_weighted_change in KL, and all those things \n",
        "            neighbor_w_log_probs = []\n",
        "            neighbor_m_log_probs = []\n",
        "            # the following array will contain the identities of the neighbors serially so that specific wildtype neighbor positions in the probability\n",
        "            # distribution can be extracted later\n",
        "            neighbor_aa_identities = []\n",
        "            # \"top5\" and \"top10\" should be extractable from \"top15\", since the neighbor\n",
        "            neighbor_w_message_vector_coming_from_center = []\n",
        "            neighbor_m_message_vector_coming_from_center = []\n",
        "            # I will pick out the neighbor embeddings, and put them inside the lists below\n",
        "            # But, do I need to access them one by one, or can I just take a slice out of the embedding tensor across the seq_pos dimension?\n",
        "            # what more information will I get if I fetch out the embeddings one by one?\n",
        "            # if I want to do a slicing, I might have to make all the neighbors designable at the same time, which will \n",
        "            # for one, I can take out the embeddings for each of the neighbors while they are designable, before and \n",
        "            # okay, lets say we will fetch the neighbors out, one by one; we can do that right inside the next loop\n",
        "            # what will be the significance of those neighbor embeddings, in that case?\n",
        "            # they will see everything around them, expcept the mutated position, will they change much due to that?\n",
        "            # neighbor embedding difference in that case might actually catch something about the new interactions that have\n",
        "            # been formed, interesting...very, very interesting\n",
        "            neighbor_w_embedding_info = []\n",
        "            neighbor_m_embedding_info = [] \n",
        "            # informations are stored serially in the lists\n",
        "            for n_ind in mut[\"top_15_neighbor_indices\"]:\n",
        "                neighbor_aa_identities.append(seq_chain[n_ind])\n",
        "                # Some sequence-input manipulation is done later in this loop, so the wildtype aa is placed in the position, so that\n",
        "                # previous iteration manipulations do not cause trouble in this iteration\n",
        "                alpha_tok = \"ACDEFGHIKLMNPQRSTVWYX\"\n",
        "                aa_1_N = {a:n for n,a in enumerate(alpha_tok)}\n",
        "                aa_N_1 = {n:a for n,a in enumerate(alpha_tok)}\n",
        "\n",
        "                # adding (+1) to n_ind, since fixed positions are 1-indexed in the original implementation\n",
        "                n_pos = n_ind + 1  \n",
        "                fixed_positions_dict = {}\n",
        "                fixed_positions_dict[protein[\"name\"]] = {}\n",
        "                f_list = []\n",
        "                for ind_fixed in range(0,len(seq_chain)):\n",
        "                    # Fixing everything except the \"n_pos\" neighbor position\n",
        "                    if (ind_fixed + 1) not in [n_pos]:\n",
        "                        f_list.append(ind_fixed + 1)\n",
        "                fixed_positions_dict[protein[\"name\"]][filename.split(\".\")[0][-1]] = f_list\n",
        "\n",
        "                # Extracting \"n_ind\" 21-way log probabilities when the center is wildtype \n",
        "                X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "                omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "                = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "                randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "\n",
        "                # we want to store the 128-length message vector coming from the center to the neighbor at \"n_ind\"\n",
        "                # for this, at first, we need to find which neighbor of \"n_ind\" is our center so that we can pull out the message vector coming from \n",
        "                # the center to the neighbor at \"n_ind\" \n",
        "                loc_local_distances, loc_local_neighbors = return_neighbor_info(X, mask)\n",
        "                # \"neighbor_neighbor_index\" is the index of the center with respect to the neighbor at \"n_ind\"\n",
        "                # if len(neighbor_neighbor_index) is 0, center is not among the spatially close 48 neighbors of the neighbor at \"n_ind\"\n",
        "                # in that case, message vector passed from center to that neighbor can be considered as a 128 length all 0 vector for now\n",
        "                # for now, it is important to note that if len(neighbor_neighbor_index) is not zero, then the index can be retrived by neighbor_neighbor_index[0][0]  \n",
        "                neighbor_neighbor_index = (loc_local_neighbors[0,n_ind,:] == seq_index).nonzero(as_tuple=False)\n",
        "                neighbor_neighbor_index =  neighbor_neighbor_index[0][0] if (len(neighbor_neighbor_index) == 1) else torch.tensor(-1,device=neighbor_neighbor_index.device)\n",
        "\n",
        "                # calling \"mpnn_model\" \"forward\" function three times below for getting the three tensors is definitely not efficient,\n",
        "                # but, doing it this way for now, since I am getting CUDA out-of-memory errors due to some unsolved (for now) reason   \n",
        "                n_log_probs  = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[0][0,n_ind,:].cpu().data.numpy()\n",
        "                decoder_message = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[1][0,n_ind,neighbor_neighbor_index,:].cpu().data.numpy()\n",
        "                node_embedding_info = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[2][0,n_ind,:].cpu().data.numpy()\n",
        "\n",
        "                neighbor_w_log_probs.append(n_log_probs)\n",
        "                neighbor_w_embedding_info.append(node_embedding_info)\n",
        "\n",
        "                if neighbor_neighbor_index >= 0:\n",
        "                    neighbor_w_message_vector_coming_from_center.append(decoder_message)\n",
        "                else:\n",
        "                    # Adding all-0 vector of length 128 if the center is not among the closest 48 neighbors of center\n",
        "                    neighbor_w_message_vector_coming_from_center.append(np.zeros(128)) \n",
        "                 \n",
        "                # Now, make mutation, and process the corresponding probabilities\n",
        "                X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "                omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "                = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "                randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "                # seems like passing mutant sequence through the model will be a bit more difficult that expected since PDB file is read in by the underlying parser\n",
        "                # How, do I only change the amino acids identity in the sequence, but keep the PDB backbone and everything same?\n",
        "                # At first, just try to manipulate the input \"S\"\n",
        "                S[0,seq_index] = aa_1_N[alternate_aa]\n",
        "                n_log_probs  = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[0][0,n_ind,:].cpu().data.numpy()\n",
        "                decoder_message = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[1][0,n_ind,neighbor_neighbor_index,:].cpu().data.numpy()\n",
        "                node_embedding_info = \\\n",
        "                    mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)[2][0,n_ind,:].cpu().data.numpy()\n",
        "\n",
        "                neighbor_m_log_probs.append(n_log_probs)\n",
        "                neighbor_m_embedding_info.append(node_embedding_info)\n",
        "\n",
        "                if neighbor_neighbor_index >= 0:\n",
        "                    neighbor_m_message_vector_coming_from_center.append(decoder_message)\n",
        "                else:\n",
        "                    # Adding all-0 vector of length 128 if the center is not among the closest 48 neighbors of center\n",
        "                    neighbor_m_message_vector_coming_from_center.append(np.zeros(128))           \n",
        "            mut[\"w_n_log_prob\"] = neighbor_w_log_probs\n",
        "            mut[\"m_n_log_prob\"] = neighbor_m_log_probs\n",
        "            mut[\"neighbor_aa_identities\"] = neighbor_aa_identities\n",
        "            mut[\"neighbor_w_message_vector_coming_from_center\"] = neighbor_w_message_vector_coming_from_center\n",
        "            mut[\"neighbor_m_message_vector_coming_from_center\"] = neighbor_m_message_vector_coming_from_center\n",
        "            mut[\"neighbor_w_neighbor_embedding\"] = neighbor_w_embedding_info\n",
        "            mut[\"neighbor_m_neighbor_embedding\"] = neighbor_m_embedding_info\n",
        "        prot_end = time.time()\n",
        "        print(f\"Took {prot_end-prot_start} for {filename} with {mut_track+1} forward-mutations\")\n",
        "        print(\"....................\")"
      ],
      "metadata": {
        "id": "b8cEsTK1EQ9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the incomplete \"two_level_dict\" as pickle file for a quick dirty comparison\n",
        "# import pickle\n",
        "# with open(\"Ssym_pmppn_info_dict_V3.pickle\",\"wb\") as f:\n",
        "#     pickle.dump(two_level_dict,f)"
      ],
      "metadata": {
        "id": "rXvc5PDmIQyF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# with open(\"Ssym_pmppn_info_dict_V2.pickle\",\"rb\") as f:\n",
        "#     two_level_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "T8iPDaqrZg4U"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import entropy\n",
        "from scipy.special import expit\n",
        "alpha_list = list(\"ACDEFGHIKLMNPQRSTVWYX\")\n",
        "# The following dictionary will be used for fetching out the log-probabilities corresponding to the wild-type and mutated residues at the mutation positions\n",
        "aa_to_N = {a:n for n,a in enumerate(alpha_list)}\n",
        "# This list will contain the experimental ddg values for the mutations for which two-level dict contains information regarding log_probabilities\n",
        "true_vals = []\n",
        "# This list will contain (wild_proba,mut_proba) tuples for the mutations for which two-level dict contains information regarding log_probabilities\n",
        "wild_mut_log_probabilities = []\n",
        "# saving max probabilites for debugging\n",
        "max_log_probabilities = []\n",
        "# Want to add entropy of the position with some kind of weight (maybe, just a for loop for checking weight combinations that sum to 1?)\n",
        "position_entropies = []\n",
        "weighted_neighbor_entropies = []\n",
        "# This \"weighted_neighbor_energy_changes\" will be ((-log(m))-(-log(w))) for each of the topk neighbors, weighted summed by corresponding attention weights   \n",
        "weighted_neighbor_energy_changes = []\n",
        "#\n",
        "backward_weighted_neighbor_energy_changes = []\n",
        "V2_backward_weighted_neighbor_energy_changes = []\n",
        "# the neighbor-forward-KL will at this point treat the center-wildtype conditioned neighbor distributions as true, \n",
        "# and center-mutated conditioned neighbor distributions as approximation\n",
        "weighted_neighbor_forward_KL = []\n",
        "# the neighbor-backward-KL will treat the center-mutated conditioned neighbor distributions as true, \n",
        "# and center-wildtype conditioned neighbor distributions as approximation\n",
        "weighted_neighbor_backward_KL = []\n",
        "#\n",
        "backward_weighted_neighbor_backward_KL = []\n",
        "V2_backward_weighted_neighbor_backward_KL = []  \n",
        "# # This \"weighted_neighbor_entropy_changes\" will be ((entropy(p(nieghbor|m))-(entropy(p(nieghbor|w))) for each of the topk neighbors, weighted summed by corresponding attention weights \n",
        "weighted_neighbor_entropy_changes = []\n",
        "## the weights will now be based on change in center->neighbor message vector L2-norm due to mutation, instead of neighbor->center message norm \n",
        "## however, I think a softmaxing across all those weights will now be a must since scales could be crazily different\n",
        "backward_weighted_neighbor_entropy_changes = []\n",
        "V2_backward_weighted_neighbor_entropy_changes = []\n",
        "# the two arrays below are being saved for checking correlations of (m/w) and (w/m) attention weight changes to ddgs\n",
        "# this debugging-type correlation analysis could reveal significant insights into the best weighing mechanism, and even provide a way to differentiate\n",
        "# between neighbors that have established new connections with the center, and neighbors whose connections with the center has been severed (kinda severed,maybe or weakened?..whatever)  \n",
        "center_neighbor_weight_check_m_w = []\n",
        "center_neighbor_weight_check_w_m = []\n",
        "\n",
        "# putting the dictionary here since we are going to need positions corresponding to alternate amino acid 1-letter codes\n",
        "alpha_tok = \"ACDEFGHIKLMNPQRSTVWYX\"\n",
        "aa_1_N = {a:n for n,a in enumerate(alpha_tok)}\n",
        "for i,(prot,muts) in enumerate(two_level_dict.items()):\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for ind_track, mut in enumerate(muts):\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            # where the fuck is \"log_prob\" coming from, but \"top_5_attention_weights\" and \"top_5_neighbor_indices\" are not there?\n",
        "            if (\"log_prob\" in mut) and (\"w_n_log_prob\" in mut):\n",
        "                wild = mut[\"mut\"][0] \n",
        "                alternate = mut[\"mut\"][-1]\n",
        "                true_vals.append(mut[\"ddg\"])\n",
        "                sequence_index_of_mutation = cur_map_dict[mut[\"mut\"][0:-1]]\n",
        "                position_log_probabilities = mut[\"log_prob\"][0,sequence_index_of_mutation,:]\n",
        "                wild_mut_log_probabilities.append((position_log_probabilities[aa_to_N[wild]],position_log_probabilities[aa_to_N[alternate]]))\n",
        "                max_log_probabilities.append(position_log_probabilities.max())\n",
        "                position_entropies.append(entropy(np.exp(position_log_probabilities)))\n",
        "                # These 0-based neighbor indices will be used for extracting the log-probabilities corresponding to the neighbor positions\n",
        "                n_indices= mut[\"top_15_neighbor_indices\"]\n",
        "                # The neighbor weights will be used here for multiplying \n",
        "                n_weights = mut[\"top_15_attention_weights\"].reshape(-1,1)\n",
        "                # Take entropy while taking care of the dimension along which entropy is calculated\n",
        "                # Taking entropy across last axis, because the shape of the input is (k,21), where 21 is the 21-way probability distribution \n",
        "                n_entropies = entropy(np.exp(mut[\"log_prob\"][0,n_indices,:]),axis=-1).reshape(-1,1)\n",
        "                # I think this element-wise product is getting wrong \n",
        "                weighted_neighbor_entropies.append((n_entropies*softmax(n_weights)).sum())\n",
        "                # weighted_neighbor_entropies.append((n_entropies*softmax(n_weights)).sum())\n",
        "                # weighted_neighbor_entropies.append((n_entropies*n_weights).sum())\n",
        "\n",
        "                # Now, calculate neighbor energy changes, and then weighted sum them after extracting specific log_probabilities\n",
        "                # for mutant center, and wildtype center impacted versions for the top neighbor positions\n",
        "                neighbor_w_log_probabilities = mut[\"w_n_log_prob\"]\n",
        "                neighbor_m_log_probabilities = mut[\"m_n_log_prob\"]\n",
        "                neighbor_amino_a_identities = mut[\"neighbor_aa_identities\"]\n",
        "                neighbor_w_message_vector_coming_from_center = mut[\"neighbor_w_message_vector_coming_from_center\"]\n",
        "                neighbor_m_message_vector_coming_from_center = mut[\"neighbor_m_message_vector_coming_from_center\"]\n",
        "                neighbor_w_neighbor_embedding = mut[\"neighbor_w_neighbor_embedding\"]\n",
        "                neighbor_m_neighbor_embedding = mut[\"neighbor_m_neighbor_embedding\"]\n",
        "                # The \"local_neighbor_log_prob_vals\" will be a list of negative log-probability differences(a.k.a. energy differences)\n",
        "                local_neighbor_log_prob_vals = []\n",
        "                local_neighbor_forward_KL_vals = []\n",
        "                local_neighbor_backward_KL_vals = []\n",
        "                local_neighbor_entropy_change_vals = []\n",
        "                local_neighbor_attention_change_vals = []\n",
        "                # the two lists below are for debugging, and insight-revelation purposes, mostly\n",
        "                local_center_neighbor_weight_check_m_w = []\n",
        "                local_center_neighbor_weight_check_w_m = []\n",
        "                # the \"local_neighbor_embedding_changes\" list below will hold (neighbor_m_embedding/neighbor_w_embedding) arrays of length 128\n",
        "                # so, technically, this list can be converted to a (15,128) 2D numpy array\n",
        "                # all those (15,128) numpy arrays will later be concatenated across axis-0 before taking the PCA in the next cell\n",
        "                local_neighbor_embedding_changes = []\n",
        "                local_neighbor_embedding_changes_raw = []\n",
        "                local_neighbor_message_changes_raw = []\n",
        "                # the vector below is very similar to (w/m), but L2 norm is taken on the difference vector\n",
        "                local_center_neighbor_message_change_diff = []\n",
        "                # For example, selecting the numbers from the first 5 iterations of this loop will give neighbor energy change corresponding to the first 5 neighbors\n",
        "                for neighbor_w, neighbor_m, neighbor_aa, neighbor_w_message, neighbor_m_message, neighbor_w_embedding, neighbor_m_embedding  in \\\n",
        "                zip(neighbor_w_log_probabilities,neighbor_m_log_probabilities,neighbor_amino_a_identities,neighbor_w_message_vector_coming_from_center,neighbor_m_message_vector_coming_from_center,\n",
        "                    neighbor_w_neighbor_embedding,neighbor_m_neighbor_embedding):\n",
        "                    # get the amino acid identity for the neighbor position, run it through the mapping dictionary, get the log probabilities from those positions,\n",
        "                    # \"neighbor_w\" and \"neighbor_m\" arrays will directly give the log probabilities that need to be substracted to get the energy (put (-1) before thoese numbers?...think a bit)\n",
        "                    neighbor_index = aa_1_N[neighbor_aa]\n",
        "                    local_neighbor_log_prob_vals.append((-1*neighbor_m[neighbor_index])-(-1*neighbor_w[neighbor_index]))\n",
        "                    # summing the output of \"kl_div\", because one number comes for every positions in the currently processing neighbor distribution,\n",
        "                    # and I want to take the total deviation in that distribution \n",
        "                    local_neighbor_forward_KL_vals.append(kl_div(np.exp(neighbor_w),np.exp(neighbor_m)).sum())\n",
        "                    local_neighbor_backward_KL_vals.append(kl_div(np.exp(neighbor_m),np.exp(neighbor_w)).sum())\n",
        "                    local_neighbor_entropy_change_vals.append(entropy(np.exp(neighbor_m))-entropy(np.exp(neighbor_w)))\n",
        "                    # lets just put the absolute value of the difference between the L2-norms for now (taking sign into consideration will require\n",
        "                    # taking care of the correct direction of change, which might make things a bit ncomplicated for now, and have unintended effects)\n",
        "                    # But, having a direction can definitely help with stabilization vs. de-stabilization figuring out\n",
        "                    # some kind of \n",
        "                    # usiung only the norm would more like predict the magnitude of DDG\n",
        "                    # local_neighbor_attention_change_vals.append()\n",
        "                    neighbor_w_message = neighbor_w_message.reshape((-1,1))\n",
        "                    neighbor_m_message = neighbor_m_message.reshape((-1,1))\n",
        "                    # Adding the small numbers for numerical stability, which hopefully will not change the information content of these features\n",
        "                    neighbor_w_message_norm = np.linalg.norm(neighbor_w_message,ord=2,axis=0) + 0.00000001\n",
        "                    neighbor_m_message_norm = np.linalg.norm(neighbor_m_message,ord=2,axis=0) + 0.00000001\n",
        "                    # taking average of two ratios for kind of capturing the change in both (mutant->wild) and (wild->mutant) directions with the same measure \n",
        "                    # the ratio should help to avoid any neighbor to neighbor variability related-scale\n",
        "                    # but scale could also be important, right? since, the same transformation is applied for calculating the numbers for every position in the proteins \n",
        "                    # local_neighbor_attention_change_vals.append((0.5*(neighbor_w_message_norm/neighbor_m_message_norm))+(0.5*(neighbor_m_message_norm/neighbor_w_message_norm)))\n",
        "                    local_neighbor_attention_change_vals.append((neighbor_w_message_norm/neighbor_m_message_norm))\n",
        "                    # the two list-appending lines below are mostly for debugging purposes at the moment,\n",
        "                    # might be something more than that in a few minutes?\n",
        "                    local_center_neighbor_weight_check_m_w.append(neighbor_m_message_norm/neighbor_w_message_norm)\n",
        "                    local_center_neighbor_weight_check_w_m.append(neighbor_w_message_norm/neighbor_m_message_norm)\n",
        "                    # can take PCA of the below as well\n",
        "                    # currently, taking the norm of division vector (-1 to discourage (+1) from contributing to the norm)\n",
        "                    # local_neighbor_embedding_changes.append(np.linalg.norm((neighbor_m_embedding/neighbor_w_embedding)))\n",
        "                    # local_neighbor_embedding_changes.append(neighbor_m_embedding/neighbor_w_embedding)\n",
        "                    # local_neighbor_embedding_changes.append(neighbor_w_embedding)\n",
        "                    local_neighbor_embedding_changes.append(np.linalg.norm(neighbor_w_embedding-neighbor_m_embedding))\n",
        "                    local_neighbor_embedding_changes_raw.append(neighbor_w_embedding-neighbor_m_embedding)\n",
        "                    local_neighbor_message_changes_raw.append(neighbor_w_message-neighbor_m_message)\n",
        "                    local_center_neighbor_message_change_diff.append(np.linalg.norm(neighbor_w_message-neighbor_m_message))\n",
        "                # The energy change approximation can be constrained to the top few neighbors by just indexing the arrays below\n",
        "                # So, it looks like a better idea to save log_probs for atleast the top_20 neighbors since we can always fetch the first few from there\n",
        "                weighted_neighbor_energy_changes.append((np.array(local_neighbor_log_prob_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_forward_KL.append((np.array(local_neighbor_forward_KL_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_backward_KL.append((np.array(local_neighbor_backward_KL_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_entropy_changes.append((np.array(local_neighbor_entropy_change_vals[0:15])*expit(n_weights[0:15])).sum())\n",
        "                # versions of neighbor features, just weighted by backward weights (center->neighbor attention change due to mutation) instead of forward weights (neighbor->center attention)\n",
        "                # sum() of these (m/w) weight-change is apparently positively correlated with DDGs\n",
        "                backward_weighted_neighbor_energy_changes.append((np.array(local_neighbor_log_prob_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_m_w))[0:15])).sum())\n",
        "                backward_weighted_neighbor_backward_KL.append((np.array(local_neighbor_backward_KL_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_m_w))[0:15])).sum())\n",
        "                backward_weighted_neighbor_entropy_changes.append(((np.array(local_neighbor_entropy_change_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_m_w)))[0:15]).sum()))\n",
        "                # the two list-appending lines below are mostly for debugging purposes at the moment,\n",
        "                # might be something more than that in a few minutes?\n",
        "                center_neighbor_weight_check_m_w.append(np.array(local_center_neighbor_weight_check_m_w).sum())\n",
        "                center_neighbor_weight_check_w_m.append(np.array(local_center_neighbor_weight_check_w_m).sum())\n",
        "                # now, let us add features weighted by the other version of attention changes\n",
        "                # sum() of these (w/m) weight-change is apparently negatievly correlated with DDGs\n",
        "                V2_backward_weighted_neighbor_energy_changes.append((np.array(local_neighbor_log_prob_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_w_m))[0:15])).sum())\n",
        "                V2_backward_weighted_neighbor_backward_KL.append((np.array(local_neighbor_backward_KL_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_w_m))[0:15])).sum())\n",
        "                V2_backward_weighted_neighbor_entropy_changes.append(((np.array(local_neighbor_entropy_change_vals[0:15])*expit((np.array(local_center_neighbor_weight_check_w_m)))[0:15]).sum()))\n",
        "\n",
        "\n",
        "                # let us also save the features in the \"mut\" dictionary, so that \"two_letter_dict\" containing all the features for every mutation\n",
        "                # can be saved after this cell in pickle format, and later be accessed from any other script\n",
        "                # print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "                # print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "                # energies (negative log probabilities of the most_probable,wild,and mutated residue, respectively, at the center position)\n",
        "                e_max = (-1*(max_log_probabilities[-1]))\n",
        "                e_wild = (-1*((wild_mut_log_probabilities[-1])[0]))\n",
        "                e_mut = (-1*((wild_mut_log_probabilities[-1])[1]))\n",
        "                mut[\"center_mut_wild_energy\"] = e_mut - e_wild \n",
        "                mut[\"center_mut_max_energy\"] = e_mut - e_max\n",
        "                mut[\"center_entropy\"] = (position_entropies[-1] * (-1))\n",
        "                mut[\"weighted_neighbor_entropies\"] = weighted_neighbor_entropies[-1] \n",
        "                mut[\"weighted_neighbor_energy_changes\"] = weighted_neighbor_energy_changes[-1]\n",
        "                mut[\"backward_weighted_neighbor_energy_changes\"] = backward_weighted_neighbor_energy_changes[-1]\n",
        "                mut[\"V2_backward_weighted_neighbor_energy_changes\"] = V2_backward_weighted_neighbor_energy_changes[-1]\n",
        "                mut[\"weighted_neighbor_forward_KL\"] = weighted_neighbor_forward_KL[-1] \n",
        "                mut[\"weighted_neighbor_backward_KL\"] = weighted_neighbor_backward_KL[-1]\n",
        "                mut[\"backward_weighted_neighbor_backward_KL\"] = backward_weighted_neighbor_backward_KL[-1]\n",
        "                mut[\"V2_backward_weighted_neighbor_backward_KL\"] = V2_backward_weighted_neighbor_backward_KL[-1]  \n",
        "                mut[\"weighted_neighbor_entropy_changes\"] = weighted_neighbor_entropy_changes[-1]\n",
        "                mut[\"backward_weighted_neighbor_entropy_changes\"] = backward_weighted_neighbor_entropy_changes[-1]\n",
        "                mut[\"V2_backward_weighted_neighbor_entropy_changes\"] = V2_backward_weighted_neighbor_entropy_changes[-1]  \n",
        "                mut[\"center_neighbor_weight_check_m_w\"] = center_neighbor_weight_check_m_w[-1]\n",
        "                mut[\"center_neighbor_weight_check_w_m\"] = center_neighbor_weight_check_w_m[-1]\n",
        "                # mut[\"neighbor_embedding_change_m_w\"] should be a (15,128) numpy array for every mutation since we are currently \n",
        "                # considering top15 attended neighbors for every mutation, and the decoder last layer embedding before \n",
        "                # output_transformation is of length 128 \n",
        "                # mut[\"neighbor_embedding_change_m_w\"] = np.array(local_neighbor_embedding_changes)\n",
        "                mut[\"neighbor_embedding_change_m_w\"] = np.array(local_neighbor_embedding_changes).sum()\n",
        "                # for each mutation, mut[\"neighbor_embedding_change_m_w_raw\"] should be a (15,128) array since we are considering\n",
        "                # top15 most attended neighbors \n",
        "                mut[\"neighbor_embedding_change_m_w_raw\"] = np.array(local_neighbor_embedding_changes_raw)\n",
        "                mut[\"neighbor_message_change_m_w_raw\"] = np.array(local_neighbor_message_changes_raw)\n",
        "                mut[\"neighbor_message_change_m_w\"] = np.array(local_center_neighbor_message_change_diff).sum()\n",
        "                mut[\"unweighted_backward_KL\"] = np.array(local_neighbor_backward_KL_vals).sum()\n",
        "                mut[\"unweighted_forward_KL\"] = np.array(local_neighbor_forward_KL_vals).sum()"
      ],
      "metadata": {
        "id": "7m4jsITsJHmE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "TwMx2ZMs60Pz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experimental_energies = []\n",
        "mut_wild_predictions = []\n",
        "mut_min_predictions = []\n",
        "entropy_predictions = []\n",
        "neighbor_entropy_change_predictions = []\n",
        "neighbor_energy_change_predictions = []\n",
        "center_neighbor_weight_check_w_m = []\n",
        "V2_backward_weighted_neighbor_backward_KL = []\n",
        "sum_neighbor_embedding_change_m_w = []\n",
        "neighbor_message_change_m_w = []\n",
        "\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        for mut in muts:\n",
        "            if \"center_mut_wild_energy\" in mut:\n",
        "                experimental_energies.append(mut[\"ddg\"])\n",
        "                mut_wild_predictions.append(mut[\"center_mut_wild_energy\"])\n",
        "                mut_min_predictions.append(mut[\"center_mut_max_energy\"])\n",
        "                entropy_predictions.append(mut[\"center_entropy\"])\n",
        "                neighbor_entropy_change_predictions.append(mut[\"weighted_neighbor_entropy_changes\"])\n",
        "                neighbor_energy_change_predictions.append(mut[\"weighted_neighbor_energy_changes\"])\n",
        "                center_neighbor_weight_check_w_m.append(mut[\"center_neighbor_weight_check_w_m\"])\n",
        "                V2_backward_weighted_neighbor_backward_KL.append(mut[\"V2_backward_weighted_neighbor_backward_KL\"])\n",
        "                sum_neighbor_embedding_change_m_w.append(mut[\"neighbor_embedding_change_m_w\"])\n",
        "                neighbor_message_change_m_w.append(mut[\"neighbor_message_change_m_w\"])\n",
        "\n",
        "print(len(experimental_energies),len(mut_wild_predictions))\n",
        "\n",
        "print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "print(pearsonr(experimental_energies,entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_entropy_change_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_energy_change_predictions))\n",
        "print(pearsonr(experimental_energies,center_neighbor_weight_check_w_m))\n",
        "print(pearsonr(experimental_energies,V2_backward_weighted_neighbor_backward_KL))\n",
        "print(pearsonr(experimental_energies,sum_neighbor_embedding_change_m_w))\n",
        "print(pearsonr(experimental_energies,neighbor_message_change_m_w))\n",
        "\n",
        "# something is definitely fucked up in here\n",
        "# why the fuck are the correlations so much deviated???\n",
        "# V6 for Ssym was definitely not showing patterns like these\n",
        "# check, recheck, and set this shit straight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StvbASTsfta0",
        "outputId": "52e58265-3ce2-486e-a495-84fd51b72f59"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "342 342\n",
            "(0.567391786943631, 1.5691298971421216e-30)\n",
            "(0.582062409268496, 2.1155606134818152e-32)\n",
            "(0.36369732334720606, 3.909041388529533e-12)\n",
            "(0.35227849671059386, 1.984763898648971e-11)\n",
            "(0.31869048055079785, 1.6397158704779038e-09)\n",
            "(-0.25388605312756196, 1.9732813632404045e-06)\n",
            "(0.1680061221141445, 0.0018221078320998286)\n",
            "(0.27457041703947704, 2.4882302717008426e-07)\n",
            "(0.06692694497904732, 0.21699824260362663)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let me get PSSM values and do some comparison quickly\n",
        "# getting the PSSM extraction functions from my custom model data processing scripts\n",
        "from string import ascii_uppercase\n",
        "\n",
        "# In rare cases, some PDB files number chains with 1,2,3 instead of A,B,C\n",
        "def convertChainFromAlphabetToNumber(alphabet):\n",
        "    mappingDict = {ch:(idx+1) for idx,ch in enumerate(ascii_uppercase)}\n",
        "    return str(mappingDict[alphabet])\n",
        "\n",
        "# Before executing this function, the PSSM files with naming format \"pdbIdchain.pssm\" needs to be stored\n",
        "# in the pssm_dir\n",
        "def returnPSSMArray(pdbIdPlusChain,pssm_dir=\"train_pssm_dir\",convert_upper = False):\n",
        "#     Currently, assuming that the pssm file names contain pdbId in upper case\n",
        "    if convert_upper:\n",
        "        fileName = pdbIdPlusChain.upper() + \".pssm\"\n",
        "    else:\n",
        "        fileName = pdbIdPlusChain + \".pssm\"\n",
        "    try:\n",
        "        fullPath = os.path.join(pssm_dir,fileName)\n",
        "        f = open(fullPath)\n",
        "    except:\n",
        "        fileName = pdbIdPlusChain[0:4].upper() + str(convertChainFromAlphabetToNumber(pdbIdPlusChain[4])) + \".pssm\" \n",
        "        fullPath = os.path.join(pssm_dir,fileName)\n",
        "        f = open(fullPath)\n",
        "        \n",
        "# #     all the target lines in the PSSM files have (2+20+20+2=44) strings after line.split()\n",
        "    target_lines = [line.split() for line in f.readlines() if (len(line.split()))==44]\n",
        "    number_of_residues = len(target_lines)\n",
        "    \n",
        "    pssm_features = np.zeros((number_of_residues,20))\n",
        "\n",
        "    for idx,line in enumerate(target_lines):\n",
        "        pssm_features[idx,:] = line[2:22]\n",
        "\n",
        "    f.close()\n",
        "    \n",
        "    return pssm_features\n",
        "\n",
        "# This function also seems necessary for extracting the two pssm values\n",
        "# Must review the three pssm feature functions (this one and the two above) later\n",
        "# These functions seem to be taking up a lot of time....must review\n",
        "def returnPSSMMapping(residue):\n",
        "    pssm_letter_to_index_dict = {\"A\" : 0,   \n",
        "    \"R\" : 1,\n",
        "    \"N\" : 2,\n",
        "    \"D\" : 3,\n",
        "    \"C\" : 4,\n",
        "    \"Q\" : 5,\n",
        "    \"E\" : 6,\n",
        "    \"G\" : 7,\n",
        "    \"H\" : 8,\n",
        "    \"I\" : 9,\n",
        "    \"L\" : 10,\n",
        "    \"K\" : 11,\n",
        "    \"M\" : 12,\n",
        "    \"F\" : 13,\n",
        "    \"P\" : 14,\n",
        "    \"S\" : 15,\n",
        "    \"T\" : 16,\n",
        "    \"W\" : 17,\n",
        "    \"Y\" : 18,\n",
        "    \"V\" : 19}\n",
        "\n",
        "    return pssm_letter_to_index_dict[residue]\n",
        "\n",
        "\n",
        "# I will add PSSM values to the two-level dictionary for places where log_prob is available\n",
        "pssmDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/Ssym_pssm_dir\"\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                wild = mut[\"mut\"][0] \n",
        "                alternate = mut[\"mut\"][-1]\n",
        "                sequence_index_of_mutation = cur_map_dict[mut[\"mut\"][0:-1]]\n",
        "                pdbId = prot[0:-1]\n",
        "                mutChain = prot[-1]\n",
        "                pssm_array = returnPSSMArray(pdbId + mutChain,pssm_dir=pssmDirectory,convert_upper = False)\n",
        "                position_pssm = pssm_array[sequence_index_of_mutation]\n",
        "                wild_pssm = position_pssm[returnPSSMMapping(wild)] \n",
        "                alternate_pssm = position_pssm[returnPSSMMapping(alternate)]\n",
        "                mut[\"wild_pssm\"] = wild_pssm\n",
        "                mut[\"alternate_pssm\"] = alternate_pssm"
      ],
      "metadata": {
        "id": "eBgpxQx4ispc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pssm_predictions = []\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                pssm_predictions.append((mut[\"wild_pssm\"]-mut[\"alternate_pssm\"]))"
      ],
      "metadata": {
        "id": "xOkQhEQzn32m"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experimental_energies = []\n",
        "mut_wild_predictions = []\n",
        "mut_min_predictions = []\n",
        "entropy_predictions = []\n",
        "neighbor_entropy_change_predictions = []\n",
        "neighbor_energy_change_predictions = []\n",
        "center_neighbor_weight_check_w_m = []\n",
        "V2_backward_weighted_neighbor_backward_KL = []\n",
        "sum_neighbor_embedding_change_m_w = []\n",
        "neighbor_message_change_m_w = []\n",
        "\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        for mut in muts:\n",
        "            if \"center_mut_wild_energy\" in mut:\n",
        "                experimental_energies.append(mut[\"ddg\"])\n",
        "                mut_wild_predictions.append(mut[\"center_mut_wild_energy\"])\n",
        "                mut_min_predictions.append(mut[\"center_mut_max_energy\"])\n",
        "                entropy_predictions.append(mut[\"center_entropy\"])\n",
        "                neighbor_entropy_change_predictions.append(mut[\"weighted_neighbor_entropy_changes\"])\n",
        "                neighbor_energy_change_predictions.append(mut[\"weighted_neighbor_energy_changes\"])\n",
        "                center_neighbor_weight_check_w_m.append(mut[\"center_neighbor_weight_check_w_m\"])\n",
        "                V2_backward_weighted_neighbor_backward_KL.append(mut[\"V2_backward_weighted_neighbor_backward_KL\"])\n",
        "                sum_neighbor_embedding_change_m_w.append(mut[\"neighbor_embedding_change_m_w\"])\n",
        "                neighbor_message_change_m_w.append(mut[\"neighbor_message_change_m_w\"])\n",
        "\n",
        "print(len(experimental_energies),len(mut_wild_predictions))\n",
        "\n",
        "print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "print(pearsonr(experimental_energies,entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_entropy_change_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_energy_change_predictions))\n",
        "print(pearsonr(experimental_energies,center_neighbor_weight_check_w_m))\n",
        "print(pearsonr(experimental_energies,V2_backward_weighted_neighbor_backward_KL))\n",
        "print(pearsonr(experimental_energies,sum_neighbor_embedding_change_m_w))\n",
        "print(pearsonr(experimental_energies,neighbor_message_change_m_w))\n",
        "print(pearsonr(experimental_energies,pssm_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tyw_4erpj1C",
        "outputId": "7697adc6-8a0a-4cd1-8b78-9f669e7cd2f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "342 342\n",
            "(0.567391786943631, 1.5691298971421216e-30)\n",
            "(0.582062409268496, 2.1155606134818152e-32)\n",
            "(0.36369732334720606, 3.909041388529533e-12)\n",
            "(0.35227849671059386, 1.984763898648971e-11)\n",
            "(0.31869048055079785, 1.6397158704779038e-09)\n",
            "(-0.25388605312756196, 1.9732813632404045e-06)\n",
            "(0.1680061221141445, 0.0018221078320998286)\n",
            "(0.27457041703947704, 2.4882302717008426e-07)\n",
            "(0.06692694497904732, 0.21699824260362663)\n",
            "(0.25485992422573917, 1.7969755175311432e-06)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "df_Ssym = pd.DataFrame(\n",
        "\n",
        "    {'DDG' : experimental_energies,\n",
        "     'P_DP': mut_wild_predictions,\n",
        "     'P_ET': entropy_predictions,\n",
        "     'P_DEC': pssm_predictions,\n",
        "     'Neighbor_Energy_Change' : neighbor_energy_change_predictions,\n",
        "     'Neighbor_backward_KL' : V2_backward_weighted_neighbor_backward_KL,\n",
        "     'Neighbor_Entropy_Change' : neighbor_entropy_change_predictions,\n",
        "     'neighbor_attention_change_w/m' : center_neighbor_weight_check_w_m,\n",
        "     'neighbor_embedding_change' : sum_neighbor_embedding_change_m_w,\n",
        "     'neighbor_message_change' : neighbor_message_change_m_w  \n",
        "    })\n",
        "corr = df_Ssym.corr()\n",
        "\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(corr, \n",
        "        xticklabels=corr.columns,\n",
        "        yticklabels=corr.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "QlQuGW7f7KDy",
        "outputId": "04f323e4-a44b-4462-a079-01daae3d19ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1c3c0fa8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}