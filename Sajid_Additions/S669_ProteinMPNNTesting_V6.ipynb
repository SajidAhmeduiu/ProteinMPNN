{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S669_ProteinMPNNTesting_V6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e5408439a08d42d88661c0a2f32c8c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0da9cced688544638ed83e8d11c3a7c6",
              "IPY_MODEL_a316c99b9a8249ef8c3df8c7810a5eb9",
              "IPY_MODEL_d1f1c177118e4f5183861b5d6e1f95a3"
            ],
            "layout": "IPY_MODEL_b762c113e64846cebef75c715bd1cfbc"
          }
        },
        "0da9cced688544638ed83e8d11c3a7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b828e5b65ca541d590cd85f56fe65ea9",
            "placeholder": "​",
            "style": "IPY_MODEL_957a52ca0aa743469663558419a8fefd",
            "value": ""
          }
        },
        "a316c99b9a8249ef8c3df8c7810a5eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13a9ae8d5d0a465c80bffbcee2d6ddf0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a106aaef3c824bf5b486bccb52e4c537",
            "value": 1
          }
        },
        "d1f1c177118e4f5183861b5d6e1f95a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e52aace42b242f8bbfd935cbbc6df39",
            "placeholder": "​",
            "style": "IPY_MODEL_d12e077e8e1b428981586d63990d9d8c",
            "value": " 669/? [00:00&lt;00:00, 17968.34it/s]"
          }
        },
        "b762c113e64846cebef75c715bd1cfbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b828e5b65ca541d590cd85f56fe65ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "957a52ca0aa743469663558419a8fefd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13a9ae8d5d0a465c80bffbcee2d6ddf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a106aaef3c824bf5b486bccb52e4c537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e52aace42b242f8bbfd935cbbc6df39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12e077e8e1b428981586d63990d9d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d1cb0efb13e45aaa751e71a27a84bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bb47c1b12b642eda2f00ffe7a7b3807",
              "IPY_MODEL_fe5a021532e04e049613895d8fda3929",
              "IPY_MODEL_3ec9063329d141e1bf501bc539935d51"
            ],
            "layout": "IPY_MODEL_258084713f4f42fa9b1ef41992fb671b"
          }
        },
        "8bb47c1b12b642eda2f00ffe7a7b3807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1541a0c68c6b403894d45bf6bbd41c8e",
            "placeholder": "​",
            "style": "IPY_MODEL_5c2eab21538548ff86e256416ed3f6bd",
            "value": "100%"
          }
        },
        "fe5a021532e04e049613895d8fda3929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56c872a2c1fb4a058e8d7039e9052939",
            "max": 93,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dc40fdb1094444ca2eb14dbf253133f",
            "value": 93
          }
        },
        "3ec9063329d141e1bf501bc539935d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_330277f6e5aa444a8c3aa750c9ee5596",
            "placeholder": "​",
            "style": "IPY_MODEL_fd432bc45e6646c796889d8f18b578e6",
            "value": " 93/93 [01:04&lt;00:00,  1.50it/s]"
          }
        },
        "258084713f4f42fa9b1ef41992fb671b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1541a0c68c6b403894d45bf6bbd41c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c2eab21538548ff86e256416ed3f6bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56c872a2c1fb4a058e8d7039e9052939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc40fdb1094444ca2eb14dbf253133f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "330277f6e5aa444a8c3aa750c9ee5596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd432bc45e6646c796889d8f18b578e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99020b6675654210856919908788c155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c16b088071354d67b4046d3d75fdc5a6",
              "IPY_MODEL_d704309ba54e4facb212641947b2878e",
              "IPY_MODEL_bac383df87c94dada4058aafe9a38d0f"
            ],
            "layout": "IPY_MODEL_706c12c9d8b847f29562ae9f87d350e3"
          }
        },
        "c16b088071354d67b4046d3d75fdc5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5e5e159967848b7ba0add4ad9a4ae25",
            "placeholder": "​",
            "style": "IPY_MODEL_af14b86fea294b08825f0d5081d521a6",
            "value": ""
          }
        },
        "d704309ba54e4facb212641947b2878e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29c3ddaf5fae45a6840ecaaf68030f3f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2145d656e57e4bf181daa63cf74c738d",
            "value": 1
          }
        },
        "bac383df87c94dada4058aafe9a38d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f79b905f5bd4f809d3958930bcda025",
            "placeholder": "​",
            "style": "IPY_MODEL_97b6a5c98eb64a89ae1eac3a99a49097",
            "value": " 93/? [06:45&lt;00:00,  4.41s/it]"
          }
        },
        "706c12c9d8b847f29562ae9f87d350e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5e5e159967848b7ba0add4ad9a4ae25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af14b86fea294b08825f0d5081d521a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29c3ddaf5fae45a6840ecaaf68030f3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2145d656e57e4bf181daa63cf74c738d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f79b905f5bd4f809d3958930bcda025": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97b6a5c98eb64a89ae1eac3a99a49097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_wbcvVBv0QJ",
        "outputId": "20c2b330-ad71-4508-ac2d-14de01343983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import sys \n",
        "installation_path = \"/content/drive/MyDrive/Colab_Installations_V2\"\n",
        "# The path is being modified so that everything installed in the installation path can now be used without re-installing (in this case, I just need biopython)\n",
        "sys.path.insert(0,installation_path)\n",
        "protein_mpnn_path = \"/content/drive/MyDrive/Protein_MPNN_Digging/ProteinMPNN/vanilla_proteinmpnn\"\n",
        "sys.path.insert(0,protein_mpnn_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Protein_MPNN_Digging"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgTOgsabxBaC",
        "outputId": "77ab22f9-559c-404f-dd42-91234d116921"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Protein_MPNN_Digging\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import warnings\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, Subset\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import os\n",
        "from protein_mpnn_utils import loss_nll, loss_smoothed, gather_edges, gather_nodes, gather_nodes_t, cat_neighbors_nodes, _scores, _S_to_seq, tied_featurize\n",
        "from protein_mpnn_utils import StructureDataset, StructureDatasetPDB, ProteinMPNN\n",
        "from Bio.PDB import *\n",
        "\n",
        "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")"
      ],
      "metadata": {
        "id": "jX5ScMeGyLcy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from Bio.PDB.Polypeptide import *\n",
        "from string import ascii_uppercase"
      ],
      "metadata": {
        "id": "NBjszWagtiYL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = os.path.join(protein_mpnn_path,\"vanilla_model_weights\")\n",
        "model_name = \"v_48_020\"\n",
        "checkpoint_path = os.path.join(weights_path,model_name+\".pt\")"
      ],
      "metadata": {
        "id": "Z6ZHe2IIyy1G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, load and dig into the checkpoint object\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device) "
      ],
      "metadata": {
        "id": "JPE_pX8tzdUO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import json, time, os, sys, glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split, Subset\n",
        "\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "#A number of functions/classes are adopted from: https://github.com/jingraham/neurips19-graph-protein-design\n",
        "\n",
        "def _scores(S, log_probs, mask):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    criterion = torch.nn.NLLLoss(reduction='none')\n",
        "    loss = criterion(\n",
        "        log_probs.contiguous().view(-1,log_probs.size(-1)),\n",
        "        S.contiguous().view(-1)\n",
        "    ).view(S.size())\n",
        "    # The designable positions have mask set to 1.0, so this function seems to be returning the average score for the designable positions\n",
        "    scores = torch.sum(loss * mask, dim=-1) / torch.sum(mask, dim=-1)\n",
        "    return scores\n",
        "\n",
        "def _S_to_seq(S, mask):\n",
        "    # This is the decoding order\n",
        "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    seq = ''.join([alphabet[c] for c, m in zip(S.tolist(), mask.tolist()) if m > 0])\n",
        "    return seq\n",
        "\n",
        "def parse_PDB_biounits(x, atoms=['N','CA','C'], chain=None):\n",
        "  '''\n",
        "  input:  x = PDB filename\n",
        "          atoms = atoms to extract (optional)\n",
        "  output: (length, atoms, coords=(x,y,z)), sequence\n",
        "  '''\n",
        "\n",
        "  alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "  states = len(alpha_1)\n",
        "  alpha_3 = ['ALA','ARG','ASN','ASP','CYS','GLN','GLU','GLY','HIS','ILE',\n",
        "             'LEU','LYS','MET','PHE','PRO','SER','THR','TRP','TYR','VAL','GAP']\n",
        "  \n",
        "  # The following dictionaries are mapping from one-letter to 0-20 index,\n",
        "  # three-letter to 0-20 index,\n",
        "  # 0-20 index to one-letter,\n",
        "  # one-letter to three-letter, and vice-versa \n",
        "  aa_1_N = {a:n for n,a in enumerate(alpha_1)}\n",
        "  aa_3_N = {a:n for n,a in enumerate(alpha_3)}\n",
        "  aa_N_1 = {n:a for n,a in enumerate(alpha_1)}\n",
        "  aa_1_3 = {a:b for a,b in zip(alpha_1,alpha_3)}\n",
        "  aa_3_1 = {b:a for a,b in zip(alpha_1,alpha_3)}\n",
        "  \n",
        "  def AA_to_N(x):\n",
        "    # [\"ARND\"] -> [[0,1,2,3]]\n",
        "    x = np.array(x);\n",
        "    if x.ndim == 0: x = x[None]\n",
        "    return [[aa_1_N.get(a, states-1) for a in y] for y in x]\n",
        "  \n",
        "  def N_to_AA(x):\n",
        "    # [[0,1,2,3]] -> [\"ARND\"]\n",
        "    x = np.array(x);\n",
        "    if x.ndim == 1: x = x[None]\n",
        "    return [\"\".join([aa_N_1.get(a,\"-\") for a in y]) for y in x]\n",
        "\n",
        "  xyz,seq,min_resn,max_resn = {},{},1e6,-1e6\n",
        "  for line in open(x,\"rb\"):\n",
        "    line = line.decode(\"utf-8\",\"ignore\").rstrip()\n",
        "\n",
        "    if line[:6] == \"HETATM\" and line[17:17+3] == \"MSE\":\n",
        "      line = line.replace(\"HETATM\",\"ATOM  \")\n",
        "      line = line.replace(\"MSE\",\"MET\")\n",
        "\n",
        "    if line[:4] == \"ATOM\":\n",
        "      ch = line[21:22]\n",
        "      # If the input chain is not in the PDB file, which can be the case if the target chains are named differently in the runner script,\n",
        "      # this line will cause the output to have literally no information, this is the case for integer named chains\n",
        "      # that does not mean that this line is not doing its job correctly, this is just a constraint that input chain names and \n",
        "      # chain names in the PDB file have to be congruent\n",
        "      if ch == chain or chain is None:\n",
        "        atom = line[12:12+4].strip()\n",
        "        resi = line[17:17+3]\n",
        "        resn = line[22:22+5].strip()\n",
        "        x,y,z = [float(line[i:(i+8)]) for i in [30,38,46]]\n",
        "\n",
        "        if resn[-1].isalpha(): \n",
        "            resa,resn = resn[-1],int(resn[:-1])-1\n",
        "        else: \n",
        "            resa,resn = \"\",int(resn)-1\n",
        "#         resn = int(resn)\n",
        "        if resn < min_resn: \n",
        "            min_resn = resn\n",
        "        if resn > max_resn: \n",
        "            max_resn = resn\n",
        "        if resn not in xyz: \n",
        "            xyz[resn] = {}\n",
        "        if resa not in xyz[resn]: \n",
        "            xyz[resn][resa] = {}\n",
        "        if resn not in seq: \n",
        "            seq[resn] = {}\n",
        "        if resa not in seq[resn]: \n",
        "            seq[resn][resa] = resi\n",
        "\n",
        "        if atom not in xyz[resn][resa]:\n",
        "          xyz[resn][resa][atom] = np.array([x,y,z])\n",
        "\n",
        "  # convert to numpy arrays, fill in missing values\n",
        "  seq_,xyz_ = [],[]\n",
        "  try:\n",
        "      for resn in range(min_resn,max_resn+1):\n",
        "        if resn in seq:\n",
        "          for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k],20))\n",
        "        else: seq_.append(20)\n",
        "        if resn in xyz:\n",
        "          for k in sorted(xyz[resn]):\n",
        "            for atom in atoms:\n",
        "              if atom in xyz[resn][k]: xyz_.append(xyz[resn][k][atom])\n",
        "              else: xyz_.append(np.full(3,np.nan))\n",
        "        else:\n",
        "          for atom in atoms: xyz_.append(np.full(3,np.nan))\n",
        "      return np.array(xyz_).reshape(-1,len(atoms),3), N_to_AA(np.array(seq_))\n",
        "  except TypeError:\n",
        "      return 'no_chain', 'no_chain'\n",
        "\n",
        "### calling signature\n",
        "# pdb_dict_list = parse_PDB(pdb_path, input_chain_list=chain_list)\n",
        "def parse_PDB(path_to_pdb, input_chain_list=None):\n",
        "    c=0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V','W','X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v','w','x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "     \n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list  \n",
        " \n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    # Each of the biounits is a separate PDB file, so for running with a single PDB file like from colab, this loop will be executed only once\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {} \n",
        "        # This loop will be executed only once for single chain DDG type cases\n",
        "        for letter in chain_alphabet:\n",
        "            xyz, seq = parse_PDB_biounits(biounit, atoms=['N','CA','C','O'], chain=letter)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_'+letter]=seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                coords_dict_chain['N_chain_'+letter]=xyz[:,0,:].tolist()\n",
        "                coords_dict_chain['CA_chain_'+letter]=xyz[:,1,:].tolist()\n",
        "                coords_dict_chain['C_chain_'+letter]=xyz[:,2,:].tolist()\n",
        "                coords_dict_chain['O_chain_'+letter]=xyz[:,3,:].tolist()\n",
        "                my_dict['coords_chain_'+letter]=coords_dict_chain\n",
        "                s += 1\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        my_dict['name']=biounit[(fi+1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c+=1\n",
        "    return pdb_dict_list\n",
        "\n",
        "\n",
        "# X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta \n",
        "# = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "# fixed_pos_list = fixed_position_dict[b['name']][letter]\n",
        "# The trick will be to populate this fixed_position_dict from the calling function, and \n",
        "def tied_featurize(batch, device, chain_dict, fixed_position_dict=None, omit_AA_dict=None, tied_positions_dict=None, pssm_dict=None, bias_by_res_dict=None):\n",
        "    \"\"\" Pack and pad batch into torch tensors \"\"\"\n",
        "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    B = len(batch)\n",
        "    lengths = np.array([len(b['seq']) for b in batch], dtype=np.int32) #sum of chain seq lengths\n",
        "    L_max = max([len(b['seq']) for b in batch])\n",
        "    X = np.zeros([B, L_max, 4, 3])\n",
        "    residue_idx = -100*np.ones([B, L_max], dtype=np.int32)\n",
        "    # This \"chain_M\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of the single sequence as a consequence\n",
        "    chain_M = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    pssm_coef_all = np.zeros([B, L_max], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    pssm_bias_all = np.zeros([B, L_max, 21], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    pssm_log_odds_all = 10000.0*np.ones([B, L_max, 21], dtype=np.float32) #1.0 for the bits that need to be predicted\n",
        "    # This \"chain_M_pos\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of single sequence as a consequence\n",
        "    chain_M_pos = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    bias_by_res_all = np.zeros([B, L_max, 21], dtype=np.float32)\n",
        "    # This \"chain_encoding_all\" is the variable of interest for controlling which positions will be fixed vs. which will be designed\n",
        "    # For scoring function-based uses, I intend on sending the sequences one by one for not caring about the slow speed\n",
        "    # Therefore, B will be == 1\n",
        "    # So, for now, I just need to somehow manipulate the indexes corresponding to L_max which will be equal to the length of single sequence as a consequence\n",
        "    chain_encoding_all = np.zeros([B, L_max], dtype=np.int32) #1.0 for the bits that need to be predicted\n",
        "    S = np.zeros([B, L_max], dtype=np.int32)\n",
        "    omit_AA_mask = np.zeros([B, L_max, len(alphabet)], dtype=np.int32)\n",
        "    # Build the batch\n",
        "    letter_list_list = []\n",
        "    visible_list_list = []\n",
        "    masked_list_list = []\n",
        "    masked_chain_length_list_list = []\n",
        "    tied_pos_list_of_lists_list = []\n",
        "    #shuffle all chains before the main loop\n",
        "    for i, b in enumerate(batch):\n",
        "        # for my current energy function like usecase, the code will reach \"if and not else\" because chain_dict will not be None\n",
        "        if chain_dict != None:\n",
        "            ### Calling function argument assignment START\n",
        "            # chain_id_dict[pdb_dict_list[0]['name']] = (designed_chain_list, fixed_chain_list)\n",
        "            ### Calling function argument assignment END\n",
        "            masked_chains, visible_chains = chain_dict[b['name']] #masked_chains a list of chain letters to predict [A, D, F]\n",
        "        else:\n",
        "            masked_chains = [item[-1:] for item in list(b) if item[:10]=='seq_chain_']\n",
        "            visible_chains = []\n",
        "        num_chains = b['num_of_chains']\n",
        "        all_chains = masked_chains + visible_chains\n",
        "        #random.shuffle(all_chains)\n",
        "    # This for loop can be ignored since it will be executed only once in my single-chain or single-chain-at-a-time implementation\n",
        "    for i, b in enumerate(batch):\n",
        "        mask_dict = {}\n",
        "        a = 0\n",
        "        x_chain_list = []\n",
        "        chain_mask_list = []\n",
        "        # \"chain_seq_list\" will contain string format sequences of all the chains both fixed and designable \n",
        "        chain_seq_list = []\n",
        "        chain_encoding_list = []\n",
        "        c = 1\n",
        "        # \"letter_list\" will contain names of all the chains both fixed and designable\n",
        "        letter_list = []\n",
        "        global_idx_start_list = [0]\n",
        "        # \"visible_list\" will contain names of the fixed chains \n",
        "        visible_list = []\n",
        "        # \"masked_list\" will contain names of the designable chains\n",
        "        masked_list = []\n",
        "        masked_chain_length_list = []\n",
        "        fixed_position_mask_list = []\n",
        "        omit_AA_mask_list = []\n",
        "        pssm_coef_list = []\n",
        "        pssm_bias_list = []\n",
        "        pssm_log_odds_list = []\n",
        "        bias_by_res_list = []\n",
        "        l0 = 0\n",
        "        l1 = 0\n",
        "        # This loop will also be executed once for my single chain case,\n",
        "        # and since the same chain has both designable and fixed positions, the codes insides both of the if \n",
        "        # statements will be executed\n",
        "        for step, letter in enumerate(all_chains):\n",
        "            if letter in visible_chains:\n",
        "                letter_list.append(letter)\n",
        "                visible_list.append(letter)\n",
        "                chain_seq = b[f'seq_chain_{letter}']\n",
        "                chain_seq = ''.join([a if a!='-' else 'X' for a in chain_seq])\n",
        "                chain_length = len(chain_seq)\n",
        "                global_idx_start_list.append(global_idx_start_list[-1]+chain_length)\n",
        "                chain_coords = b[f'coords_chain_{letter}'] #this is a dictionary\n",
        "                # the \"chain_mask\" varies between fixed and designable chains (1.0 for designable chains which are maxed)\n",
        "                chain_mask = np.zeros(chain_length) #0.0 for visible chains\n",
        "                x_chain = np.stack([chain_coords[c] for c in [f'N_chain_{letter}', f'CA_chain_{letter}', f'C_chain_{letter}', f'O_chain_{letter}']], 1) #[chain_lenght,4,3]\n",
        "                x_chain_list.append(x_chain)\n",
        "                chain_mask_list.append(chain_mask)\n",
        "                chain_seq_list.append(chain_seq)\n",
        "                # \"chain_encoding_list\" contains numpy arrays corresponding to chains (each array corresponds to one chain),\n",
        "                # where all elements of the same array is the same value, which is equal to the index of the chain the it corresponds to\n",
        "                # by index, I mean index of the different numpy arrays annotating the chains\n",
        "                chain_encoding_list.append(c*np.ones(np.array(chain_mask).shape[0]))\n",
        "                # l0 points at the starting of the current chain and l1 points after the ending of the current chain\n",
        "                l1 += chain_length\n",
        "                # the only value i will have is 0 since it will be executed only once in my single-chain or single-chain-at-a-time implementation\n",
        "                # seems like the chains are separated by  \n",
        "                residue_idx[i, l0:l1] = 100*(c-1)+np.arange(l0, l1)\n",
        "                l0 += chain_length\n",
        "                c+=1\n",
        "                # The following variables are numpy arrays with entries corresponding to every position in the sequence\n",
        "                # appending these numpy arrays to a list indicates that the chains are added one after one\n",
        "                # same thing goes for the chain_mask and chain_seq variables declared above\n",
        "                # In code-block below in this cell, these lists of numpy arrays are going through np.concatenate(), which is creating\n",
        "                # the final numpy arrays containing co-ordinates, sequence identity, fixed position, masked position, PSSM bias, and everything\n",
        "                # required to pass the sequences through the model\n",
        "                ### START\n",
        "                fixed_position_mask = np.ones(chain_length)\n",
        "                fixed_position_mask_list.append(fixed_position_mask)\n",
        "                # The omit_AA_mask, pssm_coef, pssm_bias, \"bias_by_res_list\", all these numpy arrays are zero for the fixed positions\n",
        "                # since these positions are used as it is, while for the masked_positions, these values can get activated\n",
        "                # which is why the next if statement has several extra lines manipulating these variables according to the amount of information passed \n",
        "                omit_AA_mask_temp = np.zeros([chain_length, len(alphabet)], np.int32)\n",
        "                omit_AA_mask_list.append(omit_AA_mask_temp)\n",
        "                pssm_coef = np.zeros(chain_length)\n",
        "                pssm_bias = np.zeros([chain_length, 21])\n",
        "                pssm_log_odds = 10000.0*np.ones([chain_length, 21])\n",
        "                pssm_coef_list.append(pssm_coef)\n",
        "                pssm_bias_list.append(pssm_bias)\n",
        "                pssm_log_odds_list.append(pssm_log_odds)\n",
        "                bias_by_res_list.append(np.zeros([chain_length, 21]))\n",
        "                ### END\n",
        "            if letter in masked_chains:\n",
        "                masked_list.append(letter)\n",
        "                letter_list.append(letter)\n",
        "                chain_seq = b[f'seq_chain_{letter}']\n",
        "                chain_seq = ''.join([a if a!='-' else 'X' for a in chain_seq])\n",
        "                chain_length = len(chain_seq)\n",
        "                global_idx_start_list.append(global_idx_start_list[-1]+chain_length)\n",
        "                masked_chain_length_list.append(chain_length)\n",
        "                chain_coords = b[f'coords_chain_{letter}'] #this is a dictionary\n",
        "                chain_mask = np.ones(chain_length) #1.0 for masked\n",
        "                x_chain = np.stack([chain_coords[c] for c in [f'N_chain_{letter}', f'CA_chain_{letter}', f'C_chain_{letter}', f'O_chain_{letter}']], 1) #[chain_lenght,4,3]\n",
        "                x_chain_list.append(x_chain)\n",
        "                chain_mask_list.append(chain_mask)\n",
        "                chain_seq_list.append(chain_seq)\n",
        "                chain_encoding_list.append(c*np.ones(np.array(chain_mask).shape[0]))\n",
        "                l1 += chain_length\n",
        "                residue_idx[i, l0:l1] = 100*(c-1)+np.arange(l0, l1)\n",
        "                l0 += chain_length\n",
        "                c+=1\n",
        "                fixed_position_mask = np.ones(chain_length)\n",
        "                if fixed_position_dict!=None:\n",
        "                    fixed_pos_list = fixed_position_dict[b['name']][letter]\n",
        "                    if fixed_pos_list:\n",
        "                        # seems like \"fixed_pos_list\"  can be an 1-indexed integer list corresponding to positions in \"chain_seq\"\n",
        "                        # this thing ultimately controls which positions in the designable chain will be masked, which is why the fixed \n",
        "                        # positions are set to 0.0 since those positions will not be maxed (1 if maxed, 0 if not maxed)\n",
        "                        fixed_position_mask[np.array(fixed_pos_list)-1] = 0.0\n",
        "                fixed_position_mask_list.append(fixed_position_mask)\n",
        "                omit_AA_mask_temp = np.zeros([chain_length, len(alphabet)], np.int32)\n",
        "                # For my current energy function like usecase, \"omit_AA_dict\" will be None, so the following loop can be ignored\n",
        "                if omit_AA_dict!=None:\n",
        "                    for item in omit_AA_dict[b['name']][letter]:\n",
        "                        idx_AA = np.array(item[0])-1\n",
        "                        AA_idx = np.array([np.argwhere(np.array(list(alphabet))== AA)[0][0] for AA in item[1]]).repeat(idx_AA.shape[0])\n",
        "                        idx_ = np.array([[a, b] for a in idx_AA for b in AA_idx])\n",
        "                        omit_AA_mask_temp[idx_[:,0], idx_[:,1]] = 1\n",
        "                omit_AA_mask_list.append(omit_AA_mask_temp)\n",
        "                pssm_coef = np.zeros(chain_length)\n",
        "                pssm_bias = np.zeros([chain_length, 21])\n",
        "                pssm_log_odds = 10000.0*np.ones([chain_length, 21])\n",
        "                if pssm_dict:\n",
        "                    if pssm_dict[b['name']][letter]:\n",
        "                        pssm_coef = pssm_dict[b['name']][letter]['pssm_coef']\n",
        "                        pssm_bias = pssm_dict[b['name']][letter]['pssm_bias']\n",
        "                        pssm_log_odds = pssm_dict[b['name']][letter]['pssm_log_odds']\n",
        "                pssm_coef_list.append(pssm_coef)\n",
        "                pssm_bias_list.append(pssm_bias)\n",
        "                pssm_log_odds_list.append(pssm_log_odds)\n",
        "                if bias_by_res_dict:\n",
        "                    bias_by_res_list.append(bias_by_res_dict[b['name']][letter])\n",
        "                else:\n",
        "                    bias_by_res_list.append(np.zeros([chain_length, 21]))\n",
        "\n",
        "        ### TIED position START\n",
        "        # Since there will technically be no tied positions for my single chain energy-based usecase for now,\n",
        "        # I do not need to dig into this part of the code\n",
        "        letter_list_np = np.array(letter_list)\n",
        "        tied_pos_list_of_lists = []\n",
        "        tied_beta = np.ones(L_max)\n",
        "        if tied_positions_dict!=None:\n",
        "            tied_pos_list = tied_positions_dict[b['name']]\n",
        "            if tied_pos_list:\n",
        "                set_chains_tied = set(list(itertools.chain(*[list(item) for item in tied_pos_list])))\n",
        "                for tied_item in tied_pos_list:\n",
        "                    one_list = []\n",
        "                    for k, v in tied_item.items():\n",
        "                        start_idx = global_idx_start_list[np.argwhere(letter_list_np == k)[0][0]]\n",
        "                        if isinstance(v[0], list):\n",
        "                            for v_count in range(len(v[0])):\n",
        "                                one_list.append(start_idx+v[0][v_count]-1)#make 0 to be the first\n",
        "                                tied_beta[start_idx+v[0][v_count]-1] = v[1][v_count]\n",
        "                        else:\n",
        "                            for v_ in v:\n",
        "                                one_list.append(start_idx+v_-1)#make 0 to be the first\n",
        "                    tied_pos_list_of_lists.append(one_list)\n",
        "        tied_pos_list_of_lists_list.append(tied_pos_list_of_lists)\n",
        "        ### TIED position END\n",
        " \n",
        "        # Interestingly, although the backbone atom coordinates are used for generating edge features,\n",
        "        # the \"x\" in the following line contains the coodinates of the backbone atoms \n",
        "        x = np.concatenate(x_chain_list,0) #[L, 4, 3]\n",
        "        # \"all_sequence\" is a string where all the chain sequences have been put one after another\n",
        "        all_sequence = \"\".join(chain_seq_list)\n",
        "        # This \"chain_mask_list\" and \"m_pos\" below are the variables of interest if these actually contain full information regarding the\n",
        "        # fixed vs. variable positions definitions \n",
        "        # consequently, since these are concatenated numpy arrays of numpy arrays inside the lists \"chain_mask_list\" and \"fixed_position_mask_list\",\n",
        "        # when those lists are populated in the above code-block with binary numpy arrays \"fixed_position_mask\" and \"fixed_position_mask\" corresponding to \n",
        "        # each of the chains,\n",
        "        # that is where all the controlling needs to be done from\n",
        "        m = np.concatenate(chain_mask_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        # \"chain_encoding_list\" contains numpy arrays corresponding to chains (each array corresponds to one chain),\n",
        "        # where all elements of the same array is the same value, which is equal to the index of the chain the it corresponds to\n",
        "        # by index, I mean index of the different numpy arrays annotating the chains\n",
        "        chain_encoding = np.concatenate(chain_encoding_list,0)\n",
        "        m_pos = np.concatenate(fixed_position_mask_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "\n",
        "        pssm_coef_ = np.concatenate(pssm_coef_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        pssm_bias_ = np.concatenate(pssm_bias_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "        pssm_log_odds_ = np.concatenate(pssm_log_odds_list,0) #[L,], 1.0 for places that need to be predicted\n",
        "\n",
        "        bias_by_res_ = np.concatenate(bias_by_res_list, 0)  #[L,21], 0.0 for places where AA frequencies don't need to be tweaked\n",
        "\n",
        "        # Interestingly, all the chains are padded to the same length\n",
        "        # this has to be done most probably because the same layers are applied to all chains\n",
        "        # but for single chain or homomer cases, this should not be an issue\n",
        "        # need to be sure later why this is done\n",
        "        # does not significant when it comes to single chain energy-based usecase\n",
        "        # PADDING START\n",
        "        l = len(all_sequence)\n",
        "        x_pad = np.pad(x, [[0,L_max-l], [0,0], [0,0]], 'constant', constant_values=(np.nan, ))\n",
        "        X[i,:,:,:] = x_pad\n",
        "\n",
        "        m_pad = np.pad(m, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        m_pos_pad = np.pad(m_pos, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        omit_AA_mask_pad = np.pad(np.concatenate(omit_AA_mask_list,0), [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        chain_M[i,:] = m_pad\n",
        "        chain_M_pos[i,:] = m_pos_pad\n",
        "        omit_AA_mask[i,] = omit_AA_mask_pad\n",
        "\n",
        "        chain_encoding_pad = np.pad(chain_encoding, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        chain_encoding_all[i,:] = chain_encoding_pad\n",
        "\n",
        "        pssm_coef_pad = np.pad(pssm_coef_, [[0,L_max-l]], 'constant', constant_values=(0.0, ))\n",
        "        pssm_bias_pad = np.pad(pssm_bias_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "        pssm_log_odds_pad = np.pad(pssm_log_odds_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "\n",
        "        pssm_coef_all[i,:] = pssm_coef_pad\n",
        "        pssm_bias_all[i,:] = pssm_bias_pad\n",
        "        pssm_log_odds_all[i,:] = pssm_log_odds_pad\n",
        "\n",
        "        bias_by_res_pad = np.pad(bias_by_res_, [[0,L_max-l], [0,0]], 'constant', constant_values=(0.0, ))\n",
        "        bias_by_res_all[i,:] = bias_by_res_pad\n",
        "        # PADDING END\n",
        "\n",
        "        # Convert to labels\n",
        "        indices = np.asarray([alphabet.index(a) for a in all_sequence], dtype=np.int32)\n",
        "        S[i, :l] = indices\n",
        "        letter_list_list.append(letter_list)\n",
        "        visible_list_list.append(visible_list)\n",
        "        masked_list_list.append(masked_list)\n",
        "        masked_chain_length_list_list.append(masked_chain_length_list)\n",
        "\n",
        "\n",
        "    isnan = np.isnan(X)\n",
        "    mask = np.isfinite(np.sum(X,(2,3))).astype(np.float32)\n",
        "    X[isnan] = 0.\n",
        "\n",
        "    # Conversion\n",
        "    pssm_coef_all = torch.from_numpy(pssm_coef_all).to(dtype=torch.float32, device=device)\n",
        "    pssm_bias_all = torch.from_numpy(pssm_bias_all).to(dtype=torch.float32, device=device)\n",
        "    pssm_log_odds_all = torch.from_numpy(pssm_log_odds_all).to(dtype=torch.float32, device=device)\n",
        "\n",
        "    tied_beta = torch.from_numpy(tied_beta).to(dtype=torch.float32, device=device)\n",
        "\n",
        "    jumps = ((residue_idx[:,1:]-residue_idx[:,:-1])==1).astype(np.float32)\n",
        "    bias_by_res_all = torch.from_numpy(bias_by_res_all).to(dtype=torch.float32, device=device)\n",
        "    phi_mask = np.pad(jumps, [[0,0],[1,0]])\n",
        "    psi_mask = np.pad(jumps, [[0,0],[0,1]])\n",
        "    omega_mask = np.pad(jumps, [[0,0],[0,1]])\n",
        "    dihedral_mask = np.concatenate([phi_mask[:,:,None], psi_mask[:,:,None], omega_mask[:,:,None]], -1) #[B,L,3]\n",
        "    dihedral_mask = torch.from_numpy(dihedral_mask).to(dtype=torch.float32, device=device)\n",
        "    residue_idx = torch.from_numpy(residue_idx).to(dtype=torch.long,device=device)\n",
        "    S = torch.from_numpy(S).to(dtype=torch.long,device=device)\n",
        "    X = torch.from_numpy(X).to(dtype=torch.float32, device=device)\n",
        "    mask = torch.from_numpy(mask).to(dtype=torch.float32, device=device)\n",
        "    chain_M = torch.from_numpy(chain_M).to(dtype=torch.float32, device=device)\n",
        "    chain_M_pos = torch.from_numpy(chain_M_pos).to(dtype=torch.float32, device=device)\n",
        "    omit_AA_mask = torch.from_numpy(omit_AA_mask).to(dtype=torch.float32, device=device)\n",
        "    chain_encoding_all = torch.from_numpy(chain_encoding_all).to(dtype=torch.long, device=device)\n",
        "    # in general, in this return statement, *_list_list has the list inside list format because the outer list corresponds to \"batch_clones\", \n",
        "    # whereas the inner list corresponds to \"chains\" for each of the elements of \"batch_clones\"\n",
        "    # \"masked_list_list\" contains names of the designable chains (which is my target for single chain energy), whereas \"visible_list_list\" \n",
        "    # contains names of the fixed chains (which should be empty for my single chain energy)\n",
        "    # for my single chain energy case, \"letter_list_list\" should be equal to \"masked_list_list\", and three lists should have one list for now\n",
        "    # \"chain_encoding_all\" should also contain chain-index related to the only single chain which should be 0 (all 0s)\n",
        "    # the last lists starting from \"tied_pos_list_of_lists_list\" to the end should be irrelevant for my single chain energy case\n",
        "    # but still it would be good to check the values of these irrelevant lists, and get an idea if everything makes sense or not\n",
        "    # \"chain_M_pos\" contains values from \"fixed_position_mask\" through \"m_pos\", which should get populated with 0.0 for fixed positions\n",
        "    # and 1.0 for designable positions, which can be controlled through the , which\n",
        "    # is controlled by \"fixed_position_dict\" input to this function from the running script\n",
        "    # \"chain_M\" is formed from \"m_pad\" which comes from \"m\" which comes from chain_mask = np.ones(chain_length) #1.0 for masked\n",
        "    # so, for my single chain energy usecase, \"chain_M\" should be all 1.0s with the same length as chain_M_pos\n",
        "    # I do not think \"X\", \"S\", and \"mask\" need to be manipulated for now \n",
        "    return X, S, mask, lengths, chain_M, chain_encoding_all, letter_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef_all, pssm_bias_all, pssm_log_odds_all, bias_by_res_all, tied_beta\n",
        "\n",
        "\n",
        "# No need to dig into this loss function for now\n",
        "def loss_nll(S, log_probs, mask):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    criterion = torch.nn.NLLLoss(reduction='none')\n",
        "    loss = criterion(\n",
        "        log_probs.contiguous().view(-1, log_probs.size(-1)), S.contiguous().view(-1)\n",
        "    ).view(S.size())\n",
        "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
        "    return loss, loss_av\n",
        "\n",
        "# No need to dig into this label smoothing stuff for now\n",
        "def loss_smoothed(S, log_probs, mask, weight=0.1):\n",
        "    \"\"\" Negative log probabilities \"\"\"\n",
        "    S_onehot = torch.nn.functional.one_hot(S, 21).float()\n",
        "\n",
        "    # Label smoothing\n",
        "    S_onehot = S_onehot + weight / float(S_onehot.size(-1))\n",
        "    S_onehot = S_onehot / S_onehot.sum(-1, keepdim=True)\n",
        "\n",
        "    loss = -(S_onehot * log_probs).sum(-1)\n",
        "    loss_av = torch.sum(loss * mask) / torch.sum(mask)\n",
        "    return loss, loss_av\n",
        "\n",
        "# Objects of this class can be indexed since dunder methods __len()__ and __getitem()__ have been implemented, which \n",
        "# indexes a list that has been declared as an instance variable in the constructor,\n",
        "# and each element of that underlying list is a dictionary containing information regarding a specific sequence\n",
        "class StructureDataset():\n",
        "    def __init__(self, jsonl_file, verbose=True, truncate=None, max_length=100,\n",
        "        alphabet='ACDEFGHIKLMNPQRSTVWYX-'):\n",
        "        alphabet_set = set([a for a in alphabet])\n",
        "        discard_count = {\n",
        "            'bad_chars': 0,\n",
        "            'too_long': 0,\n",
        "            'bad_seq_length': 0\n",
        "        }\n",
        "\n",
        "        with open(jsonl_file) as f:\n",
        "            self.data = []\n",
        "\n",
        "            lines = f.readlines()\n",
        "            start = time.time()\n",
        "            for i, line in enumerate(lines):\n",
        "                entry = json.loads(line)\n",
        "                seq = entry['seq'] \n",
        "                name = entry['name']\n",
        "\n",
        "                # Convert raw coords to np arrays\n",
        "                #for key, val in entry['coords'].items():\n",
        "                #    entry['coords'][key] = np.asarray(val)\n",
        "\n",
        "                # Check if in alphabet\n",
        "                bad_chars = set([s for s in seq]).difference(alphabet_set)\n",
        "                if len(bad_chars) == 0:\n",
        "                    if len(entry['seq']) <= max_length:\n",
        "                        if True:\n",
        "                            self.data.append(entry)\n",
        "                        else:\n",
        "                            discard_count['bad_seq_length'] += 1\n",
        "                    else:\n",
        "                        discard_count['too_long'] += 1\n",
        "                else:\n",
        "                    print(name, bad_chars, entry['seq'])\n",
        "                    discard_count['bad_chars'] += 1\n",
        "\n",
        "                # Truncate early\n",
        "                if truncate is not None and len(self.data) == truncate:\n",
        "                    return\n",
        "\n",
        "                if verbose and (i + 1) % 1000 == 0:\n",
        "                    elapsed = time.time() - start\n",
        "                    print('{} entries ({} loaded) in {:.1f} s'.format(len(self.data), i+1, elapsed))\n",
        "\n",
        "            print('discarded', discard_count)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "\n",
        "# Objects of this class can be indexed since dunder methods __len()__ and __getitem()__ have been implemented, which \n",
        "# indexes a list that has been declared as an instance variable in the constructor,\n",
        "# and each element of that underlying list is a dictionary containing information regarding a specific structure,\n",
        "# seems like a structure-specific version of the above method which deals with sequences \n",
        "class StructureDatasetPDB():\n",
        "    def __init__(self, pdb_dict_list, verbose=True, truncate=None, max_length=100,\n",
        "        alphabet='ACDEFGHIKLMNPQRSTVWYX-'):\n",
        "        alphabet_set = set([a for a in alphabet])\n",
        "        discard_count = {\n",
        "            'bad_chars': 0,\n",
        "            'too_long': 0,\n",
        "            'bad_seq_length': 0\n",
        "        }\n",
        "\n",
        "        self.data = []\n",
        "\n",
        "        start = time.time()\n",
        "        # elements of pdb_dict_list are dictionaries containing information regarding a specific pdb file\n",
        "        for i, entry in enumerate(pdb_dict_list):\n",
        "            seq = entry['seq']\n",
        "            name = entry['name']\n",
        "\n",
        "            bad_chars = set([s for s in seq]).difference(alphabet_set)\n",
        "            if len(bad_chars) == 0:\n",
        "                if len(entry['seq']) <= max_length:\n",
        "                    self.data.append(entry)\n",
        "                else:\n",
        "                    discard_count['too_long'] += 1\n",
        "            else:\n",
        "                discard_count['bad_chars'] += 1\n",
        "\n",
        "            # Truncate early\n",
        "            if truncate is not None and len(self.data) == truncate:\n",
        "                return\n",
        "\n",
        "            if verbose and (i + 1) % 1000 == 0:\n",
        "                elapsed = time.time() - start\n",
        "\n",
        "            #print('Discarded', discard_count)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "\n",
        "    \n",
        "class StructureLoader():\n",
        "    def __init__(self, dataset, batch_size=100, shuffle=True,\n",
        "        collate_fn=lambda x:x, drop_last=False):\n",
        "        self.dataset = dataset\n",
        "        self.size = len(dataset)\n",
        "        self.lengths = [len(dataset[i]['seq']) for i in range(self.size)]\n",
        "        self.batch_size = batch_size\n",
        "        sorted_ix = np.argsort(self.lengths)\n",
        "\n",
        "        # Cluster into batches of similar sizes\n",
        "        clusters, batch = [], []\n",
        "        batch_max = 0\n",
        "        for ix in sorted_ix:\n",
        "            size = self.lengths[ix]\n",
        "            if size * (len(batch) + 1) <= self.batch_size:\n",
        "                batch.append(ix)\n",
        "                batch_max = size\n",
        "            else:\n",
        "                clusters.append(batch)\n",
        "                batch, batch_max = [], 0\n",
        "        if len(batch) > 0:\n",
        "            clusters.append(batch)\n",
        "        self.clusters = clusters\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.clusters)\n",
        "\n",
        "    def __iter__(self):\n",
        "        np.random.shuffle(self.clusters)\n",
        "        for b_idx in self.clusters:\n",
        "            batch = [self.dataset[i] for i in b_idx]\n",
        "            yield batch\n",
        "            \n",
        "            \n",
        "            \n",
        "# The following gather functions\n",
        "def gather_edges(edges, neighbor_idx):\n",
        "    # Features [B,N,N,C] at Neighbor indices [B,N,K] => Neighbor features [B,N,K,C]\n",
        "    neighbors = neighbor_idx.unsqueeze(-1).expand(-1, -1, -1, edges.size(-1))\n",
        "    edge_features = torch.gather(edges, 2, neighbors)\n",
        "    return edge_features\n",
        "\n",
        "def gather_nodes(nodes, neighbor_idx):\n",
        "    # Features [B,N,C] at Neighbor indices [B,N,K] => [B,N,K,C]\n",
        "    # Flatten and expand indices per batch [B,N,K] => [B,NK] => [B,NK,C]\n",
        "    neighbors_flat = neighbor_idx.view((neighbor_idx.shape[0], -1))\n",
        "    neighbors_flat = neighbors_flat.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
        "    # Gather and re-pack\n",
        "    neighbor_features = torch.gather(nodes, 1, neighbors_flat)\n",
        "    neighbor_features = neighbor_features.view(list(neighbor_idx.shape)[:3] + [-1])\n",
        "    return neighbor_features\n",
        "\n",
        "def gather_nodes_t(nodes, neighbor_idx):\n",
        "    # Features [B,N,C] at Neighbor index [B,K] => Neighbor features[B,K,C]\n",
        "    idx_flat = neighbor_idx.unsqueeze(-1).expand(-1, -1, nodes.size(2))\n",
        "    neighbor_features = torch.gather(nodes, 1, idx_flat)\n",
        "    return neighbor_features\n",
        "\n",
        "def cat_neighbors_nodes(h_nodes, h_neighbors, E_idx):\n",
        "    h_nodes = gather_nodes(h_nodes, E_idx)\n",
        "    h_nn = torch.cat([h_neighbors, h_nodes], -1)\n",
        "    return h_nn\n",
        "\n",
        "\n",
        "class EncLayer(nn.Module):\n",
        "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
        "        super(EncLayer, self).__init__()\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_in = num_in\n",
        "        self.scale = scale\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(num_hidden)\n",
        "        self.norm2 = nn.LayerNorm(num_hidden)\n",
        "        self.norm3 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W11 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W12 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W13 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
        "\n",
        "    def forward(self, h_V, h_E, E_idx, mask_V=None, mask_attend=None):\n",
        "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
        "\n",
        "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
        "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
        "        if mask_attend is not None:\n",
        "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
        "        dh = torch.sum(h_message, -2) / self.scale\n",
        "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
        "\n",
        "        dh = self.dense(h_V)\n",
        "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
        "        if mask_V is not None:\n",
        "            mask_V = mask_V.unsqueeze(-1)\n",
        "            h_V = mask_V * h_V\n",
        "\n",
        "        h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_EV.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_EV], -1)\n",
        "        h_message = self.W13(self.act(self.W12(self.act(self.W11(h_EV)))))\n",
        "        h_E = self.norm3(h_E + self.dropout3(h_message))\n",
        "        return h_V, h_E\n",
        "\n",
        "\n",
        "class DecLayer(nn.Module):\n",
        "    def __init__(self, num_hidden, num_in, dropout=0.1, num_heads=None, scale=30):\n",
        "        super(DecLayer, self).__init__()\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_in = num_in\n",
        "        self.scale = scale\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(num_hidden)\n",
        "        self.norm2 = nn.LayerNorm(num_hidden)\n",
        "\n",
        "        self.W1 = nn.Linear(num_hidden + num_in, num_hidden, bias=True)\n",
        "        self.W2 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.W3 = nn.Linear(num_hidden, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
        "\n",
        "    def forward(self, h_V, h_E, mask_V=None, mask_attend=None):\n",
        "        \"\"\" Parallel computation of full transformer layer \"\"\"\n",
        "\n",
        "        # Concatenate h_V_i to h_E_ij\n",
        "        h_V_expand = h_V.unsqueeze(-2).expand(-1,-1,h_E.size(-2),-1)\n",
        "        h_EV = torch.cat([h_V_expand, h_E], -1)\n",
        "\n",
        "        # Maybe, length of the message vector can serve as attention\n",
        "        h_message = self.W3(self.act(self.W2(self.act(self.W1(h_EV)))))\n",
        "        # the mask attend here is most probably just for zeroing out the padded positions\n",
        "        # I do not think it will matter that much\n",
        "        if mask_attend is not None:\n",
        "            h_message = mask_attend.unsqueeze(-1) * h_message\n",
        "            # why divide by 30 when we are dealing with 48 neighbors in the current version of the model?\n",
        "        # Let me check the messages corresponding to \n",
        "        dh = torch.sum(h_message, -2) / self.scale\n",
        "\n",
        "        h_V = self.norm1(h_V + self.dropout1(dh))\n",
        "\n",
        "        # Position-wise feedforward\n",
        "        dh = self.dense(h_V)\n",
        "        h_V = self.norm2(h_V + self.dropout2(dh))\n",
        "\n",
        "        if mask_V is not None:\n",
        "            mask_V = mask_V.unsqueeze(-1)\n",
        "            h_V = mask_V * h_V\n",
        "\n",
        "        # \"h_message\" can be returned without dividing by \"self.scale\" also\n",
        "        return h_V, (h_message/self.scale) \n",
        "\n",
        "\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, num_hidden, num_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.W_in = nn.Linear(num_hidden, num_ff, bias=True)\n",
        "        self.W_out = nn.Linear(num_ff, num_hidden, bias=True)\n",
        "        self.act = torch.nn.GELU()\n",
        "    def forward(self, h_V):\n",
        "        h = self.act(self.W_in(h_V))\n",
        "        h = self.W_out(h)\n",
        "        return h\n",
        "\n",
        "class PositionalEncodings(nn.Module):\n",
        "    def __init__(self, num_embeddings, max_relative_feature=32):\n",
        "        super(PositionalEncodings, self).__init__()\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.max_relative_feature = max_relative_feature\n",
        "        self.linear = nn.Linear(2*max_relative_feature+1+1, num_embeddings)\n",
        "\n",
        "    def forward(self, offset, mask):\n",
        "        d = torch.clip(offset + self.max_relative_feature, 0, 2*self.max_relative_feature)*mask + (1-mask)*(2*self.max_relative_feature+1)\n",
        "        d_onehot = torch.nn.functional.one_hot(d, 2*self.max_relative_feature+1+1)\n",
        "        E = self.linear(d_onehot.float())\n",
        "        return E\n",
        "\n",
        "# Does not look like this function needs to be modified for now to use the model as sort of an energy function\n",
        "# The only thing that could do something is \"top_k\", which can be changed for considering more or less neighbors\n",
        "# for each of the nodes, but that too I think does not matter if the default value of top_k is updated by parameter passing\n",
        "# This function is called from the model itself with node_features=128, edge_features=128, and top_k=48\n",
        "# ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
        "class ProteinFeatures(nn.Module):\n",
        "    def __init__(self, edge_features, node_features, num_positional_embeddings=16,\n",
        "        num_rbf=16, top_k=30, augment_eps=0., num_chain_embeddings=16):\n",
        "        \"\"\" Extract protein features \"\"\"\n",
        "        super(ProteinFeatures, self).__init__()\n",
        "        self.edge_features = edge_features\n",
        "        self.node_features = node_features\n",
        "        self.top_k = top_k\n",
        "        self.augment_eps = augment_eps \n",
        "        self.num_rbf = num_rbf\n",
        "        self.num_positional_embeddings = num_positional_embeddings\n",
        "\n",
        "        self.embeddings = PositionalEncodings(num_positional_embeddings)\n",
        "        node_in, edge_in = 6, num_positional_embeddings + num_rbf*25\n",
        "        self.edge_embedding = nn.Linear(edge_in, edge_features, bias=False)\n",
        "        self.norm_edges = nn.LayerNorm(edge_features)\n",
        "\n",
        "    # the output of this function MUST be analyzed either directly or via some other function to \n",
        "    # understand how to get \"index/position\" of neighbors\n",
        "    def _dist(self, X, mask, eps=1E-6):\n",
        "        mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
        "        dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
        "        D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
        "        D_max, _ = torch.max(D, -1, keepdim=True)\n",
        "        D_adjust = D + (1. - mask_2D) * D_max\n",
        "        sampled_top_k = self.top_k\n",
        "        D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(self.top_k, X.shape[1]), dim=-1, largest=False)\n",
        "        return D_neighbors, E_idx\n",
        "\n",
        "    def _rbf(self, D):\n",
        "        device = D.device\n",
        "        D_min, D_max, D_count = 2., 22., self.num_rbf\n",
        "        D_mu = torch.linspace(D_min, D_max, D_count, device=device)\n",
        "        D_mu = D_mu.view([1,1,1,-1])\n",
        "        D_sigma = (D_max - D_min) / D_count\n",
        "        D_expand = torch.unsqueeze(D, -1)\n",
        "        RBF = torch.exp(-((D_expand - D_mu) / D_sigma)**2)\n",
        "        return RBF\n",
        "\n",
        "    def _get_rbf(self, A, B, E_idx):\n",
        "        D_A_B = torch.sqrt(torch.sum((A[:,:,None,:] - B[:,None,:,:])**2,-1) + 1e-6) #[B, L, L]\n",
        "        D_A_B_neighbors = gather_edges(D_A_B[:,:,:,None], E_idx)[:,:,:,0] #[B,L,K]\n",
        "        RBF_A_B = self._rbf(D_A_B_neighbors)\n",
        "        return RBF_A_B\n",
        "\n",
        "    # this function will be called with the arguments as forward(), but will return information regarding \n",
        "    # the neighbors which I will figure out a way to parse\n",
        "    def return_neighbor_info(self, X, mask, residue_idx, chain_labels):\n",
        "        b = X[:,:,1,:] - X[:,:,0,:]\n",
        "        c = X[:,:,2,:] - X[:,:,1,:]\n",
        "        a = torch.cross(b, c, dim=-1)\n",
        "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "        Ca = X[:,:,1,:]\n",
        "        N = X[:,:,0,:]\n",
        "        C = X[:,:,2,:]\n",
        "        O = X[:,:,3,:]\n",
        " \n",
        "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
        "\n",
        "\n",
        "    def forward(self, X, mask, residue_idx, chain_labels):\n",
        "        if self.augment_eps > 0:\n",
        "            X = X + self.augment_eps * torch.randn_like(X)\n",
        "        \n",
        "        b = X[:,:,1,:] - X[:,:,0,:]\n",
        "        c = X[:,:,2,:] - X[:,:,1,:]\n",
        "        a = torch.cross(b, c, dim=-1)\n",
        "        Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "        Ca = X[:,:,1,:]\n",
        "        N = X[:,:,0,:]\n",
        "        C = X[:,:,2,:]\n",
        "        O = X[:,:,3,:]\n",
        " \n",
        "        D_neighbors, E_idx = self._dist(Ca, mask)\n",
        "\n",
        "        RBF_all = []\n",
        "        RBF_all.append(self._rbf(D_neighbors)) #Ca-Ca\n",
        "        RBF_all.append(self._get_rbf(N, N, E_idx)) #N-N\n",
        "        RBF_all.append(self._get_rbf(C, C, E_idx)) #C-C\n",
        "        RBF_all.append(self._get_rbf(O, O, E_idx)) #O-O\n",
        "        RBF_all.append(self._get_rbf(Cb, Cb, E_idx)) #Cb-Cb\n",
        "        RBF_all.append(self._get_rbf(Ca, N, E_idx)) #Ca-N\n",
        "        RBF_all.append(self._get_rbf(Ca, C, E_idx)) #Ca-C\n",
        "        RBF_all.append(self._get_rbf(Ca, O, E_idx)) #Ca-O\n",
        "        RBF_all.append(self._get_rbf(Ca, Cb, E_idx)) #Ca-Cb\n",
        "        RBF_all.append(self._get_rbf(N, C, E_idx)) #N-C\n",
        "        RBF_all.append(self._get_rbf(N, O, E_idx)) #N-O\n",
        "        RBF_all.append(self._get_rbf(N, Cb, E_idx)) #N-Cb\n",
        "        RBF_all.append(self._get_rbf(Cb, C, E_idx)) #Cb-C\n",
        "        RBF_all.append(self._get_rbf(Cb, O, E_idx)) #Cb-O\n",
        "        RBF_all.append(self._get_rbf(O, C, E_idx)) #O-C\n",
        "        RBF_all.append(self._get_rbf(N, Ca, E_idx)) #N-Ca\n",
        "        RBF_all.append(self._get_rbf(C, Ca, E_idx)) #C-Ca\n",
        "        RBF_all.append(self._get_rbf(O, Ca, E_idx)) #O-Ca\n",
        "        RBF_all.append(self._get_rbf(Cb, Ca, E_idx)) #Cb-Ca\n",
        "        RBF_all.append(self._get_rbf(C, N, E_idx)) #C-N\n",
        "        RBF_all.append(self._get_rbf(O, N, E_idx)) #O-N\n",
        "        RBF_all.append(self._get_rbf(Cb, N, E_idx)) #Cb-N\n",
        "        RBF_all.append(self._get_rbf(C, Cb, E_idx)) #C-Cb\n",
        "        RBF_all.append(self._get_rbf(O, Cb, E_idx)) #O-Cb\n",
        "        RBF_all.append(self._get_rbf(C, O, E_idx)) #C-O\n",
        "        RBF_all = torch.cat(tuple(RBF_all), dim=-1)\n",
        "\n",
        "        offset = residue_idx[:,:,None]-residue_idx[:,None,:]\n",
        "        offset = gather_edges(offset[:,:,:,None], E_idx)[:,:,:,0] #[B, L, K]\n",
        "\n",
        "        d_chains = ((chain_labels[:, :, None] - chain_labels[:,None,:])==0).long() #find self vs non-self interaction\n",
        "        E_chains = gather_edges(d_chains[:,:,:,None], E_idx)[:,:,:,0]\n",
        "        E_positional = self.embeddings(offset.long(), E_chains)\n",
        "        E = torch.cat((E_positional, RBF_all), -1)\n",
        "        E = self.edge_embedding(E)\n",
        "        E = self.norm_edges(E)\n",
        "        return E, E_idx \n",
        "\n",
        "\n",
        "\n",
        "class ProteinMPNN(nn.Module):\n",
        "    # \"node_features\" and \"edge_features\" are actually dimensionality of these features (\"hidden_dim\" in the calling script)\n",
        "    # the value is 128 for the version that I am using\n",
        "    def __init__(self, num_letters, node_features, edge_features,\n",
        "        hidden_dim, num_encoder_layers=3, num_decoder_layers=3,\n",
        "        vocab=21, k_neighbors=64, augment_eps=0.05, dropout=0.1):\n",
        "        super(ProteinMPNN, self).__init__()\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.node_features = node_features\n",
        "        self.edge_features = edge_features\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Featurization layers\n",
        "        # The version that I am using considers 48 neighbors for each position\n",
        "        self.features = ProteinFeatures(node_features, edge_features, top_k=k_neighbors, augment_eps=augment_eps)\n",
        "\n",
        "        self.W_e = nn.Linear(edge_features, hidden_dim, bias=True)\n",
        "        # This W_s is for embedding the sequence\n",
        "        self.W_s = nn.Embedding(vocab, hidden_dim)\n",
        "\n",
        "        # Encoder layers\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            EncLayer(hidden_dim, hidden_dim*2, dropout=dropout)\n",
        "            for _ in range(num_encoder_layers)\n",
        "        ])\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder_layers = nn.ModuleList([\n",
        "            DecLayer(hidden_dim, hidden_dim*3, dropout=dropout)\n",
        "            for _ in range(num_decoder_layers)\n",
        "        ])\n",
        "        self.W_out = nn.Linear(hidden_dim, num_letters, bias=True)\n",
        "\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    # Creating my own versions of forward should be an easy way to get embeddings or attention weights from diffrerent layers of the model\n",
        "    # See here (https://discuss.pytorch.org/t/how-can-i-extract-intermediate-layer-output-from-loaded-cnn-model/77301) in the forums for adding forward\n",
        "    # hooks or manipulating the forward method\n",
        "    # but my easy solution would be to create different versions of the forward method with different namaes, and calling them explicitly\n",
        "    # \"chain_M\" and \"mask\" seem to be the things that I need to understand very well and play-around with \n",
        "    def forward(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn, use_input_decoding_order=False, decoding_order=None):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Concatenate sequence embeddings for autoregressive decoder\n",
        "        # h_S denotes embedding of the sequence itself for use in decoder\n",
        "        h_S = self.W_s(S)\n",
        "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "\n",
        "\n",
        "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
        "        if not use_input_decoding_order:\n",
        "            decoding_order = torch.argsort((chain_M+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for layer in self.decoder_layers:\n",
        "            # Masked positions attend to encoder information, unmasked see. \n",
        "            h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "            h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
        "            # only the last layer decoder-messages will be stored in \"decoder_messages\"\n",
        "            h_V, decoder_messages = layer(h_V, h_ESV, mask)\n",
        "\n",
        "        logits = self.W_out(h_V)\n",
        "        # The probabilities are passed through log() function so that the sequences can be ranked based by summing the respective values \n",
        "        # for each position instead of multiplication \n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        # messages from the last layer decoder will also be returned for extracting neighbor-attention approximation\n",
        "        return log_probs, decoder_messages\n",
        "\n",
        "\n",
        "\n",
        "    # Seems like this is the method which is used by the notebook for calculating probabilites and scoring\n",
        "    # Need to dig into it thoroughly\n",
        "    # \"chain_mask\" and \"residue_idx\" seem like the tensors of interest\n",
        "    def sample(self, X, randn, S_true, chain_mask, chain_encoding_all, residue_idx, mask=None, temperature=1.0, omit_AAs_np=None, bias_AAs_np=None, chain_M_pos=None, omit_AA_mask=None, pssm_coef=None, pssm_bias=None, pssm_multi=None, pssm_log_odds_flag=None, pssm_log_odds_mask=None, pssm_bias_flag=None, bias_by_res=None):\n",
        "        device = X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Decoder uses masked self-attention\n",
        "        chain_mask = chain_mask*chain_M_pos*mask #update chain_M to include missing regions\n",
        "        decoding_order = torch.argsort((chain_mask+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        N_batch, N_nodes = X.size(0), X.size(1)\n",
        "        log_probs = torch.zeros((N_batch, N_nodes, 21), device=device)\n",
        "        all_probs = torch.zeros((N_batch, N_nodes, 21), device=device, dtype=torch.float32)\n",
        "        h_S = torch.zeros_like(h_V, device=device)\n",
        "        S = torch.zeros((N_batch, N_nodes), dtype=torch.int64, device=device)\n",
        "        h_V_stack = [h_V] + [torch.zeros_like(h_V, device=device) for _ in range(len(self.decoder_layers))]\n",
        "        constant = torch.tensor(omit_AAs_np, device=device)\n",
        "        constant_bias = torch.tensor(bias_AAs_np, device=device)\n",
        "        #chain_mask_combined = chain_mask*chain_M_pos \n",
        "        omit_AA_mask_flag = omit_AA_mask != None\n",
        "\n",
        "\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for t_ in range(N_nodes):\n",
        "            t = decoding_order[:,t_] #[B]\n",
        "            chain_mask_gathered = torch.gather(chain_mask, 1, t[:,None]) #[B]\n",
        "            bias_by_res_gathered = torch.gather(bias_by_res, 1, t[:,None,None].repeat(1,1,21))[:,0,:] #[B, 21]\n",
        "            if (chain_mask_gathered==0).all():\n",
        "                S_t = torch.gather(S_true, 1, t[:,None])\n",
        "            else:\n",
        "                # Hidden layers\n",
        "                E_idx_t = torch.gather(E_idx, 1, t[:,None,None].repeat(1,1,E_idx.shape[-1]))\n",
        "                h_E_t = torch.gather(h_E, 1, t[:,None,None,None].repeat(1,1,h_E.shape[-2], h_E.shape[-1]))\n",
        "                h_ES_t = cat_neighbors_nodes(h_S, h_E_t, E_idx_t)\n",
        "                h_EXV_encoder_t = torch.gather(h_EXV_encoder_fw, 1, t[:,None,None,None].repeat(1,1,h_EXV_encoder_fw.shape[-2], h_EXV_encoder_fw.shape[-1]))\n",
        "                mask_t = torch.gather(mask, 1, t[:,None])\n",
        "                for l, layer in enumerate(self.decoder_layers):\n",
        "                    # Updated relational features for future states\n",
        "                    h_ESV_decoder_t = cat_neighbors_nodes(h_V_stack[l], h_ES_t, E_idx_t)\n",
        "                    h_V_t = torch.gather(h_V_stack[l], 1, t[:,None,None].repeat(1,1,h_V_stack[l].shape[-1]))\n",
        "                    h_ESV_t = torch.gather(mask_bw, 1, t[:,None,None,None].repeat(1,1,mask_bw.shape[-2], mask_bw.shape[-1])) * h_ESV_decoder_t + h_EXV_encoder_t\n",
        "                    h_V_stack[l+1].scatter_(1, t[:,None,None].repeat(1,1,h_V.shape[-1]), layer(h_V_t, h_ESV_t, mask_V=mask_t))\n",
        "                # Sampling step\n",
        "                h_V_t = torch.gather(h_V_stack[-1], 1, t[:,None,None].repeat(1,1,h_V_stack[-1].shape[-1]))[:,0]\n",
        "                logits = self.W_out(h_V_t) / temperature\n",
        "                probs = F.softmax(logits-constant[None,:]*1e8+constant_bias[None,:]/temperature+bias_by_res_gathered/temperature, dim=-1)\n",
        "                if pssm_bias_flag:\n",
        "                    pssm_coef_gathered = torch.gather(pssm_coef, 1, t[:,None])[:,0]\n",
        "                    pssm_bias_gathered = torch.gather(pssm_bias, 1, t[:,None,None].repeat(1,1,pssm_bias.shape[-1]))[:,0]\n",
        "                    probs = (1-pssm_multi*pssm_coef_gathered[:,None])*probs + pssm_multi*pssm_coef_gathered[:,None]*pssm_bias_gathered\n",
        "                if pssm_log_odds_flag:\n",
        "                    pssm_log_odds_mask_gathered = torch.gather(pssm_log_odds_mask, 1, t[:,None, None].repeat(1,1,pssm_log_odds_mask.shape[-1]))[:,0] #[B, 21]\n",
        "                    probs_masked = probs*pssm_log_odds_mask_gathered\n",
        "                    probs_masked += probs * 0.001\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                if omit_AA_mask_flag:\n",
        "                    omit_AA_mask_gathered = torch.gather(omit_AA_mask, 1, t[:,None, None].repeat(1,1,omit_AA_mask.shape[-1]))[:,0] #[B, 21]\n",
        "                    probs_masked = probs*(1.0-omit_AA_mask_gathered)\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                # Here is where sampling from the multinomial distribution is happening\n",
        "                # this will sample 1 element according to the given distribution, and return the index of that element [from 0 to 20]\n",
        "                S_t = torch.multinomial(probs, 1)\n",
        "                all_probs.scatter_(1, t[:,None,None].repeat(1,1,21), (chain_mask_gathered[:,:,None,]*probs[:,None,:]).float())\n",
        "            S_true_gathered = torch.gather(S_true, 1, t[:,None])\n",
        "            S_t = (S_t*chain_mask_gathered+S_true_gathered*(1.0-chain_mask_gathered)).long()\n",
        "            temp1 = self.W_s(S_t)\n",
        "            h_S.scatter_(1, t[:,None,None].repeat(1,1,temp1.shape[-1]), temp1)\n",
        "            S.scatter_(1, t[:,None], S_t)\n",
        "        output_dict = {\"S\": S, \"probs\": all_probs, \"decoding_order\": decoding_order}\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "    def tied_sample(self, X, randn, S_true, chain_mask, chain_encoding_all, residue_idx, mask=None, temperature=1.0, omit_AAs_np=None, bias_AAs_np=None, chain_M_pos=None, omit_AA_mask=None, pssm_coef=None, pssm_bias=None, pssm_multi=None, pssm_log_odds_flag=None, pssm_log_odds_mask=None, pssm_bias_flag=None, tied_pos=None, tied_beta=None, bias_by_res=None):\n",
        "        device = X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=device)\n",
        "        h_E = self.W_e(E)\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Decoder uses masked self-attention\n",
        "        chain_mask = chain_mask*chain_M_pos*mask #update chain_M to include missing regions\n",
        "        decoding_order = torch.argsort((chain_mask+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "\n",
        "        new_decoding_order = []\n",
        "        for t_dec in list(decoding_order[0,].cpu().data.numpy()):\n",
        "            if t_dec not in list(itertools.chain(*new_decoding_order)):\n",
        "                list_a = [item for item in tied_pos if t_dec in item]\n",
        "                if list_a:\n",
        "                    new_decoding_order.append(list_a[0])\n",
        "                else:\n",
        "                    new_decoding_order.append([t_dec])\n",
        "        decoding_order = torch.tensor(list(itertools.chain(*new_decoding_order)), device=device)[None,].repeat(X.shape[0],1)\n",
        "\n",
        "        mask_size = E_idx.shape[1]\n",
        "        permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "        order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        N_batch, N_nodes = X.size(0), X.size(1)\n",
        "        log_probs = torch.zeros((N_batch, N_nodes, 21), device=device)\n",
        "        all_probs = torch.zeros((N_batch, N_nodes, 21), device=device, dtype=torch.float32)\n",
        "        h_S = torch.zeros_like(h_V, device=device)\n",
        "        S = torch.zeros((N_batch, N_nodes), dtype=torch.int64, device=device)\n",
        "        h_V_stack = [h_V] + [torch.zeros_like(h_V, device=device) for _ in range(len(self.decoder_layers))]\n",
        "        constant = torch.tensor(omit_AAs_np, device=device)\n",
        "        constant_bias = torch.tensor(bias_AAs_np, device=device)\n",
        "        omit_AA_mask_flag = omit_AA_mask != None\n",
        "\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for t_list in new_decoding_order:\n",
        "            logits = 0.0\n",
        "            logit_list = []\n",
        "            done_flag = False\n",
        "            for t in t_list:\n",
        "                if (chain_mask[:,t]==0).all():\n",
        "                    S_t = S_true[:,t]\n",
        "                    for t in t_list:\n",
        "                        h_S[:,t,:] = self.W_s(S_t)\n",
        "                        S[:,t] = S_t\n",
        "                    done_flag = True\n",
        "                    break\n",
        "                else:\n",
        "                    E_idx_t = E_idx[:,t:t+1,:]\n",
        "                    h_E_t = h_E[:,t:t+1,:,:]\n",
        "                    h_ES_t = cat_neighbors_nodes(h_S, h_E_t, E_idx_t)\n",
        "                    h_EXV_encoder_t = h_EXV_encoder_fw[:,t:t+1,:,:]\n",
        "                    mask_t = mask[:,t:t+1]\n",
        "                    for l, layer in enumerate(self.decoder_layers):\n",
        "                        h_ESV_decoder_t = cat_neighbors_nodes(h_V_stack[l], h_ES_t, E_idx_t)\n",
        "                        h_V_t = h_V_stack[l][:,t:t+1,:]\n",
        "                        h_ESV_t = mask_bw[:,t:t+1,:,:] * h_ESV_decoder_t + h_EXV_encoder_t\n",
        "                        h_V_stack[l+1][:,t,:] = layer(h_V_t, h_ESV_t, mask_V=mask_t).squeeze(1)\n",
        "                    h_V_t = h_V_stack[-1][:,t,:]\n",
        "                    logit_list.append((self.W_out(h_V_t) / temperature)/len(t_list))\n",
        "                    logits += tied_beta[t]*(self.W_out(h_V_t) / temperature)/len(t_list)\n",
        "            if done_flag:\n",
        "                pass\n",
        "            else:\n",
        "                bias_by_res_gathered = bias_by_res[:,t,:] #[B, 21]\n",
        "                probs = F.softmax(logits-constant[None,:]*1e8+constant_bias[None,:]/temperature+bias_by_res_gathered/temperature, dim=-1)\n",
        "                if pssm_bias_flag:\n",
        "                    pssm_coef_gathered = pssm_coef[:,t]\n",
        "                    pssm_bias_gathered = pssm_bias[:,t]\n",
        "                    probs = (1-pssm_multi*pssm_coef_gathered[:,None])*probs + pssm_multi*pssm_coef_gathered[:,None]*pssm_bias_gathered\n",
        "                if pssm_log_odds_flag:\n",
        "                    pssm_log_odds_mask_gathered = pssm_log_odds_mask[:,t]\n",
        "                    probs_masked = probs*pssm_log_odds_mask_gathered\n",
        "                    probs_masked += probs * 0.001\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                if omit_AA_mask_flag:\n",
        "                    omit_AA_mask_gathered = omit_AA_mask[:,t]\n",
        "                    probs_masked = probs*(1.0-omit_AA_mask_gathered)\n",
        "                    probs = probs_masked/torch.sum(probs_masked, dim=-1, keepdim=True) #[B, 21]\n",
        "                S_t_repeat = torch.multinomial(probs, 1).squeeze(-1)\n",
        "                for t in t_list:\n",
        "                    h_S[:,t,:] = self.W_s(S_t_repeat)\n",
        "                    S[:,t] = S_t_repeat\n",
        "                    all_probs[:,t,:] = probs.float()\n",
        "        output_dict = {\"S\": S, \"probs\": all_probs, \"decoding_order\": decoding_order}\n",
        "        return output_dict\n",
        "\n",
        "\n",
        "    # I am not seeing an immediate use of this method when the model is called through notebook\n",
        "    # So, will skip further commenting and digging for now\n",
        "    # But, seems like an interesting way of interacting with the model in a specific way, so\n",
        "    # might get back to this later\n",
        "    def conditional_probs(self, X, S, mask, chain_M, residue_idx, chain_encoding_all, randn, backbone_only=False):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V_enc = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V_enc, h_E = layer(h_V_enc, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Concatenate sequence embeddings for autoregressive decoder\n",
        "        h_S = self.W_s(S)\n",
        "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V_enc, h_EX_encoder, E_idx)\n",
        "\n",
        "\n",
        "        chain_M = chain_M*mask #update chain_M to include missing regions\n",
        "  \n",
        "        chain_M_np = chain_M.cpu().numpy()\n",
        "        idx_to_loop = np.argwhere(chain_M_np[0,:]==1)[:,0]\n",
        "        log_conditional_probs = torch.zeros([X.shape[0], chain_M.shape[1], 21], device=device).float()\n",
        "\n",
        "        for idx in idx_to_loop:\n",
        "            h_V = torch.clone(h_V_enc)\n",
        "            order_mask = torch.zeros(chain_M.shape[1], device=device).float()\n",
        "            if backbone_only:\n",
        "                order_mask = torch.ones(chain_M.shape[1], device=device).float()\n",
        "                order_mask[idx] = 0.\n",
        "            else:\n",
        "                order_mask = torch.zeros(chain_M.shape[1], device=device).float()\n",
        "                order_mask[idx] = 1.\n",
        "            decoding_order = torch.argsort((order_mask[None,]+0.0001)*(torch.abs(randn))) #[numbers will be smaller for places where chain_M = 0.0 and higher for places where chain_M = 1.0]\n",
        "            mask_size = E_idx.shape[1]\n",
        "            permutation_matrix_reverse = torch.nn.functional.one_hot(decoding_order, num_classes=mask_size).float()\n",
        "            order_mask_backward = torch.einsum('ij, biq, bjp->bqp',(1-torch.triu(torch.ones(mask_size,mask_size, device=device))), permutation_matrix_reverse, permutation_matrix_reverse)\n",
        "            mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "            mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "            mask_bw = mask_1D * mask_attend\n",
        "            mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "            h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "            for layer in self.decoder_layers:\n",
        "                # Masked positions attend to encoder information, unmasked see. \n",
        "                h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
        "                h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n",
        "                h_V = layer(h_V, h_ESV, mask)\n",
        "\n",
        "            logits = self.W_out(h_V)\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "            log_conditional_probs[:,idx,:] = log_probs[:,idx,:]\n",
        "        return log_conditional_probs\n",
        "\n",
        "\n",
        "    # I am not seeing an immediate use of this method when the model is called through notebook\n",
        "    # So, will skip further commenting and digging for now\n",
        "    # But, seems like an interesting way of interacting with the model in a specific way, so\n",
        "    # might get back to this later\n",
        "    def unconditional_probs(self, X, mask, residue_idx, chain_encoding_all):\n",
        "        \"\"\" Graph-conditioned sequence model \"\"\"\n",
        "        device=X.device\n",
        "        # Prepare node and edge embeddings\n",
        "        E, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\n",
        "        h_V = torch.zeros((E.shape[0], E.shape[1], E.shape[-1]), device=E.device)\n",
        "        h_E = self.W_e(E)\n",
        "\n",
        "        # Encoder is unmasked self-attention\n",
        "        mask_attend = gather_nodes(mask.unsqueeze(-1),  E_idx).squeeze(-1)\n",
        "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
        "        for layer in self.encoder_layers:\n",
        "            h_V, h_E = layer(h_V, h_E, E_idx, mask, mask_attend)\n",
        "\n",
        "        # Build encoder embeddings\n",
        "        h_EX_encoder = cat_neighbors_nodes(torch.zeros_like(h_V), h_E, E_idx)\n",
        "        h_EXV_encoder = cat_neighbors_nodes(h_V, h_EX_encoder, E_idx)\n",
        "\n",
        "        order_mask_backward = torch.zeros([X.shape[0], X.shape[1], X.shape[1]], device=device)\n",
        "        mask_attend = torch.gather(order_mask_backward, 2, E_idx).unsqueeze(-1)\n",
        "        mask_1D = mask.view([mask.size(0), mask.size(1), 1, 1])\n",
        "        mask_bw = mask_1D * mask_attend\n",
        "        mask_fw = mask_1D * (1. - mask_attend)\n",
        "\n",
        "        h_EXV_encoder_fw = mask_fw * h_EXV_encoder\n",
        "        for layer in self.decoder_layers:\n",
        "            h_V = layer(h_V, h_EXV_encoder_fw, mask)\n",
        "\n",
        "        logits = self.W_out(h_V)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        return log_probs"
      ],
      "metadata": {
        "id": "Ma8sESx1ovkY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 128\n",
        "num_layers = 3 \n",
        "# Seems like, backbone_noise is set to 0 at inference path which seems logical\n",
        "backbone_noise=0.00\n",
        "mpnn_model = ProteinMPNN(num_letters=21, node_features=hidden_dim, edge_features=hidden_dim, hidden_dim=hidden_dim, num_encoder_layers=num_layers, num_decoder_layers=num_layers, augment_eps=backbone_noise, k_neighbors=checkpoint['num_edges'])\n",
        "mpnn_model.to(device)\n",
        "mpnn_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "mpnn_model.eval()"
      ],
      "metadata": {
        "id": "QBgBJd3J0N_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint['model_state_dict'].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pYLpMQS-ill",
        "outputId": "d08d2f75-5f88-4bab-ab97-fddcbb10a81b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['features.embeddings.linear.weight', 'features.embeddings.linear.bias', 'features.edge_embedding.weight', 'features.norm_edges.weight', 'features.norm_edges.bias', 'W_e.weight', 'W_e.bias', 'W_s.weight', 'encoder_layers.0.norm1.weight', 'encoder_layers.0.norm1.bias', 'encoder_layers.0.norm2.weight', 'encoder_layers.0.norm2.bias', 'encoder_layers.0.norm3.weight', 'encoder_layers.0.norm3.bias', 'encoder_layers.0.W1.weight', 'encoder_layers.0.W1.bias', 'encoder_layers.0.W2.weight', 'encoder_layers.0.W2.bias', 'encoder_layers.0.W3.weight', 'encoder_layers.0.W3.bias', 'encoder_layers.0.W11.weight', 'encoder_layers.0.W11.bias', 'encoder_layers.0.W12.weight', 'encoder_layers.0.W12.bias', 'encoder_layers.0.W13.weight', 'encoder_layers.0.W13.bias', 'encoder_layers.0.dense.W_in.weight', 'encoder_layers.0.dense.W_in.bias', 'encoder_layers.0.dense.W_out.weight', 'encoder_layers.0.dense.W_out.bias', 'encoder_layers.1.norm1.weight', 'encoder_layers.1.norm1.bias', 'encoder_layers.1.norm2.weight', 'encoder_layers.1.norm2.bias', 'encoder_layers.1.norm3.weight', 'encoder_layers.1.norm3.bias', 'encoder_layers.1.W1.weight', 'encoder_layers.1.W1.bias', 'encoder_layers.1.W2.weight', 'encoder_layers.1.W2.bias', 'encoder_layers.1.W3.weight', 'encoder_layers.1.W3.bias', 'encoder_layers.1.W11.weight', 'encoder_layers.1.W11.bias', 'encoder_layers.1.W12.weight', 'encoder_layers.1.W12.bias', 'encoder_layers.1.W13.weight', 'encoder_layers.1.W13.bias', 'encoder_layers.1.dense.W_in.weight', 'encoder_layers.1.dense.W_in.bias', 'encoder_layers.1.dense.W_out.weight', 'encoder_layers.1.dense.W_out.bias', 'encoder_layers.2.norm1.weight', 'encoder_layers.2.norm1.bias', 'encoder_layers.2.norm2.weight', 'encoder_layers.2.norm2.bias', 'encoder_layers.2.norm3.weight', 'encoder_layers.2.norm3.bias', 'encoder_layers.2.W1.weight', 'encoder_layers.2.W1.bias', 'encoder_layers.2.W2.weight', 'encoder_layers.2.W2.bias', 'encoder_layers.2.W3.weight', 'encoder_layers.2.W3.bias', 'encoder_layers.2.W11.weight', 'encoder_layers.2.W11.bias', 'encoder_layers.2.W12.weight', 'encoder_layers.2.W12.bias', 'encoder_layers.2.W13.weight', 'encoder_layers.2.W13.bias', 'encoder_layers.2.dense.W_in.weight', 'encoder_layers.2.dense.W_in.bias', 'encoder_layers.2.dense.W_out.weight', 'encoder_layers.2.dense.W_out.bias', 'decoder_layers.0.norm1.weight', 'decoder_layers.0.norm1.bias', 'decoder_layers.0.norm2.weight', 'decoder_layers.0.norm2.bias', 'decoder_layers.0.W1.weight', 'decoder_layers.0.W1.bias', 'decoder_layers.0.W2.weight', 'decoder_layers.0.W2.bias', 'decoder_layers.0.W3.weight', 'decoder_layers.0.W3.bias', 'decoder_layers.0.dense.W_in.weight', 'decoder_layers.0.dense.W_in.bias', 'decoder_layers.0.dense.W_out.weight', 'decoder_layers.0.dense.W_out.bias', 'decoder_layers.1.norm1.weight', 'decoder_layers.1.norm1.bias', 'decoder_layers.1.norm2.weight', 'decoder_layers.1.norm2.bias', 'decoder_layers.1.W1.weight', 'decoder_layers.1.W1.bias', 'decoder_layers.1.W2.weight', 'decoder_layers.1.W2.bias', 'decoder_layers.1.W3.weight', 'decoder_layers.1.W3.bias', 'decoder_layers.1.dense.W_in.weight', 'decoder_layers.1.dense.W_in.bias', 'decoder_layers.1.dense.W_out.weight', 'decoder_layers.1.dense.W_out.bias', 'decoder_layers.2.norm1.weight', 'decoder_layers.2.norm1.bias', 'decoder_layers.2.norm2.weight', 'decoder_layers.2.norm2.bias', 'decoder_layers.2.W1.weight', 'decoder_layers.2.W1.bias', 'decoder_layers.2.W2.weight', 'decoder_layers.2.W2.bias', 'decoder_layers.2.W3.weight', 'decoder_layers.2.W3.bias', 'decoder_layers.2.dense.W_in.weight', 'decoder_layers.2.dense.W_in.bias', 'decoder_layers.2.dense.W_out.weight', 'decoder_layers.2.dense.W_out.bias', 'W_out.weight', 'W_out.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse and create dictionaries for all the mutations in PremPS 2648\n",
        "# This dictionary will be a dictionary of dictionaries, where outer-dict keys will be pdbid+mutchain and inner-dict keys will be (wild+pos+mut) and ddg\n",
        "# the icodes can be brought to picture later\n",
        "# this \"two_level_dict\" is literally used everywhere throughout this code for storing all the numbers that are compared with each other under feature-specific keys\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/ACCRE_PyRun_Setup/Data_s669_with_predictions.csv\")\n",
        "\n",
        "\n",
        "pdbIdsChains = list(dataset[\"Protein\"])\n",
        "\n",
        "pdbIds = []\n",
        "mutChains = []\n",
        "\n",
        "for pdbIdChain in pdbIdsChains:\n",
        "    pdbIds.append(pdbIdChain[0:-1])\n",
        "    mutChains.append(pdbIdChain[-1])\n",
        "\n",
        "mutations = list(dataset[\"PDB_Mut\"])\n",
        "ddgs = list(dataset[\"DDG_checked_dir\"])\n",
        "\n",
        "two_level_dict = {}\n",
        "\n",
        "for pdbId, mutChain, mutation, ddg in tqdm(zip(pdbIds,mutChains,mutations,ddgs)):\n",
        "    pos = [int(s) for s in re.findall('-?\\d+',mutation)][0]\n",
        "    wild = mutation[0]\n",
        "    mut = mutation[len(mutation)-1]\n",
        "\n",
        "    pdbId = pdbId.lower()\n",
        "\n",
        "    inner_dict = {}\n",
        "    inner_dict[\"mut\"] = f\"{wild}{pos}{mut}\"\n",
        "    inner_dict[\"ddg\"] = float(ddg)\n",
        "    outer_key = f\"{pdbId}{mutChain}\"\n",
        "    if outer_key not in two_level_dict:\n",
        "        two_level_dict[f\"{pdbId}{mutChain}\"] = [inner_dict]\n",
        "    else:\n",
        "        two_level_dict[f\"{pdbId}{mutChain}\"].append(inner_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e5408439a08d42d88661c0a2f32c8c6b",
            "0da9cced688544638ed83e8d11c3a7c6",
            "a316c99b9a8249ef8c3df8c7810a5eb9",
            "d1f1c177118e4f5183861b5d6e1f95a3",
            "b762c113e64846cebef75c715bd1cfbc",
            "b828e5b65ca541d590cd85f56fe65ea9",
            "957a52ca0aa743469663558419a8fefd",
            "13a9ae8d5d0a465c80bffbcee2d6ddf0",
            "a106aaef3c824bf5b486bccb52e4c537",
            "9e52aace42b242f8bbfd935cbbc6df39",
            "d12e077e8e1b428981586d63990d9d8c"
          ]
        },
        "id": "vP_unq7_sXrn",
        "outputId": "87bc392e-aca3-4d75-b2b2-32181f2f73bb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5408439a08d42d88661c0a2f32c8c6b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a seqres to position mapping dictionary\n",
        "# This dictionary will be a dictionary of dictionaries, where outer-dict keys will be pdbid+mutchain and inner-dict key will be (wild+pos) and value of 0-indexed position\n",
        "# the icodes can be brought to picture later\n",
        "mapping_dict = {}\n",
        "pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_669_PDB_Files\"\n",
        "parser = PDBParser(QUIET=True)\n",
        "# some proteins need to be skipped for now due to ICODE related discrapency\n",
        "proteins_to_skip = []\n",
        "\n",
        "for filename in tqdm(os.listdir(pdbDirectory)):\n",
        "    filepath = os.path.join(pdbDirectory,filename)\n",
        "    structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "    model = structure[0]\n",
        "    inner_dict = {}\n",
        "    outer_key = filename.split(\".\")[0]\n",
        "    skip_flag = False\n",
        "    # single chain-assumption in action again\n",
        "    for chain in model:\n",
        "        for i,residue in enumerate(chain):\n",
        "            inner_key = f\"{three_to_one(residue.get_resname())}{residue.get_id()[1]}\"\n",
        "            if inner_key not in inner_dict:\n",
        "                inner_dict[inner_key] = i\n",
        "            else:\n",
        "                # For \"2immA:N31\" and \"1lveA:S27\", I have been fucked\n",
        "                # Need to think whether this will effect other positions or I can just avoid these two-protein related mutations for now?\n",
        "                # Let me just avoid these two proteins for now\n",
        "                print(\"YOU HAVE JUST BEEN FUCKED BY ICODE\")\n",
        "                print(f\"{outer_key}:{inner_key}\")\n",
        "                skip_flag = True\n",
        "    # The ICODE related problematic proteins will not be considered for now\n",
        "    if not skip_flag:\n",
        "        mapping_dict[outer_key] = inner_dict\n",
        "    else:\n",
        "        proteins_to_skip.append(outer_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6d1cb0efb13e45aaa751e71a27a84bdd",
            "8bb47c1b12b642eda2f00ffe7a7b3807",
            "fe5a021532e04e049613895d8fda3929",
            "3ec9063329d141e1bf501bc539935d51",
            "258084713f4f42fa9b1ef41992fb671b",
            "1541a0c68c6b403894d45bf6bbd41c8e",
            "5c2eab21538548ff86e256416ed3f6bd",
            "56c872a2c1fb4a058e8d7039e9052939",
            "7dc40fdb1094444ca2eb14dbf253133f",
            "330277f6e5aa444a8c3aa750c9ee5596",
            "fd432bc45e6646c796889d8f18b578e6"
          ]
        },
        "id": "vxARThyX3VYv",
        "outputId": "7b6c34aa-867f-4952-e201-34e6f65b0203"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/93 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d1cb0efb13e45aaa751e71a27a84bdd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing this \"parse_PDB_biounits()\" function locally for addressing the fucked up integer named chain problem  \n",
        "def parse_PDB_biounits(x, atoms=['N', 'CA', 'C'], chain=None):\n",
        "    '''\n",
        "    input:  x = PDB filename\n",
        "            atoms = atoms to extract (optional)\n",
        "    output: (length, atoms, coords=(x,y,z)), sequence\n",
        "    '''\n",
        "    alpha_1 = list(\"ARNDCQEGHILKMFPSTWYV-\")\n",
        "    states = len(alpha_1)\n",
        "    alpha_3 = ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE',\n",
        "               'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL', 'GAP']\n",
        "\n",
        "    # The following dictionaries are mapping from one-letter to 0-20 index,\n",
        "    # three-letter to 0-20 index,\n",
        "    # 0-20 index to one-letter,\n",
        "    # one-letter to three-letter, and vice-versa\n",
        "    aa_1_N = {a: n for n, a in enumerate(alpha_1)}\n",
        "    aa_3_N = {a: n for n, a in enumerate(alpha_3)}\n",
        "    aa_N_1 = {n: a for n, a in enumerate(alpha_1)}\n",
        "    aa_1_3 = {a: b for a, b in zip(alpha_1, alpha_3)}\n",
        "    aa_3_1 = {b: a for a, b in zip(alpha_1, alpha_3)}\n",
        "\n",
        "    def AA_to_N(x):\n",
        "        # [\"ARND\"] -> [[0,1,2,3]]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 0: x = x[None]\n",
        "        return [[aa_1_N.get(a, states - 1) for a in y] for y in x]\n",
        "\n",
        "    def N_to_AA(x):\n",
        "        # [[0,1,2,3]] -> [\"ARND\"]\n",
        "        x = np.array(x);\n",
        "        if x.ndim == 1: x = x[None]\n",
        "        return [\"\".join([aa_N_1.get(a, \"-\") for a in y]) for y in x]\n",
        "\n",
        "    xyz, seq, min_resn, max_resn = {}, {}, 1e6, -1e6\n",
        "    for line in open(x, \"rb\"):\n",
        "        line = line.decode(\"utf-8\", \"ignore\").rstrip()\n",
        "\n",
        "        if line[:6] == \"HETATM\" and line[17:17 + 3] == \"MSE\":\n",
        "            line = line.replace(\"HETATM\", \"ATOM  \")\n",
        "            line = line.replace(\"MSE\", \"MET\")\n",
        "\n",
        "        if line[:4] == \"ATOM\":\n",
        "            ch = line[21:22]\n",
        "            # If the input chain is not in the PDB file, which can be the case if the target chains are named differently in the runner script,\n",
        "            # this line will cause the output to have literally no information, this is the case for integer named chains\n",
        "            # that does not mean that this line is not doing its job correctly, this is just a constraint that input chain names and\n",
        "            # chain names in the PDB file have to be congruent\n",
        "            # If \"ch\" is an integer, map it to alphabet, because input \"chain\" has been converted to alphabet\n",
        "            # In rare cases, some PDB files number chains with 1,2,3 instead of A,B,C\n",
        "            # This \"loc_dict\" dictionary contains integer to alphabet mapping for weird as fuck integer chain names\n",
        "            # This conversion will be done only when  chain name is actually an integer\n",
        "            if ord(ch) >= 49 and ord(ch) <= 57:\n",
        "                loc_dict = {(idx+1):ch for idx,ch in enumerate(ascii_uppercase)}\n",
        "                ch =  str(loc_dict[int(ch)])\n",
        "            if ch == chain or chain is None:\n",
        "                atom = line[12:12 + 4].strip()\n",
        "                resi = line[17:17 + 3]\n",
        "                resn = line[22:22 + 5].strip()\n",
        "                x, y, z = [float(line[i:(i + 8)]) for i in [30, 38, 46]]\n",
        "\n",
        "                if resn[-1].isalpha():\n",
        "                    resa, resn = resn[-1], int(resn[:-1]) - 1\n",
        "                else:\n",
        "                    resa, resn = \"\", int(resn) - 1\n",
        "                #         resn = int(resn)\n",
        "                if resn < min_resn:\n",
        "                    min_resn = resn\n",
        "                if resn > max_resn:\n",
        "                    max_resn = resn\n",
        "                if resn not in xyz:\n",
        "                    xyz[resn] = {}\n",
        "                if resa not in xyz[resn]:\n",
        "                    xyz[resn][resa] = {}\n",
        "                if resn not in seq:\n",
        "                    seq[resn] = {}\n",
        "                if resa not in seq[resn]:\n",
        "                    seq[resn][resa] = resi\n",
        "\n",
        "                if atom not in xyz[resn][resa]:\n",
        "                    xyz[resn][resa][atom] = np.array([x, y, z])\n",
        "\n",
        "    # convert to numpy arrays, fill in missing values\n",
        "    seq_, xyz_ = [], []\n",
        "    try:\n",
        "        for resn in range(min_resn, max_resn + 1):\n",
        "            if resn in seq:\n",
        "                for k in sorted(seq[resn]): seq_.append(aa_3_N.get(seq[resn][k], 20))\n",
        "            else:\n",
        "                seq_.append(20)\n",
        "            if resn in xyz:\n",
        "                for k in sorted(xyz[resn]):\n",
        "                    for atom in atoms:\n",
        "                        if atom in xyz[resn][k]:\n",
        "                            xyz_.append(xyz[resn][k][atom])\n",
        "                        else:\n",
        "                            xyz_.append(np.full(3, np.nan))\n",
        "            else:\n",
        "                for atom in atoms: xyz_.append(np.full(3, np.nan))\n",
        "        return np.array(xyz_).reshape(-1, len(atoms), 3), N_to_AA(np.array(seq_))\n",
        "    except TypeError:\n",
        "        return 'no_chain', 'no_chain'\n",
        "\n",
        "# Took this part out of \"utils.py\", and put here so that smalll changes can be made to address pesky issues like\n",
        "# integer named chain, and shit like those\n",
        "def parse_PDB(path_to_pdb, input_chain_list=None):\n",
        "    c=0\n",
        "    pdb_dict_list = []\n",
        "    init_alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G','H', 'I', 'J','K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T','U', 'V','W','X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j','k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't','u', 'v','w','x', 'y', 'z']\n",
        "    extra_alphabet = [str(item) for item in list(np.arange(300))]\n",
        "    chain_alphabet = init_alphabet + extra_alphabet\n",
        "     \n",
        "    if input_chain_list:\n",
        "        chain_alphabet = input_chain_list  \n",
        " \n",
        "\n",
        "    biounit_names = [path_to_pdb]\n",
        "    # Each of the biounits is a separate PDB file, so for running with a single PDB file like from colab, this loop will be executed only once\n",
        "    for biounit in biounit_names:\n",
        "        my_dict = {}\n",
        "        s = 0\n",
        "        concat_seq = ''\n",
        "        concat_N = []\n",
        "        concat_CA = []\n",
        "        concat_C = []\n",
        "        concat_O = []\n",
        "        concat_mask = []\n",
        "        coords_dict = {} \n",
        "        # This loop will be executed only once for single chain DDG type cases\n",
        "        for letter in chain_alphabet:\n",
        "            xyz, seq = parse_PDB_biounits(biounit, atoms=['N','CA','C','O'], chain=letter)\n",
        "            if type(xyz) != str:\n",
        "                concat_seq += seq[0]\n",
        "                my_dict['seq_chain_'+letter]=seq[0]\n",
        "                coords_dict_chain = {}\n",
        "                coords_dict_chain['N_chain_'+letter]=xyz[:,0,:].tolist()\n",
        "                coords_dict_chain['CA_chain_'+letter]=xyz[:,1,:].tolist()\n",
        "                coords_dict_chain['C_chain_'+letter]=xyz[:,2,:].tolist()\n",
        "                coords_dict_chain['O_chain_'+letter]=xyz[:,3,:].tolist()\n",
        "                my_dict['coords_chain_'+letter]=coords_dict_chain\n",
        "                s += 1\n",
        "        fi = biounit.rfind(\"/\")\n",
        "        my_dict['name']=biounit[(fi+1):-4]\n",
        "        my_dict['num_of_chains'] = s\n",
        "        my_dict['seq'] = concat_seq\n",
        "        if s <= len(chain_alphabet):\n",
        "            pdb_dict_list.append(my_dict)\n",
        "            c+=1\n",
        "    return pdb_dict_list"
      ],
      "metadata": {
        "id": "UzBk27pmlfh7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distance_func_local(X, mask, eps=1E-6):\n",
        "    mask_2D = torch.unsqueeze(mask,1) * torch.unsqueeze(mask,2)\n",
        "    dX = torch.unsqueeze(X,1) - torch.unsqueeze(X,2)\n",
        "    D = mask_2D * torch.sqrt(torch.sum(dX**2, 3) + eps)\n",
        "    D_max, _ = torch.max(D, -1, keepdim=True)\n",
        "    D_adjust = D + (1. - mask_2D) * D_max\n",
        "    top_k = checkpoint[\"num_edges\"]\n",
        "    sampled_top_k = top_k\n",
        "    D_neighbors, E_idx = torch.topk(D_adjust, np.minimum(top_k, X.shape[1]), dim=-1, largest=False)\n",
        "    return D_neighbors, E_idx\n",
        "\n",
        "def return_neighbor_info(X, mask):\n",
        "    b = X[:,:,1,:] - X[:,:,0,:]\n",
        "    c = X[:,:,2,:] - X[:,:,1,:]\n",
        "    a = torch.cross(b, c, dim=-1)\n",
        "    Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + X[:,:,1,:]\n",
        "    Ca = X[:,:,1,:]\n",
        "    N = X[:,:,0,:]\n",
        "    C = X[:,:,2,:]\n",
        "    O = X[:,:,3,:]\n",
        "\n",
        "    D_neighbors, E_idx = distance_func_local(Ca, mask)\n",
        "    # Got the indices of the neighbors, E_idx should be the 0-based indexing of the topK closest neighbors\n",
        "    # and D_neighbors should be the distances of those neighbors\n",
        "    return D_neighbors, E_idx"
      ],
      "metadata": {
        "id": "oq_NFZaMrNQW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "from scipy.special import kl_div\n",
        "\n",
        "# read in the PDB files from the directory where the S_2648 PDB Files are stored, and set-them up one by one for featuirization, and passing through the model\n",
        "pdbDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_669_PDB_Files\"\n",
        "parser = PDBParser(QUIET=True)\n",
        "\n",
        "pdbId_info = []\n",
        "pos_info = []\n",
        "neighbor_pos = []\n",
        "neighbor_attention = []\n",
        "neighbor_attention_softmaxed = []\n",
        "neighbor_distances_tracking = []\n",
        "\n",
        "np.set_printoptions(suppress=True,precision=2)\n",
        "loc_proteins = []\n",
        "for i,filename in tqdm(enumerate(os.listdir(pdbDirectory))):\n",
        "    #ICODE related problematic proteins will be skipped from analysis for now\n",
        "    if (filename.split(\".\")[0] not in proteins_to_skip):\n",
        "        # if i > 100:\n",
        "        #     break\n",
        "        loc_proteins.append(filename.split(\".\")[0])\n",
        "        filepath = os.path.join(pdbDirectory,filename)\n",
        "        structure = parser.get_structure(id=filename.split(\".\")[0],file=filepath)\n",
        "        model = structure[0]\n",
        "        \n",
        "        # Since there is only one chain, and that same chain is both fixed designable for different residues, extracting that name, and putting them in pertinent lists\n",
        "        # taking chainname from filename since one of the files \"1rtpA.pdb\" has chain name with \"1\" instead of \"A\"\n",
        "        # fuck you motherfucking fucked up PDB file submitter. Have you shoved your head into your ass?\n",
        "        chain_name = (filename.split(\".\")[0])[-1]\n",
        "        fixed_chain_list = []\n",
        "        # the trick is to put the single chain as designable chain, and then create the \"fixed_positions_dict\" dictionary  \n",
        "        designed_chain_list = [chain_name]\n",
        "        chain_list = list(set(designed_chain_list + fixed_chain_list))\n",
        "\n",
        "        # Using the programs custome PDB parser for processing the PDB files\n",
        "        pdb_dict_list = parse_PDB(filepath, input_chain_list=chain_list)\n",
        "        # tacking max_length parameter value from the original colab notebook since I need to process all residues at the same time\n",
        "        # all the PDB files can technically be processed together and put inside the dataset_valid list-like object, but right now\n",
        "        # I am trying to keep everything consistent and simple\n",
        "        # Each element of dataset_valid is a dictionary \n",
        "        dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=20000)\n",
        "\n",
        "        # Simplying the sequence generation loop\n",
        "        protein = dataset_valid[0]\n",
        "\n",
        "        wildtype_seq = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        # If there are gaps in the wildtype_seq \"seq\", remove those positions from both the \"seq\", \"\" and ('coords_chain_{designed_chain_list[0]}'), \n",
        "        # and ('seq_chain_{designed_chain_list[0]}') of the \"protein\"\n",
        "        # print(protein.keys())\n",
        "        # protein is a dict with keys(['seq_chain_A', 'coords_chain_A', 'name', 'num_of_chains', 'seq'])\n",
        "        # \"seq_chain\" and \"seq_all\" are both strings of the same length where gapped positions need to be identified and removed\n",
        "        seq_chain = protein[f\"seq_chain_{designed_chain_list[0]}\"]\n",
        "        seq_all = protein[f\"seq\"]\n",
        "        # \"coordinates_chain\" is a dict with keys(['N_chain_A', 'CA_chain_A', 'C_chain_A', 'O_chain_A'])\n",
        "        coordinates_chain = protein[f\"coords_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        \n",
        "        # The following four variables are lists of length equal to seq_chain and seq_all length\n",
        "        # Therefore, the gapped positions can be retrived from seq_chain and removed from everything accordingly\n",
        "        N_chain = coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"]\n",
        "        CA_chain = coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"]\n",
        "        C_chain = coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"]\n",
        "        O_chain = coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"]\n",
        "\n",
        "        # delete everything related to gapped positions now\n",
        "        # at first, find out the positions that are gapped\n",
        "        # these gapped positions are absolutely messed up fucked up artifact of some kind of sophistification \n",
        "        # provided by proteinMPNN, FUCK YOU motherfucking oversmart CODERS\n",
        "        N_chain = [v for i,v in enumerate(N_chain) if seq_chain[i] != \"-\"]\n",
        "        CA_chain = [v for i,v in enumerate(CA_chain) if seq_chain[i] != \"-\"]\n",
        "        C_chain = [v for i,v in enumerate(C_chain) if seq_chain[i] != \"-\"]\n",
        "        O_chain = [v for i,v in enumerate(O_chain) if seq_chain[i] != \"-\"]\n",
        "        seq_all = [v for i,v in enumerate(seq_all) if seq_chain[i] != \"-\"]\n",
        "        seq_chain = [v for i,v in enumerate(seq_chain) if seq_chain[i] != \"-\"]\n",
        "\n",
        "        # Now, finally, pack everything back to the dictionary \"protein\"\n",
        "        protein[f\"seq_chain_{designed_chain_list[0]}\"] = seq_chain\n",
        "        protein[f\"seq\"] = seq_all\n",
        "        coordinates_chain[f\"N_chain_{designed_chain_list[0]}\"] = N_chain\n",
        "        coordinates_chain[f\"CA_chain_{designed_chain_list[0]}\"] = CA_chain\n",
        "        coordinates_chain[f\"C_chain_{designed_chain_list[0]}\"] = C_chain\n",
        "        coordinates_chain[f\"O_chain_{designed_chain_list[0]}\"] = O_chain\n",
        "        protein[f\"coords_chain_{designed_chain_list[0]}\"] = coordinates_chain\n",
        "\n",
        "        # At this point, probably need to put None values in a lot of parameters that are not relevant to my usecase, but need to be sent to featurizer before running model forward\n",
        "        # For now, I will not tie positions together\n",
        "        tied_positions_dict = None\n",
        "        pssm_dict = None\n",
        "        omit_AA_dict = None\n",
        "        bias_AA_dict = None\n",
        "        tied_positions_dict = None\n",
        "        bias_by_res_dict = None\n",
        "        alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "        bias_AAs_np = np.zeros(len(alphabet))\n",
        "\n",
        "        chain_id_dict = {}\n",
        "        chain_id_dict[pdb_dict_list[0]['name']]= (designed_chain_list, fixed_chain_list)\n",
        "\n",
        "        BATCH_COPIES = 1\n",
        "\n",
        "        batch_clones = [copy.deepcopy(protein) for i in range(BATCH_COPIES)]\n",
        "\n",
        "        # \"muts_for_prot\" is a list with information about all the mutations in \"protein\", whose sequence only version is \"wildtype_seq\" \n",
        "        muts_for_prot = two_level_dict[filename.split(\".\")[0]]\n",
        "        # \"cur_map_dict\" will give the 0-based sequence index for the mutations, which will be almost directly used for masking and then running the model\n",
        "        # 1-based indexing needed for the fixed position\n",
        "        cur_map_dict = mapping_dict[filename.split(\".\")[0]]\n",
        "\n",
        "        for mut in muts_for_prot:\n",
        "            wild_aa = mut[\"mut\"][0]\n",
        "            alternate_aa = mut[\"mut\"][-1]\n",
        "            # (+1) because we need to pass 1-based indexing to tied_featurize() method\n",
        "            seq_pos = cur_map_dict[mut[\"mut\"][0:-1]] + 1\n",
        "            # only need to mask the mutated position position in \"wildtype_seq\" for now\n",
        "            fixed_positions_dict = {}\n",
        "            fixed_positions_dict[protein[\"name\"]] = {}\n",
        "            f_list = []\n",
        "            for ind_fixed in range(0,len(seq_chain)):\n",
        "                if (ind_fixed + 1) not in [seq_pos]:\n",
        "                    f_list.append(ind_fixed + 1)\n",
        "            fixed_positions_dict[protein[\"name\"]][filename.split(\".\")[0][-1]] = f_list\n",
        "\n",
        "            # finally, had to take chain-name from filename instead of biopython parsing to get rid of chain-name with \"1\" instead of \"A\" in \"1rtpA.pdb\"\n",
        "            X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "            omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "            = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "            randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "            log_probs, decoder_messages = mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "            # Adding the log_probs to the same inner dictionary where DDG values exist for easier comparison\n",
        "            mut[\"log_prob\"] = log_probs.cpu().data.numpy()\n",
        "            \n",
        "            # the top_k attention weights will be stored here for weighted sum later\n",
        "            # \"seq_pos\" is 1-based since \"fixed_positions_dict\" above needs to hold 1-based indices for the mutation,\n",
        "            # but accessing the tensors will require 0-based indexing\n",
        "            seq_index = seq_pos - 1\n",
        "            # \"dim = 1\", because decoder_messages[0,seq_index,:,:] should be (48,128), and we want to take norm of each of the 48 vectors across the last dimension,\n",
        "            # get 48 norm values, and fetch out the k highest values from there\n",
        "            message_norms = (torch.linalg.vector_norm(x=decoder_messages[0,seq_index,:,:],ord=2,dim=1))\n",
        "            local_distances, local_neighbors = return_neighbor_info(X, mask)\n",
        "            # \"top_k_attended_neighbor_indices\" is the indices from [0,47] corresponding to the highest attended neighbors\n",
        "            # top_(k-1) can technically be extracted from top_k, but currently just for simplicity and easier debugging, extracting everything separately\n",
        "            top_15_attention_vals, top_15_attended_neighbor_indices = torch.topk(message_norms,k=15)\n",
        "            top_10_attention_vals, top_10_attended_neighbor_indices = torch.topk(message_norms,k=10)\n",
        "            top_5_attention_vals, top_5_attended_neighbor_indices = torch.topk(message_norms,k=5)\n",
        "            # now, using \"local_neighbors\" to get the original indices of the neighbors corresponding to the top_k attended positions\n",
        "            # taking both top_5 and top_10 for now\n",
        "            top_15_attended_neighbor_indices = local_neighbors[0,seq_index,top_15_attended_neighbor_indices]\n",
        "            top_10_attended_neighbor_indices = local_neighbors[0,seq_index,top_10_attended_neighbor_indices]\n",
        "            top_5_attended_neighbor_indices = local_neighbors[0,seq_index,top_5_attended_neighbor_indices]\n",
        "            top_15_closest_neighbor_indices = local_neighbors[0,seq_index,1:16]\n",
        "            top_10_closest_neighbor_indices = local_neighbors[0,seq_index,1:11]\n",
        "            mut[\"top_15_attention_weights\"] = top_15_attention_vals.cpu().data.numpy()\n",
        "            mut[\"top_10_attention_weights\"] = top_10_attention_vals.cpu().data.numpy()\n",
        "            mut[\"top_5_attention_weights\"] = top_5_attention_vals.cpu().data.numpy()\n",
        "            # the neighbor indices corresponding to the top_k attention weights will be stored here for entropy calculation later\n",
        "            # 0-based indices of the neighbors will be saved so that corresponding log-probability vectors can be extracted readily from \"log_prob\" keyed value\n",
        "            mut[\"top_15_neighbor_indices\"] = top_15_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_10_neighbor_indices\"] = top_10_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_5_neighbor_indices\"] = top_5_attended_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_15_closest_neighbor_indices\"] = top_15_closest_neighbor_indices.cpu().data.numpy()\n",
        "            mut[\"top_10_closest_neighbor_indices\"] = top_10_closest_neighbor_indices.cpu().data.numpy()\n",
        "\n",
        "            # The lines below are mostly for printing purposes to do external analysis with PyMol,and ROSETTA with Cristina\n",
        "            loc_pos_scores = []\n",
        "            for enum_val,(neighbor_p, neighbor_s, neighbor_distance) in enumerate(zip(local_neighbors[0,seq_index,1:15].cpu().data.numpy(),\n",
        "                                                                 (torch.linalg.vector_norm(x=decoder_messages[0,seq_index,1:15,:],ord=2,dim=1)).cpu().data.numpy(),\n",
        "                  \n",
        "                                                               local_distances[0,seq_index,1:15].cpu().data.numpy())):\n",
        "                # skippoing the first neighbor since it is the mutated position itself\n",
        "                if enum_val == 0:\n",
        "                    continue\n",
        "                pdbId_info.append(filename)\n",
        "                pos_info.append(seq_index+1)\n",
        "                neighbor_pos.append(neighbor_p+1)\n",
        "                neighbor_attention.append(neighbor_s)\n",
        "                loc_pos_scores.append(neighbor_s)\n",
        "                neighbor_distances_tracking.append(neighbor_distance)\n",
        "            # since softmax has to be done over all the neighbors, taking the softmax, and later adding it to the data generation list after\n",
        "            # neighbor enumeration loop\n",
        "            loc_pos_scores = softmax(np.array(loc_pos_scores))\n",
        "            for s in loc_pos_scores:\n",
        "                neighbor_attention_softmaxed.append(s)\n",
        "\n",
        "            # take (\"neighbor_attention\"-weighted sum/average) of the entropies of the top 5 attended neighbors\n",
        "            # are the neighbors with highest message passing values always among the closest 10?\n",
        "            # point to be noted that the closest, therefore the first neighbor of every position is the neighbor itself\n",
        "            # check correlation between distance and attention values since a possible manual edge feature would be distance\n",
        "            # let us see if the model attends to distant neighbors more, or attention value is inversely proportional to distance?\n",
        "            # take L2-norms of the message vectors instead of attention\n",
        "            # take the softmax of L2-norms to approximate attention, although technically the positions are not constrained by each other, this can be considered a sigmoid attention\n",
        "            # where having neighbors with large messages will effect differently than having neighbors with small messages\n",
        "            # can this be correlated with position-entropy?\n",
        "            # the L2-norms should be able to approximate how much each of the neighbors are effecting the mutated position\n",
        "            # This information can be stored for checking the effect of center mutation on those positions afterwards\n",
        "            # Identify major interacting partners (neighbors that are important for center prediction, and also which take center into consideration for its own prediction)\n",
        "            # then check how much the major neighbor position deviates from wildtype due to the mutation\n",
        "            # another much more simples thing can be to check the deviation for top 10 neighbors\n",
        "            # this deviation can be calculated using the log(W) for the neighbor before center mutation, and log(W) for the neighbor after center mutation \n",
        "\n",
        "            # Now, take top_k most attended positions, make them designable, mutate center, and take change in -log(p) of the wildtype at each of the neighbor positions\n",
        "            # take weighted sum of these neighbor energy changes, see if there is any correlation\n",
        "            # next, go for \"strong\" neighbor positions (both way strong attention)\n",
        "            # Many of the tensors will take on new values after running the model again with different fixed positions\n",
        "            \n",
        "            # the \"fixed_positions_dict\" has to be repopulated now since neighbor positions will be masked one by one\n",
        "            # here, \"n_ind\" is the 0-based index corresponding to one of the \"top_k\" attended neighbors \n",
        "            # these lists will contain the log_probabilities for the top_k most attended neighbors serially\n",
        "            # before and after making the center mutation currently at hand, these probabilities will be used later for calculating\n",
        "            # attention_weighted change in neighbor_wildtype probability, attention_weighted_change in KL, and all those things \n",
        "            neighbor_w_log_probs = []\n",
        "            neighbor_m_log_probs = []\n",
        "            # the following array will contain the identities of the neighbors serially so that specific wildtype neighbor positions in the probability\n",
        "            # distribution can be extracted later\n",
        "            neighbor_aa_identities = []\n",
        "            # \"top5\" and \"top10\" should be extractable from \"top15\", since the neighbor \n",
        "            # informations are stored serially in the lists\n",
        "            for n_ind in mut[\"top_15_neighbor_indices\"]:\n",
        "                neighbor_aa_identities.append(seq_chain[n_ind])\n",
        "                # Some sequence-input manipulation is done later in this loop, so the wildtype aa is placed in the position, so that\n",
        "                # previous iteration manipulations do not cause trouble in this iteration\n",
        "                alpha_tok = \"ACDEFGHIKLMNPQRSTVWYX\"\n",
        "                aa_1_N = {a:n for n,a in enumerate(alpha_tok)}\n",
        "                aa_N_1 = {n:a for n,a in enumerate(alpha_tok)}\n",
        "\n",
        "                # adding (+1) to n_ind, since fixed positions are 1-indexed in the original implementation\n",
        "                n_pos = n_ind + 1  \n",
        "                fixed_positions_dict = {}\n",
        "                fixed_positions_dict[protein[\"name\"]] = {}\n",
        "                f_list = []\n",
        "                for ind_fixed in range(0,len(seq_chain)):\n",
        "                    # Fixing everything except the \"n_pos\" neighbor position\n",
        "                    if (ind_fixed + 1) not in [n_pos]:\n",
        "                        f_list.append(ind_fixed + 1)\n",
        "                fixed_positions_dict[protein[\"name\"]][filename.split(\".\")[0][-1]] = f_list\n",
        "\n",
        "                # Extracting \"n_ind\" 21-way log probabilities when the center is wildtype \n",
        "                X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "                omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "                = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "                randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "                log_probs, decoder_messages = mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "                # Adding the log_probs to the same inner dictionary where DDG values exist for easier comparison\n",
        "                # Here, ideally only n_ind should be extracted from log_probs before saving to the dictionary for memory efficiency\n",
        "                n_log_probs = log_probs.cpu().data.numpy()\n",
        "                n_log_probs = n_log_probs[0,n_ind,:]\n",
        "                # This is the 21-way log_probability for the neighbor position when the center is the wildtype residue\n",
        "                neighbor_w_log_probs.append(n_log_probs) \n",
        "                 \n",
        "                # Now, make mutation, and process the corresponding probabilities\n",
        "                X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, \\\n",
        "                omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta  \\\n",
        "                = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
        "                randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
        "                # seems like passing mutant sequence through the model will be a bit more difficult that expected since PDB file is read in by the underlying parser\n",
        "                # How, do I only change the amino acids identity in the sequence, but keep the PDB backbone and everything same?\n",
        "                # At first, just try to manipulate the input \"S\"\n",
        "                S[0,seq_index] = aa_1_N[alternate_aa]\n",
        "                log_probs, decoder_messages = mpnn_model(X, S, mask, chain_M*chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
        "                # Adding the log_probs to the same inner dictionary where DDG values exist for easier comparison\n",
        "                # Here, ideally only n_ind should be extracted from log_probs before saving to the dictionary for memory efficiency\n",
        "                n_log_probs = log_probs.cpu().data.numpy()\n",
        "                n_log_probs = n_log_probs[0,n_ind,:]\n",
        "                # This is the 21-way log_probability for the neighbor position when the center is the mutated residue \n",
        "                neighbor_m_log_probs.append(n_log_probs)\n",
        "                # take KL of the before mutation, and after mutation distributions\n",
        "                # before mutation is the true distribution, and after mutation is the perturbed, that might decide forward vs. reverse KL\n",
        "                # also, consider entropy change\n",
        "            mut[\"w_n_log_prob\"] = neighbor_w_log_probs\n",
        "            mut[\"m_n_log_prob\"] = neighbor_m_log_probs\n",
        "            mut[\"neighbor_aa_identities\"] = neighbor_aa_identities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "99020b6675654210856919908788c155",
            "c16b088071354d67b4046d3d75fdc5a6",
            "d704309ba54e4facb212641947b2878e",
            "bac383df87c94dada4058aafe9a38d0f",
            "706c12c9d8b847f29562ae9f87d350e3",
            "f5e5e159967848b7ba0add4ad9a4ae25",
            "af14b86fea294b08825f0d5081d521a6",
            "29c3ddaf5fae45a6840ecaaf68030f3f",
            "2145d656e57e4bf181daa63cf74c738d",
            "1f79b905f5bd4f809d3958930bcda025",
            "97b6a5c98eb64a89ae1eac3a99a49097"
          ]
        },
        "id": "b8cEsTK1EQ9J",
        "outputId": "a5bac79d-2205-4456-bdc8-d735e4c21c67"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99020b6675654210856919908788c155"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the incomplete \"two_level_dict\" as pickle file for a quick dirty comparison\n",
        "# import pickle\n",
        "# with open(\"S_669_pmppn_info_dict.pickle\",\"wb\") as f:\n",
        "#     pickle.dump(two_level_dict,f)"
      ],
      "metadata": {
        "id": "rXvc5PDmIQyF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# with open(\"S_669_pmppn_info_dict.pickle\",\"rb\") as f:\n",
        "#     two_level_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "QVXEWT9ye7NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import entropy\n",
        "alpha_list = list(\"ACDEFGHIKLMNPQRSTVWYX\")\n",
        "# The following dictionary will be used for fetching out the log-probabilities corresponding to the wild-type and mutated residues at the mutation positions\n",
        "aa_to_N = {a:n for n,a in enumerate(alpha_list)}\n",
        "# This list will contain the experimental ddg values for the mutations for which two-level dict contains information regarding log_probabilities\n",
        "true_vals = []\n",
        "# This list will contain (wild_proba,mut_proba) tuples for the mutations for which two-level dict contains information regarding log_probabilities\n",
        "wild_mut_log_probabilities = []\n",
        "# saving max probabilites for debugging\n",
        "max_log_probabilities = []\n",
        "# Want to add entropy of the position with some kind of weight (maybe, just a for loop for checking weight combinations that sum to 1?)\n",
        "position_entropies = []\n",
        "weighted_neighbor_entropies = []\n",
        "# This \"weighted_neighbor_energy_changes\" will be ((-log(m))-(-log(w))) for each of the topk neighbors, weighted summed by corresponding attention weights   \n",
        "weighted_neighbor_energy_changes = []\n",
        "# the neighbor-forward-KL will at this point treat the center-wildtype conditioned neighbor distributions as true, \n",
        "# and center-mutated conditioned neighbor distributions as approximation\n",
        "weighted_neighbor_forward_KL = []\n",
        "# the neighbor-backward-KL will treat the center-mutated conditioned neighbor distributions as true, \n",
        "# and center-wildtype conditioned neighbor distributions as approximation\n",
        "weighted_neighbor_backward_KL = []\n",
        "# putting the dictionary here since we are going to need positions corresponding to alternate amino acid 1-letter codes\n",
        "alpha_tok = \"ACDEFGHIKLMNPQRSTVWYX\"\n",
        "aa_1_N = {a:n for n,a in enumerate(alpha_tok)}\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            # where the fuck is \"log_prob\" coming from, but \"top_5_attention_weights\" and \"top_5_neighbor_indices\" are not there?\n",
        "            if (\"log_prob\" in mut) and (\"w_n_log_prob\" in mut):\n",
        "                wild = mut[\"mut\"][0] \n",
        "                alternate = mut[\"mut\"][-1]\n",
        "                true_vals.append(mut[\"ddg\"])\n",
        "                sequence_index_of_mutation = cur_map_dict[mut[\"mut\"][0:-1]]\n",
        "                position_log_probabilities = mut[\"log_prob\"][0,sequence_index_of_mutation,:]\n",
        "                wild_mut_log_probabilities.append((position_log_probabilities[aa_to_N[wild]],position_log_probabilities[aa_to_N[alternate]]))\n",
        "                max_log_probabilities.append(position_log_probabilities.max())\n",
        "                position_entropies.append(entropy(np.exp(position_log_probabilities)))\n",
        "                # These 0-based neighbor indices will be used for extracting the log-probabilities corresponding to the neighbor positions\n",
        "                n_indices= mut[\"top_15_neighbor_indices\"]\n",
        "                # The neighbor weights will be used here for multiplying \n",
        "                n_weights = mut[\"top_15_attention_weights\"].reshape(-1,1)\n",
        "                # Take entropy while taking care of the dimension along which entropy is calculated\n",
        "                # Taking entropy across last axis, because the shape of the input is (k,21), where 21 is the 21-way probability distribution \n",
        "                n_entropies = entropy(np.exp(mut[\"log_prob\"][0,n_indices,:]),axis=-1).reshape(-1,1)\n",
        "                # I think this element-wise product is getting wrong \n",
        "                weighted_neighbor_entropies.append((n_entropies*softmax(n_weights)).sum())\n",
        "                # weighted_neighbor_entropies.append((n_entropies*softmax(n_weights)).sum())\n",
        "                # weighted_neighbor_entropies.append((n_entropies*n_weights).sum())\n",
        "\n",
        "                # Now, calculate neighbor energy changes, and then weighted sum them after extracting specific log_probabilities\n",
        "                # for mutant center, and wildtype center impacted versions for the top neighbor positions\n",
        "                neighbor_w_log_probabilities = mut[\"w_n_log_prob\"]\n",
        "                neighbor_m_log_probabilities = mut[\"m_n_log_prob\"]\n",
        "                neighbor_amino_a_identities = mut[\"neighbor_aa_identities\"]\n",
        "                # The \"local_neighbor_log_prob_vals\" will be a list of negative log-probability differences(a.k.a. energy differences)\n",
        "                local_neighbor_log_prob_vals = []\n",
        "                local_neighbor_forward_KL_vals = []\n",
        "                local_neighbor_backward_KL_vals = []\n",
        "                # For example, selecting the numbers from the first 5 iterations of this loop will give neighbor energy change corresponding to the first 5 neighbors\n",
        "                for neighbor_w, neighbor_m, neighbor_aa  in zip(neighbor_w_log_probabilities,neighbor_m_log_probabilities,neighbor_amino_a_identities):\n",
        "                    # get the amino acid identity for the neighbor position, run it through the mapping dictionary, get the log probabilities from those positions,\n",
        "                    # \"neighbor_w\" and \"neighbor_m\" arrays will directly give the log probabilities that need to be substracted to get the energy (put (-1) before thoese numbers?...think a bit)\n",
        "                    neighbor_index = aa_1_N[neighbor_aa]\n",
        "                    local_neighbor_log_prob_vals.append((-1*neighbor_m[neighbor_index])-(-1*neighbor_w[neighbor_index]))\n",
        "                    # summing the output of \"kl_div\", because one number comes for every positions in the currently processing neighbor distribution,\n",
        "                    # and I want to take the total deviation in that distribution \n",
        "                    local_neighbor_forward_KL_vals.append(kl_div(np.exp(neighbor_w),np.exp(neighbor_m)).sum())\n",
        "                    local_neighbor_backward_KL_vals.append(kl_div(np.exp(neighbor_m),np.exp(neighbor_w)).sum())\n",
        "                # The energy change approximation can be constrained to the top few neighbors by just indexing the arrays below\n",
        "                # So, it looks like a better idea to save log_probs for atleast the top_20 neighbors since we can always fetch the first few from there\n",
        "                weighted_neighbor_energy_changes.append((np.array(local_neighbor_log_prob_vals[0:15])*softmax(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_forward_KL.append((np.array(local_neighbor_forward_KL_vals[0:15])*softmax(n_weights[0:15])).sum())\n",
        "                weighted_neighbor_backward_KL.append((np.array(local_neighbor_backward_KL_vals[0:15])*softmax(n_weights[0:15])).sum())"
      ],
      "metadata": {
        "id": "7m4jsITsJHmE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let us also look at the energy of the most probable amino acid in those mutation positions\n",
        "wild_energies = []\n",
        "mut_energies = []\n",
        "min_energies = []\n",
        "experimental_energies = []\n",
        "entropy_conservations = []\n",
        "neighbor_entropy_conservations = []\n",
        "# Now, add entropy of the position\n",
        "for true, estimate, max_prob, entropy_conservation, neighbor_entropy_conservation in zip(true_vals,wild_mut_log_probabilities,max_log_probabilities,position_entropies,weighted_neighbor_entropies):\n",
        "    experimental_energies.append(true)\n",
        "    wild_energies.append(estimate[0]*-1)\n",
        "    mut_energies.append(estimate[1]*-1)\n",
        "    min_energies.append(max_prob*-1)\n",
        "    entropy_conservations.append(entropy_conservation*-1)\n",
        "    neighbor_entropy_conservations.append(neighbor_entropy_conservation*-1)"
      ],
      "metadata": {
        "id": "vn-AjUmcoYDF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "TwMx2ZMs60Pz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wild_energies = np.array(wild_energies)\n",
        "mut_energies = np.array(mut_energies)\n",
        "min_energies = np.array(min_energies)\n",
        "experimental_energies = np.array(experimental_energies)\n",
        "mut_wild_predictions = mut_energies - wild_energies\n",
        "mut_min_predictions = mut_energies - min_energies\n",
        "entropy_predictions = np.array(entropy_conservations)\n",
        "neighbor_entropy_predictions = np.array(neighbor_entropy_conservations)\n",
        "neighbor_energy_change_predictions = np.array(weighted_neighbor_energy_changes)\n",
        "neighbor_forward_KL_predictions = np.array(weighted_neighbor_forward_KL)\n",
        "neighbor_backward_KL_predictions = np.array(weighted_neighbor_backward_KL)\n",
        "print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "print(pearsonr(experimental_energies,mut_min_predictions))\n",
        "print(pearsonr(experimental_energies,entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_energy_change_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_forward_KL_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_backward_KL_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jrRRaEi7fJY",
        "outputId": "bcfc573c-c092-4705-d184-64d891f1bfdf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-0.3373037057197982, 1.9321879066377103e-18)\n",
            "(-0.2900463920100605, 7.835722370430089e-14)\n",
            "(-0.25749585397443825, 4.031750517168691e-11)\n",
            "(-0.011820516754941399, 0.7657067160204968)\n",
            "(-0.22545268699508497, 8.523944193143508e-09)\n",
            "(-0.3325158114007902, 6.1796126174309906e-18)\n",
            "(-0.34783936659571696, 1.391661299409247e-19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now combine \"mut_wild_predictions\" and \"entropy_predictions\" using weight combinations from 0 to 1 in 0.05 increments so that they some to one\n",
        "# so, when one weight is x, the other weight is automatically (1-x)\n",
        "# The keys of this dictionary will be (term1_coeff,term2_coeff) tuples, and values will be the observed correlations \n",
        "coefficient_result_dictionary = {}\n",
        "for i in np.arange(0.0,1.000001,0.005):\n",
        "    term1_coeff = round(i,2)\n",
        "    term2_coeff = round((1.000001 - i),2)\n",
        "    local_preds = (term1_coeff*mut_wild_predictions) + (term2_coeff*entropy_predictions)\n",
        "    coefficient_result_dictionary[(term1_coeff,term2_coeff)] = round(pearsonr(experimental_energies,local_preds)[0],2) "
      ],
      "metadata": {
        "id": "xI2DgnlzMh6H"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefficient_result_dictionary"
      ],
      "metadata": {
        "id": "pUMxNOmfUwX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let me get PSSM values and do some comparison quickly\n",
        "# getting the PSSM extraction functions from my custom model data processing scripts\n",
        "from string import ascii_uppercase\n",
        "\n",
        "# In rare cases, some PDB files number chains with 1,2,3 instead of A,B,C\n",
        "def convertChainFromAlphabetToNumber(alphabet):\n",
        "    mappingDict = {ch:(idx+1) for idx,ch in enumerate(ascii_uppercase)}\n",
        "    return str(mappingDict[alphabet])\n",
        "\n",
        "# Before executing this function, the PSSM files with naming format \"pdbIdchain.pssm\" needs to be stored\n",
        "# in the pssm_dir\n",
        "def returnPSSMArray(pdbIdPlusChain,pssm_dir=\"train_pssm_dir\",convert_upper = False):\n",
        "#     Currently, assuming that the pssm file names contain pdbId in upper case\n",
        "    if convert_upper:\n",
        "        fileName = pdbIdPlusChain.upper() + \".pssm\"\n",
        "    else:\n",
        "        fileName = pdbIdPlusChain + \".pssm\"\n",
        "    try:\n",
        "        fullPath = os.path.join(pssm_dir,fileName)\n",
        "        f = open(fullPath)\n",
        "    except:\n",
        "        fileName = pdbIdPlusChain[0:4].upper() + str(convertChainFromAlphabetToNumber(pdbIdPlusChain[4])) + \".pssm\" \n",
        "        fullPath = os.path.join(pssm_dir,fileName)\n",
        "        f = open(fullPath)\n",
        "        \n",
        "# #     all the target lines in the PSSM files have (2+20+20+2=44) strings after line.split()\n",
        "    target_lines = [line.split() for line in f.readlines() if (len(line.split()))==44]\n",
        "    number_of_residues = len(target_lines)\n",
        "    \n",
        "    pssm_features = np.zeros((number_of_residues,20))\n",
        "\n",
        "    for idx,line in enumerate(target_lines):\n",
        "        pssm_features[idx,:] = line[2:22]\n",
        "\n",
        "    f.close()\n",
        "    \n",
        "    return pssm_features\n",
        "\n",
        "# This function also seems necessary for extracting the two pssm values\n",
        "# Must review the three pssm feature functions (this one and the two above) later\n",
        "# These functions seem to be taking up a lot of time....must review\n",
        "def returnPSSMMapping(residue):\n",
        "    pssm_letter_to_index_dict = {\"A\" : 0,   \n",
        "    \"R\" : 1,\n",
        "    \"N\" : 2,\n",
        "    \"D\" : 3,\n",
        "    \"C\" : 4,\n",
        "    \"Q\" : 5,\n",
        "    \"E\" : 6,\n",
        "    \"G\" : 7,\n",
        "    \"H\" : 8,\n",
        "    \"I\" : 9,\n",
        "    \"L\" : 10,\n",
        "    \"K\" : 11,\n",
        "    \"M\" : 12,\n",
        "    \"F\" : 13,\n",
        "    \"P\" : 14,\n",
        "    \"S\" : 15,\n",
        "    \"T\" : 16,\n",
        "    \"W\" : 17,\n",
        "    \"Y\" : 18,\n",
        "    \"V\" : 19}\n",
        "\n",
        "    return pssm_letter_to_index_dict[residue]\n",
        "\n",
        "\n",
        "# I will add PSSM values to the two-level dictionary for places where log_prob is available\n",
        "pssmDirectory = \"/content/drive/MyDrive/ACCRE_PyRun_Setup/S_669_pssm_dir\"\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                wild = mut[\"mut\"][0] \n",
        "                alternate = mut[\"mut\"][-1]\n",
        "                sequence_index_of_mutation = cur_map_dict[mut[\"mut\"][0:-1]]\n",
        "                pdbId = prot[0:-1]\n",
        "                mutChain = prot[-1]\n",
        "                pssm_array = returnPSSMArray(pdbId + mutChain,pssm_dir=pssmDirectory,convert_upper = False)\n",
        "                position_pssm = pssm_array[sequence_index_of_mutation]\n",
        "                wild_pssm = position_pssm[returnPSSMMapping(wild)] \n",
        "                alternate_pssm = position_pssm[returnPSSMMapping(alternate)]\n",
        "                mut[\"wild_pssm\"] = wild_pssm\n",
        "                mut[\"alternate_pssm\"] = alternate_pssm"
      ],
      "metadata": {
        "id": "eBgpxQx4ispc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pssm_predictions = []\n",
        "for prot,muts in two_level_dict.items():\n",
        "    if prot not in proteins_to_skip:\n",
        "        try:\n",
        "            cur_map_dict = mapping_dict[prot]\n",
        "        except:\n",
        "            continue\n",
        "        for mut in muts:\n",
        "            # only fetching those mutations that have corresponding log-probabilities calculated and saved as values of \"log_prob\" key\n",
        "            if \"log_prob\" in mut:\n",
        "                pssm_predictions.append((mut[\"wild_pssm\"]-mut[\"alternate_pssm\"]))"
      ],
      "metadata": {
        "id": "xOkQhEQzn32m"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wild_energies = np.array(wild_energies)\n",
        "mut_energies = np.array(mut_energies)\n",
        "min_energies = np.array(min_energies)\n",
        "experimental_energies = np.array(experimental_energies)\n",
        "mut_wild_predictions = mut_energies - wild_energies\n",
        "mut_min_predictions = mut_energies - min_energies\n",
        "entropy_predictions = np.array(entropy_conservations)\n",
        "pssm_predictions = np.array(pssm_predictions)\n",
        "neighbor_entropy_predictions = np.array(neighbor_entropy_conservations)\n",
        "neighbor_energy_change_predictions = np.array(neighbor_energy_change_predictions)\n",
        "neighbor_forward_KL_predictions = np.array(weighted_neighbor_forward_KL)\n",
        "neighbor_backward_KL_predictions = np.array(weighted_neighbor_backward_KL)\n",
        "print(pearsonr(experimental_energies,mut_wild_predictions))\n",
        "print(pearsonr(experimental_energies,entropy_predictions))\n",
        "print(pearsonr(experimental_energies,pssm_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_entropy_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_energy_change_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_forward_KL_predictions))\n",
        "print(pearsonr(experimental_energies,neighbor_backward_KL_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tyw_4erpj1C",
        "outputId": "a998893a-99e1-4480-ac3c-b14a1c70b5bd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-0.3373037057197982, 1.9321879066377103e-18)\n",
            "(-0.25749585397443825, 4.031750517168691e-11)\n",
            "(-0.1760175004428737, 7.741516443498937e-06)\n",
            "(-0.011820516754941399, 0.7657067160204968)\n",
            "(-0.22545268699508497, 8.523944193143508e-09)\n",
            "(-0.3325158114007902, 6.1796126174309906e-18)\n",
            "(-0.34783936659571696, 1.391661299409247e-19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now combine \"mut_wild_predictions\" and \"pssm_predictions\" using weight combinations from 0 to 1 in 0.05 increments so that they some to one\n",
        "# so, when one weight is x, the other weight is automatically (1-x)\n",
        "# The keys of this dictionary will be (term1_coeff,term2_coeff) tuples, and values will be the observed correlations \n",
        "coefficient_result_dictionary = {}\n",
        "for i in np.arange(0.0,1.000001,0.005):\n",
        "    term1_coeff = round(i,2)\n",
        "    term2_coeff = round((1.000001 - i),2)\n",
        "    local_preds = (term1_coeff*mut_wild_predictions) + (term2_coeff*neighbor_energy_change_predictions)\n",
        "    coefficient_result_dictionary[(term1_coeff,term2_coeff)] = round(pearsonr(experimental_energies,local_preds)[0],2) "
      ],
      "metadata": {
        "id": "nP6x7ym_10QD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefficient_result_dictionary"
      ],
      "metadata": {
        "id": "fQ6lfx3VunPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coefficient_result_dictionary\n",
        "# (0.82, 0.18): 0.52,\n",
        "#  (0.82, 0.19): 0.51,\n",
        "#  (0.83, 0.17): 0.52,\n",
        "#  (0.84, 0.16): 0.52,\n",
        "#  (0.84, 0.17): 0.52,\n",
        "#  (0.85, 0.15): 0.52,\n",
        "#  (0.86, 0.14): 0.52,\n",
        "#  (0.86, 0.15): 0.52,\n",
        "#  (0.87, 0.13): 0.52,\n",
        "#  (0.88, 0.12): 0.52,\n",
        "#  (0.88, 0.13): 0.52,\n",
        "#  (0.89, 0.11): 0.52,\n",
        "#  (0.9, 0.1): 0.52,\n",
        "#  (0.9, 0.11): 0.52,\n",
        "#  (0.91, 0.09): 0.52,\n",
        "#  (0.92, 0.08): 0.52,\n",
        "#  (0.92, 0.09): 0.52,\n",
        "#  (0.93, 0.07): 0.52,\n",
        "#  (0.94, 0.06): 0.52,\n",
        "#  (0.94, 0.07): 0.52,\n",
        "#  (0.95, 0.05): 0.52,\n",
        "#  (0.96, 0.04): 0.52,\n",
        "# great thing since the decorrelation is actually interesting, and using both definitely seems to help"
      ],
      "metadata": {
        "id": "GZYSS4zz2CSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "methods = ['PMPNN_DEP','PMPNN_ET','PMPNN_DEP_ET','PSSM_DEC','PMPNN_DEP_PSSM_DEC']\n",
        "vals = [0.34,0.26,0.34,0.18,0.36]\n",
        "plt.ylabel(\"Pearson Correlation\",fontsize=18)\n",
        "plt.xlabel(\"Informative Features\",fontsize=18)\n",
        "plt.xticks(fontsize=18, rotation=90)\n",
        "plt.yticks(fontsize=18)\n",
        "plt.ylim(0.10,0.40)\n",
        "ax.bar(methods,vals,color=\"maroon\",width=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "sirQvLLnyerw",
        "outputId": "ff41bb46-8f82-453a-8b23-4146487e04c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "mut_wild_predictions = np.array(mut_energies - wild_energies)\n",
        "entropy_predictions = np.array(entropy_conservations)\n",
        "first_second_combined = 0.5*mut_wild_predictions + 0.5*entropy_predictions\n",
        "pssm_predictions = np.array(pssm_predictions)\n",
        "# first_pssm_combined = 0.89*mut_wild_predictions + 0.11*pssm_predictions\n",
        "neighbor_energy_change_predictions = np.array(neighbor_energy_change_predictions)\n",
        "neighbor_entropy_predictions = np.array(neighbor_entropy_predictions)\n",
        "neighbor_forward_KL_predictions = np.array(weighted_neighbor_forward_KL)\n",
        "neighbor_backward_KL_predictions = np.array(weighted_neighbor_backward_KL)\n",
        "\n",
        "df_Ssym = pd.DataFrame(\n",
        "    {'P_DP': mut_wild_predictions,\n",
        "     'P_ET': entropy_predictions,\n",
        "     'P_DP_ET':first_second_combined,\n",
        "     'P_DEC': pssm_predictions,\n",
        "    #  'PMPNN_DP_PSSM_DEC' : first_pssm_combined,\n",
        "     'Neighbor_Entropy' : neighbor_entropy_predictions,\n",
        "     'Neighbor_Energy_Change' : neighbor_energy_change_predictions,\n",
        "     'Neighbor_forward_KL' : neighbor_forward_KL_predictions,\n",
        "     'Neighbor_backward_KL' : neighbor_backward_KL_predictions \n",
        "    })\n",
        "corr = df_Ssym.corr()\n",
        "\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(corr, \n",
        "        xticklabels=corr.columns,\n",
        "        yticklabels=corr.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "QlQuGW7f7KDy",
        "outputId": "5eb023bb-69ee-4cee-b1df-5b43faa8bd24"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb7e20d3d90>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}